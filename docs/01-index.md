<details>
<summary>100. HW3 (presented by 謝宏祺, 朱柏澄, 蔡昀達)</summary><br>

<a href="https://www.youtube.com/watch?v=TR937eL1WLc" target="_blank">
    <img src="https://img.youtube.com/vi/TR937eL1WLc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>99. HW1 (presented by 劉俊緯, 吳宗翰)</summary><br>

<a href="https://www.youtube.com/watch?v=Lobg0qVR-y0" target="_blank">
    <img src="https://img.youtube.com/vi/Lobg0qVR-y0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>98. HW1 (presented by 毛弘仁, 王克安, 林哲賢)</summary><br>

<a href="https://www.youtube.com/watch?v=95hyyAMJieU" target="_blank">
    <img src="https://img.youtube.com/vi/95hyyAMJieU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>97. HW1 (presented by 黃文璁,蔡昕宇,許傑盛)</summary><br>

<a href="https://www.youtube.com/watch?v=LGAMeOgAwU4" target="_blank">
    <img src="https://img.youtube.com/vi/LGAMeOgAwU4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>96. DRL Lecture 6: Actor-Critic</summary><br>

<a href="https://www.youtube.com/watch?v=j82QLgfhFiY" target="_blank">
    <img src="https://img.youtube.com/vi/j82QLgfhFiY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>95. DRL Lecture 7: Sparse Reward</summary><br>

<a href="https://www.youtube.com/watch?v=-5cCWhu0OaM" target="_blank">
    <img src="https://img.youtube.com/vi/-5cCWhu0OaM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>94. DRL Lecture 5: Q-learning (Continuous Action)</summary><br>

<a href="https://www.youtube.com/watch?v=tnPVcec22cg" target="_blank">
    <img src="https://img.youtube.com/vi/tnPVcec22cg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>93. DRL Lecture 8: Imitation Learning</summary><br>

<a href="https://www.youtube.com/watch?v=rl_ozvqQUU8" target="_blank">
    <img src="https://img.youtube.com/vi/rl_ozvqQUU8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>92. DRL Lecture 2:  Proximal Policy Optimization (PPO)</summary><br>

<a href="https://www.youtube.com/watch?v=OAKAZhFmYoI" target="_blank">
    <img src="https://img.youtube.com/vi/OAKAZhFmYoI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>91. DRL Lecture 1: Policy Gradient (Review)</summary><br>

<a href="https://www.youtube.com/watch?v=z95ZYgPgXOY" target="_blank">
    <img src="https://img.youtube.com/vi/z95ZYgPgXOY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>90. DRL Lecture 3: Q-learning (Basic Idea)</summary><br>

<a href="https://www.youtube.com/watch?v=o_g9JUMw1Oc" target="_blank">
    <img src="https://img.youtube.com/vi/o_g9JUMw1Oc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>89. DRL Lecture 4: Q-learning (Advanced Tips)</summary><br>

<a href="https://www.youtube.com/watch?v=2-zGCx4iv_k" target="_blank">
    <img src="https://img.youtube.com/vi/2-zGCx4iv_k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>88. GAN Lecture 10 (2018): Evaluation & Concluding Remarks</summary><br>

<a href="https://www.youtube.com/watch?v=IB_ADssBomk" target="_blank">
    <img src="https://img.youtube.com/vi/IB_ADssBomk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>87. GAN Lecture 8 (2018): Photo Editing</summary><br>

<a href="https://www.youtube.com/watch?v=Lhs_Kphd0jg" target="_blank">
    <img src="https://img.youtube.com/vi/Lhs_Kphd0jg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>86. GAN Lecture 9 (2018): Sequence Generation</summary><br>

<a href="https://www.youtube.com/watch?v=Xb1x4ZgV6iM" target="_blank">
    <img src="https://img.youtube.com/vi/Xb1x4ZgV6iM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>85. GAN Lecture 6 (2018): WGAN, EBGAN</summary><br>

<a href="https://www.youtube.com/watch?v=3JP-xuBJsyc" target="_blank">
    <img src="https://img.youtube.com/vi/3JP-xuBJsyc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>84. GAN Lecture 3 (2018): Unsupervised Conditional Generation</summary><br>

<a href="https://www.youtube.com/watch?v=-3LgL3NXLtI" target="_blank">
    <img src="https://img.youtube.com/vi/-3LgL3NXLtI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>83. GAN Lecture 7 (2018): Info GAN, VAE-GAN, BiGAN</summary><br>

<a href="https://www.youtube.com/watch?v=sU5CG8Z0zgw" target="_blank">
    <img src="https://img.youtube.com/vi/sU5CG8Z0zgw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>82. GAN Lecture 1 (2018): Introduction</summary><br>

<a href="https://www.youtube.com/watch?v=DQNNMiAP5lw" target="_blank">
    <img src="https://img.youtube.com/vi/DQNNMiAP5lw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>81. GAN Lecture 2 (2018): Conditional Generation</summary><br>

<a href="https://www.youtube.com/watch?v=LpyL4nZSuqU" target="_blank">
    <img src="https://img.youtube.com/vi/LpyL4nZSuqU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>80. GAN Lecture 5 (2018): General Framework</summary><br>

<a href="https://www.youtube.com/watch?v=av1bqilLsyQ" target="_blank">
    <img src="https://img.youtube.com/vi/av1bqilLsyQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>79. GAN Lecture 4 (2018): Basic Theory</summary><br>

<a href="https://www.youtube.com/watch?v=DMA4MrNieWo" target="_blank">
    <img src="https://img.youtube.com/vi/DMA4MrNieWo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>78. Deep Learning Theory 3-2: Indicator of Generalization</summary><br>

<a href="https://www.youtube.com/watch?v=pivB5jEBOQw" target="_blank">
    <img src="https://img.youtube.com/vi/pivB5jEBOQw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>77. Deep Learning Theory 3-1: Generalization Capability of Deep Learning</summary><br>

<a href="https://www.youtube.com/watch?v=9dtxv4HLq_8" target="_blank">
    <img src="https://img.youtube.com/vi/9dtxv4HLq_8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>76. Deep Learning Theory 2-5: Geometry of Loss Surfaces (Empirical)</summary><br>

<a href="https://www.youtube.com/watch?v=XysGHdNOTbg" target="_blank">
    <img src="https://img.youtube.com/vi/XysGHdNOTbg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>75. Deep Learning Theory 2-2: Deep Linear Network</summary><br>

<a href="https://www.youtube.com/watch?v=0O6nYRC7GeY" target="_blank">
    <img src="https://img.youtube.com/vi/0O6nYRC7GeY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>74. Deep Learning Theory 2-4: Geometry of Loss Surfaces (Conjecture)</summary><br>

<a href="https://www.youtube.com/watch?v=_VuWvQUMQVk" target="_blank">
    <img src="https://img.youtube.com/vi/_VuWvQUMQVk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>73. Deep Learning Theory 2-3: Does Deep Network have Local Minima?</summary><br>

<a href="https://www.youtube.com/watch?v=NmelPQkUark" target="_blank">
    <img src="https://img.youtube.com/vi/NmelPQkUark/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>72. Deep Learning Theory 2-1: When Gradient is Zero</summary><br>

<a href="https://www.youtube.com/watch?v=XSdkBG6Vvr0" target="_blank">
    <img src="https://img.youtube.com/vi/XSdkBG6Vvr0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>71. [2018-03-09] Deep Learning Theory 1-3: Is Deep better than Shallow?</summary><br>

<a href="https://www.youtube.com/watch?v=qpuLxXrHQB4" target="_blank">
    <img src="https://img.youtube.com/vi/qpuLxXrHQB4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 文章重點整理

## 核心主題  
文章探討深度_learning_（Deep Learning）相對於淺層_learning_（Shallow Learning）在模型訓練和函數擬合方面的優勢，特別是在處理複雜 함수時的表現差異。

---

## 主要觀念  
1. **深度與淺層學習的對比**：  
   - 深度學習模型具有多個隱藏層，能夠捕獲數據中的高級特徵。  
   - 淺層學習模型通常只有一到兩層，擬合能力有限，特別是在處理非線性複雜 함수時表現不佳。  

2. **函數擬合能力**：  
   - 深度學習在擬合高度非線性和結構化的數據時具有顯著優勢。  
   - 淺層學習在簡單的線性或低複雜度函數上表現足夠，但面對高維或高曲率數據時效果有限。

3. **實驗結果**：  
   - 使用淺層網絡（如兩層）擬合球狀數據集時，無論寬度如何增加，模型性能改善不明顯。  
   - 深度網絡（如三層）即使在窄.Width下也能有效降低錯誤率。

---

## 問題原因  
1. **函數複雜性**：  
   - 淺層學習模型無法有效表達高維或高度非線性的數據結構，導致擬合能力受限。  

2. **模型容量限制**：  
   - 淺層網絡的深度不足，限制了其捕獲數據中多級特徵的能力。  

---

## 解決方法  
1. **增加網絡深度**：  
   - 使用更深的網絡架構（如三層及以上）來提高模型表達能力。  

2. **適當調整網絡寬度**：  
   - 在確保深度的前提下，合理設計網絡寬度以平衡計算資源和模型性能。  

3. **利用 compositional structure**：  
   - 針對具有 compositional（組合式）結構的函數，深度學習能更有效地表達其特性。  

---

## 結論  
1. 深度學習在擬合複雜函數時具備顯著優勢，尤其是在數據具有高維或高度非線性特性時。  
2. 淺層學習適合簡單的線性或低複雜度任務，但無法有效處理更複雜的數據模式。  
3. 深度學習模型的性能提升往往伴隨著深度的增加和適當的寬度設計。  

---

## 優化方式  
1. **網絡架構設計**：選擇合適的深度和.Width來平衡模型容量與計算效率。  
2. **數據特性分析**：根據數據的複雜性（如高維、曲率等）選擇適合的學習方法。  
3. **實驗驗證**：通過實驗驗證不同網絡架構在特定任務中的性能表現，以指導模型設計。  

--- 

以上為文章的核心內容整理，強調了深度學習在函數擬合方面的優越性及其應用條件。
</details>

<details>
<summary>70. [2018-03-09] Deep Learning Theory 1-2: Potential of Deep</summary><br>

<a href="https://www.youtube.com/watch?v=FN8jclCrqY0" target="_blank">
    <img src="https://img.youtube.com/vi/FN8jclCrqY0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 清理與分析文章重點

此篇文章主要探討深度學習（Deep Learning）與淺層學習（Shallow Learning）在函數擬合（Function Fitting）任務中的差異。文章通過具體案例與理論分析，展示了深度網絡在特定情況下的優勢，並引發對淺層網絡能力的反思。

---

### 核心主題

- **深度學習 vs. 樺層學習**  
  探討深度網絡與淺層網絡在函數擬合任務中的性能差異。
  
- **函數擬合問題**  
  研究如何通過不同架構的神經網絡來實現對特定函數（如二次函數）的逼近。

---

### 主要觀念

- **淺層網絡的局限性**  
  淺層網絡在擬合某些複雜函數時，需要大量的神經元（_neurons_），其數量與誤差呈反比關係。例如，在擬合 \( y = x^2 \) 的情況下，淺層網絡所需的神經元數量為 \( O(1/\sqrt{\epsilon}) \)，其中 \( \epsilon \) 是可接受的誤差。

- **深度網絡的優勢**  
  深度網絡通過多層疊加（_stacked layers_）的方式，能夠用更少的參數實現對同一函數的逼近。例如，在同樣的任務中，深度網絡所需的神經元數量為 \( O(\log(1/\sqrt{\epsilon})) \)，比淺層網絡效率更高。

- **理論與實踐的差距**  
  文章指出，上述分析主要是基於理論上的構造方法（_constructive methods_），並不代表實際訓練中淺層網絡的最佳性能。可能存在某些情況下，淺層網絡也能夠高效地完成任務。

---

### 問題原因

- **淺層網絡的能力限制**  
  淺層網絡在處理非線性函數時，需要大量的隱藏層（_hidden layers_）來逼近目標函數，這導致其參數需求量大，計算成本高。

- **深度網絡的 expressive power**  
  深度網絡通過多層疊加增強了表示能力（_expressive power_），能夠用更少的參數實現對複雜函數的擬合。

---

### 解決方法

- **理論分析**  
  通過信息論（_information theory_）與逼近論（_approximation theory_）等工具，分析不同網絡架構在函數擬合任務中的表現。

- **實驗驗證**  
  需要進一步的實驗來驗證淺層網絡在最佳狀態下是否能夠超越深度網絡。

---

### 優化方式

- **網絡架構優化**  
  設計更高效的 network architectures，如使用卷積神經網絡（_CNNs_）或圖 neural networks（_GNNs_），來進一步提升淺層網絡的性能。

- **訓練算法改進**  
  研究更有效的訓練方法（如遷移學習 _transfer learning_ 或自監督學習 _self-supervised learning_），以幫助淺層網絡更好地逼近目標函數。

---

### 結論

- **深度網絡的優越性**  
  在理論上，深度網絡在某些任務中能夠用更少的參數實現更高的精度。例如，在擬合二次函數的情況下，深度網絡所需的神經元數量比淺層網絡少得多。

- **淺層網絡的潛力**  
  雖然目前的分析顯示淺層網絡在某些情況下表現較差，但不能排除其在最佳訓練策略下的優異性能。未來的研究應該更加注重淺層網絡的最佳化與實際應用。

- **進一步研究方向**  
  接下來需要通過實驗來驗證淺層網絡在最佳狀態下的能力，並探索如何通過網絡架構與算法的改進來彌平深度與淺層網絡之間的性能差距。
</details>

<details>
<summary>69. Deep Learning Theory 1-1: Can shallow network fit any function?</summary><br>

<a href="https://www.youtube.com/watch?v=KKT2VkTdFyc" target="_blank">
    <img src="https://img.youtube.com/vi/KKT2VkTdFyc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>68. [2018-01-18] ML Lecture 23-3: Reinforcement Learning (including Q-learning)</summary><br>

<a href="https://www.youtube.com/watch?v=2-JNBzCq77c" target="_blank">
    <img src="https://img.youtube.com/vi/2-JNBzCq77c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 文章整理：Inverse Reinforcement Learning（逆向強化學習）及其應用

#### 一、核心主題
- **逆向強化學習**：通過觀察專家的行爲，推斷出獎勵函數，並指導智能體學習最優策略。
- **GAN類比**：將逆向強化學習與生成對抗網絡（GAN）進行類比，解釋其工作原理。

#### 二、主要觀念
1. **專家行爲的利用**：
   - 專家通過與環境互動產生軌跡（trajectory），這些軌跡反映了專家的決策策略。
2. **獎勵函數的學習**：
   - 獎勵函數的設計目標是使得專家的行爲得分高於智能體，類似於「先射箭，再畫靶」的過程。
3. **智能體的改進**：
   - 智能體基於學習到的獎勵函數不斷調整自身行爲，以最大化獎勵分數。

#### 三、問題原因
- **獎勵函數的缺失**：傳統強化學習需要明確的獎勵函數，但在許多實際場景中難以定義。
- **專家行爲的複雜性**：專家行爲可能涉及複雜的策略和決策過程，直接模擬或複製具有挑戰性。

#### 四、解決方法
1. **逆向強化學習框架**：
   - 通過觀察專家的行爲軌跡，推斷出獎勵函數。
2. **GAN類比的應用**：
   - 將智能體（actor）與生成器（generator）、獎勵函數與判別器（discriminator）進行對應，利用對抗訓練的方法改進智能體行爲。

#### 五、優化方式
1. **迭代優化**：
   - 不斷更新獎勵函數和智能體策略，使得智能體的行爲逐步逼近專家水平。
2. **反饋機制**：
   - 利用獎勵函數的反饋，指導智能體調整行爲，確保其得分低於專家。

#### 六、結論
- 逆向強化學習提供了一種有效的替代方法，特別是在無法明確定義獎勵函數的情況下。
- 通過與GAN的類比，展示了該方法在實際應用中的潛力和可行性。
- 結合專家行爲數據和迭代優化過程，可以有效提升智能體的學習效果。

#### 七、附錄
- **圖表建議**：
  - 添加GAN和逆向強化學習的工作流程圖，以清晰展示其相似性。
  - 添加伯克利研究團隊的實驗結果圖表，展示逆向強化學習在機器人行爲學習中的應用效果。
</details>

<details>
<summary>67. [2018-01-18] ML Lecture 23-2: Policy Gradient (Supplementary Explanation)</summary><br>

<a href="https://www.youtube.com/watch?v=y8UPGr36ccI" target="_blank">
    <img src="https://img.youtube.com/vi/y8UPGr36ccI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 文章重點整理

#### 核心主題
文章圍繞強化學習（Reinforcement Learning）中的策略梯度方法展開討論，特別是將強化學習問題轉化為分類問題進行處理的方式。

#### 主要觀念
1. **策略梯度方法**：通過最大化期望獎賞來更新策略網絡參數。
2. **分類問題的轉化**：將強化學習中的每個狀態-行動對視為一筆分類數據，並給其加權.reward(τⁿ)。
3. **批量訓練與在線訓練**：強調了強化學習中數據收集和模型訓練的反覆迭代特性。

#### 問題原因
1. **\data dependencies**: 狡猾的策略網絡可能過早鎖定優行動，影響探索效率。
2. **\data imbalance**: 不同獎賞值的數據對模型更新的影響不均衡。

#### 解決方法
1. **加權分類**：將每筆數據按其reward值進行加權，以反映其重要性。
2. **批量訓練**：定期收集數據後集中訓練模型，避免\data dependencies並提高學習效率。

#### 優化方式
1. **_reward weighting**: 根據獎勵值調整數據的影響力，確保高獎勵數據對模型更新起更大作用。
2. **_data augmentation**: 通過複製數據來增加低獎勵數據的代表性，平衡數據分布。

#### 理論支持
- **策略梯度**：利用概率梯度法最大化期望獎賞。
- **分類框架**：將強化學習問題重新表述為加權分類任務，借鑒分類算法進行處理。

#### 實現方法
1. **數據收集**: 在每一個_episode_中收集狀態和行動對，並記錄相應的_reward_值。
2. **數據加權**: 對每筆數據按照其_reward_值進行加權。
3. **模型訓練**: 使用加權數據批量訓練策略網絡，然後再利用更新後的網絡進行新一輪數據收集。

#### 結論
1. **方法可行性**：將強化學習問題轉化為分類問題是可行的，並且可以利用現有的深度學習框架（如Keras）實現。
2. **優勢**: 通過加權和批量訓練，可以有效提高策略網絡的學習效率和性能。
3. **挑戰**: 強化學習需要反覆迭代數據收集和模型訓練，這增加了計算開銷，但現代計算資源可以充分支撐其實現。

---

### 總結
文章提出了一種將強化學習問題轉化為加權分類問題的方法，詳細探討了其核心思想、實現步驟及優化策略。該方法利用現有深度學習框架，通過數據加權和批量訓練提高了學習效率，展示了強化學習在實際應用中的可行性和有效性。
</details>

<details>
<summary>66. GAN Lecture 4 (2017):  From A to Z</summary><br>

<a href="https://www.youtube.com/watch?v=dFwesaqC_Wo" target="_blank">
    <img src="https://img.youtube.com/vi/dFwesaqC_Wo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>65. GAN Lecture 3 (2017): Improving Sequence Generation by GAN</summary><br>

<a href="https://www.youtube.com/watch?v=Adi54-wp8Qk" target="_blank">
    <img src="https://img.youtube.com/vi/Adi54-wp8Qk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>64. GAN Lecture 2 (2017): CycleGAN</summary><br>

<a href="https://www.youtube.com/watch?v=9N_uOIPghuo" target="_blank">
    <img src="https://img.youtube.com/vi/9N_uOIPghuo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>63. GAN Lecture 1 (2017): Introduction of Generative Adversarial Network (GAN)</summary><br>

<a href="https://www.youtube.com/watch?v=G0dZc-8yIjE" target="_blank">
    <img src="https://img.youtube.com/vi/G0dZc-8yIjE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>62. SELU</summary><br>

<a href="https://www.youtube.com/watch?v=1WPjVpwJ88I" target="_blank">
    <img src="https://img.youtube.com/vi/1WPjVpwJ88I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>61. Tuning Hyperparameters</summary><br>

<a href="https://www.youtube.com/watch?v=kyX29rUntjM" target="_blank">
    <img src="https://img.youtube.com/vi/kyX29rUntjM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>60. Interesting things about deep learning</summary><br>

<a href="https://www.youtube.com/watch?v=1KElr75pHdQ" target="_blank">
    <img src="https://img.youtube.com/vi/1KElr75pHdQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>59. Batch Normalization</summary><br>

<a href="https://www.youtube.com/watch?v=BZh1ltr5Rkg" target="_blank">
    <img src="https://img.youtube.com/vi/BZh1ltr5Rkg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>58. [2017-11-18] ML Lecture 9-3: Fizz Buzz in Tensorflow (sequel)</summary><br>

<a href="https://www.youtube.com/watch?v=F1vek6ULo9w" target="_blank">
    <img src="https://img.youtube.com/vi/F1vek6ULo9w/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 核心主題
- 人工智慧在Fizz Buzz問題上的應用。
- 探討深度學習模型在模式識別任務中的表現。

### 主要觀念
1. **硬訓練（Hard Training）**：指將看似不能訓練的任務通過訓練方法來實現。
2. **Fizz Buzz задача**：一個簡單的程式問題，要求根據數字的整除性輸出特定字符串。
3. **深度學習模型**：使用TensorFlow和神經網絡架構解決Fizz Buzz問題。

### 問題原因
- 原始模型（10個輸入單元、100個隱藏層單元）在訓練集上的準確率僅爲76%，未能有效擬合數據。
- 模型的容量不足，無法充分學習複雜的模式。

### 解決方法
1. **增加網絡容量**：將隱藏層單元數從100增加到1000，提升模型的學習能力。
2. **調整訓練參數**：使用Adam優化器和Softmax激活函數，確保模型能夠更好地擬合數據。

### 優化方式
- 通過增加網絡層數或單元數來提高模型的複雜度，使其能夠捕捉更細微的數據特徵。
- 使用適當的訓練策略（如交叉驗證）進一步優化模型性能。

### 結論
1. **初始模型表現有限**：原始深度學習模型在處理Fizz Buzz問題時表現出較低的準確率，表明其結構可能過於簡單。
2. **網絡容量的重要性**：通過增加隱藏層單元數，模型能夠顯著提升準確率至100%，證明了網絡容量對任務適應性的影響。
3. **深度學習的有效性**：儘管看似簡單的任務可以通過複雜的模型解決，但選擇合適的架構和參數是關鍵。

### 參考資料
- 文章提供了一個使用TensorFlow實現的簡單神經網絡結構，展示了如何通過調整模型結構來提高性能。
</details>

<details>
<summary>57. Pointer Network</summary><br>

<a href="https://www.youtube.com/watch?v=VdOyqNQ9aww" target="_blank">
    <img src="https://img.youtube.com/vi/VdOyqNQ9aww/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>56. [2017-11-18] ML Lecture 22: Ensemble</summary><br>

<a href="https://www.youtube.com/watch?v=tH9FH1DH5n0" target="_blank">
    <img src="https://img.youtube.com/vi/tH9FH1DH5n0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 文章整理： ensemble methods in machine learning

#### 1. 核心主題
- **Ensemble Learning**: 利用多個學習器（模型）的集體智慧來提升整體性能。
- **STACKING、BOOSTING、BAGGING**等集成技術在機器學習中的應用。

#### 2. 主要觀念
- **STACKING (堆疊)**:
  - 將多個基模型的輸出作為高級模型的輸入，形成分層結構。
  - 基模型可以是任何類型的學習器，如 Decision Trees、Neural Networks 等。
  - 最後一層通常使用簡單的分類器（如 Logistic Regression）來整合各基模型的結果。

- **BOOSTING**:
  - 通過迭代提升弱學習器的性能，最終形成強大learner。
  - 每次迭代根據前一次分類錯誤的樣本調整權重，逐步改進模型。
  - Adaboost 是一種常見的Boosting算法。

- **BAGGING (包裝)**:
  - 使用_bootstrapping_技術生成多個訓練數據集，並基於每個數據集訓練一個基模型。
  - 最後通過投票或平均的方式來決定最終結果。
  - 主要用於降低過度擬合和提升模型的泛化能力。

#### 3. 問題與挑戰
- **Base Learners 的性能**:
  - 基模型可能存在性能差異，甚至有些模型可能表現不佳或完全失效。
  
- **數據分配問題**:
  - 在STACKING中，若基模型過度擬合訓練數據，可能影響最終分類器的性能。

#### 4. 解決方法與優化方式
- **STACKING 的改進**:
  - 將訓練數據集分為多個部分，一部分用於訓練基模型，另一部分用於訓練最終的整合分類器。
  - 這樣可以避免最終分類器過度依賴基模型的性能。

- **BOOSTING 的優化**:
  - 確定適當的學習速率（learning rate）和弱learner數量，防止模型過度擬合。
  - 使用正規化技術來控制模型複雜度。

- **BAGGING 的改進**:
  - 增加訓練數據集的多樣性，確保每個基模型都能夠捕獲不同的特徵信息。
  - 結合其他集成方法（如STACKING）進一步提升性能。

#### 5. 啟發與結論
- **Adaboost 的啟示**:
  - Adaboost 可以被看作是一種Gradient Descent算法，通過反覆調整模型權重來最優化解題。
  
- **STACKING 的實用性**:
  - 在多團隊或多模型的情況下，STACKING 可以有效整合各個模型的結果，提升整體性能。
  
- **ensemble方法的靈活性**:
  - 集成學習方法具有高度的靈活性，可以根據不同的任務和數據特性進行調整和優化。

#### 6. 總結
Ensemble Learning 是機器學習中一項重要的技術，通過將多個基模型的結果整合起來，往往能夠顯著提升模型的性能和泛化能力。STACKING、BOOSTING 和 BAGGING 分別從不同角度提供了有效的集成方案，而 Adaboost 則展示了如何通過.gradient descent的方式來優化ensemble模型。STACKING 的實用性在於它可以有效地整合各個模型的結果，特別是在團隊合作或多模型的情況下，這對於提升最終性能具有重要意義。
</details>

<details>
<summary>55. Gated RNN and Sequence Generation (Recorded at Fall, 2017)</summary><br>

<a href="https://www.youtube.com/watch?v=T8mGfIy9dWM" target="_blank">
    <img src="https://img.youtube.com/vi/T8mGfIy9dWM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>54. [2017-10-20] ML Lecture 9-2: Keras Demo 2</summary><br>

<a href="https://www.youtube.com/watch?v=Ky1ku1miDow" target="_blank">
    <img src="https://img.youtube.com/vi/Ky1ku1miDow/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 核心主題：人工智慧模型在MNIST數據集上的訓練與優化

---

#### 主要觀念：
1. **模型結構**：使用簡單的神經網路結構（如多層感知機）來處理MNIST手寫數字分類任務。
2. **數據特性**：MNIST數據集具有平衡且清潔的特徵，適合用於示範基本的人工智慧技術。
3. **性能指標**：模型在訓練集和測試集上的正確率用於評估其泛化能力。

---

#### 問題原因：
1. **過度擬合（Overfitting）**：模型在訓練數據上表現極佳，但在測試數據上性能大幅下降。
2. **不平衡的訓練與測試性能**：訓練集和測試集之間存在性能 mismatch，表明模型缺乏泛化能力。

---

#### 解決方法：
1. **正規化技術（Dropout）**：
   - 在隱藏層後加入_dropout_層，以降低過度擬合的可能性。
   - Dropout rate設置為0.7，用於限制_neurons_的相關性並提升模型的泛化能力。

2. **優化算法（AdamOptimizer）**：
   - 使用Adam優化器加速訓練過程，提高學習效率。
   - 相對於常規SGD，Adam在訓練初期階段顯著提升了性能。

3. **數據增強（加入Noise）**：
   - 在測試數據上故意添加隨機噪聲，用於模擬真實世界中的數據不確定性。
   - 通過此方法評估模型的魯棒性。

---

#### 優化方式：
1. **學習率調整**：在訓練過程中動態調整 learning rate，以平衡收斂速度和穩定性。
2. **	layer size 設計**：適當增加隱藏層大小，提升模型 capacity。
3. **批量規範化（Batch Normalization）**：在某些情況下可進一步優化模型性能。

---

#### 結論：
1. 適當引入_dropout_技術可以有效降低過度擬合，但會稍微影響訓練過程中的性能。
2. 使用Adam優化器顯著提升了training efficiency和model generalizability。
3. 模型在加入_noise_後的測試數據上表現有所提升，但仍需進一步優化以達到更好的 robustness。

---

#### 總結：
本文通過實驗展示了多種常見的人工智慧技術在MNIST分類任務中的應用效果。結果表明，結合_dropout_、AdamOptimizer和數據增強等方法可以有效改善模型性能，但依然需要根據具體任務需求進一步調優。
</details>

<details>
<summary>53. [2017-10-19] ML Lecture 8-2: Keras 2.0</summary><br>

<a href="https://www.youtube.com/watch?v=5BJDJd-dzzg" target="_blank">
    <img src="https://img.youtube.com/vi/5BJDJd-dzzg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 小節歸納

#### 核心主題
- 神經網路在手寫數字辨識中的應用。
- 使用 Keras 搭建和訓練神經網路模型。

#### 主要觀念
1. **模型結構**：
   - 使用多層感知機（MLP）架構，包含輸入層、隱藏層和輸出層。
   - 輸入層接受 784 維向量（28x28 圖像），輸出層有 10 個神經元對應 0-9 的數字。

2. **訓練過程**：
   - 使用訓練數據（training data）進行模型訓練。
   - 訓練目標是使模型學習到將 입력向量映射到正確的數字標籤。

3. **數據表示**：
   - 輸入數據為一維向量，大小為 (number of examples, 784)。
   - 標籤數據為獨熱編碼（one-hot encoding），大小為 (number of examples, 10)，每個樣本只有一個位置為 1，對應其數字類別。

#### 問題原因
- 手寫數字辨識需要模型學習複雜的圖像特徵。
- 需要確保模型能夠有效地從數據中提取這些特徵並分類。

#### 解決方法
1. **模型設計**：
   - 選擇合適的神經網路架構，如多層感知機（MLP）。
   - 使用適當的激活函數（如ReLU）和損失函數（如交叉熵損失）。

2. **數據預處理**：
   - 將圖像展平為一維向量。
   - 將標籤轉換為獨熱編碼格式以適應模型輸出。

3. **訓練與評估**：
   - 使用訓練數據進行模型訓練，並定期評估模型在測試數據上的表現。
   - 通過損失值和 accuracy 等指標來衡量模型性能。

#### 優化方式
1. **超參數調優**：
   - 選擇合適的學習率（learning rate）。
   - 調整神經網路層數和 neurons 數量以優化模型性能。

2. **正則化技術**：
   - 使用正規化或dropout來防止過度擬合。

3. **數據增強**：
   - 對訓練數據進行 augmentation（如旋轉、翻轉）以增加數據多樣性，提升模型泛化能力。

#### 結論
- 通過適當的模型設計和數據處理，神經網路能夠有效完成手寫數字辨識任務。
- 模型在訓練後可以儲存起來，用於實際應用中的預測。
- 使用evaluation和predict功能可分別評估模型性能和進行線上預測。
</details>

<details>
<summary>52. [2017-10-15] ML Lecture 8-3: Keras Demo</summary><br>

<a href="https://www.youtube.com/watch?v=L8unuZNpWw8" target="_blank">
    <img src="https://img.youtube.com/vi/L8unuZNpWw8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 文章整理：人工智慧深度學習入門與挑戰

## 核心主題
- **深度學習入門**：文章主要介紹了深度學習的基本概念和應用，特別是通過手寫數字辨識的簡單案例來展示深度學習的實際操作。
- **Keras框架簡介**：使用Keras框架搭建神經網路模型，強調其易用性和快速開發的特點。

## 主要觀念
1. **深度學習的核心價值**：
   - 深度學習適合處理大型數據集和複雜模式識別任務。
   - 通過多層神經網路結構，能夠自動提取高級特徵。

2. **Keras框架優勢**：
   - 簡單易用：提供高級API，降低深度學習門檻。
   - 快速開發：適合快速原型設計和 experimentation。

3. **手寫數字辨識案例**：
   - 使用MNIST數據集進行訓練和評估。
   - 展示了模型搭建、訓練和評價的基本流程。

## 問題原因
1. **初學者常見挑戰**：
   - 模型表現不佳：最初模型的驗證accuracy僅為10%，接近隨機猜測水平。
   - 網路結構設計不合理：初始模型深度不足，層數過少。
   - 調參困難：學習率、:hidden_units等超參數選擇不當。

2. **常見錯誤與局限**：
   - 忽略正則化：導致模型過擬合或欠擬合。
   - 網路結構設計不合理：層數不足，影響模型表達能力。
   - 評估方法不科學：未使用交叉驗證等更可靠的評估值。

## 解決方法
1. **改善網路結構**：
   - 增加隱藏層數，提升模型深度。
   - 使用Batch Normalization等技術優化訓練過程。

2. **合理調參**：
   - 選擇適當的學習率和(hidden_units)。
   - 引入Dropout等正則化方法防止過擬合。

3. **科學評估**：
   - 使用交叉驗證等更可靠的模型評估值。
   - 仔細分析損失函數變化，確保模型訓練效果。

## 結論
1. **深度學習的潛力與挑戰**：
   - 深度學習在模式識別領域具有巨大潛力。
   - 初學者需要克服技術門檻和實踐經驗不足等困難。

2. **持續改進建議**：
   - 開始於簡單案例，逐步掌握核心概念。
   - 多進行 experimentation，累積調參經驗。
   - 學習更先進的模型架構和訓練技巧。

3. **未來學習方向**：
   - 探索更複雜的模型結構，如卷積神經網路（CNN）。
   - 學習深度學習的理論基礎，如Optimizer、Activation Function等。
   - 練習實際項目，提升問題分析和解決能力。
</details>

<details>
<summary>51. ML Lecture 0-2: Why we need to learn machine learning?</summary><br>

<a href="https://www.youtube.com/watch?v=On1N8u1z2Ng" target="_blank">
    <img src="https://img.youtube.com/vi/On1N8u1z2Ng/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

