<details>
<summary>201. Network Compression (5/6)</summary><br>

<a href="https://www.youtube.com/watch?v=L0TOXlNpCJ8" target="_blank">
    <img src="https://img.youtube.com/vi/L0TOXlNpCJ8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Network Compression (5/6)


</details>

<details>
<summary>202. Network Compression (6/6)</summary><br>

<a href="https://www.youtube.com/watch?v=f0rOMyZSZi4" target="_blank">
    <img src="https://img.youtube.com/vi/f0rOMyZSZi4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Network Compression (6/6)


</details>

<details>
<summary>203. GAN (Quick Review)</summary><br>

<a href="https://www.youtube.com/watch?v=ufcKFjdpT98" target="_blank">
    <img src="https://img.youtube.com/vi/ufcKFjdpT98/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# GAN (Quick Review)


</details>

<details>
<summary>204. Transformer</summary><br>

<a href="https://www.youtube.com/watch?v=ugWDIIOHtPA" target="_blank">
    <img src="https://img.youtube.com/vi/ugWDIIOHtPA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Transformer


</details>

<details>
<summary>205. Meta Learning - Train+Test as RNN</summary><br>

<a href="https://www.youtube.com/watch?v=ePimv_k-H24" target="_blank">
    <img src="https://img.youtube.com/vi/ePimv_k-H24/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Meta Learning - Train+Test as RNN


</details>

<details>
<summary>206. ELMO, BERT, GPT</summary><br>

<a href="https://www.youtube.com/watch?v=UYPa347-DdE" target="_blank">
    <img src="https://img.youtube.com/vi/UYPa347-DdE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# ELMO, BERT, GPT


</details>

<details>
<summary>207. Flow-based  Generative Model</summary><br>

<a href="https://www.youtube.com/watch?v=uXY18nzdSsM" target="_blank">
    <img src="https://img.youtube.com/vi/uXY18nzdSsM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Flow-based  Generative Model


</details>

<details>
<summary>208. Machine Learning (2020): Course Introduction</summary><br>

<a href="https://www.youtube.com/watch?v=c9TwBeWAj_U" target="_blank">
    <img src="https://img.youtube.com/vi/c9TwBeWAj_U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# Machine Learning (2020): Course Introduction


</details>

<details>
<summary>209. [DLHLP 2020] Speech Recognition (1/7) - Overview</summary><br>

<a href="https://www.youtube.com/watch?v=AIKu43goh-8" target="_blank">
    <img src="https://img.youtube.com/vi/AIKu43goh-8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Recognition (1/7) - Overview


</details>

<details>
<summary>210. [DLHLP 2020] Deep Learning for Human Language Processing (Course Overview)</summary><br>

<a href="https://www.youtube.com/watch?v=nER51ZyJaCQ" target="_blank">
    <img src="https://img.youtube.com/vi/nER51ZyJaCQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Human Language Processing (Course Overview)


</details>

<details>
<summary>211. [DLHLP 2020] Speech Recognition (2/7) - Listen, Attend, Spell</summary><br>

<a href="https://www.youtube.com/watch?v=BdUeBa6NbXA" target="_blank">
    <img src="https://img.youtube.com/vi/BdUeBa6NbXA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Recognition (2/7) - Listen, Attend, Spell


</details>

<details>
<summary>212. [DLHLP 2020] Speech Recognition (3/7) - CTC, RNN-T and more</summary><br>

<a href="https://www.youtube.com/watch?v=CGuLuBaLIeI" target="_blank">
    <img src="https://img.youtube.com/vi/CGuLuBaLIeI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Recognition (3/7) - CTC, RNN-T and more


</details>

<details>
<summary>213. [DLHLP 2020] Speech Recognition (4/7) - HMM (optional)</summary><br>

<a href="https://www.youtube.com/watch?v=XWTGY_PNABo" target="_blank">
    <img src="https://img.youtube.com/vi/XWTGY_PNABo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Recognition (4/7) - HMM (optional)


</details>

<details>
<summary>214. [DLHLP 2020] Speech Recognition (5/7) - Alignment of HMM, CTC and RNN-T (optional)</summary><br>

<a href="https://www.youtube.com/watch?v=5SSVra6IJY4" target="_blank">
    <img src="https://img.youtube.com/vi/5SSVra6IJY4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Recognition (5/7) - Alignment of HMM, CTC and RNN-T (optional)


</details>

<details>
<summary>215. [DLHLP 2020] Speech Recognition (6/7) - RNN-T Training  (optional)</summary><br>

<a href="https://www.youtube.com/watch?v=L519dCHUCog" target="_blank">
    <img src="https://img.youtube.com/vi/L519dCHUCog/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Recognition (6/7) - RNN-T Training  (optional)


</details>

<details>
<summary>216. [DLHLP 2020] Speech Recognition (7/7) - Language Modeling</summary><br>

<a href="https://www.youtube.com/watch?v=dymfkWtVUdo" target="_blank">
    <img src="https://img.youtube.com/vi/dymfkWtVUdo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Recognition (7/7) - Language Modeling


</details>

<details>
<summary>217. [DLHLP 2020] Voice Conversion (1/2) - Feature Disentangle</summary><br>

<a href="https://www.youtube.com/watch?v=Jj6blc8UijY" target="_blank">
    <img src="https://img.youtube.com/vi/Jj6blc8UijY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Voice Conversion (1/2) - Feature Disentangle


</details>

<details>
<summary>218. [2020-03-26] [TA 補充課] Graph Neural Network (1/2) (由助教姜成翰同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=eybCCtNKwzA" target="_blank">
    <img src="https://img.youtube.com/vi/eybCCtNKwzA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Graph Neural Network (1/2) (由助教姜成翰同學講授)

### 本文重點整理

#### 核心主題
文章主要探討圖神經網路（Graph Neural Networks, GNNs）中 aggregation 操作的核心思想及其不同實現方法。並分析了各種 aggregation 技術的優缺點以及適用場景。

---

#### 主要觀念
1. **Aggregation 操作的重要性**  
   Aggregation 是 GNN 中用於將鄰居節點的特徵信息聚合起來，以更新當前節點表示的核心操作。
   
2. **常見的 Aggregation 方法**  
   - **Mean Pooling**：簡單平均鄰居特徵。  
   - **Max Pooling**：取鄰居特徵的最大值。  
   - **Sum Pooling**：將鄰居特徵相加。  
   - **Attention Mechanism**：基於注意力機制的加權聚合。  

3. **Recent Developments**  
   最近的研究（如 Graph Isomorphism Network,GIN）提出，使用合適的 aggregation 方法可以顯著提升模型性能。

---

#### 問題原因
1. **Mean Pooling 的缺點**  
   - 無法區分具有相同鄰居特徵但結構不同的圖。  

2. **Max Pooling 的缺點**  
   - 可能忽略較小但重要的特徵值，導致信息丟失。  

3. **傳統 Aggregation 方法的局限性**  
   - 離散的聚合方式可能無法充分捕捉到圖結構中的細緻變化。

---

#### 解決方法
1. **GIN 的創新**  
   GIN 提出使用 aggregation 操作後再加上一個 multi-layer perceptron (MLP)，以學習更加豐富的表徵信息。具體公式如下：  
   $$ h_v^{(k+1)} = \text{AGGREGATE}(\{h_u^{(k)}\}_{u \in \mathcal{N}(v)}, h_v^{(k)}) $$  

2. **注意力機制的優化**  
   - 基於鄰居特徵計算注意力權重，實現動態聚合。  
   - 公式：  
     $$ \alpha_{uv} = \text{softmax}(e(h_u, h_v)) $$  
     $$ h_v^{(k+1)} = \sum_{u \in \mathcal{N}(v)} \alpha_{uv} h_u^{(k)} $$  

3. **Sum Pooling 的優勢**  
   - 使用鄰居特徵的簡單相加，避免平均和最大操作的局限性。  

---

#### 結論
1. **GIN 的理論意義**  
   GIN 提供了 aggregation 操作的理論基礎，證明了合適的聚合方式可以顯著提升模型在圖結構數據上的表現。

2. **未來研究方向**  
   - 探索更加高效的注意力機制。  
   - 研究不同聚合方法在特定應用場景下的最佳匹配。  

3. **實踐建議**  
   - 在實際應用中，根據具體任務需求選擇合適的 aggregation 方法。  
   - GIN 提供了一種簡單而有效的聚合方式，值得進一步探索和適用。

---

以上為文章的主要內容整理，涵蓋了核心思想、主要觀念、問題分析及解決方案等關鍵點。
</details>

<details>
<summary>219. [2020-03-26] [TA 補充課] Graph Neural Network (2/2) (由助教姜成翰同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=M9ht8vsVEw8" target="_blank">
    <img src="https://img.youtube.com/vi/M9ht8vsVEw8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Graph Neural Network (2/2) (由助教姜成翰同學講授)

### 核心主題
- **圖神經網路（Graph Neural Networks, GNNs）**：研究如何將圖結構數據引入深度學習模型中，進行各種任務如分類、聚類等。

### 主要觀念
1. **圖神經網路的基本概念**：
   - **圖結構數據**：由節點和邊組成的數據結構，反映實體之間的關係。
   - **圖神經網路的目的**：將非結構化或結構化的圖數據轉換為可學習的表示。

2. **GNN的主要方法**：
   - **基於空間的方法**（Spatial-based）：如GAT（Graph Attention Networks），直接在圖的節點上進行操作。
   - **基於光譜的方法**（Spectral-based）：如GCN（Graph Convolutional Networks），通過傅裏葉變換將圖數據轉化為頻域進行處理。

3. **主要任務**：
   - **監督分類（Supervised Classification）**：在部分或完全標註的數據上訓練模型。
   - **半監督分類（Semi-supervised Classification）**：利用少量標註數據和大量未標註數據進行學習。
   - **圖生成（Graph Generation）**：使用VAE、GAN等方法從頭生成符合特定分布的圖數據。

### 問題原因
1. **GCN的局限性**：
   - **疊代深度增加的性能下降**：隨著模型深度的增加，性能反而惡化。
   - **過平滑現象（Over-smoothing）**：多次聚合操作後，節點表示趨於相似，導致信息喪失。

2. **GNN訓練中的挑戰**：
   - **圖數據的多樣性**：不同類型的圖數據可能需要不同的模型結構。
   - **計算複雜度高**：處理大型圖數據時，計算資源需求較高。

### 解決方法
1. **GCN性能提升**：
   - **DropEdge技術**：在聚合鄰居節點特徵時，隨機丟失一些邊，防止過平滑現象。
   
2. **模型優化**：
   - **使用注意力機制（Attention Mechanism）**：如GAT，根據不同鄰居的重要性分配權重。
   - **引入殘差連接（Residual Connections）**：在深度網絡中，將某層的輸出直接傳遞到淺層，防止梯度消失。

3. **圖生成模型改進**：
   - **Auto-regressive模型**：逐步生成節點和邊，提高生成的可控性。
   - **混合 GenerationTypechniques**：結合VAE和GAN優勢，提升生成數據的多樣性和真實性。

### 結論
- **GNN的研究意義**：作為一種有效的處理結構化數據的方法，在社交網絡、生物信息學等領域有廣泛應用。
- **未來研究方向**：
   - 探索更高效的圖聚合操作。
   - 研究圖神經網路與其他深度學習技術（如Transformer）的結合。
   - 開發適合大規模圖數據的並行計算方法。

### 其他
- **教育意義**：了解GNN的基本原理和應用場景，對於處理複雜實體關係問題具有重要啟示。
</details>

<details>
<summary>220. [DLHLP 2020] Voice Conversion (2/2) - CycleGAN and StarGAN</summary><br>

<a href="https://www.youtube.com/watch?v=JUWVuF2ucTk" target="_blank">
    <img src="https://img.youtube.com/vi/JUWVuF2ucTk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Voice Conversion (2/2) - CycleGAN and StarGAN


</details>

<details>
<summary>221. [DLHLP 2020] Speech Separation (1/2) - Deep Clustering, PIT</summary><br>

<a href="https://www.youtube.com/watch?v=tovg5ZxNgIo" target="_blank">
    <img src="https://img.youtube.com/vi/tovg5ZxNgIo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Separation (1/2) - Deep Clustering, PIT


</details>

<details>
<summary>222. PyTorch Tutorial (由助教劉記良同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=kQeezFrNoOg" target="_blank">
    <img src="https://img.youtube.com/vi/kQeezFrNoOg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# PyTorch Tutorial (由助教劉記良同學講授)


</details>

<details>
<summary>223. [2020-04-09] [TA 補充課] Optimization for Deep Learning (1/2) (由助教簡仲明同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=4pUmZ8hXlHM" target="_blank">
    <img src="https://img.youtube.com/vi/4pUmZ8hXlHM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Optimization for Deep Learning (1/2) (由助教簡仲明同學講授)

### 文章整理：SGD 收斂性改進方法研究

#### 1. 核心主題
- **研究目標**：探討隨機梯度下降（Stochastic Gradient Descent, SGD）算法在深度學習中的收斂性問題，提出改進方法以提升其性能和效率。

#### 2. 主要觀念
- **SGD的基本原理**：SGD是一種常用優化算法，通過隨機採樣訓練數據來更新模型參數，具有計算效率高、內存佔用低的優點。
- **SGD的局限性**：
  - 學習率（Learning Rate, LR）的選擇對收斂速度和結果影響顯著。
  - 易陷入局部最優解，缺乏探索能力。
  - 在複雜的優化landscape中表現不穩定。

#### 3. 問題原因
- **學習率選擇不當**：過大的學習率可能導致模型發散，過小的學習率則會降低收斂速度。
- **優化landscape的複雜性**：深度神經網絡的損失函數 landscape 存在多個局部最優解和鞍點，SGD容易陷入其中。
- **缺乏動態調整機制**：固定學習率無法適應不同階段的優化需求。

#### 4. 解決方法
- **自適應學習率方法**：
  - **Adam優化器**：通過計算梯度的一階矩和二階矩估計來動態調整學習率，具有良好的收斂性和穩定性。
  - **Adagrad**：根據參數梯度的歷史信息自適應地調整學習率。
  - **RMSprop**：基於梯度的平方平均值來調整學習率。

- **周期性學習率方法**：
  - **Cyclical Learning Rate (CLR)**：通過周期性地增加和減少學習率，幫助模型在局部最優解之間進行探索。
  - **One-Cycle Learning Rate**：在一個周期內先增大後減小學習率，以實現快速收斂。

- **學習率範圍測試（LR Range Test）**：
  - 通過實驗確定合適的學習率範圍，避免手動調參的盲目性。

#### 5. 優化方式
- **動態調整機制**：引入自適應算法，根據梯度信息動態調節學習率。
- **探索與收斂結合**：利用周期性變化的學習率，在局部最優解附近進行細緻搜索的同時，保持一定的探索能力。
- **預熱階段（Warm-Up）**：在訓練初期逐漸增加學習率，幫助模型平穩進入優化狀態。

#### 6. 結論
- **研究意義**：改進的SGD算法能夠顯著提升深度神經網絡的訓練效率和收斂質量。
- **未來方向**：
  - 結合多種優化方法，進一步提高算法的通用性和魯棒性。
  - 探索更高效的自適應學習率調整策略。
</details>

<details>
<summary>224. [2020-04-09] [TA 補充課] Optimization for Deep Learning (2/2) (由助教簡仲明同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=e03YKGHXnL8" target="_blank">
    <img src="https://img.youtube.com/vi/e03YKGHXnL8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Optimization for Deep Learning (2/2) (由助教簡仲明同學講授)

### 小節一：核心主題
- 探討深度學習中優化器（Optimizer）的選擇與應用。
- 分析不同優化器在不同任務中的表現及其適用場景。

### 小節二：主要觀念
1. **SGD 與 Momentum SGD (SGDM)**：
   - SGD 是最基本的優化器，但收斂速度較慢且容易陷入鞍點。
   - Momentum SGD 引入動量機制，加速收斂並改善梯度下降的穩定性。

2. **Adam 優化器**：
   - 結合了 AdaGrad 和 RMSprop 的優點，自適應調整學習率。
   - 在大多數深度學習任務中表現優異，尤其在 NLP 領域。

3. **AdamW**：
   - Adam 的改進版本，通過引入權重衰減機制提升模型的泛化能力。

4. **Lookahead 策略**：
   - 一種優化器封裝策略，結合其他優化器（如 SGD 或 Adam）進一步提升性能。

### 小節三：問題原因
1. **SGD 的局限性**：
   - 收斂速度慢，容易陷入局部最優。
   - 對初始學習率敏感，難以處理複雜的損失函數 landscapes。

2. **Adam 的潛在問題**：
   - 在某些 CV 任務中可能不如 SGDM 穩定。
   - 可能導致模型在測試集上的表現不佳（generalization gap）。

3. **數據與架構的影響**：
   - 數據質量問題或網絡架構不合理可能導致優化器選擇無法解決的根本性問題。

### 小節四：解決方法
1. **選擇合適的優化器**：
   - CV 任務優先考慮 SGDM。
   - NLP 和生成模型推薦使用 Adam 或 AdamW。

2. **調整學習率與權重衰減**：
   - 使用適當的學習率調度策略（如餘弦退火）。
   - 在 AdamW 等優化器中引入權重衰減以提升泛化能力。

3. **結合 Lookahead 策略**：
   - 將 Lookahead 與其他優化器結合，進一步優化訓練效果。

4. **多嘗試與調整**：
   - 根據具體任務需求，多次實驗並調整優化器參數和策略。

### 小節五：優化方式
1. **學習率調度（Learning Rate Scheduling）**：
   - 使用如餘弦退火等方法動態調整學習率，加速收斂並提升模型性能。

2. **權重衰減（Weight Decay）**：
   - 在優化器中引入 L2 正則化，防止過擬合，提升泛化能力。

3. **動量機制（Momentum）**：
   - 通過引入動量，加速梯度下降過程，避免陷入鞍點。

4. **自適應學習率調整（Adaptive Learning Rate）**：
   - Adam 等優化器通過自適應調整學習率，提升訓練效率和穩定性。

### 小節六：結論
- 沒有一款 optimizer 是萬能的，選擇合適的優化器需根據具體任務需求。
- SGD 和 SGDM 在 CV 任務中表現較好，而 Adam 和 AdamW 更適合 NLP 和生成模型。
- Lookahead 策略可作爲提升訓練效果的輔助手段。
- 雖然優化器的選擇對性能有一定影響，但數據質量和網絡架構才是模型性能的關鍵因素。
</details>

<details>
<summary>225. [DLHLP 2020] Speech Synthesis (1/2) - Tacotron</summary><br>

<a href="https://www.youtube.com/watch?v=DMxKeHW8KdM" target="_blank">
    <img src="https://img.youtube.com/vi/DMxKeHW8KdM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Synthesis (1/2) - Tacotron


</details>

<details>
<summary>226. [DLHLP 2020] Speech Separation (2/2) - TasNet</summary><br>

<a href="https://www.youtube.com/watch?v=G0O1A7lONSY" target="_blank">
    <img src="https://img.youtube.com/vi/G0O1A7lONSY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Separation (2/2) - TasNet


</details>

<details>
<summary>227. [DLHLP 2020] Speaker Verification</summary><br>

<a href="https://www.youtube.com/watch?v=z3yvxvyP-lE" target="_blank">
    <img src="https://img.youtube.com/vi/z3yvxvyP-lE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speaker Verification


</details>

<details>
<summary>228. [TA 補充課] More about Explainable AI (由助教楊書文同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=LsdiOt0wiWM" target="_blank">
    <img src="https://img.youtube.com/vi/LsdiOt0wiWM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Explainable AI (由助教楊書文同學講授)


</details>

<details>
<summary>229. [DLHLP 2020] Speech Synthesis (2/2) - More than Tacotron</summary><br>

<a href="https://www.youtube.com/watch?v=Eau1Fr2x86Y" target="_blank">
    <img src="https://img.youtube.com/vi/Eau1Fr2x86Y/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Speech Synthesis (2/2) - More than Tacotron


</details>

<details>
<summary>230. [2020-04-20] [TA 補充課] More about Adversarial Attack (2/2) (由助教黃冠博同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=PaHhMlxFPyU" target="_blank">
    <img src="https://img.youtube.com/vi/PaHhMlxFPyU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Adversarial Attack (2/2) (由助教黃冠博同學講授)

# 文章重點整理

## 核心主題
文章主要探討了深度學習模型在音視覺領域中的安全問題，並介紹了針對音視覺模型的攻擊方法。這些攻擊包括影像攻擊（如One Pixel Attack）和音訊攻擊（如Hidden Voice Attack），旨在揭示模型的脆弱性。

---

## 主要觀念

### 1. 影像攻擊
- **核心思想**：通過少量修改（如一像素更改）來擾亂深度學習模型的判斷。
- **技術實現**：
  - 使用差分進化算法搜索最有效的攻擊像素。
  - 確定攻擊像素後，計算其RGB值以最大化模型誤判機率。

### 2. 音訊攻擊
- **核心思想**：在音訊中植入幹擾信號（如高頻正弦波），使模型無法準確識別內容。
- **技術實現**：
  - **Time Domain Inversion**：反轉音訊的時域特性。
  - **Random Phase Generation**：隨機修改音訊的相位。
  - **High Frequency Addition**：添加高頻正弦波擾動。
  - **Time Scaling**：改變音訊的速度，同時保持採樣率恆定。

---

## 問題原因
- 深度學習模型對輸入數據的高度敏感性導致其易受攻擊。
- 音視覺模型在處理結構化數據時的脆弱性為攻擊提供了可乘之機。

---

## 解決方法
- **影晌_Attack**：
  - 差分進化算法用於搜索最小幹擾下的最大影響像素。
  - 確定攻擊像素後，計算其RGB值以最大化模型誤判機率。

- **音訊_Attack**：
  - 添加高頻正弦波或修改音訊特性（如相位、速度）來擾亂模型。
  - 確保添加的幹擾在預處理階段被濾除，使模型保持穩定性。

---

## 優化方式
- **影晌_Attack**：
  - 開發更高效的搜索算法以降低計算成本。
  - 提高攻擊策略的通用性，使其適用於不同類型的深度學習模型。

- **音訊_Attack**：
  - 研究更隱蔽的幹擾方式，使其不易被人類感知。
  - 警告：濫用此技術可能對用戶體驗造成影響，需注意倫理問題。

---

## 結論
文章展示了深度學習模型在音視覺領域中的脆弱性，並提出了多種攻擊方法。這些方法可幫助研究者理解模型的局限性，從而在未來的研究中進一步改進模型的安全性和 robustness。
</details>

<details>
<summary>231. [2020-04-20] [TA 補充課] More about Adversarial Attack (1/2) (由助教黃冠博同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=tfpKIZIWidA" target="_blank">
    <img src="https://img.youtube.com/vi/tfpKIZIWidA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Adversarial Attack (1/2) (由助教黃冠博同學講授)

### 小節一：核心主題  
- 文章介紹了差分進化（Differential Evolution, DE）算法及其在單像素攻擊（One Pixel Attack）中的應用。  
- 重點討論了DE算法的基本原理、實現步驟以及其在圖像對抗攻擊中的具體應用。

### 小節二：主要觀念  
1. **差分進化算法**  
   - DE是一種基於羣體的優化算法，通過迭代搜索來找到最優解。  
   - 主要步驟包括初始化種羣、變異、交叉和選擇。  
2. **單像素攻擊**  
   - 一種圖像對抗攻擊方法，僅修改一個像素即可實現對目標模型的攻擊。  
   - 攻擊目標是欺騙分類器，使其誤判圖像類別。

### 小節三：問題原因  
1. **算法適用性問題**  
   - DE算法最初設計用於連續空間優化，需適應其在離散和高維空間中的應用。  
2. **單像素攻擊的限制**  
   - 僅修改一個像素，增加了搜索空間的難度，且可能影響攻擊的成功率。  
3. **圖片大小的影響**  
   - 圖片越大，搜索空間越大，DE算法在固定迭代次數下成功率下降。

### 小節四：解決方法  
1. **適應DE算法到單像素攻擊**  
   - 將DE應用於五維向量（x, y, r, g, b），分別表示攻擊的像素坐標及顏色值。  
2. **優化搜索策略**  
   - 通過調整變異和交叉參數，提高種羣多樣性。  
3. **平衡圖片大小與資源**  
   - 在大圖片中增加迭代次數或候選數量，以提高攻擊成功率。

### 小節五：優化方式  
1. **參數調整**  
   - 調整DE算法的變異因子和交叉概率，以適應不同問題。  
2. **局部搜索增強**  
   - 結合其他優化方法（如梯度下降）進行局部精煉，提高解的質量。  
3. **資源分配策略**  
   - 根據圖片大小動態調整候選數量或迭代次數，確保攻擊效率。

### 小節六：結論  
- 差分進化算法在單像素攻擊中表現出良好的效果，但需根據具體問題進行參數和策略的優化。  
- 圖片大小對攻擊成功率有顯著影響，需通過增加資源投入來應對大尺寸圖片的挑戰。  
- 未來研究可進一步探索DE與其他優化方法的結合，提升攻擊效率和成功率。
</details>

<details>
<summary>232. [DLHLP 2020] Vocoder (由助教許博竣同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=6g2aPc0ol2Y" target="_blank">
    <img src="https://img.youtube.com/vi/6g2aPc0ol2Y/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Vocoder (由助教許博竣同學講授)


</details>

<details>
<summary>233. [DLHLP 2020] Overview of NLP Tasks</summary><br>

<a href="https://www.youtube.com/watch?v=tFBrqPPxWzE" target="_blank">
    <img src="https://img.youtube.com/vi/tFBrqPPxWzE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Overview of NLP Tasks


</details>

<details>
<summary>234. [DLHLP 2020] BERT and its family - Introduction and Fine-tune</summary><br>

<a href="https://www.youtube.com/watch?v=1_gRK9EIQpc" target="_blank">
    <img src="https://img.youtube.com/vi/1_gRK9EIQpc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] BERT and its family - Introduction and Fine-tune


</details>

<details>
<summary>235. [2020-05-03] [ICASSP 2020] TOWARDS UNSUPERVISED SPEECH RECOGNITION AND SYNTHESIS (Speaker: Tao Tu)</summary><br>

<a href="https://www.youtube.com/watch?v=cnZdfLSqwiE" target="_blank">
    <img src="https://img.youtube.com/vi/cnZdfLSqwiE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] TOWARDS UNSUPERVISED SPEECH RECOGNITION AND SYNTHESIS (Speaker: Tao Tu)

### 文章整理：基於共享表徵的語音自監督學習框架

---

#### 核心主題  
本文提出了一種基於共享表徵的語音自我監督學習架構，旨在 simultaneou 語音重建、語音識別和文本到語音合成（TTS）。該方法利用少量帶標籤數據和多部分訓練目標來提升模型性能。

---

#### 主要觀念  
1. **共享表徵架構**：(encoder 和 decoder 共享同一對稱表示，橋接重建、識別和合成模塊。)  
2. **三重_training 設計**：
   - **重建部分**：無需標籤數據，學習語音表示。
   - **識別部分**：使用CTC損失，將表徵與音素對齊。
   - **合成部分**：使用少量標籤數據،訓練.decoder 將離散表徵轉換為語音。  
3. **多模塊協作**：重建、識別和合成模塊通過共享表徵實現相互提升。

---

#### 問題分析  
1. **數據匱乏問題**：文本到語音合成傳統方法依賴大量帶標籤數據，限制了實用性。  
2. **孤立學習問題**：傳統模型的重建、識別和合成模塊缺乏共享表徵，導致性能瓶頸。

---

#### 解決方案  
1. **提出共享表徵架構**：(encoder 和 decoder 共享同一對稱表示，實現多模塊協作。)  
2. **三重_training 框架**：
   - 利用無標籤數據進行語音重建。
   - 使用少量帶標籤數據訓練語音識別和合成模塊。
3. **橋接重建與合成**：通過共享表徵，將語音重建與文本到語音合成有機結合。

---

#### 優化方式  
1. **自監督學習**：利用無標籤數據進行語音重建，降低對帶標籤數據的依賴。  
2. **多任務學習**：三重訓練目標（重建、識別、合成）共同提升模型性能。  
3. **共享表徵設計**：通過(encoder-decoder)共用表徵，實現模塊之間的相互增益。

---

#### 結論與實驗結果  
1. **表示能力**：
   - t-SNE 證據表示在 IPA 元音圖上與 linguistic 知識一致。
2. **語音識別性能**：
   - 在不同標籤數據量下，模型性能超越基準模型。
3. **語音合成質量**：
   - 使用少量標籤數據（20 分鐘），生成語音的MLS指標接近上限。
4. **實時演示效果**：
   - 模型在語音識別和文本到語音合成任務中表現出色，與真值高度一致。

---

#### 未來方向  
1. **擴展數據集**：進一步驗證模型在多說話人或多語言環境下的性能。  
2. **優化架構設計**：探索更高效的共享表徵結構。  
3. **提升合成質量**：研究如何利用更多語音特徵（如情感、語調）進一步提高合成效果。

---

### 總結  
本文提出了一種基於共享表徵的語音自我監督學習框架，同時實現語音重建、識別和合成。通過三重_training 和模塊協作，該方法在數據匱乏的情況下取得了優異的性能，為自監督學習在語音領域的應用提供了新思路。
</details>

<details>
<summary>236. [2020-05-03] [ICASSP 2020] META LEARNING FOR END-TO-END LOW-RESOURCE SPEECH RECOGNITION (Speaker: Jui-Yang Hsu)</summary><br>

<a href="https://www.youtube.com/watch?v=goav0eXKPwg" target="_blank">
    <img src="https://img.youtube.com/vi/goav0eXKPwg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] META LEARNING FOR END-TO-END LOW-RESOURCE SPEECH RECOGNITION (Speaker: Jui-Yang Hsu)

### 文章整理與分析

---

#### **1. 核心主題**
本文圍繞**多語種自動語音識別（ASR）模型的跨語言遷移學習**展開研究，重點探討如何利用來源語言數據提升目標語言的性能，特別是在資源受限的情況下。

---

#### **2. 主要觀念**
- **多語種ASR模型**：通過訓練一個能夠處理多種語言的模型，實現跨語言遷移學習。
- **SOURCE LANGUAGE AND TARGET LANGUAGE PAIRS (SLTPs)**：來源語言和目標語言對的研究是核心，用於驗證不同語言之間的遷移效果。
- **LIMITED LANGUAGE PACK (LLP) 和 FULL LANGUAGE PACK (FLP)**：研究中使用了兩種數據集，分別代表資源受限和資源充足的場景。

---

#### **3. 問題與原因分析**
- **問題**：在資源匱乏的情況下（如目標語言只有少量數據），ASR模型的性能受限。
- **原因**：
  - 少數語言的數據不足，導致模型訓練效果差。
  - 多語種模型的遷移能力未被充分驗證。

---

#### **4. 解決方法**
- **多語種訓練策略**：利用來源語言（如 Bengali, Tagalog, Zulu）的豐富數據，訓練一個多語種ASR模型，然後將其遷移到目標語言。
- **META-SOCKET TRAINING APPROACH (MSTA)**：一種改進的訓練方法，考慮到適應過程中的潛在優化，提升遷移效果。
- **跨語言遷移學習**：通過來源語言和目標language pairs的研究，驗證模型的遷移能力。

---

#### **5. 優化方式**
- **數據資源利用**：
  - 使用FULL LANGUAGE PACK (FLP) 和LIMITED LANGUAGE PACK (LLP) 過多語言對進行訓練。
  - 對LLP進行交叉驗證，提升模型的泛化能力。
- **性能評估指標**：
  - 使用字符錯誤率（Character Error Rate, CER）作為主要評估指標。
  - 測試遷移學習的效果，降低過擬合風險。

---

#### **6. 結論**
- **實驗結果**：
  - META-SOCKET TRAINING APPROACH (MSTA) 的性能優於隨機初始化（Random Initialization），字符錯誤率更低。
  - 對來源語言和目標語言對的遷移效果進行了多種測試，結果一致顯示MSTA的效果更佳。
- **未來工作**：
  - 延伸研究更多語言對，提升模型的 robustness。
  - 探索更多應用場景，如文本到語音合成（Text-to-Speech, TTS）等。

---

#### **7. 總結**
本文提出了一種基於多語種ASR模型的跨語言遷移學習方法，並通過實驗驗證了其有效性。研究結果表明，META-SOCKET TRAINING APPROACH (MSTA) 能顯著提升目標語言的性能，特別是在資源匱乏的情況下。此方法具有廣泛的應用潛力，可進一步優化以應對更多多樣化的語言場景。
</details>

<details>
<summary>237. [2020-05-03] [ICASSP 2020] WHAT DOES A NETWORK LAYER HEAR? (Speaker: Chung-Yi Li)</summary><br>

<a href="https://www.youtube.com/watch?v=6gtn7H-pWr8" target="_blank">
    <img src="https://img.youtube.com/vi/6gtn7H-pWr8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] WHAT DOES A NETWORK LAYER HEAR? (Speaker: Chung-Yi Li)

# 文章重點整理

## 核心主題
- 提出一種分析語音恢復（Speech Recognition, SR）的新方法，通過探查模型的隱藏狀態來了解模型行為。
- 方法具有模型agnostic性，適用於不同類型的模型架構。

## 主要觀念
1. **問題焦點**：語音恢復模型在處理Noise corrupted audio時的能力與限制，特別是對話音特徵（如Prosody和韻律）的影響。
2. **探查隱藏狀態的作用**：通過分析不同層次的隱藏狀態，揭示模型如何逐層提取和消除信息，特別是語音特徵和Noise。

## 啟發與方法
- 使用生成的語音片段來模擬真實場景，並利用Speaker Verification指標（如ER）來衡量模型性能。
- 通過STOI（Short Time Objective Intelligibility）評估恢復語音的可懂度，量化 distortion 的影響。

## 問題原因
1. **語音特徵的逐層消除**：模型在深度學習過程中，Prosody和韻律等語音特徵逐漸被削弱或移除。
2. **Noise對Baseline模型的幹擾**：在低信噪比（SNR）環境下，基線模型無法有效抑制Noise，導致語音恢復效果差。

## 解決方法與優化
1. **提出新分析框架**：
   - 採用探查隱藏狀態的方式，提供直觀的模型行為洞察。
   - 方法具備通用性，可廣泛應用於不同模型架構。
2. **改進語音恢復能力**：
   - 開發Noise-Robust SR模型，提升在 noisy 環境中的性能。
   - 通過STOI測量揭示modelo的局限性，為未來研究提供方向。

## 測試與結果
1. **語音特徵保留度**：
   - CN部分：主要負責頻譜提取，保留語音信息，但未顯著影響Prosody和韻律。
   - TCN層：Prosody逐漸被削弱，導致Speaker Verification指標ER值上升。
2. **Noise抑制能力**：
   - Noise-Robust模型在低SNR條件下表現 superior，Noise被有效消除。
   - 基線模型在高Noise幹擾下性能下降明顯。

## 結論
- 提出的探查隱藏狀態方法為理解SR模型提供新視角，具有重要研究價值。
- Noise-Robust SR模型在實際應用中展現出更好的 robustness 和性能。
- 未來研究可進一步優化模型架構，提升語音特徵保留和Noise抑制能力。
</details>

<details>
<summary>238. [ICASSP 2020] ONE-SHOT VOICE CONVERSION BY VECTOR QUANTIZATION (Speaker: Da-Yi Wu)</summary><br>

<a href="https://www.youtube.com/watch?v=W3t8FHgV90M" target="_blank">
    <img src="https://img.youtube.com/vi/W3t8FHgV90M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] ONE-SHOT VOICE CONVERSION BY VECTOR QUANTIZATION (Speaker: Da-Yi Wu)


</details>

<details>
<summary>239. [ICASSP 2020] MOCKINGJAY: UNSUPERVISED SPEECH REPRESENTATION LEARNING (Speaker: Andy T. Liu)</summary><br>

<a href="https://www.youtube.com/watch?v=JlOSyRNFjOw" target="_blank">
    <img src="https://img.youtube.com/vi/JlOSyRNFjOw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] MOCKINGJAY: UNSUPERVISED SPEECH REPRESENTATION LEARNING (Speaker: Andy T. Liu)


</details>

<details>
<summary>240. [ICASSP 2020] Defense against adversarial attacks on spoofing countermeasures (Speaker: Haibin Wu)</summary><br>

<a href="https://www.youtube.com/watch?v=sKwz5GvxGgI" target="_blank">
    <img src="https://img.youtube.com/vi/sKwz5GvxGgI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] Defense against adversarial attacks on spoofing countermeasures (Speaker: Haibin Wu)


</details>

<details>
<summary>241. [ICASSP 2020] ASR WITH WORD EMBEDDING REGULARIZATION AND FUSED DECODING (Speaker: Alexander H. Liu)</summary><br>

<a href="https://www.youtube.com/watch?v=1j46kdawA4Q" target="_blank">
    <img src="https://img.youtube.com/vi/1j46kdawA4Q/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] ASR WITH WORD EMBEDDING REGULARIZATION AND FUSED DECODING (Speaker: Alexander H. Liu)


</details>

<details>
<summary>242. [ICASSP 2020] INTERRUPTED AND CASCADED PIT FOR SPEECH SEPARATION (Speaker: Gene-Ping Yang)</summary><br>

<a href="https://www.youtube.com/watch?v=RUhkc6ihyYI" target="_blank">
    <img src="https://img.youtube.com/vi/RUhkc6ihyYI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] INTERRUPTED AND CASCADED PIT FOR SPEECH SEPARATION (Speaker: Gene-Ping Yang)


</details>

<details>
<summary>243. [ICASSP 2020] TRAINING CODE-SWITCHING LANGUAGE MODEL WITH MONOLINGUAL DATA (Speaker: Shun-Po Chuang)</summary><br>

<a href="https://www.youtube.com/watch?v=qf0j0A0-SVM" target="_blank">
    <img src="https://img.youtube.com/vi/qf0j0A0-SVM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICASSP 2020] TRAINING CODE-SWITCHING LANGUAGE MODEL WITH MONOLINGUAL DATA (Speaker: Shun-Po Chuang)


</details>

<details>
<summary>244. [DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more</summary><br>

<a href="https://www.youtube.com/watch?v=Bywo7m6ySlk" target="_blank">
    <img src="https://img.youtube.com/vi/Bywo7m6ySlk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] BERT and its family - ELMo, BERT, GPT, XLNet, MASS, BART, UniLM, ELECTRA, and more


</details>

<details>
<summary>245. [TA 補充課] Transformer and its variant (由助教紀伯翰同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=lluMBz5AoOg" target="_blank">
    <img src="https://img.youtube.com/vi/lluMBz5AoOg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Transformer and its variant (由助教紀伯翰同學講授)


</details>

<details>
<summary>246. [ICLR 2020] Language Modeling for Lifelong Language Learning (Speaker: Fan-Keng Sun)</summary><br>

<a href="https://www.youtube.com/watch?v=cW04Sb02lU4" target="_blank">
    <img src="https://img.youtube.com/vi/cW04Sb02lU4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ICLR 2020] Language Modeling for Lifelong Language Learning (Speaker: Fan-Keng Sun)


</details>

<details>
<summary>247. [DLHLP 2020] Non-Autoregressive Sequence Generation (由助教莊永松同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=jvyKmU4OM3c" target="_blank">
    <img src="https://img.youtube.com/vi/jvyKmU4OM3c/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Non-Autoregressive Sequence Generation (由助教莊永松同學講授)


</details>

<details>
<summary>248. [TA 補充課] Network Compression (2/2): Network Pruning (由助教劉俊緯同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=w6gdV2_PtsE" target="_blank">
    <img src="https://img.youtube.com/vi/w6gdV2_PtsE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Network Compression (2/2): Network Pruning (由助教劉俊緯同學講授)


</details>

<details>
<summary>249. [TA 補充課] Network Compression (1/2): Knowledge Distillation (由助教劉俊緯同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=9CCn9uPfJ64" target="_blank">
    <img src="https://img.youtube.com/vi/9CCn9uPfJ64/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Network Compression (1/2): Knowledge Distillation (由助教劉俊緯同學講授)


</details>

<details>
<summary>250. [DLHLP 2020] Text Style Transfer and Unsupervised Summarization/Translation/Speech Recognition</summary><br>

<a href="https://www.youtube.com/watch?v=WROBoprE0js" target="_blank">
    <img src="https://img.youtube.com/vi/WROBoprE0js/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Text Style Transfer and Unsupervised Summarization/Translation/Speech Recognition


</details>

