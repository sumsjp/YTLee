<details>
<summary>251. [DLHLP 2020] Deep Learning for Coreference Resolution</summary><br>

<a href="https://www.youtube.com/watch?v=2BemmceHKOU" target="_blank">
    <img src="https://img.youtube.com/vi/2BemmceHKOU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Coreference Resolution


</details>

<details>
<summary>252. [TA 補充課] SAGAN, BigGAN, SinGAN, GauGAN, GANILLA, NICE-GAN (由助教吳宗翰同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=hTNE8iFXEMU" target="_blank">
    <img src="https://img.youtube.com/vi/hTNE8iFXEMU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] SAGAN, BigGAN, SinGAN, GauGAN, GANILLA, NICE-GAN (由助教吳宗翰同學講授)


</details>

<details>
<summary>253. [DLHLP 2020] Deep Learning for Constituency Parsing</summary><br>

<a href="https://www.youtube.com/watch?v=pHQ2lcDgoFs" target="_blank">
    <img src="https://img.youtube.com/vi/pHQ2lcDgoFs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Constituency Parsing


</details>

<details>
<summary>254. [TA 補充課] More about Anomaly Detection (由助教林政豪同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=-C8RUrWb7F8" target="_blank">
    <img src="https://img.youtube.com/vi/-C8RUrWb7F8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Anomaly Detection (由助教林政豪同學講授)


</details>

<details>
<summary>255. [TA 補充課] More about Domain Adaptation (1/2) (由助教趙崇皓同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=gvfLq4sPW4k" target="_blank">
    <img src="https://img.youtube.com/vi/gvfLq4sPW4k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Domain Adaptation (1/2) (由助教趙崇皓同學講授)


</details>

<details>
<summary>256. [TA 補充課] More about Domain Adaptation (2/2) (由助教楊晟甫同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=-DQBMAULXX8" target="_blank">
    <img src="https://img.youtube.com/vi/-DQBMAULXX8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Domain Adaptation (2/2) (由助教楊晟甫同學講授)


</details>

<details>
<summary>257. [TA 補充課] Self-supervised Learning (由助教劉記良同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=ZGnKfoUb7h8" target="_blank">
    <img src="https://img.youtube.com/vi/ZGnKfoUb7h8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Self-supervised Learning (由助教劉記良同學講授)


</details>

<details>
<summary>258. [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (1/2)</summary><br>

<a href="https://www.youtube.com/watch?v=QBbeIsiqw-U" target="_blank">
    <img src="https://img.youtube.com/vi/QBbeIsiqw-U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (1/2)


</details>

<details>
<summary>259. [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=w0-7BO09kdo" target="_blank">
    <img src="https://img.youtube.com/vi/w0-7BO09kdo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (2/2)


</details>

<details>
<summary>260. [DLHLP 2020] Multilingual BERT</summary><br>

<a href="https://www.youtube.com/watch?v=8rDN1jUI82g" target="_blank">
    <img src="https://img.youtube.com/vi/8rDN1jUI82g/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Multilingual BERT


</details>

<details>
<summary>261. [DLHLP 2020] Deep Learning for Dependency Parsing</summary><br>

<a href="https://www.youtube.com/watch?v=9erBrs-VIqc" target="_blank">
    <img src="https://img.youtube.com/vi/9erBrs-VIqc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Dependency Parsing


</details>

<details>
<summary>262. [DLHLP 2020] Deep Learning for Question Answering (1/2) (重新上傳)</summary><br>

<a href="https://www.youtube.com/watch?v=gRfTfXCe3LA" target="_blank">
    <img src="https://img.youtube.com/vi/gRfTfXCe3LA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Question Answering (1/2) (重新上傳)


</details>

<details>
<summary>263. [DLHLP 2020] Audio BERT (1/2) (由助教劉廷緯同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=NN9Q9Jhtvvg" target="_blank">
    <img src="https://img.youtube.com/vi/NN9Q9Jhtvvg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Audio BERT (1/2) (由助教劉廷緯同學講授)


</details>

<details>
<summary>264. [DLHLP 2020] Audio BERT (2/2) (由助教紀伯翰同學和助教楊書文同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=0KNvAYb1emQ" target="_blank">
    <img src="https://img.youtube.com/vi/0KNvAYb1emQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Audio BERT (2/2) (由助教紀伯翰同學和助教楊書文同學講授)


</details>

<details>
<summary>265. [DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3</summary><br>

<a href="https://www.youtube.com/watch?v=DOG1L9lvsDY" target="_blank">
    <img src="https://img.youtube.com/vi/DOG1L9lvsDY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3


</details>

<details>
<summary>266. [DLHLP 2020] Deep Learning for Question Answering (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=h_Lptoq8spQ" target="_blank">
    <img src="https://img.youtube.com/vi/h_Lptoq8spQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Question Answering (2/2)


</details>

<details>
<summary>267. [TA 補充課] RL - Model-based, Large-scale, Meta, Multi-agent, Hide-and-seek, Alpha Star (由助教林義聖同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=ZR2AZgupIpc" target="_blank">
    <img src="https://img.youtube.com/vi/ZR2AZgupIpc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] RL - Model-based, Large-scale, Meta, Multi-agent, Hide-and-seek, Alpha Star (由助教林義聖同學講授)


</details>

<details>
<summary>268. [DLHLP 2020] Controllable Chatbot</summary><br>

<a href="https://www.youtube.com/watch?v=mk6v2raVGfk" target="_blank">
    <img src="https://img.youtube.com/vi/mk6v2raVGfk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Controllable Chatbot


</details>

<details>
<summary>269. [TA 補充課] More about Lifelong Learning (由助教楊舒涵同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=SX6_1-mvkWk" target="_blank">
    <img src="https://img.youtube.com/vi/SX6_1-mvkWk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Lifelong Learning (由助教楊舒涵同學講授)


</details>

<details>
<summary>270. [DLHLP 2020] Dialogue State Tracking (as Question Answering)</summary><br>

<a href="https://www.youtube.com/watch?v=tRDF_w700Uw" target="_blank">
    <img src="https://img.youtube.com/vi/tRDF_w700Uw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Dialogue State Tracking (as Question Answering)


</details>

<details>
<summary>271. [2020-07-15] [ACL 2020] Worse WER, but Better BLEU? (Speaker: Shun-Po Chuang)</summary><br>

<a href="https://www.youtube.com/watch?v=OybkIdSNKSc" target="_blank">
    <img src="https://img.youtube.com/vi/OybkIdSNKSc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ACL 2020] Worse WER, but Better BLEU? (Speaker: Shun-Po Chuang)

# 文章整理與結構化分析

## 核心主題  
- 語音翻譯（Speech Translation, ST）：研究如何將來源語言的語音轉換為目標語言的文字。  
- 多任務學習在語音翻譯中的應用：探討語音識別和翻譯之間的關聯性，特別是.semantic information的重要性。  

---

## 主要觀念  
1. **多任務學習（Multi-task Learning）**：在同一模型中同時學習語音識別和翻譯任務。  
2. **藍分數（BLEU Score）和字錯率（Word Error Rate,WER）**：分別用於衡量翻譯質量和語音識別質量，但二者之間並無直接 correlation。  
3. **語義信息的重要性**： semantic information可能比純粹的語音識別質量更影響最終翻譯質量。  

---

## 問題與原因  
1. **問題**：傳統的WER指標無法充分反映語音翻譯模型的性能，因為高WER的結果可能在語義上更接近 ground truth。  
   - 原因：WER主要衡量字面級別的相似性，忽略了semantic context的重要性。  
2. **挑戰**：多任務學習中，如何有效整合語音識別和翻譯模塊，提升整體性能。  

---

## 解決方法  
1. **引入Word Embeddings（詞嵌入）**：利用預訓練的詞嵌入（如WordNet或大型文本數據訓練的向量），捕獲 semantic 和 syntactic信息。  
2. **.semantic Information的利用**：在多任務模型中，將hidden state與word embeddings進行相似度計算，作為語義信息的參考。  
3. **Cosine Similarity**：使用.Cosine similarity衡量hidden state和word embeddings之間的相似性，並通過Softmax函數得到概率分佈。  

---

## 優化方式  
1. **模型結構**：提出一種三元組結構（Encoder-Decoder架構），讓源語言解碼器和目標語言解碼器共享隱藏狀態（hidden state）。  
2. **訓練目標**：改進原來的多任務損失函數，引入cosine相似度作為語義信息的衡量指標。  
3. **數據需求**：使用單語文本數據訓練word embeddings，降低對平行語料庫的依賴。  

---

## 結論與實驗結果  
1. **翻譯質量提升**：使用cosine softmax方法後，BLEU分數顯著提高，表明語義信息在翻譯中起重要作用。  
2. **WER的局限性**：低WER並不總是對應高翻譯質量，語義信息的融入能更好地平衡兩者。  
3. **模型性能**：提出的多任務模型在BLEU分數和WER指標上均達到最佳效果，證明了semantic information的有效性。  

---

## 展望  
- 進一步研究如何更有效地整合語音識別和翻譯模塊，提升多語言環境下的語音翻譯性能。  
- 探索其他semantic信息捕獲方式（如使用更大規模的 pretrained models）。
</details>

<details>
<summary>272. [線性代數] 這門課在學什麼？</summary><br>

<a href="https://www.youtube.com/watch?v=SNT7LAGsLDY" target="_blank">
    <img src="https://img.youtube.com/vi/SNT7LAGsLDY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 這門課在學什麼？


</details>

<details>
<summary>273. [線性代數] 線性代數 vs. 電機系其他必修課</summary><br>

<a href="https://www.youtube.com/watch?v=sc7dicXFoZE" target="_blank">
    <img src="https://img.youtube.com/vi/sc7dicXFoZE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性代數 vs. 電機系其他必修課


</details>

<details>
<summary>274. [線性代數] 課程速覽</summary><br>

<a href="https://www.youtube.com/watch?v=J-U_zKg15f4" target="_blank">
    <img src="https://img.youtube.com/vi/J-U_zKg15f4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 課程速覽


</details>

<details>
<summary>275. [線性代數] 向量 (Vector)</summary><br>

<a href="https://www.youtube.com/watch?v=I3hyvWN78Is" target="_blank">
    <img src="https://img.youtube.com/vi/I3hyvWN78Is/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 向量 (Vector)


</details>

<details>
<summary>276. [線性代數] 線性系統 = 線性方程組 (System of Linear Equations)</summary><br>

<a href="https://www.youtube.com/watch?v=Ww3eAfLZjME" target="_blank">
    <img src="https://img.youtube.com/vi/Ww3eAfLZjME/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性系統 = 線性方程組 (System of Linear Equations)


</details>

<details>
<summary>277. [線性代數] 矩陣 (Matrix)</summary><br>

<a href="https://www.youtube.com/watch?v=7qwaAhcD2og" target="_blank">
    <img src="https://img.youtube.com/vi/7qwaAhcD2og/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 矩陣 (Matrix)


</details>

<details>
<summary>278. [線性代數] 那些有名有姓的矩陣</summary><br>

<a href="https://www.youtube.com/watch?v=cf-WpQX70Vs" target="_blank">
    <img src="https://img.youtube.com/vi/cf-WpQX70Vs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 那些有名有姓的矩陣


</details>

<details>
<summary>279. [線性代數] 矩陣乘上向量的一些特性</summary><br>

<a href="https://www.youtube.com/watch?v=OMdCNhJp60M" target="_blank">
    <img src="https://img.youtube.com/vi/OMdCNhJp60M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 矩陣乘上向量的一些特性


</details>

<details>
<summary>280. [線性代數] 線性系統 = 線性方程組 (System of Linear Equations) = 矩陣乘上向量</summary><br>

<a href="https://www.youtube.com/watch?v=6wPSfjwm_qk" target="_blank">
    <img src="https://img.youtube.com/vi/6wPSfjwm_qk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性系統 = 線性方程組 (System of Linear Equations) = 矩陣乘上向量


</details>

<details>
<summary>281. [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (高中觀點)</summary><br>

<a href="https://www.youtube.com/watch?v=zchDGSfr_yU" target="_blank">
    <img src="https://img.youtube.com/vi/zchDGSfr_yU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (高中觀點)


</details>

<details>
<summary>282. [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (線性代數觀點)</summary><br>

<a href="https://www.youtube.com/watch?v=OHgibs_pDN8" target="_blank">
    <img src="https://img.youtube.com/vi/OHgibs_pDN8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (線性代數觀點)


</details>

<details>
<summary>283. [線性代數] 線性組合 (Linear Combination)</summary><br>

<a href="https://www.youtube.com/watch?v=pZfvmcjIrpE" target="_blank">
    <img src="https://img.youtube.com/vi/pZfvmcjIrpE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性組合 (Linear Combination)


</details>

<details>
<summary>284. [線性代數] 在 Span 時耍廢的向量</summary><br>

<a href="https://www.youtube.com/watch?v=-zIPQ8hcsps" target="_blank">
    <img src="https://img.youtube.com/vi/-zIPQ8hcsps/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 在 Span 時耍廢的向量


</details>

<details>
<summary>285. [線性代數] Span 的概念</summary><br>

<a href="https://www.youtube.com/watch?v=FEnFCtNILtI" target="_blank">
    <img src="https://img.youtube.com/vi/FEnFCtNILtI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] Span 的概念


</details>

<details>
<summary>286. [2020-11-03] [INTERSPEECH 2020] VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net architecture</summary><br>

<a href="https://www.youtube.com/watch?v=JWGVfVSvQwc" target="_blank">
    <img src="https://img.youtube.com/vi/JWGVfVSvQwc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net architecture

### 核心主題  
- 語音轉換（Voice Conversion, VC）的研究與改進。

---

### 主要觀念  
1. **語音轉換的目的**：改變說話者的身份，同時保持內容信息不變。  
2. **VC系統的分類**：
   - 幵發數據（Par Data）：說話者.say相同的句子，收集困難但適合模型訓練。
   - 不相干數據（Unpar Data）： speaker的信息無限制。
3. **語音轉換方法**：
   - 直接變換（Direct Transform）
   - 特徵解耦（Feature Disentangle）

---

### 問題與原因  
1. **基於特徵解耦模型的問題**：
   - 如何分別建模內容嵌入和說話者嵌入？
   - 向量化方法雖能分離信息，但降低音質。
2. **音質低劣的原因**：
   - 向量化引入了信息瓶頸，限制了重建能力。

---

### 解決方法與優化方式  
1. **模型改進**：
   - 使用更深的架構：增加模型深度以提升表示能力。
   - 引入條件スキーム（SKI Condition Module）：分層建模，逐步解耦內容和說話者信息。
2. **數據集**：
   - 使用Vox-Copus數據集（含9位講話者，共44小時語音）。
3. **實驗評估**：
   - 語言識別準確率：模型在-content嵌入中speaker信息被有效去除，accuracy達70%。
   - 主觀評價：與基線方法（如AutoVC）相比，在自然度和相似性上表現更佳。

---

### 結論  
1. **SKI架構的優勢**：
   - 減少信息瓶頸，提升音質。
2. **進階改進建議**：
   - 經驗證，增加codebook大小可平衡重建精度與解耦性能。
3. **未來研究方向**：
   - 探索更多條件架構以進一步提升語音質量。
</details>

<details>
<summary>287. [2020-11-03] [INTERSPEECH 2020] WG-WaveNet: Real-Time High-Fidelity Speech Synthesis without GPU</summary><br>

<a href="https://www.youtube.com/watch?v=rsbT7X2-g7E" target="_blank">
    <img src="https://img.youtube.com/vi/rsbT7X2-g7E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] WG-WaveNet: Real-Time High-Fidelity Speech Synthesis without GPU

### 核心主題  
- 提出一種快速且輕量級的語音編解碼器（Vocoder）：**WGWebNet**，能夠實時生成高質量的22kHz和44kHz語音樣本，並且不需要GPU支持。  

---

### 主要觀念  
1. **語音合成的重要性**：語音合成技術在人工智慧、通信和娛樂等領域具有廣泛應用。  
2. **輕量級模型的需求**：在移動設備和嵌入式系統中，計算資源有限，需要高效的模型來實現實時語音合成。  
3. **非自回歸模型的優勢**：相對於傳統的自回歸模型，非自回歸模型在生成速度上具有顯著優勢，適合實時應用。  

---

### 問題原因  
1. **計算資源限制**：移動設備和嵌入式系統通常缺乏足夠的GPU資源來支持基於Transformer的語音合成模型。  
2. **自回歸模型的瓶頸**：傳統的自回歸模型在生成速度上較慢，無法實現實時語音 synthesis。  
3. **高_sampling_rate 的挑戰**：44kHz語音樣本需要更高的計算能力，且目前多數模型在生成高_sampling_rate語音時性能不足。  

---

### 解決方法  
1. **WGWebNet架構設計**：基於Transformer的輕量級模型，優化了編解碼器結構以降低計算複雜度。  
2. **非自回歸生成**：採用非自回歸策略，顯著提升語音生成速度，實現實時合成。  
3. **參數調整和優化**：針對不同_sampling_rate（如22kHz和44kHz）進行參數調試，確保在保持語音質量的前提下提升性能。  

---

### 優化方式  
1. **模型精簡**：通過降低模型參數數量和優化架構設計，實現了輕量化。  
2. **實時生成策略**：非自回歸機制使得模型能夠在CPU上高效運行，支持實時語音合成。  
3. **多_sampling_rate 支持**：針對不同_sampling_rate進行參數調試，平衡語音質量和生成效率。  

---

### 結論  
1. **性能提升**：WGWebNet在22kHz和44kHz語音生成中均實現了實時性能，且語音質量（MOS）接近最佳非自回歸模型。  
2. **輕量級優勢**：相比其他模型，WGWebNet在保持高語音質量的前提下，具備更快的生成速度和更低的計算資源需求。  
3. **應用前景**：該模型適合用於移動設備、嵌入式系統等資源受限環境中的語音合成任務。  

---

### 參考資料  
- 論文中提供的數據和實驗結果已用來支持上述整理內容。
</details>

<details>
<summary>288. [2020-11-03] [INTERSPEECH 2020]  Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis</summary><br>

<a href="https://www.youtube.com/watch?v=3b1S20iVyMY" target="_blank">
    <img src="https://img.youtube.com/vi/3b1S20iVyMY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020]  Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis

### 核心主題  
- 探索半監督學習在現代說話人文本到語音（TTS）合成中的應用。  
- 目標是通過利用未標記音頻數據，顯著減少高質量語音模型訓練所需的數據量。  

---

### 主要觀念  
1. **問題陳述**：  
   - 當前高性能多說話人TTS系統需要大量高質量配對數據（通常超過20小時），數據收集過程耗時且昂貴，限制了其廣泛應用。  

2. **核心挑戰**：  
   - 數據量不足導致監督學習方法性能受限，特別是在多說話人場景中。  
   - 未標記音頻數據的利用效率低下，難以有效提升模型表現。  

3. **創新點**：  
   - 提出一種半監督學習框架，通過引入可學習的代碼本和直通梯度估計器，實現未標記數據的有效利用。  
   - 驗證了該方法在噪聲環境下的魯棒性，並探討了單說話人與多說話人訓練之間的關係。  

---

### 問題原因  
- 數據收集成本高昂：高質量語音配對數據需求量大，限制了模型的普及。  
- 未標記數據難以有效融入監督學習框架，導致模型性能提升受限。  
- 單說話人與多說話人訓練之間存在輸入不匹配問題，影響模型泛化能力。  

---

### 解決方法  
1. **半監督學習框架**：  
   - 利用少量配對數據（1小時）進行監督訓練，結合大量未標記音頻數據進行無監督優化。  
   - 引入可學習的代碼本，提升編碼器和解碼器的表示能力。  

2. **直通梯度估計器**：  
   - 允許重建損失通過編碼器傳播梯度，解決傳統半監督方法中編碼器無法有效更新的問題。  

3. **噪聲魯棒性優化**：  
   - 通過訓練模型處理帶噪未標記數據，驗證其在實際應用場景中的可靠性。  

4. **多說話人與單說話人訓練的平衡**：  
   - 驗證了基於少量配對數據的模型仍能實現多說話人語音合成，但性能略遜於基於25小時數據的監督學習方法。  

---

### 結論  
- 提出的半監督學習方法在僅使用1小時配對數據的情況下，生成語音的質量與基於25小時數據的監督方法相當。  
- 該方法通過有效利用未標記數據，顯著降低了高質量TTS模型的訓練成本。  
- 實驗結果表明，模型在噪聲環境和多說話人場景中均表現出色，驗證了其泛化能力和實用性。  

---

### 優化方式  
1. **數據效率提升**：  
   - 通過半監督學習框架，減少對高質量配對數據的依賴，降低數據收集成本。  

2. **模型魯棒性增強**：  
   - 驗證了模型在噪聲環境下的性能穩定性，爲實際應用場景提供保障。  

3. **跨說話人適應能力優化**：  
   - 探討了單說話人與多說話人訓練的平衡點，爲未來研究提供了方向。
</details>

<details>
<summary>289. [INTERSPEECH 2020] DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition</summary><br>

<a href="https://www.youtube.com/watch?v=rztqT8RXyuI" target="_blank">
    <img src="https://img.youtube.com/vi/rztqT8RXyuI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition


</details>

<details>
<summary>290. [INTERSPEECH 2020] SpeechBERT: Model for End-to-end Spoken Question Answering</summary><br>

<a href="https://www.youtube.com/watch?v=7mf7nSh8dGE" target="_blank">
    <img src="https://img.youtube.com/vi/7mf7nSh8dGE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] SpeechBERT: Model for End-to-end Spoken Question Answering


</details>

<details>
<summary>291. [INTERSPEECH 2020] Understanding Self-Attention of Self-Supervised Audio Transformers</summary><br>

<a href="https://www.youtube.com/watch?v=RJq_B416V1Q" target="_blank">
    <img src="https://img.youtube.com/vi/RJq_B416V1Q/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] Understanding Self-Attention of Self-Supervised Audio Transformers


</details>

<details>
<summary>292. [INTERSPEECH 2020] Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning</summary><br>

<a href="https://www.youtube.com/watch?v=k81atCYWpzg" target="_blank">
    <img src="https://img.youtube.com/vi/k81atCYWpzg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning


</details>

<details>
<summary>293. ML Lecture 21-1: Recurrent Neural Network (Part I) English version</summary><br>

<a href="https://www.youtube.com/watch?v=Jjy6ER0bHv8" target="_blank">
    <img src="https://img.youtube.com/vi/Jjy6ER0bHv8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# ML Lecture 21-1: Recurrent Neural Network (Part I) English version


</details>

<details>
<summary>294. 【機器學習2021】預測本頻道觀看人數 (上) - 機器學習基本概念簡介</summary><br>

<a href="https://www.youtube.com/watch?v=Ye018rCVvOo" target="_blank">
    <img src="https://img.youtube.com/vi/Ye018rCVvOo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】預測本頻道觀看人數 (上) - 機器學習基本概念簡介


</details>

<details>
<summary>295. 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介</summary><br>

<a href="https://www.youtube.com/watch?v=bHcJCp2Fyxs" target="_blank">
    <img src="https://img.youtube.com/vi/bHcJCp2Fyxs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介


</details>

<details>
<summary>296. [ML 2021 (English version)] Lecture 1: Predicting the views of this channel - ML Introduction (1/2)</summary><br>

<a href="https://www.youtube.com/watch?v=Y87Ct23H3Kw" target="_blank">
    <img src="https://img.youtube.com/vi/Y87Ct23H3Kw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ML 2021 (English version)] Lecture 1: Predicting the views of this channel - ML Introduction (1/2)


</details>

<details>
<summary>297. [ML 2021 (English version)] Lecture 2: Predicting the views of this channel - ML Introduction (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=O69EqgzUl9U" target="_blank">
    <img src="https://img.youtube.com/vi/O69EqgzUl9U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ML 2021 (English version)] Lecture 2: Predicting the views of this channel - ML Introduction (2/2)


</details>

<details>
<summary>298. 【機器學習2021】機器學習任務攻略</summary><br>

<a href="https://www.youtube.com/watch?v=WeHM2xpYQpw" target="_blank">
    <img src="https://img.youtube.com/vi/WeHM2xpYQpw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】機器學習任務攻略


</details>

<details>
<summary>299. 【機器學習2021】類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)</summary><br>

<a href="https://www.youtube.com/watch?v=zzbr1h9sF54" target="_blank">
    <img src="https://img.youtube.com/vi/zzbr1h9sF54/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)


</details>

<details>
<summary>300. 【機器學習2021】類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)</summary><br>

<a href="https://www.youtube.com/watch?v=QW6uINn7uGk" target="_blank">
    <img src="https://img.youtube.com/vi/QW6uINn7uGk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)


</details>

