<details>
<summary>251. [DLHLP 2020] Deep Learning for Coreference Resolution</summary><br>

<a href="https://www.youtube.com/watch?v=2BemmceHKOU" target="_blank">
    <img src="https://img.youtube.com/vi/2BemmceHKOU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Coreference Resolution


</details>

<details>
<summary>252. [TA 補充課] SAGAN, BigGAN, SinGAN, GauGAN, GANILLA, NICE-GAN (由助教吳宗翰同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=hTNE8iFXEMU" target="_blank">
    <img src="https://img.youtube.com/vi/hTNE8iFXEMU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] SAGAN, BigGAN, SinGAN, GauGAN, GANILLA, NICE-GAN (由助教吳宗翰同學講授)


</details>

<details>
<summary>253. [DLHLP 2020] Deep Learning for Constituency Parsing</summary><br>

<a href="https://www.youtube.com/watch?v=pHQ2lcDgoFs" target="_blank">
    <img src="https://img.youtube.com/vi/pHQ2lcDgoFs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Constituency Parsing


</details>

<details>
<summary>254. [TA 補充課] More about Anomaly Detection (由助教林政豪同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=-C8RUrWb7F8" target="_blank">
    <img src="https://img.youtube.com/vi/-C8RUrWb7F8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Anomaly Detection (由助教林政豪同學講授)


</details>

<details>
<summary>255. [TA 補充課] More about Domain Adaptation (1/2) (由助教趙崇皓同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=gvfLq4sPW4k" target="_blank">
    <img src="https://img.youtube.com/vi/gvfLq4sPW4k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Domain Adaptation (1/2) (由助教趙崇皓同學講授)


</details>

<details>
<summary>256. [TA 補充課] More about Domain Adaptation (2/2) (由助教楊晟甫同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=-DQBMAULXX8" target="_blank">
    <img src="https://img.youtube.com/vi/-DQBMAULXX8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Domain Adaptation (2/2) (由助教楊晟甫同學講授)


</details>

<details>
<summary>257. [TA 補充課] Self-supervised Learning (由助教劉記良同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=ZGnKfoUb7h8" target="_blank">
    <img src="https://img.youtube.com/vi/ZGnKfoUb7h8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] Self-supervised Learning (由助教劉記良同學講授)


</details>

<details>
<summary>258. [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (1/2)</summary><br>

<a href="https://www.youtube.com/watch?v=QBbeIsiqw-U" target="_blank">
    <img src="https://img.youtube.com/vi/QBbeIsiqw-U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (1/2)


</details>

<details>
<summary>259. [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=w0-7BO09kdo" target="_blank">
    <img src="https://img.youtube.com/vi/w0-7BO09kdo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Meta Learning (由助教陳建成同學講授) (2/2)


</details>

<details>
<summary>260. [DLHLP 2020] Multilingual BERT</summary><br>

<a href="https://www.youtube.com/watch?v=8rDN1jUI82g" target="_blank">
    <img src="https://img.youtube.com/vi/8rDN1jUI82g/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Multilingual BERT


</details>

<details>
<summary>261. [DLHLP 2020] Deep Learning for Dependency Parsing</summary><br>

<a href="https://www.youtube.com/watch?v=9erBrs-VIqc" target="_blank">
    <img src="https://img.youtube.com/vi/9erBrs-VIqc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Dependency Parsing


</details>

<details>
<summary>262. [DLHLP 2020] Deep Learning for Question Answering (1/2) (重新上傳)</summary><br>

<a href="https://www.youtube.com/watch?v=gRfTfXCe3LA" target="_blank">
    <img src="https://img.youtube.com/vi/gRfTfXCe3LA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Question Answering (1/2) (重新上傳)


</details>

<details>
<summary>263. [DLHLP 2020] Audio BERT (1/2) (由助教劉廷緯同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=NN9Q9Jhtvvg" target="_blank">
    <img src="https://img.youtube.com/vi/NN9Q9Jhtvvg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Audio BERT (1/2) (由助教劉廷緯同學講授)


</details>

<details>
<summary>264. [DLHLP 2020] Audio BERT (2/2) (由助教紀伯翰同學和助教楊書文同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=0KNvAYb1emQ" target="_blank">
    <img src="https://img.youtube.com/vi/0KNvAYb1emQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Audio BERT (2/2) (由助教紀伯翰同學和助教楊書文同學講授)


</details>

<details>
<summary>265. [DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3</summary><br>

<a href="https://www.youtube.com/watch?v=DOG1L9lvsDY" target="_blank">
    <img src="https://img.youtube.com/vi/DOG1L9lvsDY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] 來自獵人暗黑大陸的模型 GPT-3


</details>

<details>
<summary>266. [DLHLP 2020] Deep Learning for Question Answering (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=h_Lptoq8spQ" target="_blank">
    <img src="https://img.youtube.com/vi/h_Lptoq8spQ/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Deep Learning for Question Answering (2/2)


</details>

<details>
<summary>267. [TA 補充課] RL - Model-based, Large-scale, Meta, Multi-agent, Hide-and-seek, Alpha Star (由助教林義聖同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=ZR2AZgupIpc" target="_blank">
    <img src="https://img.youtube.com/vi/ZR2AZgupIpc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] RL - Model-based, Large-scale, Meta, Multi-agent, Hide-and-seek, Alpha Star (由助教林義聖同學講授)


</details>

<details>
<summary>268. [DLHLP 2020] Controllable Chatbot</summary><br>

<a href="https://www.youtube.com/watch?v=mk6v2raVGfk" target="_blank">
    <img src="https://img.youtube.com/vi/mk6v2raVGfk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Controllable Chatbot


</details>

<details>
<summary>269. [TA 補充課] More about Lifelong Learning (由助教楊舒涵同學講授)</summary><br>

<a href="https://www.youtube.com/watch?v=SX6_1-mvkWk" target="_blank">
    <img src="https://img.youtube.com/vi/SX6_1-mvkWk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [TA 補充課] More about Lifelong Learning (由助教楊舒涵同學講授)


</details>

<details>
<summary>270. [DLHLP 2020] Dialogue State Tracking (as Question Answering)</summary><br>

<a href="https://www.youtube.com/watch?v=tRDF_w700Uw" target="_blank">
    <img src="https://img.youtube.com/vi/tRDF_w700Uw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [DLHLP 2020] Dialogue State Tracking (as Question Answering)


</details>

<details>
<summary>271. [2020-07-15] [ACL 2020] Worse WER, but Better BLEU? (Speaker: Shun-Po Chuang)</summary><br>

<a href="https://www.youtube.com/watch?v=OybkIdSNKSc" target="_blank">
    <img src="https://img.youtube.com/vi/OybkIdSNKSc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ACL 2020] Worse WER, but Better BLEU? (Speaker: Shun-Po Chuang)

# 文章整理與結構化分析

## 核心主題  
- 語音翻譯（Speech Translation, ST）：研究如何將來源語言的語音轉換為目標語言的文字。  
- 多任務學習在語音翻譯中的應用：探討語音識別和翻譯之間的關聯性，特別是.semantic information的重要性。  

---

## 主要觀念  
1. **多任務學習（Multi-task Learning）**：在同一模型中同時學習語音識別和翻譯任務。  
2. **藍分數（BLEU Score）和字錯率（Word Error Rate,WER）**：分別用於衡量翻譯質量和語音識別質量，但二者之間並無直接 correlation。  
3. **語義信息的重要性**： semantic information可能比純粹的語音識別質量更影響最終翻譯質量。  

---

## 問題與原因  
1. **問題**：傳統的WER指標無法充分反映語音翻譯模型的性能，因為高WER的結果可能在語義上更接近 ground truth。  
   - 原因：WER主要衡量字面級別的相似性，忽略了semantic context的重要性。  
2. **挑戰**：多任務學習中，如何有效整合語音識別和翻譯模塊，提升整體性能。  

---

## 解決方法  
1. **引入Word Embeddings（詞嵌入）**：利用預訓練的詞嵌入（如WordNet或大型文本數據訓練的向量），捕獲 semantic 和 syntactic信息。  
2. **.semantic Information的利用**：在多任務模型中，將hidden state與word embeddings進行相似度計算，作為語義信息的參考。  
3. **Cosine Similarity**：使用.Cosine similarity衡量hidden state和word embeddings之間的相似性，並通過Softmax函數得到概率分佈。  

---

## 優化方式  
1. **模型結構**：提出一種三元組結構（Encoder-Decoder架構），讓源語言解碼器和目標語言解碼器共享隱藏狀態（hidden state）。  
2. **訓練目標**：改進原來的多任務損失函數，引入cosine相似度作為語義信息的衡量指標。  
3. **數據需求**：使用單語文本數據訓練word embeddings，降低對平行語料庫的依賴。  

---

## 結論與實驗結果  
1. **翻譯質量提升**：使用cosine softmax方法後，BLEU分數顯著提高，表明語義信息在翻譯中起重要作用。  
2. **WER的局限性**：低WER並不總是對應高翻譯質量，語義信息的融入能更好地平衡兩者。  
3. **模型性能**：提出的多任務模型在BLEU分數和WER指標上均達到最佳效果，證明了semantic information的有效性。  

---

## 展望  
- 進一步研究如何更有效地整合語音識別和翻譯模塊，提升多語言環境下的語音翻譯性能。  
- 探索其他semantic信息捕獲方式（如使用更大規模的 pretrained models）。
</details>

<details>
<summary>272. [線性代數] 這門課在學什麼？</summary><br>

<a href="https://www.youtube.com/watch?v=SNT7LAGsLDY" target="_blank">
    <img src="https://img.youtube.com/vi/SNT7LAGsLDY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 這門課在學什麼？


</details>

<details>
<summary>273. [線性代數] 線性代數 vs. 電機系其他必修課</summary><br>

<a href="https://www.youtube.com/watch?v=sc7dicXFoZE" target="_blank">
    <img src="https://img.youtube.com/vi/sc7dicXFoZE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性代數 vs. 電機系其他必修課


</details>

<details>
<summary>274. [線性代數] 課程速覽</summary><br>

<a href="https://www.youtube.com/watch?v=J-U_zKg15f4" target="_blank">
    <img src="https://img.youtube.com/vi/J-U_zKg15f4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 課程速覽


</details>

<details>
<summary>275. [線性代數] 向量 (Vector)</summary><br>

<a href="https://www.youtube.com/watch?v=I3hyvWN78Is" target="_blank">
    <img src="https://img.youtube.com/vi/I3hyvWN78Is/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 向量 (Vector)


</details>

<details>
<summary>276. [線性代數] 線性系統 = 線性方程組 (System of Linear Equations)</summary><br>

<a href="https://www.youtube.com/watch?v=Ww3eAfLZjME" target="_blank">
    <img src="https://img.youtube.com/vi/Ww3eAfLZjME/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性系統 = 線性方程組 (System of Linear Equations)


</details>

<details>
<summary>277. [線性代數] 矩陣 (Matrix)</summary><br>

<a href="https://www.youtube.com/watch?v=7qwaAhcD2og" target="_blank">
    <img src="https://img.youtube.com/vi/7qwaAhcD2og/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 矩陣 (Matrix)


</details>

<details>
<summary>278. [線性代數] 那些有名有姓的矩陣</summary><br>

<a href="https://www.youtube.com/watch?v=cf-WpQX70Vs" target="_blank">
    <img src="https://img.youtube.com/vi/cf-WpQX70Vs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 那些有名有姓的矩陣


</details>

<details>
<summary>279. [線性代數] 矩陣乘上向量的一些特性</summary><br>

<a href="https://www.youtube.com/watch?v=OMdCNhJp60M" target="_blank">
    <img src="https://img.youtube.com/vi/OMdCNhJp60M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 矩陣乘上向量的一些特性


</details>

<details>
<summary>280. [線性代數] 線性系統 = 線性方程組 (System of Linear Equations) = 矩陣乘上向量</summary><br>

<a href="https://www.youtube.com/watch?v=6wPSfjwm_qk" target="_blank">
    <img src="https://img.youtube.com/vi/6wPSfjwm_qk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性系統 = 線性方程組 (System of Linear Equations) = 矩陣乘上向量


</details>

<details>
<summary>281. [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (高中觀點)</summary><br>

<a href="https://www.youtube.com/watch?v=zchDGSfr_yU" target="_blank">
    <img src="https://img.youtube.com/vi/zchDGSfr_yU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (高中觀點)


</details>

<details>
<summary>282. [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (線性代數觀點)</summary><br>

<a href="https://www.youtube.com/watch?v=OHgibs_pDN8" target="_blank">
    <img src="https://img.youtube.com/vi/OHgibs_pDN8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性方程組 (System of Linear Equations) 有解還是無解 (線性代數觀點)


</details>

<details>
<summary>283. [線性代數] 線性組合 (Linear Combination)</summary><br>

<a href="https://www.youtube.com/watch?v=pZfvmcjIrpE" target="_blank">
    <img src="https://img.youtube.com/vi/pZfvmcjIrpE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 線性組合 (Linear Combination)


</details>

<details>
<summary>284. [線性代數] 在 Span 時耍廢的向量</summary><br>

<a href="https://www.youtube.com/watch?v=-zIPQ8hcsps" target="_blank">
    <img src="https://img.youtube.com/vi/-zIPQ8hcsps/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] 在 Span 時耍廢的向量


</details>

<details>
<summary>285. [線性代數] Span 的概念</summary><br>

<a href="https://www.youtube.com/watch?v=FEnFCtNILtI" target="_blank">
    <img src="https://img.youtube.com/vi/FEnFCtNILtI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [線性代數] Span 的概念


</details>

<details>
<summary>286. [2020-11-03] [INTERSPEECH 2020] VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net architecture</summary><br>

<a href="https://www.youtube.com/watch?v=JWGVfVSvQwc" target="_blank">
    <img src="https://img.youtube.com/vi/JWGVfVSvQwc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] VQVC+: One-Shot Voice Conversion by Vector Quantization and U-Net architecture

### 核心主題  
- 語音轉換（Voice Conversion, VC）的研究與改進。

---

### 主要觀念  
1. **語音轉換的目的**：改變說話者的身份，同時保持內容信息不變。  
2. **VC系統的分類**：
   - 幵發數據（Par Data）：說話者.say相同的句子，收集困難但適合模型訓練。
   - 不相干數據（Unpar Data）： speaker的信息無限制。
3. **語音轉換方法**：
   - 直接變換（Direct Transform）
   - 特徵解耦（Feature Disentangle）

---

### 問題與原因  
1. **基於特徵解耦模型的問題**：
   - 如何分別建模內容嵌入和說話者嵌入？
   - 向量化方法雖能分離信息，但降低音質。
2. **音質低劣的原因**：
   - 向量化引入了信息瓶頸，限制了重建能力。

---

### 解決方法與優化方式  
1. **模型改進**：
   - 使用更深的架構：增加模型深度以提升表示能力。
   - 引入條件スキーム（SKI Condition Module）：分層建模，逐步解耦內容和說話者信息。
2. **數據集**：
   - 使用Vox-Copus數據集（含9位講話者，共44小時語音）。
3. **實驗評估**：
   - 語言識別準確率：模型在-content嵌入中speaker信息被有效去除，accuracy達70%。
   - 主觀評價：與基線方法（如AutoVC）相比，在自然度和相似性上表現更佳。

---

### 結論  
1. **SKI架構的優勢**：
   - 減少信息瓶頸，提升音質。
2. **進階改進建議**：
   - 經驗證，增加codebook大小可平衡重建精度與解耦性能。
3. **未來研究方向**：
   - 探索更多條件架構以進一步提升語音質量。
</details>

<details>
<summary>287. [2020-11-03] [INTERSPEECH 2020] WG-WaveNet: Real-Time High-Fidelity Speech Synthesis without GPU</summary><br>

<a href="https://www.youtube.com/watch?v=rsbT7X2-g7E" target="_blank">
    <img src="https://img.youtube.com/vi/rsbT7X2-g7E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] WG-WaveNet: Real-Time High-Fidelity Speech Synthesis without GPU

### 核心主題  
- 提出一種快速且輕量級的語音編解碼器（Vocoder）：**WGWebNet**，能夠實時生成高質量的22kHz和44kHz語音樣本，並且不需要GPU支持。  

---

### 主要觀念  
1. **語音合成的重要性**：語音合成技術在人工智慧、通信和娛樂等領域具有廣泛應用。  
2. **輕量級模型的需求**：在移動設備和嵌入式系統中，計算資源有限，需要高效的模型來實現實時語音合成。  
3. **非自回歸模型的優勢**：相對於傳統的自回歸模型，非自回歸模型在生成速度上具有顯著優勢，適合實時應用。  

---

### 問題原因  
1. **計算資源限制**：移動設備和嵌入式系統通常缺乏足夠的GPU資源來支持基於Transformer的語音合成模型。  
2. **自回歸模型的瓶頸**：傳統的自回歸模型在生成速度上較慢，無法實現實時語音 synthesis。  
3. **高_sampling_rate 的挑戰**：44kHz語音樣本需要更高的計算能力，且目前多數模型在生成高_sampling_rate語音時性能不足。  

---

### 解決方法  
1. **WGWebNet架構設計**：基於Transformer的輕量級模型，優化了編解碼器結構以降低計算複雜度。  
2. **非自回歸生成**：採用非自回歸策略，顯著提升語音生成速度，實現實時合成。  
3. **參數調整和優化**：針對不同_sampling_rate（如22kHz和44kHz）進行參數調試，確保在保持語音質量的前提下提升性能。  

---

### 優化方式  
1. **模型精簡**：通過降低模型參數數量和優化架構設計，實現了輕量化。  
2. **實時生成策略**：非自回歸機制使得模型能夠在CPU上高效運行，支持實時語音合成。  
3. **多_sampling_rate 支持**：針對不同_sampling_rate進行參數調試，平衡語音質量和生成效率。  

---

### 結論  
1. **性能提升**：WGWebNet在22kHz和44kHz語音生成中均實現了實時性能，且語音質量（MOS）接近最佳非自回歸模型。  
2. **輕量級優勢**：相比其他模型，WGWebNet在保持高語音質量的前提下，具備更快的生成速度和更低的計算資源需求。  
3. **應用前景**：該模型適合用於移動設備、嵌入式系統等資源受限環境中的語音合成任務。  

---

### 參考資料  
- 論文中提供的數據和實驗結果已用來支持上述整理內容。
</details>

<details>
<summary>288. [2020-11-03] [INTERSPEECH 2020]  Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis</summary><br>

<a href="https://www.youtube.com/watch?v=3b1S20iVyMY" target="_blank">
    <img src="https://img.youtube.com/vi/3b1S20iVyMY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020]  Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis

### 核心主題  
- 探索半監督學習在現代說話人文本到語音（TTS）合成中的應用。  
- 目標是通過利用未標記音頻數據，顯著減少高質量語音模型訓練所需的數據量。  

---

### 主要觀念  
1. **問題陳述**：  
   - 當前高性能多說話人TTS系統需要大量高質量配對數據（通常超過20小時），數據收集過程耗時且昂貴，限制了其廣泛應用。  

2. **核心挑戰**：  
   - 數據量不足導致監督學習方法性能受限，特別是在多說話人場景中。  
   - 未標記音頻數據的利用效率低下，難以有效提升模型表現。  

3. **創新點**：  
   - 提出一種半監督學習框架，通過引入可學習的代碼本和直通梯度估計器，實現未標記數據的有效利用。  
   - 驗證了該方法在噪聲環境下的魯棒性，並探討了單說話人與多說話人訓練之間的關係。  

---

### 問題原因  
- 數據收集成本高昂：高質量語音配對數據需求量大，限制了模型的普及。  
- 未標記數據難以有效融入監督學習框架，導致模型性能提升受限。  
- 單說話人與多說話人訓練之間存在輸入不匹配問題，影響模型泛化能力。  

---

### 解決方法  
1. **半監督學習框架**：  
   - 利用少量配對數據（1小時）進行監督訓練，結合大量未標記音頻數據進行無監督優化。  
   - 引入可學習的代碼本，提升編碼器和解碼器的表示能力。  

2. **直通梯度估計器**：  
   - 允許重建損失通過編碼器傳播梯度，解決傳統半監督方法中編碼器無法有效更新的問題。  

3. **噪聲魯棒性優化**：  
   - 通過訓練模型處理帶噪未標記數據，驗證其在實際應用場景中的可靠性。  

4. **多說話人與單說話人訓練的平衡**：  
   - 驗證了基於少量配對數據的模型仍能實現多說話人語音合成，但性能略遜於基於25小時數據的監督學習方法。  

---

### 結論  
- 提出的半監督學習方法在僅使用1小時配對數據的情況下，生成語音的質量與基於25小時數據的監督方法相當。  
- 該方法通過有效利用未標記數據，顯著降低了高質量TTS模型的訓練成本。  
- 實驗結果表明，模型在噪聲環境和多說話人場景中均表現出色，驗證了其泛化能力和實用性。  

---

### 優化方式  
1. **數據效率提升**：  
   - 通過半監督學習框架，減少對高質量配對數據的依賴，降低數據收集成本。  

2. **模型魯棒性增強**：  
   - 驗證了模型在噪聲環境下的性能穩定性，爲實際應用場景提供保障。  

3. **跨說話人適應能力優化**：  
   - 探討了單說話人與多說話人訓練的平衡點，爲未來研究提供了方向。
</details>

<details>
<summary>289. [2020-11-03] [INTERSPEECH 2020] DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition</summary><br>

<a href="https://www.youtube.com/watch?v=rztqT8RXyuI" target="_blank">
    <img src="https://img.youtube.com/vi/rztqT8RXyuI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] DARTS-ASR: Differentiable Architecture Search for Multilingual Speech Recognition

# 文章整理：基於可微架構搜索的語音識別模型優化研究

## 核心主題
- 探討將可微架構搜索（Differential Architecture Search, DAR）應用於語音識別（ASR）任務中的有效性和優勢。
- 研究如何通過多語言預訓練和適應策略，提升語音識別模型在單語和多語環境下的性能。

## 主要觀念
1. **可微架構搜索**：一種通過端到端優化自動尋找最優網絡結構的方法，適用於語音識別任務。
2. **多語言語音識別**：探討共享 acoustic 模型在多種語言間的可行性及其優勢。
3. **模型適應策略**：研究如何通過參數調整和架構微調，提升預訓練模型在目標語言上的性能。

## 問題原因
- 傳統固定架構的語音識別模型難以有效處理多種語言及其複雜的 acoustic 特性。
- 缺乏有效的多語言共享機制，導致模型泛化能力有限。

## 解決方法
1. **可微架構搜索**：
   - 通過 DAR 方法自動搜索最優網絡結構，取代人工設計固定架構。
   - 在單語和多語環境下分別進行架構搜索，驗證其通用性。
2. **多語言預訓練與適應**：
   - 預先在多種源語言上訓練共享 acoustic 模型。
   - 通過三種適應策略（僅參數調整、參數與架構聯合微調、剪枝架構）優化模型在目標語言上的性能。

## 優化方式
1. **架構搜索結果分析**：
   - 單語環境下，不同語言的最優架構存在差異，但淺層結構中標準卷積爲主。
   - 多語環境下，較大的 kernel size 卷積和深度可分離卷積在深層架構中更爲普遍。

2. **適應策略優化**：
   - 參數與架構聯合微調能顯著提升性能，同時保持較低的計算成本。
   - 架構剪枝在減少計算開銷的同時，僅造成輕微性能下降。

## 結論
- 可微架構搜索方法能在單語和多語語音識別任務中提供優於傳統固定架構的性能。
- 多語言預訓練有助於發現適用於廣泛語言的通用 acoustic 模型。
- 未來工作可將 DAR 方法與其他 ASR 技術（如元學習）結合，探索更大規模模型和更多任務的應用。

---

以上整理基於文章內容，結構清晰地歸納了核心主題、主要觀念、問題原因、解決方法、優化方式及結論。
</details>

<details>
<summary>290. [2020-11-03] [INTERSPEECH 2020] SpeechBERT: Model for End-to-end Spoken Question Answering</summary><br>

<a href="https://www.youtube.com/watch?v=7mf7nSh8dGE" target="_blank">
    <img src="https://img.youtube.com/vi/7mf7nSh8dGE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] SpeechBERT: Model for End-to-end Spoken Question Answering

### 小節整理：端到端spoken question answering模型的研究與實現

#### 1. 核心主題
- **核心主題**：開發一種端到端（end-to-end）的spoken question answering系統，直接從音頻信號中進行問題解答，避免傳統管道式方法的局限性。

#### 2. 主要觀念
- **信息獲取限制**：
  - 文本中的信息有限，大量信息隱藏在語音中。
  - 舊有管道式方法依賴高精度的文字轉錄（ASR），易受錯誤影響。
  
- **端到端模型優勢**：
  - 直接處理音頻信號，跳過傳統的文本轉錄步驟。
  - 更好地利用語音信息，提升在高錯誤率下的性能。

#### 3. 問題原因
- **管道式方法的局限性**：
  - 高ASR錯誤率導致模型性能下降。
  - 認識錯誤會影響最終答案的準確性。

#### 4. 解決方法
- **提出Speech-BIR架構**：
  - 將文本基礎的BIR模型改進為語音版本，名為Speech-BIR。
  - 端到端訓練：直接從音頻信號中提取特徵並進行問題解答。
  
- **實現細節**：
  - 使用ground truth transcription進行模型訓練。
  - 測試階段使用ASR轉錄，模擬實際應用環境。

#### 5. 優化方式
- **預訓練與微調**：
  - 在音頻數據上進行預訓練，提升模型的語音理解能力。
  
- **世界邊界分割**：
  - 使用.ALIGNMENT技術提取世界邊界信息，進行音頻分割，降低ASR錯誤影響。

#### 6. 結論
- **性能優勢**：
  - 在低錯誤率場景下，Speech-BIR性能接近傳統管道式方法。
  - 在高錯誤率場景下（>40%），Speech-BIR表現明顯優於管道式方法。

- **實驗結果**：
  - 在spoken Squad數據集上，Speech-BIR在更困難的子集上取得了顯著提升。
  - 結合文本BIR模型進行聯合訓練，進一步提升了性能。

#### 7. 未來方向
- **改進ASR錯誤處理**：探索更 robust 的方法來應對高錯誤率場景。
- **多模態融合**：將語音和文本信息有機結合，進一步提升模型性能。
- **擴展應用場景**：將此技術應用於更多實際問題中，如客服系統、智能音箱等。
</details>

<details>
<summary>291. [2020-11-03] [INTERSPEECH 2020] Understanding Self-Attention of Self-Supervised Audio Transformers</summary><br>

<a href="https://www.youtube.com/watch?v=RJq_B416V1Q" target="_blank">
    <img src="https://img.youtube.com/vi/RJq_B416V1Q/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] Understanding Self-Attention of Self-Supervised Audio Transformers

# The Role and Importance of Self-Attention in Continuous Input Reconstruction: An Empirical Study

## 小節整理

### 1. 核心主題  
- 探討自注意力機制（Self-Attention）在連續輸入重建任務中的作用和重要性。  
- 分析不同類型的注意力頭（Attention Heads）對下遊任務的影響。  

### 2. 主要觀念  
- 自注意力機制能夠捕捉序列中的全局信息，並在重建任務中表現出強大的能力。  
- 注意力頭可以分爲三類：** diagonal, vertical, 和 global**，每種類型在處理不同類型的信息時具有不同的作用。  

### 3. 問題原因  
- 不同類型的注意力頭對下遊任務的重要性存在差異。  
- 部分注意力頭可能對模型性能貢獻較小甚至產生負面影響。  

### 4. 解決方法  
- 提出一種基於注意力頭重要性的評估指標：** globalness, verticality, 和 diagonality**，用於量化不同類型注意力頭的貢獻。  
- 通過逐步剪枝（Pruning）實驗，驗證不同類型注意力頭對下遊任務的影響程度。  

### 5. 優化方式  
- **Diagonal Attention Heads**: 對音素分類任務至關重要，其剪枝會導致性能顯著下降。  
- **Vertical Attention Heads**: 主要影響說話人識別任務，但可能對音素分類任務產生負面影響。  
- **Global Attention Heads**: 對整體表示質量貢獻較小，可適當剪枝以優化性能。  

### 6. 結論  
- 自注意力機制在連續輸入重建任務中表現出強大的能力。  
- **Diagonal Attention Heads** 是核心，對音素分類和說話人識別均至關重要。  
- 可通過剪枝去除超過50%的冗餘注意力頭（尤其是Global類型），在不影響說話人身份的前提下提升音素分類性能。  
- 未來研究可進一步探索注意力頭的多樣性與模型壓縮的可能性。
</details>

<details>
<summary>292. [2020-11-03] [INTERSPEECH 2020] Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning</summary><br>

<a href="https://www.youtube.com/watch?v=k81atCYWpzg" target="_blank">
    <img src="https://img.youtube.com/vi/k81atCYWpzg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [INTERSPEECH 2020] Defense for Black-box Attacks on Anti-spoofing Models by Self-Supervised Learning

### 核心主題  
- **研究目標**：提出一種基於自監督學習的方法，用於防止反轉攻擊（adversarial attacks）對ASV（Automatic Speaker Verification）反spoofing模型的效果。  
- **核心問題**：現有的反spoofing模型在面對黑盒攻擊時容易被繞過，尤其是在添加通用噪音（universal noise）的情況下。  

---

### 主要觀念  
1. **自監督學習**：提出使用一種名為Monkey J的自監督學習模型作為深度濾波器，用於削弱反轉噪音。  
2. **通用噪音攻擊**：黑盒攻擊者在不知道目標模型內部結構的情況下，通過添加通用噪音來繞過防護機制。  
3. **特徵表示的重要性**：自監督學習模型提取的高級特徵能有效防止通用攻擊範例的傳播。  

---

### 問題原因  
- 現有方法中，簡單的濾波器（如均值濾波器、高斯濾波器）只能在一定程度上削弱噪音，但面對強大的反轉攻擊時效果有限。  
- 黑盒攻擊者可以利用通用噪音繞過傳統防護機制。  

---

### 解決方法  
1. **提出Monkey J模型**：基於自監督學習 pretrained 的深度濾波器，在反spoofing模型之前插入，用以削弱反轉噪音。  
2. **模型結構**：Monkey J作為固定參數的前置模塊，提取高級特徵供反spoofing模型使用。  
3. **防護機制**：在推理階段，先通過Monkey J削弱 noises，再進行反spoofing判斷。  

---

### 優化方式  
1. **預訓練的重要性**：Monkey J需在大型數據集上進行充分的pretraining，以獲得有效的特徵提取能力。  
2. **結構固定性**：Monkey J的參數在防護階段保持不變，避免引入額外的可學習參數，確保模型穩定性。  

---

### 實驗結果  
- **數據集**：使用ASVspoof 2019 Challenge的訓練集和測試集進行實驗。  
- **攻擊方法**：採用PGD（Projected Gradient Descent）和FGSM（Fast Gradient Sign Method）兩種常見的黑盒攻擊方式。  
- **對比模型**：包括基線模型（Male Spectrogram）、均值濾波器、高斯濾波器等。  
- **結果展示**：Monkey J-based Defender在所有攻擊場景下均表現出色，防禦效果顯著優於其他方法，尤其是在噪音強度增大的情況下。  

---

### 結論  
1. 自監督學習模型提取的高級特徵能有效防止通用攻擊範例的傳播。  
2. Monkey J作為深度濾波器，在黑盒攻擊防禦中具有顯著優勢，且結構簡單、效果穩定。  
3. 預訓練是提升模型防護能力的關鍵步驟。
</details>

<details>
<summary>293. [2021-02-17] ML Lecture 21-1: Recurrent Neural Network (Part I) English version</summary><br>

<a href="https://www.youtube.com/watch?v=Jjy6ER0bHv8" target="_blank">
    <img src="https://img.youtube.com/vi/Jjy6ER0bHv8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# ML Lecture 21-1: Recurrent Neural Network (Part I) English version

# 文章整理：LSTM 在序列數據處理中的應用與優化

## 核心主題
- **長短期記憶網絡 (LSTM)**：一種用於處理序列數據的特殊 Recurrent Neural Network (RNN)，用來解決傳統 RNN 的長期依賴問題。

## 主要觀念
1. **傳統 RNN 的局限性**：
   - 長期依賴問題： traditional RNN 在處理長序列數據時，梯度消失或爆炸現象嚴重，影響模型學習能力。
   
2. **LSTM 的創新結構**：
   - **門控機制 (Gates)**：包括輸入門、forget 門和輸出門。這些門控結構能有選擇地允許信息流過，控制長期記憶的保留與更新。
   - **セル狀構造 (Cell Structure)**：包含忘れゲート、入力ゲート、出力ゲート，每個門控使用sigmoid激活函數來決定信息流量。

3. **LSTM 的計算流程**：
   - 每個時間步中，門控結構根據當前輸入和先前狀態來控制信息的存儲與刪除。
   - 輸出結果不僅依賴於當前輸入，還考慮到之前的隱藏狀態。

## 問題原因
- **梯度消失/爆炸**：傳統 RNN 在訓練長序列數據時，梯度在反向傳播過程中迅速衰減或放大，影響模型學習。
- **信息選擇性不足**： traditional RNN 不能有效控制哪些信息應該被保留或遺忘。

## 解決方法
1. **門控結構引入**：
   - **輸入門 (Input Gate)**：決定當前 timestep 的新信息有多少應該存儲在記憶中。
   - **forget 門 (Forget Gate)**：控制之前長期記憶中有多少應該被保留或刪除。
   - **輸出門 (Output Gate)**：控制記憶中的信息有多少應該作為輸出傳遞到下一 timestep。

2. **多層堆疊 LSTM**：
   - 通過多個 LSTM 層的串接，增強模型捕捉複雜序列模式的能力。
   - 每一層的輸出作為下一個層的 입력，進一步提取高級特徵。

## 優化方式
- **Gated Recurrent Unit (GRU)**：
  - GRU 結合了 LSTM 的主要思想，但結構更簡單，只包含更新門和重置門。
  - 參數較少，計算效率更高，且在某些任務上性能與 LSTM 相當。

## 應用實踐
- **Keras 支持**：
  - Keras 等深度學習框架提供現成的 LSTM 層，方便開發者輕鬆實現。
  - 使用者可通過簡單的 API 調用 LSTM，無需深入理解內部複雜結構。

## 結論
LSTM 作為一種有效的序列模型，在多種應用場景中展現了優越性能。其門控結構有效解決了傳統 RNN 的長期依賴問題，而 GRU 等變體則在保持性能的同時降低了計算成本。現代深度學習框架進一步降低了使用門檻，使得 LSTM 成為處理序列數據的標準選擇。
</details>

<details>
<summary>294. [2021-02-26] 【機器學習2021】預測本頻道觀看人數 (上) - 機器學習基本概念簡介</summary><br>

<a href="https://www.youtube.com/watch?v=Ye018rCVvOo" target="_blank">
    <img src="https://img.youtube.com/vi/Ye018rCVvOo/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】預測本頻道觀看人數 (上) - 機器學習基本概念簡介

### 核心主題
- **預測模型的建立與優化**：探討如何基於歷史數據建立有效的預測模型，並通過調整模型結構來提升預測準確性。

### 主要觀念
1. **初始模型結構**：
   - 原始模型為一元線性回歸模型，形式為 \( y = b + w_1 x_1 \)，其中 \( x_1 \) 表示前一天的觀看人次。
   - 該模型在訓練資料上的誤差（loss）為0.58k，在未見資料上的表現為0.58k。

2. **數據週期性分析**：
   - 觀察到數據存在七天週期性，即每七天後的觀看人次會重現類似模式。
   - 為了捕捉此週期性，提出考慮前七天的歷史數據作為模型輸入。

3. **多變量線性模型**：
   - 引入多個lags（延遲），將模型改為 \( y = b + w_1 x_1 + w_2 x_2 + \dots + w_7 x_7 \)，其中 \( x_i \) 表示前i天的觀看人次。
   - 經訓練後，該模型在訓練資料上的loss降低至0.38k，在未見資料上的表現為0.49k。

4. **模型擴展**：
   - 考慮更多的lags（如28天和56天），以進一步捕捉更長期的數據模式。
   - 28天模型在訓練資料上的loss為0.33k，在未見資料上為0.46k；56天模型則分別為0.32k和0.46k。

### 問題原因
- **初始模型局限性**：一元線性回歸未能充分捕捉數據的週期性特徵，導致預測精度不足。
- **信息利用不夠充分**：未充分考慮多天歷史數據，限制了模型的學習能力。

### 解決方法
1. **引入lags**：
   - 考慮前七天、28天和56天的 historical data 作為模型輸入，以提升模型的信息利用率。

2. **選擇適當模型結構**：
   - 使用多變量線性回歸模型，將多個lags納入模型訓練中，使模型能更充分地學習數據模式。

3. **優化模型參數**：
   - 通過_gradient descent_ 方法，最佳化模型的權重（weights）和截距（bias），以最小化預測誤差。

### 優化方式
1. **LAGS 的選擇**：
   - 測試不同lags數量（如7天、28天、56天）對模型性能的影響，並選擇最佳lags數量。

2. **模型結構調整**：
   - 確定是否需要引入更高lags的數據，以進一步提升預測精度。

3. **性能評估**：
   - 使用訓練資料和未見資料分別評估模型性能，確保模型在不同數據集上的穩定性。

### 結論
- ** effectiveness of多lags模型**：考慮前七天、28天和56天的歷史數據能有效降低預測誤差，在未見資料上表現尤為明顯。
- **模型結構的重要性**：適當增加lags數量可以提升模型的表現在訓練資料上，但在未見資料上的效果受到限制。
- **未來研究方向**：
   - 探索更 advanced 的模型結構（如非線性模型）以進一步提升預測精度。
   - 研究其他可能影響觀看人次的因素，並納入模型中。
</details>

<details>
<summary>295. [2021-02-26] 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介</summary><br>

<a href="https://www.youtube.com/watch?v=bHcJCp2Fyxs" target="_blank">
    <img src="https://img.youtube.com/vi/bHcJCp2Fyxs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】預測本頻道觀看人數 (下) - 深度學習基本概念簡介

# 文章重點整理

## 核心主題
深度學習的基本概念及其在預測模型中的應用。

## 主要觀念
1. **神經網絡結構**：
   - 3層神經網絡（輸入層、隱藏層、輸出層）的基本結構。
   - 確定網絡層數對模型性能的影響。

2. **訓練數據與性能評估**：
   - 訓練數據包括2月1日至2月24日的觀看人次。
   - 模型在訓練數據上的表現：4層神經網絡效果較好，但其在未見數據上的表現可能不如3層模型。

3. **模型選擇原則**：
   - 選擇模型應基於未見數據（如2月26日的觀看人次）的預測能力，而非訓練數據的性能。
   - 3 layer模型在未見數據上表現更佳。

4. **模型應用與局限性**：
   - 模型用於預測未來觀看人次。
   - 預測結果（如2月25日和2月26日）可能因數據不完整而存在較大誤差。

## 問題原因
1. **過擬合風險**：
   - 4 layer模型在訓練數據上表現更佳，但可能存在過擬合問題，在未見數據上的表現不佳。

2. **數據不足**：
   - 訓練數據截至2月24日，未能涵蓋最新日期（如2月26日），導致預測結果的不準確性。

## 解決方法
1. **模型選擇策略**：
   - 選擇在未見數據上表現較好的模型（如3 layer模型）。

2. **數據更新機制**：
   - 定期更新訓練數據，以涵蓋最新日期的觀看人次。

## 優化方式
1. **模型_TUNING**：
   - 試驗不同網絡結構（層數），選擇最佳結構。

2. **評估指標**：
   - 使用適當的指標（如MAE、MSE）來評估模型在未見數據上的性能。

## 結論
深度學習模型在預測任務中需基於未見數據的表現進行選擇，避免過擬合。本研究案例展示了3 layer模型在未見數據上具備更好的泛化能力，但數據不完整性和模型局限性導致結果存在較大誤差。

---

**參考資源**：
- 深度學習介紹：[影片連結](#)
- 反向傳播（Backpropagation）：[影片連結](#)
</details>

<details>
<summary>296. [2021-03-05] [ML 2021 (English version)] Lecture 1: Predicting the views of this channel - ML Introduction (1/2)</summary><br>

<a href="https://www.youtube.com/watch?v=Y87Ct23H3Kw" target="_blank">
    <img src="https://img.youtube.com/vi/Y87Ct23H3Kw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ML 2021 (English version)] Lecture 1: Predicting the views of this channel - ML Introduction (1/2)

### 文章重點整理

#### 核心主題
文章探討了通過改進模型輸入特徵（feature）來提升預測性能的方法，特別是針對觀衆數量這一問題。

#### 主要觀念
1. **模型性能與輸入特徵的關係**  
   - 初始模型僅考慮前一天的觀衆數量，導致在測試數據上的損失較高。
   - 通過引入更多歷史天數的觀衆數量作爲特徵，模型性能得以提升。

2. **模型改進路徑**  
   - 從單日特徵逐步擴展到七天、一個月（28天）、兩個月（56天）的歷史數據，觀察其對模型的影響。

3. **線性模型的核心機制**  
   - 模型通過將每個歷史天數的觀衆數量乘以對應的權重（weight），並添加偏差項（bias）來生成預測結果。
   - 不同天數的特徵被賦予不同的權重，表明模型認爲不同時間段的歷史數據對當前預測的重要性不同。

#### 問題原因
- 初始模型僅依賴前一天的數據，忽略了更長周期的歷史信息，導致對 unseen 數據的泛化能力不足。
- 模型未能充分挖掘歷史數據中的潛在模式和趨勢。

#### 解決方法
1. **擴展輸入特徵**  
   - 引入過去七天、一個月（28天）和兩個月（56天）的觀衆數量作爲模型輸入，以捕捉更多歷史信息。

2. **優化權重分配**  
   - 通過訓練數據調整不同天數特徵的權重，使模型能夠自動學習哪些歷史數據對預測更重要。

#### 優化方式
- **逐步增加歷史周期**  
  - 從七天開始，逐步擴展到一個月和兩個月，觀察每一步對模型性能的影響。
- **線性模型的靈活性**  
  - 線性模型通過賦予不同特徵不同的權重，能夠靈活地適應數據中的複雜關係。

#### 結論
1. **模型改進的有效性**  
   - 引入更多歷史天數作爲輸入特徵顯著降低了訓練數據和測試數據上的損失。
   - 模型在 unseen 數據上的表現也有所提升，表明其泛化能力增強。

2. **模型局限性**  
   - 儘管擴展了歷史周期，但超過兩個月的數據並未進一步改善性能，可能表明存在數據稀疏性或其他因素限制了模型的改進空間。

3. **未來方向**  
   - 可考慮引入更複雜的模型架構（如深度學習）來更好地捕捉時間序列中的複雜模式。
   - 探索其他類型的特徵（如節假日、事件等）對觀衆數量的影響。
</details>

<details>
<summary>297. [2021-03-05] [ML 2021 (English version)] Lecture 2: Predicting the views of this channel - ML Introduction (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=O69EqgzUl9U" target="_blank">
    <img src="https://img.youtube.com/vi/O69EqgzUl9U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# [ML 2021 (English version)] Lecture 2: Predicting the views of this channel - ML Introduction (2/2)

### 文章要點整理

#### 核心主題
- **深度學習（Deep Learning）**：文章圍繞深度學習的基本概念、層次結構及其在預測問題中的應用展開討論。

#### 主要觀念
1. **模型結構**：
   - 介紹了3層和4層神經網絡的結構。
   - 強調模型複雜度對訓練數據表現的影響。

2. **模型評估**：
   - 比較了不同深度模型在已知數據上的表現，強調訓練數據結果的重要性。
   - 強調實際應用中更關注未見數據（未來日期）的預測性能。

3. **模型選擇**：
   - 確定選擇3層網絡進行最終預測，因其在未見數據上表現更佳。
   - 解釋了深度學習中模型選擇的重要性及其實用考量。

#### 問題原因
- **過擬合風險**：4層網絡在訓練數據上的表現優於3層網絡，可能存在過擬合風險，導致其在未見數據上的泛化能力不足。
- **評估標準偏差**：文章指出，模型選擇應基於未見數據的預測性能，而非僅依賴訓練數據的結果。

#### 解決方法
1. **模型選擇策略**：
   - 選擇在未見數據上表現更佳的3層網絡。
   - 強調評估標準需聚焦於實際應用中關心的未來數據。

2. **預測實踐**：
   - 使用3層網絡對February 26th的viewer數進行預測，並解釋模型的合理性。
   - 譴責了基於歷史數據的模式識別和趨勢分析。

#### 優化方式
- **數據質量與特徵工程**：文章未直接提及，但暗示了數據的完整性和特徵的重要性對模型性能的影響。
- **模型複雜度控制**：通過選擇適當深度的網絡來平衡模型的複雜度和泛化能力。

#### 結論
- **深度學習的核心價值**：展示了深度學習在模式識別和時間序列預測中的應用潛力。
- **模型選擇的重要性**：強調了在實際應用中，基於未見數據的模型性能評估至關重要。
- **未來展望**：提出了進一步優化模型的可能性，如增加更多的歷史數據、引入特徵工程等。

---

### 總結
文章圍繞深度學習的基本概念和模型選擇展開討論，強調了在實際應用中需基於未見數據的性能來選擇模型。通過具體案例展示了3層網絡在 viewer 預測中的實用性，並提出了未來優化的方向。
</details>

<details>
<summary>298. [2021-03-05] 【機器學習2021】機器學習任務攻略</summary><br>

<a href="https://www.youtube.com/watch?v=WeHM2xpYQpw" target="_blank">
    <img src="https://img.youtube.com/vi/WeHM2xpYQpw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】機器學習任務攻略

# 文章重點整理

## 核心主題
1. **機器學習模型的應用與挑戰**：探討了在實際應用中，模型可能面臨的過擬合（overfitting）和分布偏移（mismatch）等問題。
2. **數據分布的影響**：分析了訓練數據與測試數據分布不一致對模型性能的影響。

## 主要觀念
1. **過擬合的定義與解決方法**：
   - 過擬合是指模型在訓練數據上表現良好，但在未見測試數據上效果不佳。
   - 解決方法包括增加數據量、正則化和交叉驗證等。
2. **分布偏移（mismatch）的定義與影響**：
   - 分布偏移指訓練數據與測試數據的分布存在顯著差異，導致模型在測試時表現不佳。
   - 分布偏移通常難以通過增加數據量來解決。

## 問題原因
1. **過擬合的原因**：
   - 數據量不足。
   - 模型複雜度過高。
2. **分布偏移的原因**：
   - 訓練數據和測試數據的時間範圍不同（如使用歷史數據預測未來）。
   - 數據採集方式的不同。

## 解決方法
1. **過擬合的解決方法**：
   - 增加訓練數據量以提高模型泛化能力。
   - 使用正則化技術減少模型複雜度。
   - 應用交叉驗證評估模型性能。
2. **分布偏移的解決方法**：
   - 重新調整數據分割方式，確保訓練和測試數據分布相似。
   - 對測試數據進行預處理或數據增強。

## 優化方式
1. **數據增強技術**：通過生成合成數據或對現有數據進行變換來擴展數據集。
2. **領域適應（Domain Adaptation）**：調整模型以適應不同領域的數據分布差異。

## 結論
1. **模型選擇與調優的重要性**：在實際應用中，需根據數據特點和任務需求選擇合適的模型，並通過交叉驗證等方法進行優化。
2. **對分布偏移的關注**：特別是在處理時間序列或跨年度數據時，需特別關注訓練數據和測試數據的分布差異，以避免性能下降。

---

# 總結性摘要
本文探討了機器學習模型在實際應用中面臨的過擬合和分布偏移問題。通過分析這些挑戰的原因，提出了相應的解決方法，如增加數據量、使用正則化技術和調整數據分割策略。文章強調了對訓練數據與測試數據分布差異的關注，並指出了解決這些問題的重要性和方法。
</details>

<details>
<summary>299. [2021-03-05] 【機器學習2021】類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)</summary><br>

<a href="https://www.youtube.com/watch?v=zzbr1h9sF54" target="_blank">
    <img src="https://img.youtube.com/vi/zzbr1h9sF54/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)

# 文章整理：動量法（Momentum）在最速下降法中的應用

## 核心主題  
本文探討了在最速下降法中引入動量法的原理及其優勢，特別是在處理非凸優化問題時的效果。

## 主要觀念  
1. **最速下降法局限性**： classical gradient descent在面對_plateaus_（平地）或_saddle points_（鞍點）時，進度會明顯放慢甚至陷入困境。
2. **動量法的引入**：為了解決上述問題，動量法被提出作為改進方案。

## 問題原因  
1. 在非凸優化中，_gradient descent_易受_plateaus_和_saddle points_影響，導致搜索速度減慢或陷入局部最小值。
2. 常規_gradient descent_缺乏歷史信息的利用，無法有效應對這些	challenges.

## 解決方法  
1. **動量法機制**：  
   - 引入動量因子（momentum factor），將前一步的移動方向納入當前步的更新中。
   - 通過加權累積_past gradients_，改進搜索策略。

2. **具體實現**：
   - 更新規則如下：
     \[
     m_t = \lambda m_{t-1} - \eta g_t
     \]
     \[
     \theta_{t+1} = \theta_t + m_t
     \]
     其中，$\lambda$為動量因子，$\eta$為學習率。

## 優化方式  
1. **加速效果**：  
   - 在_plateaus_和_saddle points_上，利用歷史信息的累積，有效加速搜索。
2. **逃逸鞍點**：  
   - 動量法幫助移動方向朝向更優解，避免陷入鞍點。
3. **學習率調參**：  
   - 需要同時調試學習率（$\eta$）和動量因子（$\lambda$），以平衡算法的穩定性和收斂速度。

## 理論基礎  
1. **動量向量**：  
   動量向量$m_t$是所有過去梯度的加權和，方向朝著最陡下降方向。
2. **更新步驟**：  
   每一步的更新不僅基於當前梯度，還考慮了先前的移動方向。

## 結論  
1. **優勢**：  
   - 動量法顯著提升了在_plateaus_和_saddle points_上的搜索效率。
   - 能夠幫助算法更快地逃逸鞍點，找到更優解。
2. **局限性**：  
   - 需要適當調參以避免過度振蕩或學習不足。
3. **實用價值**：  
   - 作為一種簡單有效的改進方法，在深度學習等領域廣泛應用。

---

此整理結構清晰地展示了文章的核心內容，涵蓋了從問題分析到解決方案再到優化與結論的完整脈絡。
</details>

<details>
<summary>300. [2021-03-05] 【機器學習2021】類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)</summary><br>

<a href="https://www.youtube.com/watch?v=QW6uINn7uGk" target="_blank">
    <img src="https://img.youtube.com/vi/QW6uINn7uGk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 【機器學習2021】類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)

# 文章整理：深度學習中 ошибки и критические точки

## 1. 核心主題
- 深度學習模型的訓練過程中，誤差表面（error surface）的複雜性導致模型卡在局部最小值或鞍點（saddle points），影響最終性能。

## 2. 主要觀念
- **錯誤表面的維度**：深度學習模型具備大量參數，導致其誤差表面處於高維空間。
- **局部最小值與鞍點**：在低維空間中，誤差表面看似充滿局部最小值；然而，在高維空間中，這些局部最小值可能實際上是鞍點。

## 3. 問題原因
- **高維特質**：在高維空間中，大部分的錯誤表面結構為鞍點而非局部最小值。
- **經驗數據支持**：訓練模型後分析Hessian矩陣，發現正的特徵值數量遠少於負的，表明鞍點比局部最小值更常見。

## 4. 解決方法
- **梯度下降法改進**：
  - 使用動量法（Momentum）或Adam優化器等方法來加速跳出鞍點。
- **初始化策略**：
  - 適當的參數初始化可幫助模型跳過鞍點，進入更有效的下降通道。

## 5. 結論
- 深度學習模型訓練中，鞍點比局部最小值更常見。理解並有效處理鞍點是提升模型性能的重要方向。
- 高維特質使得誤差表面結構複雜，但也可利用高維特性來設計更有效的優化方法。

## 6. 總結
- 深度學習模型的訓練過程存在多個挑戰，特別是在高維錯誤表面上的鞍點問題。未來研究可集中在如何有效跳過鞍點，並利用高維特性提升模型性能。
</details>

