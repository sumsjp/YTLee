<details>
<summary>351. [ML 2021 (English version)] Lecture 27: Domain Adaptation</summary><br>

<a href="https://www.youtube.com/watch?v=8AKqH6V9kjE" target="_blank">
    <img src="https://img.youtube.com/vi/8AKqH6V9kjE/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>352. [ML 2021 (English version)] Lecture 29: Introduction of Reinforcement Learning (RL) (2/5)</summary><br>

<a href="https://www.youtube.com/watch?v=jbN0oYLtXps" target="_blank">
    <img src="https://img.youtube.com/vi/jbN0oYLtXps/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>353. 【機器學習2021】概述增強式學習 (Reinforcement Learning, RL) (三) - Actor-Critic</summary><br>

<a href="https://www.youtube.com/watch?v=kk6DqWreLeU" target="_blank">
    <img src="https://img.youtube.com/vi/kk6DqWreLeU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>354. 【機器學習2021】概述增強式學習 (Reinforcement Learning, RL) (四) - 回饋非常罕見的時候怎麼辦？機器的望梅止渴</summary><br>

<a href="https://www.youtube.com/watch?v=73YyF1gmIus" target="_blank">
    <img src="https://img.youtube.com/vi/73YyF1gmIus/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>355. 【機器學習2021】概述增強式學習 (Reinforcement Learning, RL) (五) - 如何從示範中學習？逆向增強式學習 (Inverse RL)</summary><br>

<a href="https://www.youtube.com/watch?v=75rZwxKBAf0" target="_blank">
    <img src="https://img.youtube.com/vi/75rZwxKBAf0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>356. 【機器學習2021】機器終身學習 (Life Long Learning, LL) (一) - 為什麼今日的人工智慧無法成為天網？災難性遺忘(Catastrophic Forgetting)</summary><br>

<a href="https://www.youtube.com/watch?v=rWF9sg5w6Zk" target="_blank">
    <img src="https://img.youtube.com/vi/rWF9sg5w6Zk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>357. 【機器學習2021】機器終身學習 (Life Long Learning, LL) (二) - 災難性遺忘(Catastrophic Forgetting)的克服之道</summary><br>

<a href="https://www.youtube.com/watch?v=Y9Jay_vxOsM" target="_blank">
    <img src="https://img.youtube.com/vi/Y9Jay_vxOsM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>358. 【機器學習2021】神經網路壓縮 (Network Compression) (一) - 類神經網路剪枝 (Pruning) 與大樂透假說 (Lottery Ticket Hypothesis)</summary><br>

<a href="https://www.youtube.com/watch?v=utk3EnAUh-g" target="_blank">
    <img src="https://img.youtube.com/vi/utk3EnAUh-g/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>359. [ML 2021 (English version)] Lecture 34: Life-long Learning (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=-2r4cqDP4BY" target="_blank">
    <img src="https://img.youtube.com/vi/-2r4cqDP4BY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>360. [ML 2021 (English version)] Lecture 33: Life-long Learning (1/2)</summary><br>

<a href="https://www.youtube.com/watch?v=yAX8Ydfek_I" target="_blank">
    <img src="https://img.youtube.com/vi/yAX8Ydfek_I/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>361. [ML 2021 (English version)] Lecture 31: Introduction of Reinforcement Learning (RL) (4/5)</summary><br>

<a href="https://www.youtube.com/watch?v=pibO_5JhQ4U" target="_blank">
    <img src="https://img.youtube.com/vi/pibO_5JhQ4U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>362. [ML 2021 (English version)] Lecture 30: Introduction of Reinforcement Learning (RL) (3/5)</summary><br>

<a href="https://www.youtube.com/watch?v=Cf-WkM-Xef0" target="_blank">
    <img src="https://img.youtube.com/vi/Cf-WkM-Xef0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>363. [ML 2021 (English version)] Lecture 32: Introduction of Reinforcement Learning (RL) (5/5)</summary><br>

<a href="https://www.youtube.com/watch?v=9H3ShV57lHs" target="_blank">
    <img src="https://img.youtube.com/vi/9H3ShV57lHs/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>364. 【機器學習2021】神經網路壓縮 (Network Compression) (二) - 從各種不同的面向來壓縮神經網路</summary><br>

<a href="https://www.youtube.com/watch?v=xrlbLPaq_Og" target="_blank">
    <img src="https://img.youtube.com/vi/xrlbLPaq_Og/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>365. 【機器學習2021】元學習 Meta Learning (一) - 元學習跟機器學習一樣也是三個步驟</summary><br>

<a href="https://www.youtube.com/watch?v=xoastiYx9JU" target="_blank">
    <img src="https://img.youtube.com/vi/xoastiYx9JU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>366. 【機器學習2021】元學習 Meta Learning (二) - 萬物皆可 Meta</summary><br>

<a href="https://www.youtube.com/watch?v=Q68Eh-wm1Ts" target="_blank">
    <img src="https://img.youtube.com/vi/Q68Eh-wm1Ts/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>367. 【機器學習2021】課程結語 - 最後的業配並改編《為學一首示子姪》作結</summary><br>

<a href="https://www.youtube.com/watch?v=JXDjNh2qlfc" target="_blank">
    <img src="https://img.youtube.com/vi/JXDjNh2qlfc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>368. [ML 2021 (English version)] Lecture 35: Network Compression (1/2)</summary><br>

<a href="https://www.youtube.com/watch?v=CB0a3aBwND8" target="_blank">
    <img src="https://img.youtube.com/vi/CB0a3aBwND8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>369. [ML 2021 (English version)] Lecture 36: Network Compression (2/2)</summary><br>

<a href="https://www.youtube.com/watch?v=mGRdOGdOZ-4" target="_blank">
    <img src="https://img.youtube.com/vi/mGRdOGdOZ-4/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>370. SUPERB: 語音上的自督導式學習模型居然十項全能？</summary><br>

<a href="https://www.youtube.com/watch?v=MpsVE60iRLM" target="_blank">
    <img src="https://img.youtube.com/vi/MpsVE60iRLM/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>371. [2021-10-16] SUPERB: Is self-supervised learning universal in speech processing tasks? (English version)</summary><br>

<a href="https://www.youtube.com/watch?v=GTjwYzFG54E" target="_blank">
    <img src="https://img.youtube.com/vi/GTjwYzFG54E/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 小節歸納

#### 1. 核心主題  
- 探討自監督學習（Self-Supervised Learning, SSL）在語音和音頻處理中的應用及其通用性。  
- 通過SUPERB基準測試評估不同SSL模型在多種語音任務中的性能表現。  

#### 2. 主要觀念  
- 自監督學習能夠利用大量未標註數據進行有效訓練，具有顯著的潛力。  
- 傳統的FBank特徵提取方法可能不再是最佳選擇， SSL模型在多任務上表現出更好的性能。  
- 不同SSL模型的不同層可能包含適合特定任務的信息，下遊模型應有機會選擇最優層。  

#### 3. 問題原因  
- 傳統特徵提取方法（如FBank）在某些語音任務中表現有限。  
- SSL模型的各層表示信息分布不均，固定使用最後一層可能無法充分利用其潛力。  

#### 4. 解決方法  
- **SUPERB基準測試**：建立一個統一的評估框架，涵蓋多種語音相關任務（如ASR、關鍵詞 spotting 等）。  
- **多層加權求和表示**：允許下遊模型學習選擇上遊模型中哪一層的信息最爲適合特定任務。  

#### 5. 優化方式  
- 在第二輪比賽中引入了多層加權求和機制，使下遊模型能夠自適應地選擇最優的上遊模型層。  
- 鼓勵研究者上傳自己的SSL模型到SUPERB leaderboard，以促進競爭和技術進步。  

#### 6. 結論  
- 自監督學習模型在語音任務中展現出顯著的通用性，性能優於傳統的FBank方法。  
- 多層加權求和機制能夠進一步提升模型的表現。  
- 未來的研究方向應聚焦於理解這些模型如何在預訓練階段學習到通用特徵。  

#### 7. 其他重要信息  
- 鼓勵參與SUPERB挑戰、相關研討會（如AAAI 2022自監督學習工作坊）以及IEEE JSTSP的特別專刊，以推動領域的發展。  
- 提交截止日期：  
  - SUPERB Leaderboard：持續開放，建議在10月中旬前提交。  
  - AAAI 2022工作坊：11月12日截止。  
  - IEEE JSTSP專刊：本年底截止。
</details>

<details>
<summary>372. 【機器學習2022】開學囉~ 又要週更了~</summary><br>

<a href="https://www.youtube.com/watch?v=7XZR0-4uS5s" target="_blank">
    <img src="https://img.youtube.com/vi/7XZR0-4uS5s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>373. 【機器學習 2022】再探寶可夢、數碼寶貝分類器 — 淺談機器學習原理</summary><br>

<a href="https://www.youtube.com/watch?v=_j9MVVcvyZI" target="_blank">
    <img src="https://img.youtube.com/vi/_j9MVVcvyZI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>374. 【機器學習 2022】為什麼用了驗證集 (validation set) 結果卻還是過擬合(overfitting)了呢？</summary><br>

<a href="https://www.youtube.com/watch?v=xQXh3fSvD1A" target="_blank">
    <img src="https://img.youtube.com/vi/xQXh3fSvD1A/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>375. 【機器學習 2022】魚與熊掌可以兼得的深度學習</summary><br>

<a href="https://www.youtube.com/watch?v=yXd2D5J0QDU" target="_blank">
    <img src="https://img.youtube.com/vi/yXd2D5J0QDU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>376. 【機器學習 2022】各式各樣神奇的自注意力機制 (Self-attention) 變型</summary><br>

<a href="https://www.youtube.com/watch?v=yHoAq1IT_og" target="_blank">
    <img src="https://img.youtube.com/vi/yHoAq1IT_og/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>377. 【機器學習 2022】如何有效的使用自督導式模型 - Data-Efficient & Parameter-Efficient Tuning (由姜成翰助教講授)</summary><br>

<a href="https://www.youtube.com/watch?v=NzElV8jTNmw" target="_blank">
    <img src="https://img.youtube.com/vi/NzElV8jTNmw/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>378. 【機器學習 2022】語音與影像上的神奇自督導式學習 (Self-supervised Learning) 模型</summary><br>

<a href="https://www.youtube.com/watch?v=lMIN1iKYNmA" target="_blank">
    <img src="https://img.youtube.com/vi/lMIN1iKYNmA/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>379. 【機器學習2022】自然語言處理上的對抗式攻擊 (由姜成翰助教講授) - Part 1</summary><br>

<a href="https://www.youtube.com/watch?v=z-lRPFFYVJc" target="_blank">
    <img src="https://img.youtube.com/vi/z-lRPFFYVJc/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>380. 【機器學習2022】自然語言處理上的對抗式攻擊 (由姜成翰助教講授) - Part 2</summary><br>

<a href="https://www.youtube.com/watch?v=68lwXWFzCmg" target="_blank">
    <img src="https://img.youtube.com/vi/68lwXWFzCmg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>381. 【機器學習2022】自然語言處理上的對抗式攻擊 (由姜成翰助教講授) - Part 3</summary><br>

<a href="https://www.youtube.com/watch?v=LP3q72MwE7A" target="_blank">
    <img src="https://img.youtube.com/vi/LP3q72MwE7A/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>382. 【機器學習2022】自然語言處理上的模仿攻擊 (Imitation Attack) 以及後門攻擊 (Backdoor Attack) (由姜成翰助教講授)</summary><br>

<a href="https://www.youtube.com/watch?v=uHKXwwQ7A_s" target="_blank">
    <img src="https://img.youtube.com/vi/uHKXwwQ7A_s/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>383. 【機器學習 2022】惡搞自督導式學習模型 BERT 的三個故事</summary><br>

<a href="https://www.youtube.com/watch?v=Pal2DbmiYpk" target="_blank">
    <img src="https://img.youtube.com/vi/Pal2DbmiYpk/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>384. 【機器學習 2022】各種奇葩的元學習 (Meta Learning) 用法</summary><br>

<a href="https://www.youtube.com/watch?v=QNfymMRUg3M" target="_blank">
    <img src="https://img.youtube.com/vi/QNfymMRUg3M/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>385. AlphaTensor: 用增強式學習 (Reinforcement Learning) 找出更有效率的矩陣相乘演算法 (線性代數 2022 課程補充)</summary><br>

<a href="https://www.youtube.com/watch?v=KPcA8QCTm5U" target="_blank">
    <img src="https://img.youtube.com/vi/KPcA8QCTm5U/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>386. Meta 語音對語音翻譯技術背後的黑科技 (在繪圖 AI 中也有用上喔!)</summary><br>

<a href="https://www.youtube.com/watch?v=sWz4e-DM4JU" target="_blank">
    <img src="https://img.youtube.com/vi/sWz4e-DM4JU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>387. ChatGPT (可能)是怎麼煉成的 - GPT 社會化的過程</summary><br>

<a href="https://www.youtube.com/watch?v=e0aKI2GGZNg" target="_blank">
    <img src="https://img.youtube.com/vi/e0aKI2GGZNg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>388. 【生成式AI】ChatGPT 原理剖析 (1/3) — 對 ChatGPT 的常見誤解</summary><br>

<a href="https://www.youtube.com/watch?v=yiY4nPOzJEg" target="_blank">
    <img src="https://img.youtube.com/vi/yiY4nPOzJEg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>389. 【生成式AI】ChatGPT 原理剖析 (2/3) — 預訓練 (Pre-train)</summary><br>

<a href="https://www.youtube.com/watch?v=1ah7Qsri_c8" target="_blank">
    <img src="https://img.youtube.com/vi/1ah7Qsri_c8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>390. [2023-02-24] 【生成式AI】ChatGPT 原理剖析 (3/3) — ChatGPT 所帶來的研究問題</summary><br>

<a href="https://www.youtube.com/watch?v=UsaZhQ9bY2k" target="_blank">
    <img src="https://img.youtube.com/vi/UsaZhQ9bY2k/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 核心主題：人工智能（AI）系統的倫理與技術挑戰

#### 1. 主要問題領域：
- **模型調整與需求表達**：如何確保AI系統準確理解和響應用戶需求。
- **錯誤修正機制**：解決AI生成內容中的錯誤問題的方法。
- **AI生成物檢測**：識別由AI生成的內容的技術手段。
- **隱私保護與數據泄露風險**：防止AI系統無意中泄露敏感信息的策略。

#### 2. 倫理與技術挑戰分析：
- **隱私泄露問題**：AI模型可能通過間接詢問暴露個人機密信息，如地址和聯繫方式。
- **可解釋性與透明度不足**：用戶難以理解AI決策過程，影響信任。
- **數據濫用風險**：AI系統可能意外訪問或存儲不應接觸的信息。

#### 3. 解決方案與技術對策：
- **需求表達優化**：使用明確的自然語言處理方法提高指令準確性。
- **錯誤修正技術**：開發自動校正算法和用戶反饋機制來糾正生成內容中的錯誤。
- **AI生成檢測工具**：利用特徵分析和機器學習模型識別AI生成文本。
- **隱私保護措施**：實施數據脫敏、訪問限制和遺忘機制，如「Machine Unlearning」。

#### 4. 結論與未來展望：
- **提升整體水平潛力**：AI系統能幫助人類達到更高效率和創造力，成爲輔助工具。
- **倫理框架的重要性**：需建立明確的倫理規範和技術標準來指導AI系統的開發與應用。

### 主要觀點總結：

1. **需求表達優化**：
   - **Definition of Clear Requirements**: 明確界定用戶需求，提升指令準確性。
   
2. **錯誤修正技術**：
   - **Error Correction Mechanisms**: 通過自動校正和反饋系統解決AI生成內容的問題。
   
3. **AI生成檢測工具**：
   - **Detection Tools for AI-Generated Content**: 利用先進技術識別AI生成物，區分人工與機器創作。

4. **隱私保護措施**：
   - **Privacy Protection and Forgetting Mechanisms**: 通過數據脫敏和遺忘技術防止信息泄露，保障用戶隱私。

### 結論：
文章探討了在AI系統廣泛應用背景下所面臨的核心挑戰，包括需求表達、錯誤修正、生成內容識別和隱私保護。提出的解決方案和技術手段爲應對這些挑戰提供了方向，強調了倫理規範和技術標準的重要性。未來的研究應繼續關注如何提升AI系統的透明度與可解釋性，確保其安全可靠地服務於人類社會。
</details>

<details>
<summary>391. 【生成式AI】用 ChatGPT 和 Midjourney 來玩文字冒險遊戲</summary><br>

<a href="https://www.youtube.com/watch?v=A-6c584jxX8" target="_blank">
    <img src="https://img.youtube.com/vi/A-6c584jxX8/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>392. 【生成式AI】快速了解機器學習基本原理 (1/2) (已經略懂機器學習的同學可以跳過這段)</summary><br>

<a href="https://www.youtube.com/watch?v=phQK8xZpgoU" target="_blank">
    <img src="https://img.youtube.com/vi/phQK8xZpgoU/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>393. 【生成式AI】快速了解機器學習基本原理 (2/2) (已經略懂機器學習的同學可以跳過這段)</summary><br>

<a href="https://www.youtube.com/watch?v=XLyPFnephpY" target="_blank">
    <img src="https://img.youtube.com/vi/XLyPFnephpY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>394. [2023-03-03] 【生成式AI】生成式學習的兩種策略：要各個擊破，還是要一次到位</summary><br>

<a href="https://www.youtube.com/watch?v=AihBniegMKg" target="_blank">
    <img src="https://img.youtube.com/vi/AihBniegMKg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 文章整理：生成策略在文本和影像生成中的應用

## 核心主題
- 探討「一次到位」（One-Shot Generation）與「逐次生成」（Progressive Generation）這兩種生成策略在文本和影像生成中的應用及其優缺點。

## 主要觀念
1. **一次到位生成**：
   - 特性：直接生成最終結果。
   - 優點：速度快。
   - 缺點：可能缺乏清晰度和方向感，導致輸出模糊或不準確。

2. **逐次生成（各個擊破）**：
   - 特性：逐步細化生成過程，先決定大方向再完善細節。
   - 優點：結果更清晰、準確，尤其適用於複雜任務如語音合成和圖像生成。
   - 缺點：速度較慢。

## 問題原因
- **一次到位生成的問題**：
  - 由於模型在生成過程中無法有效選擇單一策略，導致輸出模糊或混合多個可能的解。
- **逐次生成的問題**：
  - 需多次迭代，計算量大，耗時較長。

## 解決方法
1. **結合兩種生成策略**：
   - 在語音合成中，先用逐次生成確定大方向（如每秒100個向量），再用一次到位生成高頻率聲音信號。
   
2. **Diffusion Model的應用**：
   - 將「一次到位」改為多次逐步細化的過程，通過逐步去噪提高圖像清晰度。

## 優化方式
- **分階段生成**：
  - 先用逐次生成確定大方向，再用一次到位完成細節。
  
- **Diffusion Model的改進**：
  - 多次迭代去噪，提升生成質量。

## 結論
- 不同生成任務需選擇適合的策略：
  - 文本生成：一次到位可能足夠。
  - 影像和語音生成：結合逐次生成與一次到位可得更優結果。
- Diffusion Model通過多次逐步細化，顯著提升了圖像生成質量，成爲當前先進的生成模型之一。

---

此整理框架清晰地展示了文章的核心內容及其邏輯關係，便於理解和進一步研究。
</details>

<details>
<summary>395. 【生成式AI】能夠使用工具的AI：New Bing, WebGPT, Toolformer</summary><br>

<a href="https://www.youtube.com/watch?v=ZID220t_MpI" target="_blank">
    <img src="https://img.youtube.com/vi/ZID220t_MpI/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>396. [2023-03-10] 【生成式AI】Finetuning vs. Prompting：對於大型語言模型的不同期待所衍生的兩類使用方式 (1/3)</summary><br>

<a href="https://www.youtube.com/watch?v=F58vJcGgjt0" target="_blank">
    <img src="https://img.youtube.com/vi/F58vJcGgjt0/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

# 文章重點整理

## 核心主題
本文圍繞如何通過插入適配器（Adapter）技術來提升大型語言模型（如GPT-3）的多任務處理能力展開探討，強調了在不顯著增加計算和存儲負擔的情況下，實現高效微調的重要性。

## 主要觀念
1. **大型語言模型的局限性**：當前主流的大語言模型（如GPT-3）參數量巨大，直接微調整個模型來完成多個任務在計算資源和存儲空間上存在顯著限制。
2. **適配器技術的作用**：通過插入輕量級的適配器模塊，可以在不修改原始模型參數的情況下，實現針對不同任務的高效微調。

## 問題原因
1. **多任務處理的計算成本高**：直接微調大型模型以支持多個任務需要存儲和運行多個版本的大模型，這在計算資源上是不可持續的。
2. **模型更新的影響範圍大**：傳統微調方法會修改整個模型的所有參數，導致模型性能受到全局性影響。

## 解決方法
1. **適配器插入技術**：
   - 在原始模型的不同位置（如注意力層或前饋網絡）插入輕量級的適配器模塊。
   - 這些適配器通常只包含少量新增參數，可以在保持原始模型結構完整性的前提下，實現針對特定任務的微調。

2. **高效微調策略**：
   - 只對適配器參數進行微調，而保留原始大模型的參數不變。
   - 這種方法顯著降低了計算和存儲成本，使得多任務處理變得更加可行。

## 優化方式
1. **適配器設計的靈活性**：有多種適配器插入方式可供選擇，如：
   - **BitFit**：只微調神經元偏置項。
   - **Houlsby Adapter**：在前饋網絡後增加一層新的前(feed-forward)網絡。
   - **Adapter Bias**：對前饋輸出進行平移操作。
   - **Prefix Tuning**：修改注意力機制。
   - **LoRA（Low-Rank Adaptation）**：針對注意力層的低秩適配器。

2. **根據任務特性選擇適配器位置**：不同的任務可能需要將適配器插入到模型的不同位置，以獲得最佳性能。例如：
   - LoRA在自然語言處理任務中表現優異。
   - 但LoRA在語音相關任務中的效果較差，需根據具體應用場景進行選擇。

## 結論
適配器技術為大規模多任務學習提供了一種高效且可持續的解決方案。通過插入輕量級的適配器模塊，可以在不顯著增加計算和存儲負擔的前提下，實現針對不同任務的有效微調，極大地提升了模型的實用價值。

---

# 問題清單
1. **適配器技術在現實應用中是否存在性能瓶頸？**  
   - 需要進一步研究不同類型的適配器在實際場景中的性能表現及其影響因素。

2. **如何系統化地選擇適合特定任務的適配器位置和結構？**  
   - 探索基於任務特性自動選擇最佳適配器插入位置的方法。

3. **適配器技術能否進一步降低計算資源消耗？**  
   - 研究更高效的適配器設計，以進一步降低模型微調的計算成本。

4. **多適配器並行處理是否會影響模型性能？**  
   - 探索在大型語言模型中插入多個適配器的可能性及其對模型性能的影響。

5. **適配器技術能否拓展到其他模態（如圖像或語音）？**  
   - 研究適配器技術在跨模態應用中的可行性與效果。
</details>

<details>
<summary>397. [2023-03-10] 【生成式AI】Finetuning vs. Prompting：對於大型語言模型的不同期待所衍生的兩類使用方式 (2/3)</summary><br>

<a href="https://www.youtube.com/watch?v=aZ_jXZvxyVg" target="_blank">
    <img src="https://img.youtube.com/vi/aZ_jXZvxyVg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 小節分類整理

#### 1. 核心主題
- 探討大型語言模型（LLM）通過指令調適（instruction tuning）實現理解和執行複雜自然語言處理任務的能力。
- 重點分析現有方法如In-context Learning和Few-shot Learning的局限性，以及Instruction Tuning在提升模型泛化能力方面的優勢。

#### 2. 主要觀念
1. **In-context Learning**：通過提供少量示例或上下文讓模型直接理解和執行指令。然而，這種方法嚴重依賴於高質量的示例，並且在面對未見過的新指令時效果有限。
2. **Instruction Tuning**：預先訓練模型理解並響應各種人類指令，使其能夠在沒有額外示例的情況下處理新任務。

#### 3. 問題原因
- 原有的In-context Learning方法依賴於高質量的示例數據，獲取這些數據往往需要大量的人力和時間。
- 模型在面對未見過的新指令時，缺乏足夠的泛化能力，導致性能下降。

#### 4. 解決方法
1. **Instruction Tuning**：
   - 收集並整理多種自然語言處理任務的數據集。
   - 將這些任務轉化爲人類可理解的指令形式，並進行模型訓練。
   - 通過大量多樣化的人類指令訓練模型，使其能夠理解並執行各種任務。

#### 5. 優化方式
1. **數據收集與整理**：
   - 收集廣泛的自然語言處理任務數據集，涵蓋翻譯、摘要、問答等多種類型。
2. **指令轉換**：
   - 將每個NLP任務轉化爲多個不同的指令描述方式，提升模型的適應性。
3. **模型訓練策略**：
   - 使用多樣化的人類指令進行監督訓練，確保模型理解不同表達方式下的同一任務。

#### 6. 結論
- Instruction Tuning是一種有效的提升LLM理解和執行複雜自然語言處理任務能力的方法。
- 通過這種方式，模型能夠在未見過的新指令下表現出色，展現出良好的泛化能力。
</details>

<details>
<summary>398. 【生成式AI】Finetuning vs. Prompting：對於大型語言模型的不同期待所衍生的兩類使用方式 (3/3)</summary><br>

<a href="https://www.youtube.com/watch?v=HnzDaEiN_eg" target="_blank">
    <img src="https://img.youtube.com/vi/HnzDaEiN_eg/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

<details>
<summary>399. [2023-03-17] 【生成式AI】大模型 + 大資料 = 神奇結果？(1/3)：大模型的頓悟時刻</summary><br>

<a href="https://www.youtube.com/watch?v=SaZTJJNOCOY" target="_blank">
    <img src="https://img.youtube.com/vi/SaZTJJNOCOY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>

### 文章重點整理

#### 核心主題
1. 大模型在特定任務中的表現優於中小模型。
2. 中小型模型在某些任務中可能表現不佳，甚至劣於隨機猜測。
3. 模型規模與性能之間的複雜關係。

#### 主要觀念
1. **規模效應**：大型模型在計算期望值等複雜任務中表現更優。
2. **陷阱任務（Distractor Task）**：某些任務設計包含誤導因素，導致部分模型失敗。
3. **一知半解的風險**：中小型模型可能因有限的理解能力而做出錯誤判斷。

#### 問題原因
1. 中小型模型缺乏足夠的參數容量，無法處理複雜的上下文信息。
2. 一些任務需要重新定義基本概念（如π=10），中小型模型難以適應。
3. 模型在推理過程中未能正確計算期望值或忽視了潛在的陷阱。

#### 解決方法
1. **增加模型規模**：使用更大的參數量以提升模型的理解和處理能力。
2. **任務設計優化**：明確任務要求，減少誤導因素。
3. **混合專家模型（Mixture-of-Expert）**：通過並行計算提高效率，同時降低資源消耗。

#### 優化方式
1. 使用混合專家模型結構，在推理時僅調用部分模組以節省資源。
2. 重新定義模型架構，如Switch Transformer，以適應超大規模參數。
3. 在訓練過程中逐步增加任務的複雜度，提升模型的適應能力。

#### 結論
1. 模型規模與性能呈非線性關係，存在最佳規模點。
2. 超大規模模型在特定任務中表現更優，但需考慮計算資源限制。
3. 未來研究應關注如何平衡模型規模與效率，優化模型設計。
</details>

<details>
<summary>400. 【生成式AI】大模型 + 大資料 = 神奇結果？(2/3)：到底要多少資料才夠</summary><br>

<a href="https://www.youtube.com/watch?v=qycxA-xX_OY" target="_blank">
    <img src="https://img.youtube.com/vi/qycxA-xX_OY/maxresdefault.jpg" 
        alt="[Youtube]" width="200">
</a>


</details>

