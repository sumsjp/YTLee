好 那我們來上課了
那我們接下來呢
要講 Global 的 Explanation
那 Global 的 Explanation 是什麼意思呢
我們在前一堂課講的是 Local 的 Explanation
也就是給機器一張照片
那它告訴我們說
看到這張圖片
它為什麼覺得裡面有一隻貓
而 Global 的 Explanation 並不是針對
特定某一張照片來進行分析
而是把我們訓練好的那個模型拿出來
根據這個模型裡面的參數去檢查說
對這個 Network 而言
到底一隻貓長什麼樣子
對一個 Network 而言
它心裡想像的貓長什麼樣子
好 舉例來說
假設你今天 Train 好一個
Convolutional 的 Neural Network
Train 好在這邊
那你知道在 Convolutional 的
Neural Network 裡面呢
就是有很多的 Filter
有很多的這個 Convolutional Layer
Convolutional Layer 裡面呢
有一堆的 Filter
那你把一張圖片作為輸入
Convolutional 的 Layer
它的輸出是什麼呢
它的輸出是一個 Feature Map
那每一個 Filter 都會給我們一個 Metric
那今天呢
假設我們有一張圖片
作為這個 Convolutional Neural Network 的輸入
這張圖片我們用一個大寫的 X 來表示
因為圖片呢
通常是一個矩陣
我們用大寫的 X
來表示這個圖片所構成的矩陣
而如果把這張圖片丟進去
你發現某一個 Filter
比如說 Filter 1
它在它的 Feature Map 裡面
很多位置都有比較大的值
那意味著什麼
那可能就是意味著說
這個 Image X 裡面有很多 Filter 1
負責偵測的那些特徵
這個 Image 裡面呢
有很多的 Pattern 是 Filter 1 負責偵測的
那 Filter 1 看到這些 Pattern
所以它在它的 Feature Map 上
就 Output 比較大的值
但是現在我們要做的是 Global 的 Explanation
也就是我們還沒有這張圖片 Image X
我們沒有要針對任何一張特定的圖片做分析
但是我們現在想要知道說
對 Filter 1 而言
它想要看的 Pattern 到底長什麼樣子
那怎麼做呢
我們就去製造出一張圖片
它不是我們的 Database 裡面
任何一個特定的圖片
而是機器自己去找出來的
自己創造出來的
我們要創造一張圖片
這張圖片它包含有 Filter 1 要 Detect 的 Pattern
那藉由看這張圖片裡面的內容
我們就可以知道 Filter 1
它負責 Detect 什麼樣的東西
那怎麼找這張圖片呢
我們假設 Filter 1
它是這個 Filter 1 的這個 Feature Map
裡面的每一個 Element 叫做 aij
就是 Filter 1 的那個 Feature Map 是一個矩陣
那矩陣裡面每一個 Element
我們用 aij 來表示
那我們現在要做的事情是找一張圖片 X
這張圖片不是 Database 裡面的圖片
而是我們把這個 X 呢
當做一個 Unknown Variable
當做我們要訓練的那個參數
我們去找一張圖片
這張圖片丟到這個 Filter 以後
通過 Convolutional Layer 以後
輸出這個 Feature Map 以後
Filter 1 對應的 Feature Map 裡面的值
也就是 aij 的值越大越好
所以我們要找一個 X
讓 aij 的總和
也就是 Filter 1 的 Feature Map的 Output
它的值越大越好
那我們找出來的這個 X
我們就用 X⋆ 來表示
它不是 Database 裡面任何一張特定的圖片
我們是把 X 當作 Unknown Variable
當作要 learn 的參數
去找出這個 X⋆
X⋆ 丟到這個已經 Train 好的 Network 裡面
這個 Network 的 Convolutional Layer
它輸出的這些 Feature 它的值
它輸出的這個 Feature Map 裡面的值
會越大越好
那怎麼解這個問題呢
你會用類似 Gradient descent 的方法
只是因為我們現在是要去 Maximize 某一個東西
所以它不是 Gradient descent
它是 Gradient ascent
不過它的原理跟 Gradient descent 是一模一樣的
好 那我找出這個 X⋆ 以後
我們就可以去觀察這個 X⋆
那看看 X⋆ 有什麼樣的特徵
我們就可以知道說
X⋆ 它可以 Maximize 這個 Filter Map 的 value
也就是這個 Filter 1
它在 Detect 什麼樣的 Pattern
那這邊是一個實際操作的結果了
我們就用這個 Mnist
Mnist 是一個手寫數字辨識的 Coper
用 Mnist Train 出一個 Classifier
這個 Classifier 給它一張圖片
它會判斷說這張圖片裡面是 1~9 的哪一個數字
訓練好這個數字的 Classifier 以後呢
我們就把它的第二層的 Convolutional Layer
裡面的 Filter 拿出來
然後找出每一個 Filter 對應的 X⋆
所以下面這邊每一張圖片
就是一個 X⋆
然後每一張圖片都對應到一個 Filter
那所以你可以想像說
這個第一張圖片就是 Filter 1
它想要 Detect 的 Pattern
第二張圖片
就是 Filter 2 想要 Detect 的 Pattern
以此類推
那這邊是畫了 12 個 Filter 出來
好 那從這些 Pattern 裡面
我們可以發現什麼呢
我們可以發現說
這個第二層的 Convolutional
它想要做的事情
確實是去偵測一些基本的 Pattern
比如說類似筆畫的東西
你可以看說這個 Filter
它想偵測什麼 Pattern
它想偵測橫線
這個 Filter
它想偵測什麼 Pattern
它想偵測斜直線等等
這個 Pattern 這個 Filter
它想偵測什麼 Pattern
它想要偵測直線
每一個 Filter
都有它想要偵測的 Pattern
那因為我們現在是在做手寫的數字辨識
那你知道數字就是有一堆筆畫所構成的
所以 Convolutiona Layer 裡面的每一個 Filter
它的工作就是去偵測某一個筆畫
這件事情是非常合理的
好 那接下來你可能就會去想說
那假設我們不是看某一個 Filter
而是去看最終這個 Image Classifier 的 Output
那可不可以呢
那我們會觀察到什麼樣的現象呢
如果我們今天是去看這個 Image Classifier
這個 Digit Classifier 的 Output
我們想辦法去找一張圖片 X
這個 X 可以讓某一個類別的分數越高越好
因為我們現在做的是這個數字辨識
所以這個 y 呢
總共就會有 10 個值
分別對應到 0~9
那我們就選某一個數字出來
比如說你選數字 1 出來
然後你希望找一張圖片
這張圖片丟到這個 Classifier 以後
數字 1 的分數越高越好
那如果你用這個方法
你可以看到什麼樣的東西呢
你可以看到數字 0~9 嗎
你實際上做一下以後發現
沒有辦法
你看到的結果大概就像是這個樣子
就這張 X
這張圖片
它可以讓這個 Image Classifier
覺得看到數字 0 的分數最高
這張圖片可以讓你的這個 Classifier
覺得看到 1 的分數最高
2 的分數最高
3 的分數最高
以此類推
你會發現說你觀察到的
其實就是一堆雜訊
你根本沒有辦法看到數字
那這個結果
假設我們還沒有教 Adversarial Attack
你可能會覺得好神奇
怎麼會這個樣子
機器看到一堆是雜訊的東西
它以為它看到數字嗎
怎麼會這麼愚蠢
但是因為我們已經教過 Adversarial Attack
所以想必你其實不會太震驚
因為我們在做 Adversarial Attack 的時候
我們就已經告訴你說
在 Image 上面加上一些
人眼根本看不到的奇奇怪怪的雜訊
就可以讓機器看到各式各樣的物件
那所以這邊也是一樣的道理
對機器來說
它不需要看到真的很像 0 那個數字的圖片
它才說它看到數字 0
你給它一些亂七八糟的雜訊
它也說看到數字 0
而且它的信心分數是非常高的
那所以其實如果你用這個方法
想用這種找一個圖片
讓 Image 的輸出
某一個對應到某一個類別的輸出
越大越好這種方法
你想要用這個方法來看到
看到這個機器心裡想像的
某一個 object 長什麼樣子
其實不一定有那麼容易
那像今天這個例子
今天這個手寫數字辨識的例子
你單純只是找說
我要找一張 Image
讓對應到某一個數字的信心分數越高越好
你單純只做這件事情
你找到了只會是一堆雜訊
怎麼辦呢
假設我們希望我們今天看到的
是比較像是人想像的數字
應該要怎麼辦呢
你在解這個 Optimization 的問題的時候
你要加上更多的限制
舉例來說
我們先對這個數字已經有一些想像
我們已經知道數字可能是長什麼樣子
我們可以把我們要的這個限制
加到這個 Optimization 的過程裡面
舉例來說
我們現在不是要找一個 X
讓 yi 的分數最大
而是要找一個 X
同時讓 yi 還有 R( X) 的分數都越大越好
那這個 R( X) 是什麼意思呢
這個 R( X) 是要拿來衡量說
這個 X 有多麼像是一個數字
舉例來說
今天數字就是由筆畫所構成的
所以一個數字它在整張圖片裡面
它有顏色的地方其實也沒那麼多
這一個圖片很大
那個筆畫就是幾畫而已
所以在整張圖片裡面
有顏色的地方沒有那麼多
所以我們可以把這件事情當做一個限制
硬是塞到我們找 X 的這個過程中
硬是塞到我們找 X 的這個最佳化
Optimization 的過程中
那期望藉此我們找出來的 X
就會比較像是數字
那如果加上一些額外的限制以後
舉例來說
我們希望這個白色的點越少越好
在這個這個 Constraint 呢
它的意思就是希望這個白色的點越少越好
那假設我們加上一個限制
希望白色的點越少越好的話
那我們看到的結果會是這個樣子
但看起來還是不太像數字了
不過你仔細觀察白色的點的話
還真有那麼一點樣子
比如說這個有點像是 6
這個有點像是 8
那如果你要真的得到
非常像是數字的東西
或者是假設你想要像那個文獻上
你知道文獻上有很多人都會說
他用某種這個 Global Explanation的方法
然後去反推一個 Image classifier
它心中的某種動物長什麼樣子
比如說你看下面這篇文獻
它告訴你說
它有一個 Image classifier
它用我們剛才提到的方法
它可以反推說
這個 Image classifier 裡面
心中的這個丹頂鶴長什麼樣子
或它心中的這個甲蟲長什麼樣子
來看這些圖片
這個真的都還蠻像丹頂鶴的
你完全可以看到說
這個有一隻鳥
有一隻丹頂鶴
然後牠有一隻腳插在水裡面
那這些圖片真的都可以看到甲蟲
在圖片裡面
但是你要得到這樣子的圖片
其實沒有你想像的那麼容易
你如果仔細去看這個文獻的話
你就會發現說
要得到這些圖片
你必須要下非常多的 Constraint
你要根據你對影像的了解
一個 Object 長什麼樣子的了解
下非常多的限制
再加上一大堆的 Hyperparameter Tuning
你知道我們解 Optimization Problem 的時候
也是需要這個調這個 Hyperparameter
比如說 Learning rate 之類的
所以下一堆 Constraint
調一堆參數
你才可以得出這樣的結果
所以這樣的結果並不是隨隨便便
就可以輕易的做出來的
好像剛才講的那種 Global Explanation 的方法
如果你真的想要看到非常清晰的圖片的話
現在有一個招數是使用 Generator
你就訓練一個 Image 的 Generator
你有一堆訓練資料
有一堆 Image
那你拿這一堆 Image 呢
來訓練一個 Image 的 Generator
比如說你可以用 GAN
可以用 VAE 等等
GAN 我們有教過了
VAE 我們沒有教過
反正就是你可以想辦法
訓練出一個 Image 的 Generator
Image 的 Generator 輸入
是一個 Low-dimensional 的 Vector
是一個從 Gaussian distribution 裡面
Sample 出來的低維度的向量叫做 z
丟到這個 Image Generator 以後呢
它輸出就是一張圖片 X
那這個 Image Generator
我們用 G 來表示
那輸出的圖片 X
我們就可以寫成 X 等於 G(z)
那怎麼拿這個 Image Generator
來幫助我們反推一個 Image classifier 裡面
它所想像的某一種類別
比如說某一隻貓
它心裡所想像的貓這個類別
或狗這個類別長什麼樣子呢
那你就把這個 Image Generator
跟這個 Image classifier 接在一起
這個 Image Generator 輸入是一個 z
輸出是一張圖片
然後這個 Image classifier
把這個圖片當做輸入
然後輸出分類的結果
那在剛才前幾頁投影片裡面
我們都是說我們要找一個 X
讓 y 裡面的某一個 dimension
讓某一個類別
它的信心分數越高越好
那我們說這個 X 叫做 X⋆
那我們剛才也看到說光這麼做
你往往做不出什麼特別厲害的結果
現在有了 Image Generator 以後
方法就不一樣了
我們現在不是去找 X
而是去找一個 z
我們要找一個 z
這個 z 通過 Image Generator 產生 X
再把這個 X 丟到 Image classifier
去產生 y 以後
希望 y 裡面對應的某一個類別
它的分數越大越好
我們找一個 z
z 產生 X
X 再產生 y 以後
希望 yi 越大越好
那這個可以讓 yi 越大越好的 z
我們就叫它 z⋆
找出這個 z⋆ 以後
我們再把這個 z⋆ 丟到 G 裡面
丟到 Generator 裡面
看看它產生出來的 Image X⋆ 長什麼樣子
好 那找出來的 X⋆ 長什麼樣子呢
假設你今天想要產生
比如說這個讓螞蟻分數
讓螞蟻的信心分數最高的 Image
那產生出來的螞蟻的照片
這個很厲害
這個長得是這個樣子
都看得出這個就是螞蟻
或者是要讓機器產生火山的照片
產生一堆照片
丟到 Classifier 以後
火山的信心分數特別高的
那確實可以找出一堆 Image
這些 Image 一看就知道像是火山一樣
好 但講到這邊你可能會覺得
這整個想法聽起來有點強要這樣
就是今天呢
你找出來的圖片
如果跟你想像的東西不一樣
今天找出來的螞蟻 火山跟你想像不一樣
你就說這個 Explanation 的方法不好
然後你硬是要弄一些方法去找出來那個圖片
跟人想像的是一樣的
你才會說這個 Explanation 的方法是好的
那也許今天對機器來說
它看到的圖片就是像是一些雜訊一樣
也許它心裡想像的某一個數字
就是像是那些雜訊一樣
那我們卻不願意認同這個事實
而是硬要想一些方法
讓機器產生出看起來比較像樣的圖片
那今天 Explainable AI 的技術
往往就是有這個特性
我們其實沒有那麼在乎
機器真正想的是什麼
其實我們不知道機器真正想的是什麼
我們是希望有些方法解讀出來的東西
是人看起來覺得很開心的
然後你就說
機器想的應該就是這個樣子
然後你的老闆 你的客戶
聽了就會覺得很開心
那今天 Explainable AI 往往會有這樣的傾向
好 那我們今天呢
就是跟大家介紹了 Explainable AI 的
兩個主流的技術
一個是 Local 的 Explanation
一個是 Global 的 Explanation
那其實 Explainable 的 Machine Learning
還有很多的技術
這邊再舉一個例子
舉例來說
你可以用一個比較簡單的模型
想辦法去模仿複雜的模型的行為
如果簡單的模型可以模仿複雜模型的行為
你再去分析那個簡單的模型
也許我們就可以知道
那個複雜的模型在做什麼
舉例來說
你有一個 Neural Network
因為它是一個黑盒子
你丟一堆 x 進去
比如說丟一堆圖片進去
它會給我們分類的結果
但我們搞不清楚它決策的過程
因為 Neural Network 本身非常地複雜
那我們能不能拿一個比較簡單的模型出來
比較能夠分析的模型出來
拿一個 Interpretable 的模型出來
比如說一個 Linear Model
然後我們訓練這個 Linear Model
去模仿 Neural Network 的行為
Neural Network 輸入 x1 到 xN
它就輸出 y1 到 yN
那我們要求這個 Linear Model
輸入的 x1到 xN
也要輸出跟 Black box
這個黑盒子一模一樣的輸出 y1 到 yN
我們要求這個 Linear 的 Model
去模仿黑盒子的行為
那如果 Linear 的 Model
可以成功模仿黑盒子的行為
我們再去分析 Linear Model 做的事情
因為 Linear 的 Model 比較容易分析
分析完以後
也許我們就可以知道
這個黑盒子在做的事情
當然這邊你可能會有非常非常多的問題
舉例來說
一個 Linear 的 Model
有辦法去模仿一個黑盒子的行為嗎
我們開學第一堂課就說過說
有很多的問題是 Neural Network 才做得到
而 Linear 的 Model 是做不到的
所以今天黑盒子可以做到的事情
Linear 的 Model 不一定能做到
沒錯
在這一系列的 work 裡面
有一個特別知名的叫做
Local Interpretable Model-Agnostic Explanations
它縮寫呢 是LIME
那像這種方法
它也沒有說
它要用 Linear Model 去模仿黑盒子全部的行為
它有特別開宗明義在名字裡面就告訴你說
它是 Local Interpretable
也就是它只要 Linear Model 去模仿這個黑盒子
在一小個區域內的行為
因為 Linear Model 能力有限
它不可能模仿整個 Neural Network 的行為
但也許讓它模仿一小個區域的行為
那我們就解讀那一小個區域裡面發生的事情
那這個是一個非常經典的方法
叫做 LIME
如果你想知道 LIME 是什麼的話
你可以看以下的錄影
那今天呢 我們就不再細講
那在作業裡面
我們也有有關 LIME 的作業
那這個部分就是留給大家
自己去閱讀文獻
自己去感受這個 LIME 是在做什麼
好 那這個部分呢
就是有關 Explainable Machine Learning 的簡介
那我們來看一下
線上有沒有同學有問問題的
好
我是可以那個看到大家的問題的
等一下
好 有同學問說
如果在 Classifier 上面多加一個都不是的選項
並把這個選項的可能性最小化會不會好一點
我試著來解讀你的問題
你的問題說
我們剛才 Trian 了一個 Image 的 Classifier
比如說 Digit 的 classifier
那如果我們在這個 Classifier 上多加一個選項
這個選項是我們輸入的東西
它不是任何的
不是任何的 Digit
那我們今天得到的結果會不會好一點
我沒有做過類似的實驗
在實作上如果我們今天是拿 Endless 的話
可能會有點小問題
因為 Endless 裡面並沒有任何圖片不是數字
我們做的圖片都是數字
那在另外一方面
假設我們說
我們今天真的蒐集到一些不是數字的圖片
然後多加一個類別說
有些東西就叫做它不是數字
然後我們要求說今天輸入一張圖片
同時要讓 Classifier 覺得它像是數字
同時又要它覺得說
不是數字的那個類別的機率越小越好
到底會發生什麼事情呢
我其實沒有試過
所以我一下子沒有非常好的答案
不過依照今天這個 Adversarial Attack
這麼容易成功的狀況
我認為還是非常有可能
可以找到一張 Image
它看起來不像是數字
但是 Network 覺得它是數字
同時它不是數字的機率又非常地小
但是我沒有試過
這個如果你有興趣的話
其實也可以自己試試看
看看結果會怎麼樣
好 這樣子不知道大家有沒有問題
我知道直播其實沒有非常地即時
所以我跟大家其實應該是有幾分鐘的
幾分鐘的 Delay
