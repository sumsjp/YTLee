臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://ai.ntu.edu.tw/
要講的就是 WGAN
我們之前已經有講到說，假設我們在 train GAN 的時候
最原始的 GAN，他量的是 generated data 跟 real data 之間的 js divergence
但是今天用 js divergence 來衡量的時候
其實有一個非常嚴重的問題，這個嚴重的問題，他的根源是什麼呢？
他的根源是，你的 generator 產生出來的 data distribution
跟你的 real data 的 distribution，往往是沒有任何重疊的
為什麼 generate 出來的 data， 跟 real 的 data，往往是沒有重疊的呢？
一個理由是，data 本質上的問題
因為我們通常相信說
image 是一個 high dimensional 的高維空間中的低維的 manifold
也就是說 image 它實際上在高維空間中的分佈
其實是低維的一個 manifold，就是你把在三維空間中
然後把一個二維的平面折到三維的空間中
這樣就是一個低維的 manifold
或是說你有一個二維的平面
如果 image 在這二維平面上的分佈 可能就像是一條曲線一樣
那你今天在一個高維空間中的兩個低維的 manifold
它們的 overlap 的地方
幾乎是可以忽略的，你有兩條曲線， 在一個二維的平面上
你有兩條曲線，他們中間重疊的地方
幾乎是可以忽略的，你的 Pdata 跟 PG
幾乎是可以忽略的
那這是第一個理由
有人可能會說，我不相信
我覺得 image 不是高維空間中的低維的 manifold
那我從另外一個角度來說服你
我們實際上在衡量 PG 跟 Pdata 的 divergence 的時候
我們是先做 sample 對不對
我們從兩個 data distribution 裡面做一些 sample 得到兩堆 data
再用 discriminator 去量他們之間的 divergence
那所以我們現在就算你的 PG 跟 Pdata 這兩個 distribution 是有 overlap 的
但是你是先從這兩個 distribution 裡面
做一些 sample，而且 sample 的時候， 你也不會 sample 太多
也就是從紅色 distribution sample 一些點
從藍色 distribution 再 sample 一些點
你 sample 了兩堆點
這兩堆點，它們的 overlap
幾乎是不會出現的，除非你 sample 真的很多
不然這兩堆點其實完全就可以 視為是兩個沒有任何交集的 distribution
所以就算是，本質上實際上 Pdata 跟 PG 有 overlap
但你在量 divergence 的時候 你是 sample 少量的 data 出來
才量 divergence，那在你 sample 出來的少量 data 裡面
PG 跟 Pdata，看起來就是沒有重合的
那怎麼辦？會遇到什麼樣的問題呢？
當 PG 跟 Pdata 沒有重合的時候
你用 js divergence 來衡量 PG 跟 Pdata 之間的距離
他們 PG 跟 Pdata 之間的差異
會對你 training 的時候，造成很大的障礙
什麼樣的障礙呢？
因為 js divergence 它的特性是這樣
如果兩個 distribution 沒有任何的重合，算出來就是 log 2
不管這兩個 distribution 實際上是不是有接近
只要沒有重合，沒有 overlap
算出來就是 log 2
所以今天假設你的 Pdata 是紅色這一條線
你有一個 G0，generator 0 號，G0 generate 出來的 distribution 是這樣一條線
你用 js divergence 去量，它們的 js divergence 是 log 2
這一個 case，你有一個 G1， 你算 G1 跟 Pdata 的 divergence
它也是 log 2
雖然實際上 G1 其實是比 G0 好的
因為 G1 產生出來的 data，其實相較於 G0
它更接近 real data distribution
所以實際上，我們知道 G1 比 G0 好
但從 js divergence 看起來，G1 和 G0 是一樣差的
除非說現在你的 G100 跟 Pdata 完全重合
這時候 js divergence，算出來才會是 0
只要沒有重合，他們就算是非常的靠近
你算出來也是 log2
所以這樣子會對你的 training 造成問題
因為我們知道說我們實際上 training 的時候，generator 要做的事情
就是想要去 minimize 你的 divergence
你用 discriminator 量出 divergence， 量出 js divergence，或其他 divergence 以後
generator 要做的事情是 minimize 你的 divergence
那對 generator 來說，PG0 跟 PG1，PG1 就是唱嘻哈的
這講過了，PG0 跟 PG1 他們其實就是一樣的， 他們其實是一樣差的
或是一樣好的，他們其實是一樣差的
所以對 generator 來說， 他根本就不會把 PG0 update 成 PG1
因為對他來說 PG0 跟 PG1 是一樣差的， 所以你根本沒有辦法把 PG0 update 到 PG1
你最後也沒有辦法 update 到 PG100，因為在 PG0 的地方就卡住了，他沒有辦法 update 到 PG1
所以你今天是用 js divergence 來衡量兩個 distribution，而恰好這兩個 distribution
又沒有太多重疊，他們重疊幾乎可以無視的時候
你會發現，你 train 起來是有問題的
那為什麼這兩個 distribution 沒有重疊
我們剛才試著用兩個不同面向來說服你說
data 的 distribution 跟 generator 的 distribution
非常可能就是沒有重疊
那假如你說你對 js divergence 不熟，你不知道說 js divergence 只要沒有重疊，算出來就是 log2
那我們從另外一個直覺的方向來告訴你說
為什麼今天只要兩個 distribution 沒有重合
他們算出來的 loss，他們量出來的 divergence 就會一樣
因為你想想看
我們今天實際上在量 js divergence 的時候， 我們做的事情是什麼？
我們是說，我們有兩群 data
把它視為是兩個 class
learn 一個 discriminator，learn 一個 binary 的 classifier
你用 minimize cross entropy 當成你的 loss function
你 learn 一個 binary 的 classifier
去分別出這兩組 data 之間的差異
但假設你 learn 的是一個 binary 的 classifier
其實只要這兩堆 data，沒有重合
它的 loss 就是一樣的，對不對？
因為假設你 learn 一個 binary 的 classifier，它可以完全的分辨
這兩堆 data，它可以完全的分辨， 這兩堆 data，只要沒有重合
binary 的 classifier，假如它 capacity 是無窮大
它就可以分辨這兩堆 data
在這兩堆 data 都可以分辨，在這兩堆 data 都可以分辨的前提之下
你算出來的 loss，其實會是一樣大或者是一樣小的
對不對，那我們所以在 train binary classifier 的時候， 你 train 到最後
你得到的那個 loss，或是你得到的那個 objective value
其實就是你的 js divergence
今天如果你的 binary 的 classifier
不管在這 case，還是在這個 case
它都可以完全把兩堆 data 分開
它算出來的 objective 都是一樣大， 它算出來的 loss 都是一樣小的
那意味著，你量出來的 divergence，就是一樣
總之這邊要告訴大家的事情是說
在原始的 GAN 裡面
當你 train 的是一個 binary classifier 的時候
你會發現，你是比較難 train 的
因為對你的 GAN 來說，這個 case 和這個 case
其實是一樣差的
或者是這邊是用另外一個直觀的方法來說明
假設這是你 real data 的 distribution
假設這是你 fake data 的 distribution
那我們今天要 learn 一個 binary classifier
這個 binary classifier 會給這些藍色的點 0 分
給這些綠色的點 1 分
那我們知道我們的 binary classifier 它的 output
是 sigmoid function
所以它在接近 1 這邊特別平
它在接近 0 這邊特別平
那你 train 好這個 classifier 以後
本來我們是期待說，你 train 一個 generator
這個 generator 會帶領這些藍色的點
順著這個紅色的線的 gradient
就 generator 會順著 discriminator 給我們的 gradient
去移動它的，去改變它的 generated distribution
所以我們本來是期待 generator
會順著這個紅色線的 gradient
把藍色的點往右移
但實際上你會發現說
這些藍色的點是不動的，為什麼
因為在這藍色的點附近的 gradient 都是 0
如果你今天是 train 一個binary 的 classifier， 它的 output 有一個 sigmoid function 的話
他在藍色的點附近，它是非常平的
你會發現說他的微分幾乎都是 0
你根本就 train 不動它
所以你真的實際上去 train 一個 binary classifier
你直接 train GAN，然後 train 一個 binary classifier 的話
你很容易遇到這樣子的狀況
過去的一個解法是說， 不要把那個 binary 的 classifier train 的太好
就不要 train 的太好，因為如果你 train 的太好的話
它把這些藍色的點，都給他 0
這邊就會變得很平
綠色點都給它 1，就會變得很平
不要讓它 train 的太好
不要 update 太多次
讓它在這邊仍然保有一些斜率
不要讓它 train 的太好
那這樣的問題就是，什麼叫做不要 train 的太好
你就會很痛苦這樣
你搞不清楚什麼叫做不要 train 的太好，你不能夠
在 train discriminator 的時候
當然太小力不行，太小力沒辦法分別 real 跟 fake data
太大力也不行，太大力的話
你就會陷入這個狀況，你會陷入這個微分是 0
沒有辦法 train 的狀況
但是什麼叫做不要太大力，不要太小力
你就會很難控制
那在早年還沒有我們剛才講的種種 tip 的時候
GAN 其實不太容易 train 起來，所以你 train 的時候通常就是
你一邊 update discriminator
然後你就一邊吃飯，然後你就看他 output 的結果
每 10 個 iteration 就 output 一次結果，我要看它好不好
如果發現結果不好的話，就重做這樣子
就一邊吃飯，一邊看那個結果
所以後來就有一個方法， 叫做 Least Square GAN (LSGAN)
那 LSGAN 做的事情，就是把 sigmoid 換成 linear
那這樣子是怎麼回事呢？
這樣子你就不會有這種在某些地方特別平坦的情形
因為你現在的 output 是linear 的
那我們本來是一個 classification problem
現在把 output 換成了 linear 以後呢
它就變成一個 regression 的 problem
這個 regression 的 problem 是怎麼樣呢？
這 regression problem 是說
如果是 positive 的 example
我們就讓它的值越接近 1 越好
如果是 negative example， 我們就讓它的值越接近 0 越好
但其實跟原來 train binary classifier 是非常像的
只是我們把 sigmoid 拔掉，把它變成 linear
那今天很多人都會用的一個技術，叫做 WGAN
Wassertein Distance GAN， 這邊有一個冷知識，就是唸法問題
WGAN 是什麼呢？在 WGAN 裡面我們做的事情是
我們換了另外一種 evaluation 的 measure
來衡量 Pdata 跟 PG
我們之前說在原來的 GAN 裡面
要衡量 Pdata 跟 PG 的差異
我們用的是 js divergence
在我們講 fGAN 的時候我們說，你不一定要用 js divergence，你其實可以用任何其他的 f divergence
那在 WGAN 裡面用的是 Earth Mover's Distance
或者又叫 Wassertein Distance
來衡量兩個distribution 的差異， 那他其實不是 f divergence 的一種
所以在 fGAN 那個 table，其實是沒有 WGAN 的
所以這邊是另外不一樣的方法
同樣的地方是，就是你換了一個 divergence
來衡量你的 generated data 和 real data 之間的差異
那我們先來介紹一下，什麼是 Earth Mover's Distance
Earth Mover's Distance 的意思是這樣
假設你有兩堆 data，這兩個 distribution 叫做 P and Q
那 Earth Mover's Distance 的意思是説，你就想像成你是在開一台推土機
那你的土從 P 的地方剷到 Q 的地方
就 P 的地方是一堆土
Q 的地方是你準備要把土移過去的位置
然後你看你那推土機
把 P 的土鏟到 Q 那邊，所走的平均的距離
就叫做 Earth Mover's Distance， 就叫做Wasserstein Distance
那這個 W Distance 怎麼定義呢？
如果是在這個非常簡單的 case， 我們假設 P 的 distribution
就集中在一維空間中的某一個點
Q 的 distribution，也集中在一維空間中的某一個點
如果你要開一台推土機把 P 的土
挪到 Q 的地方去
那假設 P 跟 Q 它們之間的距離是 d
那你的 W Distance
P 這個 distribution 跟 Q distribution 的 W Distance 就等於 d
但是實際上你可能會遇到一個更複雜的狀況
假設你 P distribution 是長這個樣子
假設你 Ｑ distribution 是長這個樣子
那如果你今天要衡量這兩個 distribution 之間的
Earth Mover's Distance，假設你要衡量他們之間的 W Distance，怎麼辦呢？
為什麼會造成問題呢？因為你會發現說
當你要把 P 的土鏟到 Q 的位置的時候
其實有很多組不同的鏟法
舉例來說你可以說我把這邊的土挪到這邊來
把這邊的土挪到這邊來，想辦法把 P 變成 Q，
是你也可以說我捨近求遠，我故意把這個土鏟到這邊來
我把這個土鏟到這邊來，一樣也可以變成 Q
但是你的推土機走的平均距離是不一樣的
這樣就會變成說同樣的兩個 distribution
推土機走的距離不一樣，你不知道哪個才是 W distance
我們說 W distance 就是你把某一堆土
鏟到你目標的位置去，平均所走的距離就是， W distance
但現在你的問題就是，鏟土的方法有很多種
到底哪一個才是 W distance 呢？
所以今天 w distance 實際上的定義是說
窮舉所有可能鏟土的方法
每種鏟土的方法，我們就叫它一個
moving plan，叫它一個鏟土的計畫
窮舉出所有鏟土的計畫，有的可能是
比較有效的，有的可能是捨近求遠的
窮舉出所有鏟土的計畫
每一個鏟土的計畫，推土機平均要走的距離通通都算出來
看哪一個距離最小，就是 W distance
那今天在這個例子裡面
其實最好的剷土的方法，是像這個圖上所示這個樣子
那我們把同樣一堆土，就用同樣的顏色來表示它
所以你把這堆土，挪到這個地方
你把這堆土，挪到這個地方
粉紅色這邊土，也挪一點到這個地方
這樣你用這一個 moving plan 來挪土的時候
你的推土機平均走的距離是最短的
這個平均走的距離就是 W distance
那這邊是一個更正式的定義
如果你要把 Q distribution
應該是把 P 挪到 Q， 但是其實意思是一樣的，它是對稱的
所以 P 挪到 Q，Q 挪到 P，你算出來的距離是一樣的
不過我們剛才都是講 P 挪到 Q 的樣子
假設你要把這個 P 的圖挪到 Q 這邊
那首先你要訂一個 moving plan
那什麼是一個 moving plan 呢？
moving plan 其實你要表現它的話，你可以把它化做是一個 matrix
把它化做是一個矩陣
今天這個矩陣，就是某一個 moving plan
我們把它叫做 gamma
那在這個矩陣上的每一個 element
就代表說，我們要從縱座標的這個位置
挪多少土到橫座標的這個位置
今天的每一個 element 的值，就代表說我們要從這個地方挪多少土
到這個位置上面去
這邊的值越亮，就代表說，我們挪的土越多
所以你會發現說，我們要從這邊挪很多的土到這邊...
如果是這一塊土，我們要挪一些到這裡
我們要挪一些到這裡，我想大家應該會了解我的意思
那因為這是一個 moving plan
所以實際上你會發現在它的 column
你把 column 這些值合起來就會變成這個 bar 的高度
如果你把 row 的這些值合起來
就會變成這個 bar 的高度，因為這邊所有的土
都會挪到這邊，這邊所有的土都會分配到這個位置
所以這邊合起來就是這個 bar 的高度
這邊合起來就是這個 bar 的高度
接下來你要做的事情是
假設給你一個 moving plan
這個 moving plan 叫做 gamma
你會不會算用這個 moving plan 挪土的時候要走多少距離呢？
那它很簡單嘛，你就算說假設這邊每一個縱軸的值
叫做 xp
橫軸的每一個值，叫做 xq
那你先算說從 xp 的這個位置， 你就窮舉所有的xp 跟 xq 的組合
然後再算說從 xp 你要挪多少的土到 xq 去
那這個土要挪多少是受這個 gamma 決定的，是 這個moving plan 決定的
然後你再算 xp 跟 xq 之間的距離
再 summation over 所有 xp 跟 xq 的 pair， 這個就是 moving plan
就是給一個 moving plan gamma 的時候
你算出來挪土的 average distance
那接下來這個 W distance 或 Earth mover's distance， 它做的事情就是
窮舉所有的 gamma
窮舉所有可能的 gamma
看哪一個gamma 他算出來的距離最小
這個最小的距離就是 W distance
所以你會發現說 W distance， 它是一個很神奇的 distance，為什麼？
今天一般的 distance 就是直接套 一個公式運算出來你就得到結果，對不對？
但 W distance，你要算它的話
你要解一個 optimization problem，很麻煩
因為你要窮舉所有的 gamma
看哪一個 gamma 可以算出來距離最小， 那個才是 W distance
所以今天給你兩個 distribution
要算 W distance 是很麻煩的
因為你要解一個 optimization problem
才算得出 W distance
那我們等一下再講說怎麼用 discriminator 來衡量 W distance
但我們現在先來看說如果用 W distance 來衡量兩個 distribution 的距離
有什麼樣的好處，那我們之前有看到說
假設你今天是用 js divergence
這一個 G0 跟 data 的距離
G50 跟 data 之間的距離
對 js divergence 來說，根本就是一樣的
除非你今天可以把 G0 一步跳到 G100
然後讓 G100 正好跟 Pdata 重疊
不然 machine 在 update 你的 generator 參數的時候
它根本沒有辦法從 G0 update 到 G50
因為在這個 case，js divergence 其實是一樣大
那這個其實就讓我想到一個演化上的例子
我們知道說人眼是非常的複雜
是一個非常複雜的器官
有人就會想說，憑藉著天擇的力量，不段的突變
到底怎麼可能讓生物突然產生人眼呢？
那也許天擇的假說並不是正確的
但是實際上今天生物是怎麼從完全沒有眼睛， 變到有眼睛呢？
他並不是一步就產生眼睛
而是透過不斷微小的突變的累積
才產生眼睛這麼複雜的器官
比如說在一開始，生物只是在皮膚上面
產生一些感光的細胞
那透過突變，某一些細胞具有感光的能力
也許是做得到的
接下來呢，感光細胞所在的那個皮膚
就凹陷下去，凹陷的好處是說
光線從不同方向進來，就不同的感光細胞會受到刺激
那生物就可以判斷光線進來的方向
接下來因為有凹洞的關係所就會容易堆灰塵
就在裡面放了一些液體，然後免得灰塵跑進去
然後再用一個蓋子把它蓋起來， 最後就變成眼睛這個器官
但是你要直接從皮膚就突然突變
變異產生出眼睛是不可能的
所以就像人，沒有辦法一下子就長出翅膀變成一個鳥人一樣
天擇只能做小小的變異
而每一個變異都必須是有好處的
那才能夠把這些變異累積起來， 最後才能夠產生巨大的變異
所以從產生感光細胞，到皮膚凹陷下去
到產生體液把蓋子蓋起來等等
每一個小小步驟對生物的生存來說都是有利的
所以演化才會由左往右走，生物才會產生眼睛
那如果要產生翅膀可能就比較困難，因為假設你一開始
產生很小的翅膀，沒有辦法飛的話
那就沒有佔到什麼優勢
所以人就沒有辦法一下子突變產生翅膀變成一個鳥人
那對這個 generator 來說也是一樣的
它如果說 G50 並沒有比 G0 好
你就沒有辦法從 G0，變到 G50
然後慢慢累積變化變到 G100
但是如果你用 W distance 就不一樣了
因為對 W distance 來說
這兩個 distribution 他們之間的差異是 d0
這兩個 distribution 之間的差異是 d50
d50 是比 d0 還要小的，所以從 W distance 來說
這個 distribution 是比這個 distribution 好的
所以對 generator 來說，它就可以 update 參數
把 distribution 從這個地方挪到這個地方
直到最後你 generator 的 output 可以和 data 真正的重合
那接下來要問的問題就是
我們現在要量 PG 和 Pdata 之間的差異
我們現在要量 PG 和 Pdata 之間的 W distance
我們要怎麼去改 discriminator
讓他可以衡量 PG 和 Pdata 的 W distance 呢？
這邊就是直接告訴大家結果，這個推論的過程
其實是非常複雜的，這個證明過程其實很複雜， 所以我們就直接告訴大家結果
怎麼樣設計一個 discriminator，它 train 完以後
它的 objective function 的值，就是 W distance
就像下面這個樣子，式子就像下面這個樣子
這個式子其實看起來很單純，其實是也很容易理解的
這個式子的意思是什麼？
意思是說如果今天 x 是從 Pdata 裡面 sample 出來的
讓它的 discriminator 的 output 越大越好
如果 x 是從 PG 裡面 sample 出來的
讓它的 discriminator 的 output 越小越好
但是你不能夠光只讓從 data 裡面 sample 出來的 x
和從 PG 裡面 sample 出來的 x
你不能夠只讓這些從 Pdata sample 出來的 x， 它的值越大越好
但 PG 裡面 sample 出來的 x，他的值越小越好
你還要有一個 constrain，這 constrain 是這樣
discriminator 必須要是一個 1-Lipschitz function
那可能大家不見得知道 Lipschitz function 是什麼
等一下會給大家定義，你先記得說
所謂的 1-Lipschitz function 意思是說
這個 discriminator，他是很平滑的， 他是很 smooth 的
這個就叫做 1-Lipschitz function
為什麼這個 1-Lipschitz function 是必要的呢？ 當然你可以說根據證明
就是要這麼做，算出來才是 W distance
但是你也可以非常的直觀地了解這件事
怎麼樣非常的直觀地了解這件事呢
你的直觀的了解方法可以是這樣
這個是 generator 產生出來的 sample
這個是從 real data 裡面 sample 出來的 samples
如果我們不考慮這個 constrain
我們只說要讓 discriminator 的分數越大越好，這些 data
帶到discriminator 裡面分數越大越好
這些 data 帶到discriminator 裡面分數越小越好
那你 train 的時候 discriminator 就會知道說
這邊的分數要讓他一直拉高一直拉高
這邊的分數要讓他一直壓低一直壓低
如果你的這兩堆 data 是沒有 overlap 的
我們講過 real data 跟 generated data
它很有可能是沒有 overlap 的
如果這兩堆 data 是沒有 overlap 的
今天如果只是 discriminator 一味的要讓這些 data
值越來越高，這邊 data 值越來越小
它就崩潰了
因為這個 training 永遠不會收斂
他這個值可以越來越大直到無限大
他這個值可以越來越小直到無限小
你的 training 永遠不會停止
所以怎麼辦，你必須要有一個額外的限制
這個額外的限制是說
你今天的 discriminator，必須要是夠平滑的
因為如果你今天的 discriminator 沒有給任何限制
那它可能 real data 這邊就跑到無窮大
這邊就會跑到無窮小
但是假設這邊跑到無窮大，這邊跑到無窮小
這一段距離之間的差距
就會變得很大，對不對，它們就會拉得很開
那你的這個 discriminator 它就不平滑了
那我們說，我們給一個限制是
discriminator 必須是平滑的
這樣就可以強迫你在 learn 這個 discriminator 的時候
不會 learn 到說這邊一直上升，這邊一直下降
永遠不會停下來，那最終還是會停下來的
那實際上什麼是 1-Lipschitz function 呢？
一個 Lipschitz function 它的定義是這個樣子的
你有一個 function 叫做 f
如果它是一個 Lipschitz function 的話呢
他滿足下面的這個條件
你把 x1 帶到 f 裡面
你把 x2 帶到 f 裡面
然後把 f of x1 減掉 f of x2
這個差距必須小於等於 K 倍的 x1 跟 x2 之間的距離
所以這個 Lipschitz function 它的意思到底是什麼？
他的意思是說，這邊是 output 的 change
這邊是 input 的 change，就是你的 input 從 x1 改到 x2
然後你的 output 會從 f of x1 變到 f of x2
那接下來這個 input 的差距
乘上 K 倍，要大於等於 output 的差距
意思就是說，當你 input 有一個變化的時候
output 的變化不能太大
才能夠讓 input 的差距乘上 K 倍
大於等於 output 的差距
也就是說你 output 的差距不能夠太大
不能夠比 input 的差距大很多
那所謂的 1-Lipschitz function 意思就是說
把 k 設為 0，就是 1-Lipschitz function
當你把 K 設為 1 的時候是 1-Lipschitz function
當把 K 設為 1 的時候，意味著說，你 output 的變化
總是比 input 的變化要小的，那意味著說
這個 function 它是一個 smooth 的 function
舉例來說現在假設有兩個 function，一個是綠色的 function
一個是藍色的 function
那像藍色的 function 它變化這麼劇烈，它變化這麼劇烈
在某些地方，它的 output 的變化
可能會大過 input 的變化
所以那就不是 1-Lipschitz function
那像藍色這個 function，他很平滑，它的變化很小
它在每一個地方，output 的變化都小於 input 的變化
那它就是一個 1-Lipschitz function
那如果這個你記不起來也沒有關係，反正你就記得說
一個 function 只要很 smooth， 它就是一個 1-Lipschitz function
只要很平滑它就是一個 1-Lipschitz function
接下來問題是，怎麼解這個 optimization problem?
如果我們把這個 constrain
這個給 discriminator 的 constrain 拿掉
你就用 gradient ascent 去 maximize 它就好了，對不對
完全沒有任何的問題
對不對，你就用 gradient ascent 你就可以
maximize 大括號裡面的這個式子
但現在問題是你的 discriminator 是有 constrain 的
我們一般在做 gradient decent 的時候， 我們並不會給我們的參數 constrain
你會發現說如果你要給參數 constrain 的話
在 learning 的時候，還蠻困難的，你會
不太清楚應該要怎麼做
所以你今天要給 discriminator constrain
是蠻困難的，但實際上到底是怎麼做的呢？
在最原始的 W GAN 裡面
他的作法就是 weight clipping
weight clipping 的想法很簡單， 它的想法是這樣子，它說
我們今天一樣用原來的 gradient decent
或者說用 gradient ascent，因為現在要 maximize 你的 objective function，所以其實是 gradient ascent
用 gradient ascent 去 train 你的 model， 去 train 你的 discriminator
但是 train 完之後，如果你發現你的 weight
大過某一個你事先設好的常數 c，就把它設為 c
如果小於 -c 就把它設為 -c，結束
那他希望說透過這個 weight clipping 的技術
可以讓你 learn 出來的 discriminator，它是比較平滑的
因為你限制著它 weight 的大小
所以可以讓這個 discriminator 它在 output 的時候
沒有辦法產生很劇烈的變化
這個 discriminator 可以是比較平滑的
但是你可能會問說，加了這個限制就可以讓他變成 1-Lipschitz function 嗎？
答案就是不行，就是這樣子
因為一開始也不知道要怎麼解這個問題， 所以就胡亂想一招這樣子
能動再說，那我覺得有時候做研究就是這樣子嘛
不需要一次解決所有的問題， 在 W GAN 的第一篇原始 paper 裡面
他就 propose 這個想法，他就 propose 説
如果 D 是 1-Lipschitz function
那我們就可以有量 W distance
但他不知道要怎麼真的 optimize 這個 problem， 沒關係先胡亂提一個
擋著先，先propose，先把 paper publish 出去， 再慢慢想這樣
所以先做一個方法叫做 weight clipping
那 weight clipping 就是非常簡單
那我們說在作業裡面你可以選擇實作 weight clipping
那很容易，這個就是秒做
那當然它的 performance 不見得是最好的
因為你用這個方法他並沒有真的讓 D 限制在 1-Lipschitz function
它就只是希望透過這個限制
可以讓你的 D 是比較 smooth 的
那這個是 W GAN 最原始的版本，用的是 weight clipping
後來就有一個新的招數， 他不是用 weight clipping，它是用
gradient 的 penalty
那這個技術叫做 improved WGAN
或者是又叫做 WGAN GP
那 WGAN GP 這邊想要講的是什麼呢？他是說他的觀察是這個樣子
如果今天一個 function 它是 1-Lipschitz function，if and only if
保證它呢它在每一個位置的 gradient 的 norm
都必須要小於等於 1
這兩件事情其實是等價的， 一個 discriminator 它是 1-Lipschitz function
等價於，如果你對所有可能的 input x
都拿去對 discriminator 求他的 gradient 的話
這 gradient 的 norm 總是會小於等於 1 的， 這兩件事情是等價的
所以今天假設你不知道怎麼弄它，那你能不能弄這一項呢？
你不知道怎麼限制你的 discriminator，是 1-Lipschitz function
你能不能限制你的 discriminator 對所有的 input x
去算他的 gradient 的時候，它的 norm
都要小於等於 1 呢？ 這件事顯然是有辦法 approximate 的
要怎麼 approximate 呢？這個 approximate 方法就是說
在原來的這項後面，再加一個 penalize 的項
這一項的作用有點像是 regularization
這一項的作用是說，它對所有的 x 做積分
然後呢，取一個 max 0 然後 gradient 的 norm 減 1
也就是說如果 gradient 的，如果這 gradient 的 norm 大於 1 的話
這邊就有值，就有 penalty，如果這個 gradient norm 小於 1 的話
那就沒有 penalty，如果 gradient norm > 1
這一項就會有值，就會有 penalty
所以今天在 train 這個 discriminator 的時候
今天在 training 的時候會儘量希望呢
這個 discriminator 它的 gradient norm，小於等於 1
但實際上這麼做會有一個問題，因為你不可能對所有的 x 都做積分
我們說一個 function 是 Lipschitz function
它的 if and only if 的條件是對所有的 x
這件事情都要滿足
但是你無法真的去 check 説
不管你是在 train 還是在 check 的時候， 你都無法做到說 sample 所有的 x
讓他們通通滿足這個條件
這件事情你根本做不到
x 代表是所有可能的 image 喔，那個 space 這麼大
你根本無法 sample 所有的 x
保證這件事情成立，所以怎麼辦？
這邊做的另外一個 approximation 是說
假設 x 是從某一個事先定好的 distribution
這個事先定好的 distribution，叫做 P penalty
這個 x 是從 P penalty 那個 distribution sample 出來的
我們只保證說在 P penalty 那個 distribution 裡面的 x
它的 gradient norm 小於等於 1
其他部分就管不了那麼多，就無視他
管不了那麼多，你不可能讓所有的 x 它的 gradient norm 都小於 1
我們現在只能確保說，我們從一個 distribution 叫 P penalty
裡面去 sample 出 x
在那個 P penalty distribution 被涵蓋的範圍內
我們讓 x gradient norm 小於 1
這個 P penalty 長什麼樣子呢？
在 W GAN GP 裡面，它 P penalty 是長這個樣子的
它說從 Pdata 裡面 sample 一個點出來
從 PG 裡面 sample 一個點出來
把這兩個點相連，然後在這兩個點中間
做一個 random 的 sample，就在這兩個點所連成的直線間
做一個 random 的 sample， sample 出來的 x 就當作是從 P penalty sample 出來的
這個紅色的點可以是 P data 裡面 sample 出來的任何點
這個黃色的點可以是 PG 裡面 sample 出來的任何點
從這兩個點連起來
從這個連線中間去 sample，就是 P penalty
所以 P penalty 的分佈大概就是在 PG 和 P data 中間
就是藍色的這一個範圍
那你可能會問說，為什麼會是這樣子呢？
為什麼我們本來應該對， 整個 space 整個 image 的 space 所有的 x
通通去給它 penalty
但為什麼只在藍色的部分給 penalty 是可以的呢？
在原始的 improved WGAN paper 它是這樣寫的，他說
剛才講過很多次了，給每個地方都給它 gradient penalty 是不可能的，他說
就是說實驗做起來，這樣就是好的這樣子
實驗做起來，這樣看起來是 ok 的
但是你從直覺上也可以了解說這麼做是 make sense 的
怎麼說這麼做是 make sense 的呢
因為我們今天在 train GAN 的時候
我們不是要 update 那個 generator
然後讓 generator 順著 discriminator 給我們的 gradient 的方向
挪到 P data 的位置去嗎，也就是說
我們要讓 generator 的這些點
慢慢往作左移，往左移，在這個例子裡面 generator 的點，要慢慢往左移，挪到 P data 的位置去
那所以 generator 在挪動它的位置的時候
在 update 參數的時候， 它看的就是 discriminator gradient
所以應該只有在 generator output 的 distribution
跟 real data 的 distribution，中間的連線這個區域
才會真的影響你最後的結果，對不對
因為今天這個 PG 是看著這個地方的 gradient， 這個地方的斜率
去挪動它的參數，去 update 它的參數的
所以只有 PG 和 P data 之間的區域
你需要去考慮你的 discriminator 的 shape*** 長什麼樣子
其他這些地方，反正你的 generator 也走不到
那你就不需要去考慮 discriminator 的 shape 長什麼樣子
所以我覺得在 PG 和 Pdata 中間做 sample 也是有道理的，也算是 make sense 的
接下來要再做另外一個 approximation
實際上在 WGAN GP 裡面
他真的做的事情是這樣子， 他說本來我們是希望這個 gradient norm
如果大過 1 給它 penalty，小於 1 不用 penalty
因為我們就是要 gradient norm 小於 1 嘛， 沒有說小於 1 會怎麼樣
小於 1 是不用懲罰的
但實際上在 WGAN 的 implementation 裡面，他說
我們實際上 training 的時候， 我們是希望 gradient 越接近 1 越好
本來理論上我們只需要 gradient < 1
大過 1 給他懲罰，小於 1 沒有關係
但實作的時候說，gradient norm 必須離 1 越接近越好
gradient norm > 1 有懲罰，< 1 也有懲罰
為什麼會這樣呢，在 paper 裡面說
實驗上這麼做的 performance 是比較好的
當然這個 improved WGAN 也不會是最終的 solution
實際上你很直覺的會覺得，它是有一些問題的
舉例來說我這邊舉一個例子
假設紅色的曲線是你的 data
你在 data 上 sample 一個點是紅色的
你在黃色的是你的 distribution，這邊sample 一個點
你說把他們兩個連起來，然後給這邊的這些線 constrain
你不覺得其實是不 make sense 的嘛
因為如果我們今天照理說
我們只考慮黃色的點，要如何挪到紅色的點
所以照理說，我們應該在紅色的這個地方
sample 一個點跟黃色是最近的
然後比如說 sample 在這邊
然後只 penalize 這個地方跟黃色的點之間的 gradient
這個才 make sense 嘛，對不對，因為
到時候黃色的點，其實它要挪動的話， 他也是走走走就走到最近的地方
他不會跨過這些已經有紅色點的地方跑到這裡來
這個是有點奇怪的，我認為他會走這個方向
而不是走這樣的方向
所以你 gradient penalty penalize 在這個地方
是有點奇怪的
那其實 improved WGAN 後面還有很多其他的變形，大家可以自己找一下
其實像今年的 ICLR 2018
就有一個 improved WGAN 的變形，叫做
improved 的 improved WGAN 這樣子
那 improved 的 improved WGAN 他一個很重要的不同是說
它的 gradient penalty 不是只放在 Pdata 跟 PG 之間
他覺得要放在這個紅色的區塊
而且還有另外一個也很像 WGAN 的變形叫做那個 dragon
就是龍的意思，paper title 就是 How to train your dragon？
我發現它最開始的版本叫做 How to train your dragon？後來 submit 到 conference 的時候
沒有很討喜，所以後來名字就通通改了這樣
他在 Archive 上名字是有換過，本來叫 How to train your dragon？
它已經改成一個正常的名字
那篇 paper 也是 propose 説，今天你要放 gradient penalty，應該放在 Pdata 的地方
是有幫助的
其實還有另外一招叫做 spectrum norm
spectrum norm 是什麼呢？spectrum norm 是說
剛才那個那個什麼 WGAN 什麼都是一堆 approximation 嘛
你聽了也覺得不太舒服這樣，就他除了很多 experimentally 就是這個樣子，你聽了也不太舒服
spectrum norm 是這樣，他 propose 了一個方法，這個方法
真的可以限制你的 discriminator
在每一個位置的 gradient norm
都是小於 1 的，本來 WGAN GP 它只是 penalize 某一個區域的 gradient norm < 1
但是 spectrum norm 這個方法可以讓你的 discriminator learn 完以後
它在每一個位置的 gradient norm都是小於 1
那細節，這個也是最近的 paper ICLR 2018 的 paper
那細節我們就不提，大家就自己去看看， 看看你作業裡面有沒有辦法 implement 這一個
這個我們還是說一下這個 GAN 的 algorithm
我們看一下怎麼從 GAN 改成 WGAN
那原來 GAN algorithm 大家都很熟
就 sample 一堆 image，從原來的 data 裡面 sample 一堆 image
然後 sample 一堆 vector
根據這些 vector 產生 generated 的 image x tilde
然後 learn 一個 discriminator
learn 的 objective function 是這個樣子，我們說這 objective function 就是量 js divergence
根據這個 objective function 去 update 你的 discriminator，然後這邊你通常會跑 k 次
接下來呢你再從你的某個 distribution 裡面 sample 一些 noise
從 prior distribution 裡面 sample 一些 noise
然後去 update 你的 generator
如果你要把原來的 GAN 改成 WGAN 的話
你只需要做這幾個改變，第一個改變是
首先你要把 log D of x 改成 D of x
你要把 log (1- D of x) 改成 D of x，結束，這個就是秒改
那這邊要注意的地方是，在原來的 GAN 裡面
你的 discriminator 有 sigmoid
這些是不是必要的就有那個 sigmoid 你算出來才會是 js divergence
總之它是有那個 sigmoid 的
但是在 WGAN 裡面，你要把 sigmoid 拔掉
讓它的 output 是 linear 的，算出來才會是 W distance
所以你要把它的 output 拔掉
接下來你在 update 你的 discriminator， 在 train 你的 discriminator 的時候呢
要注意一下就是你要加上 weight clipping
或者是加上 gradient penalty，不然這個 training 可能是不會收斂的
它會一直 train 下去，你要加上 weight clipping 或 gradient penalty
在 train generator 的時候也很容易
你就把本來是 log (1 - D of (G of z)) 改成 D of (G of z)，結束了
所以你總共只要改 4 個地方，一個地方是改這個 objective function
把 sigmoid 拿掉
然後把 weight clipping 加進去
然後改一下 generator update 的 objective function， 就結束了
其實我們還有時間稍微講一下，還有一個東西叫做 Energy based GAN，就是 EBGAN
其實 EBGAN 還有另外一個變形叫做， 把 EB 改過來就變成 BEGAN 這樣子
另外一個變形，那我們就不講， 我們就講Energy based GAN，EBGAN 就好
EBGAN 是什麼，EBGAN 他唯一跟一般的 GAN 不同的地方是
它改了 discriminator 的 network 架構
本來 discriminator 是一個 binary 的 classifier 對不對
它現在把它改成 auto encoder，就這樣
generator 不要動它， 但你的 discriminator 是一個 auto encoder
你的 discriminator 是這樣，input 一張 image
有一個 encoder，把它變成 code，然後有一個 decoder 把它解回來
接下來你算那個 auto encoder 的 reconstruction error
把 reconstruction error 乘一個負號， 就變成你的 discriminator 的 output
所以 Energy based GAN 的意思就是說
你這個 discriminator 跟一般的 discriminator， 其實也是一樣，input 一張 image
output 就是一個 scalar，那這個 scalar 是怎麼來的？
這個 scalar 是從 auto encoder 算出來的
本來你是說你有一個 binary classifier，他的 output 直接就是一個 scalar
現在變成說，你的 discriminator 是一個 auto encoder
auto encoder 丟一張 image 進去
它的 reconstruction error 就是你的 discriminator 的 output
也就是說這個 energy based GAN 它的假設就是
假設某一張 image 它可以被 reconstruction 的越好
它的 reconstruction error 越低
代表它是一個 high quality 的 image
如果它很難被 reconstruct，它的 reconstruction error 很大
代表它是一個 low quality 的 image
那這種 EBGAN 他到底有什麼樣的好處呢？
我覺得他最大的好處就是，你可以 pre train 你的 discriminator
你知道 auto encoder 在 train 的時候，不需要 negative example
你在 train 你的 discriminator 的時候
你需要 negative example，對不對
你在 train 你的 discriminator 的時候， 它是一個 binary classifier
所以你要從你的 data 裡面去 sample 一些 real image
再用你的 generator sample 一堆 fake image
然後再去 train 你的 discriminator， 去分別 real 跟 fake image
所以這個東西無法 pre trained
對不對，你沒有辦法只拿 positive example 去 train 一個 binary classifier
你沒辦法 pre train 它，所以這邊會造成的問題是什麼？會造成的問題是
一開始你的 generator 很弱
所以它 sample 出來的 negative example 也很弱
用很弱的 negative example 你 learn 出來就是一個很弱的 discriminator
那 discriminator 必須要等 generator 慢慢變強以後， 它才會越來越強
所以你 discriminator 一開始不會很厲害
你要 train 很久，才會讓 discriminator 變得比較厲害
但是 energy base GAN 就不一樣
discriminator 是一個 auto encoder
auto encoder 是可以 pre trained， auto encoder 不需要 negative example
你只要給它 positive example
讓它去 minimize reconstruction error 就好了
所以你真的要用 energy base GAN 的時候
你要先 pre-train 好你的 discriminator
先拿你手上的那些 real 的 image， 去把你的 auto encoder 先 train 好
所以你一開始的 discriminator，會很強
所以因為你的 discriminator 一開始就很強
所以你的 generator 一開始就可以 generate 很好的 image
所以如果你今天是用 energy base GAN， 你會發現說你前面幾個 epoch
你就可以還蠻清楚的 image
那這個就是 energy base GAN 一個厲害的地方
那 energy based GAN 實際上在 train 的時候， 還有一個細節你是要注意的，就是
今天在 train energy based GAN 的時候， 你要讓 real 的 example 它得到的分數越大越好
也就是 real example 它的 reconstruction error 越小越好
但是要注意你並不是要讓 generated 的 example 它的分數越小越好
或它的 reconstruction error 越大越好，為什麼？
因為建設是比較難的破壞是比較容易的
reconstruction error 要讓它變小很難，因為
你必須要 input 一張 image 把它變成 code
再 output 同樣一張 image，這件事很難
但是如果你要讓 input 跟 output 非常不像
這件事太簡單了，input 一張 image
你要讓它 reconstruction error 很大，不就 output 一個 noise 就很大了嗎？
所以如果你今天太專注於說要 maximize 這些 generated image 的 reconstruction error
那你的 discriminator， 到時候就學到說看到什麼 image 都 output 那個 noise
就這邊反正就犧牲掉就好，反正這個也增加不了多少
這邊儘量壓低都 output noise，故意把它壓低
這個時候你的 discriminator 的 loss 可以把它變得很小， 但這個不是我們要的
所以實際上在做的時候，你會設一個 margin 説
今天 generator 的 reconstruction loss 只要小於某一個 threshold 就好
當然 threshold 這個 margin 是你要手調的
所以就多一個參數要調就是了
這個 margin 意思是說 generator loss 只要小於 margin 就好
不用再小，小於 margin 就好，不用讓它再更小
那今天其實還有另外一個東西也是有用到 margin 的概念，叫做
Loss-Sensitive GAN
這個時候要講這個它有一個很有趣的地方就是，它也是
LSGAN 這樣
我們有一個 least square GAN， 這邊還有一個 Loss-Sensitive GAN
那 LSGAN 它也有用到 margin 的概念
我們之前在做 WGAN 的時候是說
如果是 positive example，就讓他的值越大越好
negative example，就讓他的值越小越好
但是假設你已經有些 image，其實已經很 realistic
你讓它的值越小越好，其實也不 make sense 對不對
所以今天在 LSGAN 裡面它的概念就是，他加了一個叫做 margin 的東西
就是你需要先有一個方法， 去 evaluate 說你現在產生出來的 image 有多好
可能是把你產生出來的 image 呢
這邊有一個錯又忘了改，x double prime
如果今天這個 x double prime 跟 x
已經很像了
那它們的 margin 就小一點
如果 x prime 跟 x 很不像，它們 margin 就大一點
所以你會希望 x prime 的分數\
被壓得很低，x double prime 的分數只要壓低過 margin 就好
不需要壓得太低
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
