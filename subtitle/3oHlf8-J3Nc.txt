好 那個接下來我們要講 Auto-Encoder
那 Auto-Encoder
我們可能先講一小段以後
我們就下課休息一下
然後我再把 Auto-Encoder 的部分補完
然後等一下助教就會講
跟 Auto-Encoder 有關的作業
好 那我們來講 Auto-Encoder
那在講 Auto-Encoder 之前
其實 Auto-Encoder 也可以算是
Self-Supervised Learning 的一環
所以再讓我們用非常短的時間
來看一下Self-Supervised Learning 的 Framework
那 Self-Supervised Learning 是怎麼運作的
首先你有大量的沒有標註的資料
用這些沒有標註的資料
你可以去訓練一個模型
你必須發明一些不需要標註資料的任務
比如說做填空題
比如說預測下一個 Token
你必須要自己想一些不需要標註資料的任務
給你的模型進行學習
那這個不用標註資料的學習叫做
Self-Supervised Learning
或者是也有人叫 Pre-Training
那用這些不用標註資料的任務
學完一個模型以後
它本身沒有什麼用
BERT 只能做填空題
GPT 只能夠把一句話補完
但是你可以把它用在其他下游的任務裡面
你可以把 Self-Supervised Learning 的 Model
做一點點的微微的調整
就可以用在下游的任務裡面
那在這些 Self-Supervised Learning 的任務裡面
在這些不用標註資料就可以學習的任務裡面
在有 BERT 在有 GPT 之前
其實有一個更古老的任務
更古老的不需要用標註資料的任務
就叫做 Auto-Encoder
所以你也可以把 Auto-Encoder
看作是 Self-Supervised Learning 的
一種 Pre-Train 的方法
當然可能不是所有人都會同意這個觀點
有人可能會說這個 Auto-Encoder
不算是 Self-Supervised Learning
這個 Auto-Encoder 很早就有了嘛
2006 年 15 年前就有了嘛
然後 Self-Supervised Learning 是
19 年才有這個詞彙嘛
所以 Auto-Encoder
不算 Self-Supervised Learning 的一環
那這個都是見仁見智的問題
這種名詞定義的問題
真的我們就不用太糾結在這個地方
從 Self-Supervised Learning
它是不需要用 Label Data 來訓練
這個觀點來看
Auto-Encoder 我認為它可以算是
Self-Supervised Learning 的其中的一種方法
它就跟填空 預測
接下來的 Token 是很類似的概念
只是用的是另外不一樣的想法
好 那接下來我們就來先看一下
Auto-Encoder 是怎麼運作的
好 那 Auto-Encoder 是怎麼運作的呢
那現在我們
因為剛才在講 Self-Supervised Learning 的時候
都是用文字做例子
那現在我們換成用影像來做例子
假設你有非常大量的圖片
在 Auto-Encoder 裡面你有兩個 Network
一個叫做 Encoder
一個叫做 Decoder
他們就是兩個 Network
這兩個 Network 做的事情是什麼
這兩個 Network 做的事情是
Encoder 把一張圖片讀進來
它把這張圖片變成一個向量
就 Encoder 它可能是很多層的 CNN
把一張圖片讀進來
它的輸出是一個向量
接下來這個向量會變成 Decoder 的輸入
Decoder 會產生一張圖片
所以 Decoder 的 Network 的架構
可能會像是 GAN 裡面的 Generator
它是 11 個向量輸出一張圖片
不管是 Encoder 還是 Decoder
反正就是多層的 Network
那現在訓練的目標是什麼
訓練的目標是希望
Encoder 的輸入跟 Decoder 的輸出
越接近越好
假設你把圖片看作是一個很長的向量的話
我們就希望這個向量跟 Decoder 的輸出
這個向量
這兩個向量他們的距離越接近越好
也有人把這件事情叫做 Reconstruction
叫做重建
因為我們就是把一張圖片
壓縮成一個向量
接下來 Decoder 要根據這個向量
重建原來的圖片
那我們希望原輸入的結果
跟重建後的結果越接近越好
講到這邊你可能會發現說
這個東西 這個概念似曾相似
沒錯 我們在講 Cycle GAN 的時候
已經講過了這個概念 對不對
我們說在做 Cycle GAN 的時候
我們會需要兩個 Generator
第一個 Generator
把 X Domain 的圖片轉到 Y Domain
另外一個 Generator
把 Y Domain 的圖片轉回來
希望最原先的圖片
跟轉完兩次後的圖片越接近越好
那這邊 Encoder 和 Decoder
這個 Auto-Encoder 的概念
跟 Cycle GAN 其實是一模一樣的
都是希望所有的圖片經過兩次轉換以後
要跟原來的輸出越接近越好
而這個訓練的過程
完全不需要任何的標註資料
你只需要蒐集到大量的圖片
你就可以做這個訓練
所以它是一個 Unsupervised Learning 的方法
跟 Self-Supervised 那一系列
Pre-Training 的做法一樣
你完全不需要任何的標註資料
那像這樣子這個 Encoder 的輸出
有時候我們叫它 Embedding
我們在講 BERT 的時候
也提過 Embedding 這個詞彙了
那有的人叫它 Representation
有的人叫它 Code
因為 Encoder 是一個編碼嘛
所以這個有人把這個 Vector 叫做 Code
那其實指的都是同一件事情
好 那這個 Auto-Encoder 的技術要怎麼用呢
怎麼把 Train 的 Auto-Encoder
用在 Downstream 的任務裡面呢
常見的用法就是
原來的圖片
你也可以把它看作是一個很長的向量
但這個向量太長了 不好處理
那怎麼辦呢
你把這個圖片丟到 Encoder 以後
輸出另外一個向量
這個向量你會讓它比較短
比如說只有 10 維 只有 100 維
那你拿這個新的向量來做你接下來的任務
也就是圖片不再是一個很高維度的向量
它通過 Encoder 的壓縮以後
變成了一個低維度的向量
你再拿這個低維度的向量
來做接下來想做的事情
這就是常見的
Auto-Encoder用在 Downstream 的任務
用在下游任務的方法
那因為通常 Encoder 的輸入
是一個維度非常高的向量
而 Encoder 的輸出
也就是我們的 Embedding
Representation 或者 Code
它是一個非常低維度的向量
比如說輸入是 100×100 的圖片
那 100×100 那就是 1 萬維的向量了
如果是 RGB 那就是 3 萬維的向量
但是通常 Encoder 的 Output 你會設得很小
比如說 10 100 這樣的等級
所以這個這邊會有一個特別窄的地方
所以這個部分
這個 Encoder 的輸出
有時候又叫做 Bottleneck
叫做瓶頸
就本來輸入是很寬的
輸出也是很寬的 中間特別窄
所以這一段就叫做 Bottleneck
而 Encoder 做的事情
是把本來很高維度的東西
轉成低維度的東西
把高維度的東西轉成低維度的東西
又叫做 Dimension 的 Reduction
Dimension Reduction 這個技術
我相信你在 Machine Learning 相關的應用上
應該常常聽到這個名詞
那有關 Dimension Reduction 的技術
它其實牽涉的非常非常地廣
所以我們這邊就不再細講
因為這門課
我們只專注在深度學習相關的技術
你可以把 Auto-Encoder 的 Encoder
當作拿來做 Dimension Reduction
那其他還有很多不是 Deep Learning Base的
不是以深度學習為基礎的
Dimension Reduction的技術
我就把錄影的連接留在這邊
比如說 PCA 比如說 T-SNE
我就把錄影的連結留在這邊給大家參考
好 那 Auto-Encoder 到底好在哪裡
當我們把一個高維度的圖片
變成一個低維度的向量的時候
到底帶來什麼樣的幫助
這讓我想到神鵰俠侶的其中一段
我不知道大家有沒有看過神鵰俠侶就是
我可以做個調查
有看過神鵰俠侶的同學可以舉手一下嗎
哇 這麼多 好 手放下
比我想像的多太多了
我還以為現在大家已經沒有在看金庸了
這個神鵰俠侶裡面有一段
就是楊過進去那個絕情谷
遇到這個絕情谷谷主公孫止的弟子
就是樊一翁
樊一翁就是這個人
那樊一翁的武器是什麼
他的武器除了一根鋼杖以外
還有他的鬍子
他可以去甩動他的鬍子當做一個軟鞭來使用
他的鬍子甩起來有兩丈那麼長
可以是一個很厲害的武器
楊過跟他打了很久都難分上下
突然呢楊過說
我在三招之內一定要剪掉你的鬍子
大家突然都很詫異
想說楊過雖然武功可能比樊一翁還高一點
但是也沒有高太多
怎麼有辦法三招就剪掉他的鬍子
後來楊過真的在三招內剪掉他的鬍子
為什麼呢
因為楊過發現說
這個鬍子是由頭所操控的
雖然鬍子甩開來有兩丈那麼長
但是頭能夠做的變化還是有限的
所以雖然表面鬍子的鞭法非常地厲害
但是只要直接去打他的頭
就直接去打他臉
就會逼著他不得不閃避
就會逼著他這個鬍子能夠動的路線變得有限
然後就打敗了樊一翁
就把他的鬍子剪掉了
故事結束
那這個跟 Auto-Encoder 有什麼關係呢
好 我們來想一下
Auto-Encoder 這件事情它要做的
是把一張圖片壓縮又還原回來
但是還原這件事情為什麼能成功呢
你想想看假設本來圖片是 3×3
3×3 很小
但我們就假設 3×3 好了
本來的圖片是 3×3
你要用 9 個數值來描述一張 3×3 的圖片
假設 Encoder 輸出的這個向量是二維的
我們怎麼有可能從二維的向量
去還原 3×3 的圖片
還原9個數值呢
我們怎麼有辦法把 9 個數值變成 2 個數值
又還原成 3
又還原回 9 個數值呢
能夠做到這件事情是因為
對於影像來說
並不是所有 3×3 的矩陣都是圖片
圖片的變化其實是有限的
你隨便 Sample 一個 Random 的 Noise
隨便 Sample 一個矩陣
出來它通常都不是你會看到的圖片
或舉例來說
假設圖片是 3×3 的
那它的變化
雖然表面上應該要有 3×3 個數值
才能夠描述 3×3 的圖片
但是也許它的變化實際上是有限的
也許你把圖片蒐集起來發現說
它只有這樣子的類型
跟這樣子的類型
其他類型根本就不是
你一般在訓練的時候會看到的狀況
就是因為說圖片的變化還是有限的
所以你在做這個 Encoder 的時候
Encoder 可以說
我就只用兩個維度就可以描述一張圖片
雖然圖片是 3×3
應該用 9 個數值才能夠儲存
但是實際上它的變化也許只有兩種類型
那你就可以說看到這種類型
我就左邊這個維度是 1 右邊是 0
看到這種類型就左邊這個維度是 0
右邊這個維度是 1
那所以對應到剛才這個樊一翁的例子
就是這個鬍子是圖片複雜的狀態
是原來的圖片
是原來圖片的 Pixel
是原來圖片的像素
而 Encoder 做的事情就是化繁為簡
本來比較複雜的東西
它只是表面上比較複雜
事實上它的變化其實是有限的
你只要找出它有限的變化
你就可以把本來複雜的東西
把它變得用比較簡單的方法來表示它
如果我們可以把複雜的圖片
用比較簡單的方法來表示它
那我們就只需要比較少的訓練資料
在下游的任務裡面
我們可能就只需要比較少的訓練資料
就可以讓機器學到
我們本來要它學的事情
這個就是 Auto-Encoder 的概念
那 Auto-Encoder
它從來都不是一個新的想法
它真的是非常非常地有歷史
舉例來說在這個 Hinton
大家知道 Hinton 吧
Hinton 就是 Deep Learning 之父
Hinton 在 06 年的 Science 的 Paper 裡面
就有提到 Auto-Encoder 這個概念
只是那個時候用的 Network
跟今天用的 Network
當然還是有很多不一樣的地方
我們講 2006 年是 15 年前
15 年前的 Auto-Encoder 長什麼樣子
那個時候人們不覺得
Deep 的 Network 是 Train 得起來的
那時候覺得說這個把 Network 疊很多很多層
然後每一層一起 Train 不太可能成功
所以那時候的信念是
每一層應該分開訓練
所以 Hinton 用的是一個叫做
Restricted Boltzmann Machine 的技術
縮寫是 RBM
我們特別把 Hinton 15 年前的文章
把它的裡面的這個
Paper 裡面的圖拿出來給大家看一下
過去 15 年前
人們是怎麼看待深度學習這個問題
那個時候覺得說
要 Train 一個這個很深的 Network 不太可能
每一層分開要 Train
雖然這個說很深也沒有很深
只是三層
這個跟你作業 2 做得還要更（00：14：01）
對不對
但是在15年前這個已經是
哇 很深啊 它有三層太可怕了
好 那這個三層要分開來訓練才可以
那這邊說分開來訓練這件事情叫做 Pretraining
但它跟 Self-Supervised Learning 的 Pre-Train
又不一樣
大家了解我的意思嗎
假設你說 Auto-Encoder 這個東西是 Pre-Train
那現在這個 Pre-Train 是
Pre-Train 的 Pre-Train
它是要 Pre-Train 那個 Auto-Encoder
而且每一層用一個叫做 RBM 的技術
分開來訓練
先把每一層都訓練好
再全部接起來做微調這件事情
那這邊的微調並不是 BERT 的微調
它是微調那個 Pre-Train 的 Model
好 那這個 Restricted Boltzmann Machine
你會發現今天很少有人在提到它了
它其實不是一個 Deep Learning 的技術
它有點複雜
我們在這門課裡面也沒有打算要深入細講
什麼是 Restricted Boltzmann Machine
那為什麼現在都沒有什麼人用它呢
就是因為它沒有什麼用這樣子
在過去呢 在10年前呢
都相信這個 Deep 的 Network
一定要用 Restricted Boltzmann Machine
然後其實 Hinton 後來在 2012 年的時候
有一篇 Paper 偷偷在結尾下一個結論說
其實 Restricted Boltzmann Machine
也沒有什麼必要 哈哈哈 這樣子
所以後來就沒有什麼人再用
Restricted Boltzmann Machine
而且那時候還有一個神奇的信念
是覺得說那個 Encoder Decoder
它必須是對稱
所以 Encoder 的第一層
跟 Encoder 的最後
跟 Decoder 的最後一層
他們必須互為 Transfers
不過現在已經沒有
比較少有人在使用這樣子的限制
好 這張投影片只想告訴你說
Auto-Encoder 不是新的概念
它是一個非常有歷史的概念
那 Auto-Encoder 還有一個常見的變形
叫做 De-Noising 的 Auto-Encoder
De-Noising 的 Auto-Encoder 是說
我們把原來要輸進去給 Encoder 的圖片
加上一些雜訊
就自己隨便找一個雜訊把它加進去
然後一樣通過 Encoder
一樣再通過 Decoder
試圖還原原來的圖片
那我們現在還原的
不是 Encoder 的輸入
Encoder 的輸入的圖片是有加雜訊的
我們要還原的不是 Encoder 的輸入
我們要還原的是加入雜訊以後的結果
加入雜訊 說錯
加入雜訊之前的結果
所以你會發現說
現在 Encoder 跟 Decoder
除了還原原來的圖片這個任務以外
它還多了一個任務
這個任務是什麼
這個任務就是
它必須要自己學會把雜訊去掉
Encoder 看到的是沒有雜訊的圖片
但 Decode要還原的目標是
Encoder 看到的是有加雜訊的圖片
但 Decoder 要還原的目標是
沒有加雜訊的圖片
所以 Encoder 加 Decoder
他們合起來必須要聯手能夠把雜訊去掉
這樣你才能夠把
De-Noising 的 Auto-Encoder 訓練起來
那說到 De-Noising 的 Auto-Encoder
有沒有發現這個概念
其實也一點都不陌生呢
De-Noising 的 Auto-Encoder
也不算是太新的技術
至少在 2008 年的時候
就已經有相關的論文了
但是如果你看今天的 BERT 的話
其實你也可以把它看作就是一個
De-Noising 的 Auto-Encoder
輸入我們會加 Masking
那些 Masking 其實就是 Noise
BERT 的模型就是 Encoder
它的輸出就是 Embedding
在講 BERT 的技術的時候
我們就告訴你說這個輸出就叫做 Embedding
接下來有一個 Linear 的模型
就是 Decoder
Decoder 要做的事情
就是還原原來的句子
也就是把填空題被蓋住的地方
把它還原回來
所以我們可以說
BERT 其實就是一個
De-Noising 的 Auto-Encoder
有同學可能會問說
為什麼這個 Decoder 一定要 Linear 的呢
它不一定要是 Linear
它可以不是 Linear
或者是我們換一個說法
這個 BERT 它有 12 層
最小的那個 BERT 有 12 層
比較大的有 24 層或者是 48 層
好 那最小的 BERT 是 12 層
如果我們說這個 12 層中間
第 6 層的輸出是 Embedding
那你其實也可以說剩下的 6 層
就是 Decoder
你可以說 BERT
就假設你在用 BERT 的時候
你用的不是第 12 層的輸出
而是第 6 層的輸出
那你完全可以說
BERT 的前 6 層就是 Encoder
後面 6 層就是 Decoder
總之這個 Decoder
沒有一定要是 Linear
