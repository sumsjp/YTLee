臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心http://ai.ntu.edu.tw/
各位同學大家好 我們就來上課吧
上週我們講了 GAN 的直觀的想法
今天要來講 GAN 背後的理論
今天要講的是當初 2014 年 Ian Goodfellow 在 propose GAN 的時候它的講法
等一下可以仔細聽看看跟我們上週講的 GAN 的直觀的想法裡面有沒有矛盾的地方
其實是有一些地方還頗矛盾的
至今仍然沒有好的 solution、好的手法可以解決
如果大家沒有甚麼問題要問的話就來講一下
GAN 背後的理論，當初 Ian Goodfellow 是怎麼說的
這個是上周說的作業 3-1 裡面要讓 GAN 做的事情 讓機器看了很多動畫的圖以後
自己產生二次元人物的頭像
GAN 要做的就是根據很多 example 自己去進行生成
所謂的生成到底是甚麼樣的問題
假設要生成的東西是 image 用 x 來代表一張 image
每一個 image 都是 high dimensional 高維空間中的一個點
假設產生 64 x 64 的 image 它是 64 x 64 維空間中的一個點
這邊為了畫圖方便假設每一個 x 就是二維空間中的一個點
雖然實際上它是高維空間中的一個點
現在要產生的東西 比如說要產生 image
它其實有一個固定的 distribution
這邊寫成 Pdata ( x )
它有一個固定的 distribution
甚麼意思 在這整個 image 的 space 裡面
在這整個 image 所構成的高維空間中
只有非常少的部分、一小部分
sample 出來的 image 看起來像是人臉
在多數的空間中 sample 出來的 image 都不像是人臉
在這個圖上的例子裡面可能只有藍色的這個區域
去 sample 出 x、sample 一個 image
它看起來像是人臉 舉例來說在這個地方 sample
看起來的圖片長的是這個樣子
在其他地方 sample，看起來的圖片看起來就不像是人臉
假設生成的 x 是人臉的話
它有一個固定的 distribution
這個 distribution 在藍色的這個區域，它的機率是高的
在藍色的區域以外，它的機率是低的
要機器做的是甚麼 要機器找出這個 distribution
而這個 distribution 到底長甚麼樣子
實際上是不知道的
可以蒐集很多的 x 知道 x 可能在某些地方分布比較高
但是要我們把這個式子找出來
我們是不知道要怎麼做的
所以現在 GAN 做的是一個 generative model 做的事情
就是要找出這個 distribution
在有 GAN 之前怎麼做 generative
是用 Maximum Likelihood Estimation
其實 Maximum Likelihood Estimation 在之前 Machine Learning 有講過，這邊只是一個很快地複習
現在有一個 data 的 distribution 它是 P data ( x )
這個 distribution 長甚麼樣子 就是這個 distribution 它的 formulation 長甚麼樣子
我們是不知道的
我們可以從裡面 sample 它
所謂從這個 distribution sample 它的意思就是
假設做二次元人物的生成
那就是從 database 裡面 sample 出 image
這個就是從這個 distribution 裡面 sample 一些 data 出來
我們可以 sample 它但我們不知道它長甚麼樣子
接下來我們要自己去找一個 distribution
這個 distribution 寫成 P 下標 G ( x )
這個 distribution 是由一組參數 θ 所操控的
所謂由 θ 所操控的意思是這個 distribution 假設它是一個 Gaussian Mixture Model
這個 θ 指的就是 Gaussian 的 mean 跟 variance
我們要去調整 Gaussian 的 mean 跟 variance
使得我們得到的這個 distribution P 下標 G 跟真實的 distribution P data 越接近越好
雖然我們不知道 P data 長甚麼樣子
我們只能夠從 P data 裡面去 sample
但是我們希望 P 下標 G 可以找一個 θ 讓 P 下標 G 跟 P data 越接近越好
怎麼做 假設用 Maximum Likelihood
首先可以從 P data sample 一些東西出來
sample x1, x2 到 xm
可以 sample 一堆 x 出來
接下來對每一個 sample 出來的 x
我們都可以計算它的 likelihood 所謂可以計算它的 likelihood 意思是
假設給定一組參數 θ
我們就知道 P 下標 G 這個 probability 的 distribution 長甚麼樣子
我們就可以計算從這個 distribution 裡面
sample 出某一個 xi 的機率 可以計算這個 likelihood
接下來要做的就是，我們要找出一個 θ
使得 P 下標 G 跟 P data 越接近越好
這件事情的意思就是說
我們希望這些從 P data 裡面 sample 出來的 example
如果是用 P 下標 G 這個 distribution 來產生的話
它的 likelihood 越大越好
每一筆 data 它從 P 下標 G 產生的 likelihood
我們都是可以算出來的
把所有的機率乘起來
就得到 total 的 likelihood
我們希望 total likelihood 越大越好
怎麼讓 total likelihood 越大越好
就是要去找一個 θ*，找一組最佳的參數
它可以去 maximize L 這個值
舉例來說在這個 case 裡面
假設你是一個 Gaussian Mixture Model
就可能希望它的 mean 落在這些地方
它的 variance 長這樣，可能這個 Gaussian Mixture Model 它產生這些 data 的機率
就是最大的
這個是 Maximum Likelihood
我記得我們在 Machine Learning 那門課講解了 Rating Model 的時候
就已經提過這些東西了
Maximum Likelihood 如果你覺得它沒有很直觀的話
這邊給你 Maximum Likelihood 的另外一個解釋
Maximum Likelihood 它等同於 Minimize KL Divergence
甚麼意思 我們說在 Maximum Likelihood 裡面我們做的事情就是
我們從 P data 裡面 sample 出 m 筆 data
然後給我們一組參數 θ 就可以計算每一個 x 被 sample 出來的機率，我們把這些機率全部乘起來
這個是我們要去 maximize 的對象
這個式子可以稍微改變一下 就前面取一個 log
取一個 log 不影響你找出來最好的 θ
這個大家都可以很快地知道
你可以把 log 放進去 本來是很多項相乘取 log
等同於每一項取 log 以後相加
相信對大家來說沒有問題
這件事情是甚麼意思
summation over i = 1 到 m
summation over 第一筆 example 到第 m 筆 example
這件事情其實就是在 approximate 從 P data 這個 distribution 裡面 sample x 出來
從 P data 這個 distribution 裡面 sample x 出來
你就得到 x1, x2 到 xm
今天這個式子它要 maximize 的對象其實就是 maximize log P 下標 G ( x )
maximize 這一項的 expected value
那你這個 expectation distribution 是你要 sample 的 data
接下來可以把 expectation 這一項
把它展開，他其實就是一個積分
這個 x 是從 P data sample 出來的
從 P data 裡面 sample 出來的意思就是
對 x 做積分然後把它乘 P data ( x )
然後乘上 log P 下標 G ( x )
接下來加一項看起來沒有甚麼用的東西
在後面加這麼一項
這一項是甚麼東西 你看一下這一項
這一項裡面只有 P data
他跟 P 下標 G 是完全沒有任何關係的
所以加這一項根本不會影響你找出來的最大的 x
既然加這一項一點用都沒有 那為甚麼要加這一項
加這一項的目的是為了告訴你 Maximum Likelihood 它就是 KL Divergence
因為加上這一項以後 就可以把式子做一下整理
這邊是對 x 做積分乘上 P data(x) 再乘上 log P 下標 G (x)
這邊是減掉對 x 做積分，P data(x) 乘上 log P data(x)
所以這邊有積分 P data (x)，這邊有積分 P data (x)
所以可以把他提出來
這一項跟這一項可以把它提出來
這邊就剩下 log P 下標 G 減掉 log P data
大家一秒鐘就可以反應 log P 下標 G 減掉 log P data 就是 P 下標 G 除以 P data
總之這個式子他就是 P data 跟 P 下標 G 的 KL Divergence
所以找一個 θ 去 maximize likelihood
等同於找一個 θ 去 minimize P data 跟 P 下標 G 的 KL Divergence
如果看到這邊覺得數學式太多你沒有看懂的話
其實只要知道一件事就好
所謂的 Maximum Likelihood 在機器學習裡面講
我們要找一個 Generative Model 去 Maximum Likelihood
就 Maximum Likelihood 這件事情就等同於 minimize
你的 Generative Model 所定義的 distribution P 下標 G 跟現在的 data P data 之間的 KL Divergence
接下來會遇到的問題是假設我們的 P 下標 G 只是一個 Gaussian Mixture Model
他顯然有非常多的限制
我們希望 P 下標 G 是一個 general 的 distribution
它可以不是 Gaussian 它可以是比 Gaussian 更複雜的東西
但假設把 P 下標 G 換成比 Gaussian 更複雜的東西
會遇到甚麼問題呢
會遇到的問題就是算不出你的 likelihood
算不出 P 下標 G x given θ 這一項
假設 P 下標 G(x) 這個東西
他是一個 Gaussian Mixture Model
給你一個 x，你可以計算他被 sample 出來的機率
但是如果它是一個很複雜的東西
等一下會講他可能是一個 Neural Network
你就沒有辦法計算它的 likelihood
所以怎麼辦
所以就有了一些新的想法
讓 machine 自動的生成東西比如說做 image generation
從來都不是新的題目，你可能看最近用 GAN 做了很多 image generation 的 task
好像 image generation 是這幾年才有的東西
其實不是，image generation 在八零年代就有人做過了
那個時候的作法是用 Gaussian Mixture Model
蒐集很多很多的 image，每一個 image 就是高維中中間一個 data point
就可以 learn 一個 Gaussian Mixture Model 去 maximize 產生那些 image likelihood
但如果你看文獻的話
你看古聖先賢留下來的東西就會發現過去做的 如果用 Gaussian Mixture Model 產生出來的 image
非常非常的糊
這個可能原因是因為 image 他是高維空間中一個 manifold
大家可能知道 image 在高維空間中 它其實是高維空間中一個低維的 manifold
所以如果用 Gaussian Mixture Model 他其實就不是一個 manifold
用 Gaussian Mixture Model 不管怎麼調 mean 跟 variance
他就不像是你的 copy distribution
所以怎麼做都是做不好
所以需要用更 generalize 的方式來 learn generation 這件事情
在這個 GAN 裡面 在 Generative Adversarial Network 裡面
generator 就是一個 network 我們把他寫作 G
等一下就會告訴大家一個 network 他怎麼被看作是一個 probability 的 distribution
我們知道 generator 就是一個 network
我們都知道 network 就是一個東西然後 output 一個東西
舉例來說，input 從某一個 distribution sample 出來的 noise z
input 一個隨機的 vector z
然後他就會 output 一個 x 這個 x，如果 generator G 看作是一個 function 的話
這個 x 就是 G(z)
如果是做 image generation 的話
那你的 x 就是一個 image
我們說這個 z 是從某一個 prior distribution
比如說是從一個 normal distribution sample 出來的
今天每次 sample 出一個 z
把他丟到這個 generator 裡面
就會得到一個 x
sample 不同的 z 得到的 x 就不一樣
今天這個 z 是從一個 Gaussian Distribution 裡面 sample 出來的
現在把這些從 Gaussian Distribution 裡面 sample 出來的 z 通通通過 G 得到另外一大堆 sample
把這些 sample 通通集合起來
得到的就會是另外一個 distribution
雖然 input 是一個 normal distribution 是一個單純的 Gaussian Distribution
但是通過 generator 以後
因為這個 generator 是一個 network
它可以把這個 z 通過一個非常複雜的轉換把他變成 x
所以把通過 generator 產生出來的 x 通通集合起來
它可以是一個非常複雜的 distribution
而這個 distribution 就是我們所謂的 P 下標 G
有人可能會問這個 Prior Distribution 應該要設成甚麼樣子
好像文獻上有人會用 Normal Distribution
有人會用 Uniform Distribution 你可以在作業裡面 verify 一下你覺得哪一種比較好
哪一種比較好我也忘記了
我覺得這邊其實 Prior Distribution 用哪種 distribution 也許影響並沒有那麼大
為甚麼？因為 generator 他是一個 network
我們在開學第一堂課就有講過
一個 hidden layer 的 network 他就可以 approximate 任何 function
更何況是有多個 hidden layer 的 network
它可以 approximate 非常複雜的 function
所以就算是 input distribution 是一個非常簡單的 distribution
通過了這個 network 以後，他也可以把這個簡單的 distribution 柪成各式各樣不同的形狀
所以不用擔心這個 input 是一個 normal distribution
會不會對 output 來說有很大的限制 其實不會
因為通過一個 generator 以後
可以把一個單純的 normal distribution 凹成各式各樣複雜的形狀
接下來目標是甚麼
接下來目標是希望根據這個 generator 所定義出來的 distribution P 下標 G
他跟我們的目標、跟我們的 data 的 distribution P data 越接近越好
如果要寫一個 Optimization Formulation 的話 這個 formulation 看起來是這個樣子
我們要找一個 generator G
這個 generator 可以讓它所定義出來的 distribution P 下標 G
跟我們的 data P data 之間的某種 divergence 越小越好
舉例來說如果是 Maximum Likelihood 的話它就是要 minimize KL Divergence
等一下我們會看到其實在 GAN 裡面 minimize 的不是 KL Divergence 而是其他的 Divergence
這邊寫一個 Div 就代表說反正他是某一種 Divergence
現在要做的就是找一個 generator 這個 generator 定義出一個 distribution P 下標 G
這個 P 下標 G 可以跟我們的 P data 的 Divergence 越接近越好
再來的問題是怎麼計算這個 Divergence 呢
假設能夠計算這個 Divergence
要找一個 G 去 minimize 這個 Divergence
那不就只是 Gradient Descent 用 Gradient Descent 就可以做了對不對
但問題就是要怎麼計算出這個 Divergence
P data 它的 formulation
我們是不知道的 它並不是甚麼 Gaussian Distribution，它是 formulation
P 下標 G 它的 formulation 我們也是不知道的
假設 P 下標 G 跟 P data 它的 formulation 我們是知道的
我們代進 Divergence 的 formulation 裡面 我們就可以算出它的 Divergence 是多少
我們就可以用 Gradient Descent 去 minimize 它的 Divergence
問題就是 P 下標 G 跟 P data 它的 formulation 我們是不知道的
我們根本就不知道要怎麼去計算它的 Divergence
所以根本不知道要怎麼找一個 G 去 minimize 它的 Divergence
所以怎麼辦 這個就是 GAN 神奇的地方
在進入比較多的數學式之前我們先很直觀的講一下 GAN 到底怎麼做到 minimize Divergence 這件事情
這邊的前提是我們不知道 P 下標 G 跟 P data 的 distribution 長甚麼樣子
但是我們可以從這兩個 distribution 裡面
去 sample data 出來
甚麼意思呢
甚麼叫做從 P data 去 sample distribution 出來呢
你就是把你的 database 拿出來 假設我們做二次元人物頭像生成的話
然後從裡面 sample 很多 image 出來 這個就是從 P data 這個 distribution 裡面做 sample
怎麼對 P 下標 G 做 sample
這個 P 下標 G 是由你的 generator 所定義的
我們在使用這個 generator 的時候
我們是從某個 prior distribution 裡面去 sample 一大堆的 vector，每一個 vector 就會產生一張 image
所謂的從 P 下標 G 裡面做 sample
其實就是 random sample 一個 vector
把這個 vector 丟到 generator 裡面產生一張 image
這個就是從 P 下標 G 裡面做 sample
所以我們可以從 P data 裡面做 sample
我們也可以從 P 下標 G 裡面做 sample
接下來的問題是我們可以從 P 下標 G 和 P data 做 sample
根據這個 sample 我們要怎麼知道這兩個 distribution 的 Divergence 呢
GAN 神奇的地方就是透過 discriminator
我們可以量這兩個 distribution 間的 Divergence
假設藍色的星星是從 P data 裡面 sample 出來的東西
紅色的星星是從 P 下標 G sample 出來的東西
根據這些 data 我們去訓練一個 discriminator 上週我們已經講過訓練 discriminator 意思就是
給 P data 的分數越大越好
給 P 下標 G 的分數越小越好 你去訓練一個 discriminator
這個訓練的結果就會告訴我們 P data 跟 P 下標 G 他們之間的 Divergence 有多大
上週講過訓練一個 discriminator 我們怎麼訓練 discriminator 呢
我們會寫一個 Objective Function D
這個 Objective Function 它跟兩項有關 一個是跟 generator 有關
一個是跟 discriminator 有關
在 train discriminator 的時候我們會 fix 住 generator
所以 G 這一項是 fix 住的
我們只是調這個 discriminator 參數想辦法去 maximize 後面這一項
後面這一像是甚麼意思呢
後面這項意思是 x 是從 P data 裡面 sample 出來的
我們希望 log D( x ) 越大越好
也就是我們希望 discriminator 的 output 假設 x 是從 P data 裡面 sample 出來的
我們就希望 D ( x ) 越大越好
反之假設 x 是從 generator sample 出來的
因為要 maximize V 這一項 所以要 maximize 第一項，也要 maximize 第二項
如果 x 是從 P 下標 G 裡面 sample 出來的
那我們要 maximize log ( 1 - D ( x ) )
就是要 maximize 1 - D ( x ) ) 也就是要 minimize D ( x )
如果 x 是從 P 下標 G 裡面 sample 出來的
我們就希望他的值越小越好 然後在訓練的時候就是要找一個 D
它可以 maximize 這個 Objective Function
如果你之前 Machine Learning 有學通的話
下面這個 optimization 的式子跟 train 一個 Binary Classifier 的式子
其實是完全一模一樣的
假設今天要 train 一個 Logistic Regression 的 model
Logistic Regression Model 是一個 Binary Classifier
然後就把 P data 當作是 class 1
把 P 下標 G 當作是 class 2
然後 train 一個 Logistic Regression Model
你會發現你的 Objective Function 其實就是下面這個式子
所以這個 discriminator 在做的事情跟一個 Binary Classifier 在做的事情其實是一模一樣的
假設藍色的點是 class 1 紅色的點是 class 2
discriminator 就是一個 Binary Classifier
train 下去，然後這個 Binary Classifier 它是在 minimize Cross Entropy
我們之前講過 Binary Classifier 是要 minimize Cross Entropy 不能 minimize Mean Square Error
要 minimize Cross Entropy 如果你 minimize Cross Entropy 的話
你其實就是在解這個 optimization 的 problem
這邊神奇的地方是當我們解完這個 optimization 的 problem 的時候
你最後會得到一個最小的 loss
或者是得到最大的 objective value
我們今天這邊不是 minimize loss 而是 maximize 一個 Objective Function
這個 V 是我們的 Objective Value
我們要調 D 去 maximize 這個 Objective Value
然後這邊神奇的地方是
這個 maximize Objective Value 就是把這個 D train 到最好，給了這些 data
把這個 D train 到最好，找出最大的 D 可以達到的 Objective Value
這個 value 其實會跟 J-S Divergence 是有非常密切關係
等一下會有更詳細的證明
你可以說這個結果它其實就是 J-S Divergence
也許你聽了覺得很神奇 但我們可以給你一個非常非常值觀的解釋
你一秒鐘就知道為甚麼這個東西它應該跟某一個 Divergence 是有關係的
你想想看，假設現在 sample 出來的 data 他們靠得很近
這個藍色的這些星星跟紅色的星星 如果把他們視成兩個類別的話
他們靠得很近
對一個 Binary Classifier 來說
它很難區別紅色的星星跟藍色的星星的不同
因為對一個 Binary Classifier 也就是 discriminator 來說
他很難區別這兩個類別的不同 所以直接 train 下去
loss 就沒有辦法壓低
假設這兩個 class 他們靠得很近 他們很難分別
training data 上的 loss 就會壓不下去
或是反過來說 在 training data 上的 loss 壓不下去
就是我們剛才看到的 Objective Value
沒有辦法把他拉得很高
沒有辦法把剛才看到的 V 這一項
沒有辦法找到一個 D 他讓 V 的值變得很大
這個時候意味著時麼
這個時候意味著這兩堆 data
他們是非常接近的
他們的 Divergence 是小的
所以如果對一個 discriminator 來說 很難分別這兩種 data 之間的不同
他很難達到很大的 Objective Value
那意味著這兩堆 data 的 Divergence 是小的
所以最後你可以達到最好的 Objective Value
跟 Divergence 是會有非朝緊密的關係的
這是一樣的例子
假設藍色的星星跟紅色的星星他們距離很遠
他們有很大的 Divergence
對 discriminator 來說他就可以輕易地分辨這兩堆 data 的不同
也就是說它可以輕易的讓你的 Objective Value，V 的這個 value 變得很大
當 V 的 value 可以變得很大的時候
意味著這兩堆 data，從 P data 裡面 generate 出來的東西
和從 P 下標 G generate 出來的東西 他們的 Divergence 是大的
所以 discriminator 就可以輕易地分辨它的不同
discriminator 就可以輕易的 maximize Objective Value
在我們進入數學之前
在這邊先稍微停一下 有沒有同學有問題要問的呢
如果沒有問題要問的話
接下來就是實際證明給你看為甚麼 Objective Value
跟 Divergence 是有關係的
再來就是一堆數學式
這個數學式是這樣
Objective Value 就寫在右上角 他長這個樣子
現在要做的事情是找一個 discriminator D
它可以 maximize 這個式子
G 是固定的 要 maximize 這個式子
怎麼 maximize 這個式子 我們把他展開
把本來 expectation 換成積分
從 P data sample x 出來
就變成對 x 做積分乘上 P data ( x )
乘上 log D ( x )
這邊是從 P 下標 G sample x 出來就是對 x 做積分
乘上 P 下標 G 乘上 log ( 1 - D ( x ) ) 我想這個對大家來說都不成問題
接下來就整理一下，因為這邊都對 x 做積分，所以把放在積分裡面的這一項根放在積分裡面的這一項加起來
接下來要想辦法找一個 D 它可以讓這個式子越大越好
這邊前提有一個假設是 D ( x ) 它可以是任何的 function
但實際上不見得是成立的 因為假設 D ( x ) 是一個 network
network 除非他的 neural 無窮多 不然他也沒有辦法變成任何的 function
除非 neural 是無窮多的
不然也沒有辦法變成任何的 function
這邊作一個非常強的假設
是假設 D ( x ) 它可以是任意的 function
假設 D ( x ) 可以是任意的 function 的話
就是 input 一個 x 他的值可以是任何的值
沒有限制 你可以 assign 給 D ( x ) 任何的值
你可以 assign 給 D ( x1 ) 任何的值 你可以 assign 給 D ( x2 ) 任何的值
這個時候假設你要 maximize 這一項的話
他實際上等同於甚麼 等同於，這邊對 x 做積分
把中括號裡面的式子代各個不同的 x
再把它通通加起來 這就是積分在做的事情
但你要 maximize 這一項 然後 D ( x ) 又可以代任何的值
意思就是說可以把各個不同的 x 通通都分開算
所以今天要找一個 D 去 maximize 這個式子
意思就是說就把某一個 x 拿出來
這邊是 P data ( x ) * log D ( x )
加上 P 下標 G ( x ) * log ( 1 - D ( x ) ) 把某一個 x 拿出來
然後要找一個 D 它可以讓這個式子越大越好
所有不同的 x 通通都分開來算
因為所有的 x 都是沒有任何關係的 因為不管是哪一個 x
你都可以 assign 給他一個不同的 D ( x )
所以積分裡面的每一項都分開來算
你就可以分開為他找一個最好的 D ( x )
講道這邊大家有沒有問題要問
如果你可以接受這個想法的話
再來的問題是怎麼找一個 D 讓這一項最大
這個數學其實是滿簡單的
現在的問題是找一個 D 讓這個式子最大
P data 是固定的
P 下標 G 也是固定的
唯一要做的事情就是找一個 D ( x ) 的值讓這個式子算起來最大
等一下為了計算方便把 P data 用 a 來表示
D ( x ) 用大 D 來表示，P 下標 G 用小 b 來表示 D ( x ) 用大 D 來表示
整個式子寫起來就是這個樣子
怎麼找一個 D 去 maximize 這個式子
你就求一下他的 gradient，求一下他的微分
然後先找出他的 Critical Point，就找出微分是 0 的地方
把這一項做微分以後得到什麼樣的結果
a * log ( D ) 對 D 做微分 = a * ( 1 / D )
b * log ( 1 - D ) 對 D 做微分得到的結果是 b * 1 / ( 1 - D ) * ( -1 )
然後要找微分是 0 的地方
把式子整理一下，把 -1 這一項拿到右邊去 所以 -1 就沒有了
a * 1 / D* = b * 1 / ( 1 - D* )
接下來就要求一下 D* 是多少
要求一下什麼樣的 D 可以讓這個微分的值是 0
什麼樣的 D 他是 Critical Point
就整理一下，這邊都很簡單的數學
這邊是 a * ( 1 - D* ) = b * D*
把 a 乘進去，得到 a - aD* = bD*
整理一下，把有 D* 項挪到同一邊去
所以變成 a = ( a + b ) D*
D* = a / ( a + b )
所以知道假設 D* = a / ( a + b ) a 就是這一項
b 就是這一項 a 就是 P data，b 就是 P 下標 G
假設 D* ( x ) 的值是 P data ( x ) / ( P data ( x ) + P 下標 G ( x ) )
他就可以讓這一項的對 D 的微分為 0
你可以輕易的檢查它現在它是一個 Local Maximum
而不是 Local Minimum 也不是 Saddle Point
你可以輕易的檢查他是一個 maximum 不是一個 minimum 也不是一個 Saddle Point
所以要怎麼讓這一項最大
你就把 D ( x ) 代這樣的值就可以讓這一項最大
所以接下來要做的事情是甚麼
接下來要做的事情就是把這一項代到這個式子裡面
我們想知道當我們找出最好的 D
也就是 D* 的時候
Objective Function 的值到底長甚麼樣子
展開來就會發現這一項其實就是 J-S Divergence
我們知道 D* 的 formulation 就寫成這個樣子
把 D* 代到這裏面去
把 D* ( x ) 用 P data ( x ) / ( P data ( x ) + P 下標 G ( x ) ) 來表示
把這一項放進來
得到的結果就長這樣
這邊有 expectation，把 expectation 展開
這邊是對 P data sample x
就對 x 做積分 這邊是對 P 下標 G sample x，就對 P 下標 G 做積分
得到的式子長這個樣子
接下來為了要把整理成看起來像是 J-S Divergence
所以就做一些好像甚麼事都沒有做的變換
就把分子跟分母都同除 2
接下來可以把 1/2 這一項把它提出來
得到的結果是兩倍的 log * (1/2)
這個如果你沒有跟上的話，不太重要
反正這邊有 1/2 可以把它提出來變成 2 * log ( 1/2 ) 或等於 -2 * log2
接下來我們就知道假設已經有一個 generator G
找到了最佳的 discriminator 也就是 D*
D* 的 function 會長這個樣子
當我們找到最佳的 D* 的時候
V 這個 Objective Function 他就寫成這個看起來很複雜的樣子
這個是 -2 * log2 + 對 x 做積分 P data ( x ) * log( P data ( x ) 除上 P data ( x ) 跟 P 下標 G ( x ) 的平均
第二項這個是積分 x
P 下標 G ( x ) * log ( P 下標 G ( x ) 除掉 P 下標 G 和 P data 的平均 )
後面這一項是甚麼
後面這一項是 P data 跟二分之一 P data 跟 PG 的平均的 KL Divergence
如果你不知道它是甚麼的話沒有關係反正後面這兩項合起來
就叫做 J-S Divergence
或許你比較常聽過 KL Divergence
或者是 Inverse KL Divergence
不常聽過 J-S Divergence
但是反正後面這個式子它就是 P data 跟 PG 的某一種 Divergence
如果 P data 跟 PG 他們距離的越遠
這兩項合起來就越大 反之他們合起來就越小
總之現在得到的結論就是如果找到一個最佳的 D*
代進去以後得到的這個 value
它是 -2 * log2 + 2JSD ( P data || PG )
假設 learn 一個 discriminator
寫出了某一個 Objective Function
去 maximize 那個 Objective Function 以後
得到的結果，最後可以 maximize 的那個 Objective Function
最後 maximize 的那個 value
其實就是 P data 跟 PG 的 J-S Divergence
假設這邊的數學推導沒有辦法跟上的話
也沒有關係反正這邊想要告訴你的事情是
當我們在 train 一個 discriminator 的時候我們想要做的事情是甚麼
當我們 train 一個 discriminator 的時候 我們想做的事情就是去 evaluate
P data 跟 PG 這兩個 distribution sample 出來的 data
這兩個 distribution 他們之間的 J-S Divergence
如果定的 Objective Function 是跟前面的式子一樣的話
你就是在量 J-S Divergence
等一下會看到如果把那個 Objective Function 寫的不一樣
你就可以量其他的各種不同的 Divergence
現在整個問題變成這個樣子
本來要找一個 G 他去 minimize PG 跟 P data 的 Divergence
我們說後面這個式子你沒有辦法算
但現在是可以算的
後面這個式子到底是甚麼
後面這個式子就是 我們寫出一個 Objective Function
V ( D, G ) 找一個 D 去 maximize 這個式子
它就是 PG 和 P data 之間的 Divergence
所以我們可以把 Divergence 這一項用 max 這一項把它替換掉
變成這個樣子
所以我們要找一個 generator
generate 出來的東西跟你的 data 越接近越好
實際上要解這樣一個 optimization problem
要解一個 min max 的 problem
這個 optimization problem 裡面它有一個 minimum
它有一個 maximum，看起來非常的複雜
這個非常的拗口，你要找一個 generator 他要去 minimize 這一個式子
在這個式子它有一個 discriminator，discriminator 要去 maximize 這個式子
我知道這個看起來非常的複雜
它實際上做的事情像是以下這個例子所講的這樣
假設世界上只有三個 generator
假設要選一個 generator 去 minimize 這個 Objective Function
但是可以選的 generator 總共只有三個
一個是 G1 一個是 G2 一個是 G3
假設選了 G1 這個 generator 的話那 V ( G1, D )
它長這個樣子
假設 generator 固定是 G1
但是你的 discriminator 它可以是不同的 discriminator
假設 discriminator 它可以用一個參數來操控
所以這個橫坐標在改變的時候
代表選擇了不同的 discriminator 但實際上是更複雜的狀況
實際上 discriminator 是一個 Neural Network
它是由數百萬個參數所控制的
它應該是分布在一個高維空間裡面
不過這邊為了簡化問題我們就說，假設當橫坐標變化的時候
代表你選擇了不同的 discriminator
今天同樣的假設你的 generator 是 G2
把 G2 代進去，選擇不同 discriminator 的時候
就得到了不同的 V ( G2, D )
假設 generator 是 G3，選了不同的 discriminator 的時候
就得到不同的 V ( G3, D )
接下來的問題是我們在給定一個 generator 的時候
我們要找一個 discriminator 它可以讓 V ( G, D ) 最大
假設固定 generator 是 G1 的時候
哪一個 discriminator 可以讓 V ( G, D ) 最大
那個是落在這裡的這個 discriminator
可以讓 V ( G1, D ) 最大
落在這裡的 discriminator 可以讓 V ( G2, D ) 最大
落在這裡的 discriminator 可以讓 V ( G3, D ) 最大
接下來要找一個 G 去 minimize 最大的那個 discriminator 可以找到的 value
大家聽得懂嗎這有點拗口 我們找一個 G
它可以最小化最大的那個 discriminator 得到的 value
找一個 G 它可以 minimize V ( G, D )
用最大的 D 可以達到的 value
這個時候假設 V ( G, D ) 長的就像是下面這個例子的話
那這個問題的 solution
最好的 G 到底應該是哪一個
給你十秒鐘的時間想一下
等一下按投影片已經不小心按到了 所以你應該知道答案是甚麼
十秒鐘的時間過了
假設這是我們 optimization problem V ( G, D ) 就是長這個樣子
現在要解這個 optimization problem 哪一個 G 才是我們的 solution 呢
G 只有三個，你只有三個選擇
所以隨便猜也有 1/3 的正確率
你覺得 G1 是正確選擇的同學舉手一下
你覺得 G1 它可以 minimize 上面這個式子的同學舉手一下
你覺得 G2 它可以 minimize 上面這個式子的同學舉手一下
你覺得 G3 它可以 minimize 上面這個式子的同學舉手一下
手放下，多數人都選擇 G3，沒錯，正確答案就是 G3
所以如果你選擇 G3 的話代表你了解前面加 min 後面又加 max 到底是甚麼樣的意思
現在找出來的 G* 就是 G3
當我們給定一個 G1 的時候
這邊這個 D1* 的這個高其實就代表了 G1 的 generator 它所 generate 出來的 distribution
跟 P data 之間的距離
所以這個高就代表 G2 這個 generator 它所定義的 distribution 跟 data 間的距離
所以這個高就代表 G3 這個 generator 它的 distribution 跟 data 間的距離
所以 G1 這個 generator
它跟 data 的 Divergence 是這麼大
G2 它所定義的 distribution 跟 data 之間的 Divergence 是這麼大
G3 它所定義的 distribution 跟 data 之間的 Divergence 是這麼大
今天要 minimize Divergence 所以會選擇 G3 當作是最好的結果
接下來就是要想辦法解這個 min max 的 problem
這個 min max 的 problem 怎麼解
你記得我們在講 GAN 的時候我們說 GAN 是怎麼做的
GAN 是說有一個 generator 有一個 discriminator 然後在 train 的時候
是 iterative 去 train generator 跟 discriminator 固定住 generator
去 update discriminator
固定住 discriminator 接下來去 update generator
如果以下等一下要講的東西你聽不太懂的話 你就知道一件事情
GAN 的這個演算法就是在解這個 min max problem
為甚麼要解 min max problem
解這個 min max problem 的目的就是要 minimize generator 跟你的 data 之間的 J-S Divergence
如果你的 V 寫得像之前的投影片放的那個樣子就是 J-S Divergence
你可以寫別的樣子那你就是 minimize 其他的 Divergence
為甚麼下面這個 algorithm 是在解這一個 optimization problem
以下投影片就要解釋為甚麼這一個 algorithm
是在解這個 optimization problem
假設要解這個 optimization problem 的話 你要怎麼做
這個 max D V ( G, D ) 找一個 D 去 maximize V ( G, D ) 看起來有點複雜
把它用 L ( G ) 來取代
它其實跟 D 是沒有關係的
given 一個 G 就會找到最好的 D 讓 L ( G ) 的值越大越好
讓 V ( G, D ) 的值越大越好
假設最大的值就是 L ( G )
現在整個問題就變成要找一個最好的 generator G
它可以 minimize L(G) 這個問題任何人都會
他就跟 train 一般的 network 是一樣的
就是用 Gradient Descent 來解它
你對 L(G) 算一個 gradient
找一個 G 去 minimize L(G)
就把 θG 對 L(G) 的 gradient 然後用 Gradient Descent 去 update θG
就可以 minimize 這個式子
就可以 optimize 這個 optimization problem
找出 G*
現在有一個麻煩的地方就是 L(G) 如果把式子寫出來的話 它長的是這個樣子
這個裡面是有 max 的
有人就會問這個式子裡面有 max 它可以微分嗎
會不會不能夠微分 因為要算 L(G) 的 gradient
L(G) 這個式子裡面如果有 max
它會不會沒有辦法做微分
其實不會，因為想想看
我們之前有學到一個 Maxout Network
Maxout Network 裡面也有 max operation
但他顯然是有辦法用 Gradient Descent 解
到底實際上是怎麼做的呢
假設有一個 function f(x)
它裡面是有 max operation
來看一下有 max operation 的這種 function
要怎麼對它作微分
有一個 f(x) 它裡面有 max operation
它是對 f1(x), f2(x) 和 f3(x) 這三個 function 裡面找一個最大的出來，它就是 f(x)
假設 f1(x) 長這個樣子
f2(x) 長這個樣子 f3(x) 長這個樣子
這個 f(x) 它是 f1, f2, f3 取大的那個
f(x) 長甚麼樣子呢
f(x) 就是長這個樣子
如果 f1 比 f2, f3 大的話就取 f1
如果 f2 比 f1, f3 都大的話就取 f2
如果 f3 是最大的話就取 f3
這個 f(x) 它長的會是這個樣子
我滑鼠移動的位子，它長的是這個樣子
如果現在要把 f(x) 對 x 做微分的話
這件事情等同於甚麼
這件事情等同於看看現在的 x
可以讓哪一個 function f1, f2, f3 最大
就拿最大的那個出來算微分
就是 x 對 f(x) 的微分
這樣可能有點抽象就舉很具體的例子
假設要在這個地方
對 f(x) 做微分
算出來的微分值多少
算出來的微分就等同於是在對 f1 做微分
如果在這個區域
算出來的微分就等同於在對 f2 做微分
如果在這個區域算出來的微分就等同於是在對 f3 做微分
假如你的這個 function 裡面
有一個 max operation
實際上在算微分的時候
你只是看現在在 f1, f2, f3 裡面哪一個人最大
就把最大的那個人拿出來算微分
你就可以用 Gradient Descent 去 optimize 這樣的式子
假設你要用 Gradient Descent 去 optimize 這個 f(x)
實際上作法就是假設 initialize 的時候在這個地方
算一下它的 gradient 就像右移
如果像右移的時候，已經移到另外一個 region
本來是在這個 region 裡面是 f1 最大
跑到這邊以後就變成 f2 最大
假設你移到另外一個 region
這個 region 是 f2 最大
這個時候算出來的微分
就會變成是 f2 的微分
以此類推
總之剛才講那麼多只想要告訴你
就算是 Objective Function 裡面有 max operation
你也不需要害怕
你一樣是可以對他做微分的
所以就回到現在要解的這個 optimization problem
實際上會怎麼解它呢
剛才有講說如果一個 optimization problem 裡面你的 Loss Function 是有 max 的
要怎麼解它呢
你會先看現在你落在哪一個 region 裡面
再算現在那個 region 裡面哪一個 function 是 max 的對 max 的 function 做微分
你現在初始的在這個地方你就看
這個 function 它是最大的就對它做微分
在 update 參數以後要重新檢查一下你落在哪個 region
發現你落在這個中間 f2 這個 function 是最大的 region，你就要對 f2 做微分
把它套用到這個要 optimize min max problem 裡面
其實也是一樣的
一開始有一個初始的 G0
接下來要算 G0 對 L(G) 的 gradient
但是在算 G0 對 L(G) 的 gradient 之前
因為 L(G) 裡面有 max
所以不知道 L(G) 長甚麼樣子
所以要把 max D 找出來
所以假設在 given G0 前提之下
哪一個 D 可以讓 L(G) 最大
它是 D0*，D0* 可以讓 V( G0, D) 最大
如果這個 D 代 D0* 的話
就可以得到 L(G)
這件事情可以用 Gradient Ascent 就可以找出這個 D
它可以 maximize 這個 Objective Function
找到 D 可以 maximize 這個 Objective Function 以後
之後這個東西
就是 L(G)
接下來就可以把 θG 對這一項算 gradient
就可以 update 參數
就得到新的 generator G1
update G 的參數
就得到新的 generator G1
有新的 generator G1 以後
就要重新找一下最好的 D
你可能本來的 region 在這邊
最好的 D 是這個
但是現在移動 G1 以後
你可能已經進入下一個 region 所以你要重新找一個最好的 D
現在把這個 generator 從 G0 update 到 G1
可以讓這個 V(G1, D) 最大的那個 D 假設是 D1*
接下來就有一個新的 Objective Function
它是 V(G, D1*) 再把它對 generator 算 gradient 再 update generator
就得到 G2
這個 operation 就是有一個 G0
找一個可以讓 V(G0, D) 最大的 D0*
就得到 V 的 function 然後讓他對 G 做微分
再重新去找一個新的 D
再重新對 Objective Function 做微分
就會發現這整個 process 其實跟 GAN 是一模一樣的
你可以把它想成現在在找 D0*
去 maximize 這個 Objective Function 的 process
其實就是在量 P* 跟 PG0 的 J-S Divergence
當我們找到一個 G1，找到一個 D1* 它可以讓這個 Objective Function 的值變 maximum
其實就是在計算 P data 跟 PG1 的 J-S Divergence
而下面這個式子
這一項就是你的 J-S Divergence
你要 update 你的 generator 去 minimize J-S Divergence
這個時候你其實就是在減少你的 J-S Divergence
就是在達成你的目標 就是要去 minimize 你的 J-S Divergence
但是這邊打了一個問號
這邊為甚麼打一個問號
因為這件事情未必等同於真的在 minimize J-S Divergence
為甚麼這麼說，因為我們有說過
假設給你一個 generator
這裡的 generator 就是 G0
那你的 V( G0, D) 假設他長這個樣子
找到一個 D0*，這個 D0* 的值
就是 G0 跟你的 data 之間的 J-S Divergence
但是當你 update 你的 G0 的時候
變成 G1 的時候
這個時候 V( G1, D) 它的 function 可能就會變了
本來 V(G0, D) 是這個樣子
V(G0, D0*) 就是 G0 跟你的 data 的 J-S Divergence
今天你 update 你的 G0 變成 G1
這個時候整個 function 就變了
這個時候因為 G0* 仍然是固定的
所以 V( G1, D0* ) 他就不是在 evaluate J-S Divergence
我們說 evaluate J-S Divergence 的 D 是今天這個 V( G, D ) 這個值裡面
最大的那一個
所以當你的 G 變了
你的這個 function 就變了
當你的 function 變的時候同樣的 D 就不是在 evaluate 你的 J-S Divergence
如果在這個例子裡面 J-S Divergence 會變成是這個值
而不是這個值
但是為甚麼我們又說這一項可以看作是在減少 J-S Divergence 呢
這邊作的前提假設就是這兩個式子可能是非常像的
假設只 update 一點點的 G 從 G0 變到 G1
G 的參數只動了一點點
那這兩個 function 他們的長相可能是比較像的
所以因為他們的長相仍是比較像的
所以一樣用 D0* 你仍然是在量 J-S Divergence
這樣的情形就這邊本來值很小
突然變很高的情形可能是不會發生的
因為 G0 跟 G1 是很像的所以這兩個 function 應該是比較接近
所以你可以只同樣用固定的 D0*
就可以 evaluate G0 跟 G1 的 J-S Divergence
所以在 train GAN 的時候
它的 tip 就是因為你有這個假設
就是 G0 跟 G1 應該是比較像的
所以在 train generator 的時候
你就不能夠一次 update 太多
但是在 train discriminator 的時候，理論上應該把它 train 到底
應該把它 update 多次一點
因為在量 discriminator 的時候
你必須要找到 maximum 的值你才是在量 J-S Divergence
所以 train discriminator 的時候 你其實會需要比較多的 iteration 把它 train 到底
但是 generator 的話
你應該只要跑比較少的 iteration
免得今天現在在這個投影片上講的假設是不成立的
接下來講一下實際上在做 GAN 的時候
其實是怎麼做的
我們的 Objective Function 裡面
要對 x 取 expectation
但是在實際上沒有辦法真的算 expectation
所以都是用 sample 來代替 expectation
本來是對 P data sample x 取它的 expectation
實際上在做的時候
就是從 P data 這個 distribution 裡面
sample m 筆 data
把這 m 筆 data 的 D(x) 通通算出來然後再把它通通平均起來
就當作是 expectation
一樣，本來要從 PG 裡面 sample 一堆 x 出來算它的 expectation，但在實作上沒有辦法這麼做
所以實作上你的行為是從 PG 裡面 sample 出 m 筆 data
再把這 m 筆 data 都去計算它的 log ( 1 - D( x tilde )) 然後把它全部平均起來，就得到這一項的 approximation
實際上在做的時候
我們就是在 maximize 這個式子
而不是真的去 maximize 它的 expectation
這個式子如果你回去檢查看看的話
剛才講過這件事情就等同於是在 train 一個 Binary Classifier
所以在實作 GAN 的時候
你完全不需要用原來不知道的東西
你在 train discriminator 的時候
你就是在 train 一個 Binary Classifier
實際在做的時候是怎樣
discriminator 是一個 Binary Classifier
這個 Binary Classifier 它是一個 Logistic Regression
它的 output 有接一個 sigmoid
所以它 output 的值是介於 0 到 1 之間的
然後從 P data 裡面 sample m 筆 data 出來
這 m 筆 data 就當作是 positive example 或是 class 1 的 example
然後從 PG 裡面再 sample 另外 m 筆 data 出來
這 m 筆 data 就當作是 negative example 就當作是 class 2 的 example
接下來就 train 你的 Binary Classifier
train 一個 criterion 會 minimize Cross Entropy
會發現 minimize Cross Entropy，你把你的式子寫出來
它會等同於上面 maximize 這個 Objective Function
minimize Cross Entropy 等同於 maximize 上面這個 Objective Function
最後就再重新複習一次 GAN 的 algorithm
整個 GAN 的 algorithm 是這樣子
有一個 θd，有一個 θg
這個是 initialize parameter
在每一個 iteration 裡面
你做的事情是甚麼 你從 P data 這個 distribution 裡面 sample m 筆 example
你從某一個 prior distribution，它可以是 Gaussian Distribution 可以是 Normal Distribution
其實沒有那麼重要，你就固定住某一個 prior distribution
從這個 prior distribution 裡面
去 sample 出 m 個 vector，這些 vector 用 z 來表示
根據這些 vector z 把它丟到 generator 裡面
他們會產生一堆 image 也就是 x tilde
所以產生一堆 x tilde
這邊有一堆 real 的 image
這邊有一堆 generated 的 image
接下來要 train discriminator
這個 discriminator 在 training 的時候
它就是 maximize 下面這個 Objective Function
但我們剛才有講過 maximize 下面這個 Objective Function 其實就等同於
直接 train 一個 Binary Classifier，把這邊的 x 當作是一類，把這邊的 x tilde 當作是另外一類
直接 train 一個 Binary Classifier，你的 Binary Classifier 是 minimum Cross Entropy
就是在 maximize 下面這個式子
train 了一個 discriminator 出來
我們之前有講過我們 train discriminator 的目的是甚麼
是為了要 evaluate J-S Divergence
而甚麼時候 discriminator 可以 evaluate J-S Divergence
當它可以讓你的 V 的值最大的時候
那個 discriminator 才是在 evaluate J-S divergence
你要讓第一個值被 maximize 他才是在 evaluate J-S Divergence
為了要讓這個 V 的值最大
你一定要 train 很多次 train 到收斂為止
它才能讓 V 的值最大，對不對
但在實作上你沒有辦法真的 train 很多次 train 到收斂為止
但是你會說，我今天 train d 的時候
我要反覆 k 次，這個參數要 update k 次
而不是像投影片上面只寫 update 一次而已 你可能會 update 三次或五次才停止
這個步驟是在解這個問題
找一個 D 它可以 maximize V(G, D)
但是其實你沒有辦法真的找到一個最好的 D 去 maximize V(G, D)
你能夠找的其實只是一個 lower bound 而已
因為這邊通常在實作的時候你沒有辦法真的 train 到收斂
你沒有辦法真的一直 train，train 到說可以讓 V(G, D) 變的最大
通常就是 train 幾步然後就停下來
就算我們退一萬步說這邊可以一直 train train 到收斂
你其實也未必真的能夠 maximize 這個 Objective Function
因為在 train 的時候，D 的 capacity 並不是無窮大的
你會 train train train 然後就卡在一個 Local Minimum 然後就結束了
你並不真的可以 maximize 這個式子
再退一萬步說假設沒有 Local Maximum、Local Minimum 的問題
你可以直接解這個問題
你的 D 它的 capacity 也是有限
記得我們說過如果要量 J-S Divergence
一個假設是 D 可以是任何 function
事實上 D 是一個 network 所以它也不是任何 function
所以你沒有辦法真的 maximize 這一項
你能夠找到的只是一個 lower bound 而已 但我們就假設你可以 maximize 這一項就是了
接下來要 train generator
我們說 train discriminator 是為了量 J-S Divergence
train generator 的時候是為了要 minimize J-S Divergence
為了要減少 J-S Divergence
前面這個步驟是在量出 J-S Divergence
接下來下一個步驟是在減少 J-S Divergence
怎麼做
就先一樣 sample m 個 vector 出來 從 prior distribution sample m 個 vector 出來
接下來就要解下面這個式子
本來 discriminator 是要 minimize 這個式子
generator 要 minimize 一個一模一樣的式子
下面這個式子裡面你會發現第一項跟 generator 是沒有關係的
因為第一項只跟 discriminator 有關
它跟 generator 沒有關係
所以要 train generator 去 minimize 這個式子的時候
第一項是可以不用考慮它的
所以把第一項拿掉只去 minimize 第二項式子
這個第二個步驟就是在 train generator
剛才有講過 generator 不能夠 train 太多
因為一旦 train 太多的話 discriminator 就沒有辦法 evaluate J-S Divergence
所以 generator 不能 train 太多
你只能夠少量的 update 它的參數而已
所以通常 generator update 一次就好
你可以 update discriminator 很多次
但是 generator update 一次就好
用 discriminator 算出 J-S Divergence 以後 你只
用 generator 少少的 update 一次讓你的 J-S Divergence 變小，但你不能走太多，你 update 太多
量出來 J-S Divergence 就不對了 你就不是在量 J-S Divergence
所以這邊就不能夠 update 太多
到目前為止講說 train generator 的時候
你要去 minimize 的式子長這個樣子
在 Ian Goodfellow 原始的 paper 裡面
從有 GAN 以來，從開天闢地以來
他就不是在 minimize 這個式子
因為他在 paper 加了一小段，他說這個式子 log( 1 - D(x)) 它長的是這個樣子
而我們一開始在做 training 的時候
你的 D(x) 的值通常是很小的
因為 discriminator 會知道 generator 產生出來的 image 它是 fake 的，所以他會給他很小的值
所以一開始 D(x) 的值會落在這個地方
它的微分是很小的，所以在 training 的時候
會造成你在 training 的一些問題
所以他說我們把它改成這個樣子
沒有為甚麼，我們把它改成這個樣子 本來是 log( 1 - D(x))
把它換成 -log(D(x))
-log(D(x)) 它長的是這個樣子
這兩個式子的趨勢是一樣的
在這邊最大的東西在這邊還是最大 在這邊最小的東西在這邊還是最小
他們的趨勢是一樣的
但是他們在同一個位置的斜率就變得不一樣
在一開始 D(x) 還很小的時候
算出來的微分會比較大
所以 Ian Goodfellow 覺得這樣子 training 是比較容易的
其實你再從另外一個實作的角度來看
如果你是要 maximize 這個式子
你會發現你需要改 code 有點麻煩
如果你再仔細想想如果你是要 minimize 這個式子
其實你要改 code
如果你是 minimize 這個式子你可以不用改 code
剛才不是說在 train discriminator 就是在 train 一個 Binary Classifier 嗎
它就分辨兩個不同的類別
如果你是要 minimize 下面這個式子的時候
你其實只是把 Binary Classifier 的 label 換過來 本來是說從 data sample 出來的是 class 1
從 generator sample 出來的是 class 2
把它 label 換過來，把 generator sample 出來的改標成 label 1，然後用同樣的 code 跑下去就可以了
我認為 Ian Goodfellow 它只是懶得改 code 而已
所以就胡亂編一個理由應該要用下面這個式子
但實際上後來有人試了比較這兩種不同的方法
發現都可以 train 得起來，performance 也是差不多的
不知道為甚麼 Ian Goodfellow 一開始就選了這個
我覺得只是因為它 implement 下去才發現弄錯了
然後又懶得改 code 所以他就用這個東西繼續做下去
這些東西是有名字的，因為這些方法有人就會說這個叫 Original GAN 這個叫 Modify GAN
然後都搞不清楚甚麼是甚麼，所以後來 Ian Goodfellow 還寫了另外一篇文章
他說我們應該把這些 GAN 正名
上面這個叫做 Minimax GAN 就是 MMGAN
下面這個叫做 Non-saturating GAN 就是 NSGAN
在下課之前，剛才講了很多數學，現在講一些比較直觀的東西
所以按照 Ian Goodfellow 的講法今天這個 generator 和 discriminator 他們之間的關係是甚麼樣呢
假設這個是 data 的 distribution
這個是 generator 所產生出來的 data distribution
現在要 learn 一個 discriminator，discriminator 要給綠色的點比較高的分數
給藍色的點比較低的分數
這個 discriminator 的 Objective Value 就是這兩堆 data 的 J-S Divergence
或某種其他的 Divergence
有了這個 discriminator 以後
這些 generated 的點，因為在 train 的時候，generator 會希望它產生出來的東西通過 discriminator 得到的分數
越大越好，所以這些點就會往右移動
可能會一下子跑太多就跑到藍色的點的右邊去
但沒有關係，接下來你會再 train 一次你的 discriminator
因為現在藍色的點根綠色的點比較近
所以 discriminator 他的 loss 就比較大 代表這兩種點的 J-S Divergence 是比較小的
接下來這些藍色的點會順著 discriminator 給的 gradient 的方向往左移
最後藍色 distribution 跟綠色 distribution 就會越來越近
當這兩種 distribution 完全一模一樣的時候
train 一個 discriminator，這個 discriminator 會完全沒有辦法分別這兩種 data
因為對 discriminator 來說這兩種 data 是一模一樣的 不管它怎麼努力
都沒有辦法分別這兩種 data 所以最後 discriminator 會壞掉
對它來說每一個地方都是一樣的
每一個地方 P data 跟 PG 出現的機率都是一樣的
所以 discriminator 就會變成一條水平的線 它沒有辦法再做任何事情
這個 demo 是這個樣子
綠色的點是 P data
藍色的點是 PG
綠色的點是你的目標 藍色的點是 generator 產生出來的東西
背景的顏色是 discriminator 的值
discriminator 會 assign 給每一個 space 上的 x 一個值
背景的這個顏色是 discriminator 的值
這個 demo 看起來是這個樣子
你就會發現這個 discriminator 就把 PG 產生出來藍色的點趕來趕去
直到最後藍色的點跟綠色的點重合在一起的時候
對 discriminator 來說它就會壞掉 它完全沒有辦法分辨 PG 跟 P data 之間的差別
最後 discriminator 就會壞掉，因為完全沒有辦法分辨 generator 跟 discriminator 之間的差別
講到這邊有沒有問題要問
一般在做的時候，在 train 一個 classifier 的時候其實會害怕 data imbalance 的問題
今天在這個 task 裡面，data 是自己 sample 出來的
我們不會給自己製造 data imbalance 的問題
所以兩種 task 會 sample 一樣的數目
假設從 generator 裡面 generate 256 筆 data
那你今天從你的 sample 的 database 裡面你也會 sample 256 筆 data
如果你沒有問題要問的話 其實我有一個問題要問
我的問題是這個樣子
你不覺得今天講的跟上週講的是有點矛盾的嗎
如果按照 Ian Goodfellow 的講法 上面這個圖是 Ian Goodfellow paper 上的圖
他說最後 discriminator train 到後來 它就會爛掉變成一個水平線
但我們上周說 discriminator 其實就是 evaluation function
也就是說 discriminator 的值代表它想要評斷這個 object、generate 出來的東西它到底是好還是不好
如果 discriminator 是一條水平線
他就不是一個 evaluation function
對他來說所有的東西都是一樣好
或者是一樣壞
這個是 Ian Goodfellow 畫的圖
右上角是 Yann LeCun 畫的圖
Yann LeCun 在畫那個圖的時候 這個它也是在講 GAN
這個圖就是 discriminator 的圖
這個綠色的點就是 real data 分布
你發現他在畫的時候，在他的想像裡面
他的 discriminator 並沒有爛掉變成一個水平線
而是有 data 分布的地方他會得到比較小的值
而沒有 data 分布的地方他會得到比較大的值
跟我上課講的是相反 我上課講有 data 分布的地方值比較大
沒有 data 分布的地方值比較小 他就講正好相反但意思完全是一樣的
有 data 分布的地方值是比較小 其他地方值是比較大的
跟 Ian Goodfellow 講的是有一些矛盾的
這個就是神奇的地方
因為這個都是上代發展中的理論
所以有很多的問題是未知的 也許明年再開同樣的課的時候
我又會有完全不一樣的講法也說不定
以前在 train Deep Learning 的時候
我們都要用 Restricted Boltzmann Machine
過去我們都相信沒有 Restricted Boltzmann Machine 是 train 不起來的
像我們之前第一次開 MLDS 的時候 其實就會花兩周講 Restricted Boltzmann Machine
但今天如果再講 Restricted Boltzmann Machine 我相信你就生氣了 覺得是在拖台錢
因為根本就用不上這個技術
所以這個變化是非常快的 也許明年再來講同樣東西的時候
就會有截然不同的講法也說不定
你如果問我到底是哪一種的話 假設你硬要我給你一個答案
告訴你到底應該是 Ian Goodfellow 講得比較對 還是 Yann LeCun 講得比較對
我的感覺是首先可以從實驗上來看看
如果你真的 train 完你的 GAN
然後去 evaluate 一下 discriminator
他的感覺好像是介於這兩個 case 中間 他絕對不是爛掉
絕對不是變成一個完全爛掉的 discriminator
你自己回去做做看，幾時 train 出這樣的結果
雖然是這種簡單的例子你也 train 不出這個結果的
就算是一維的例子也都做不出這個結果
所以不太像是 Ian Goodfellow 講的這樣
但是 discriminator 也不完全反映了 data distribution
感覺是介於這兩個 case 之間
這些觀點到底對我們了解 GAN 有甚麼幫助
也許 GAN 的 algorithm 就是一樣，那演算法就是那個樣子，就是 train generator、train discriminator
iterative train，也許他的 algorithm 是不會隨著你的觀點不同
但是你用不同的觀點來看待 GAN
你其實在設計 algorithm 的時候
空間會有些微妙的差別，也許這些微妙的差別導致最後 training 的結果會是很不一樣的
我覺得也許 Yann LeCun 的這個講法
我上週講的
discriminator 是在 evaluate 一個 object 的好還是不好
他是在反映了 data distribution 這件事
也許更接近現實
為甚麼我會這麼說
首先，你在文獻上會看到很多人會做甚麼事情
他會把 discriminator 當作 classifier 來用
所以先 train 好一個 GAN
然後把 discriminator 拿來做其他事情
假設 discriminator train 到最後
按照 Ian Goodfellow 猜想會爛掉的話
拿它來當作 pre-training 根本就沒有意義
但很多人會拿它當作 pre-training
也顯示他是有用的
所以他不太可能真的 train 到後來就壞掉
這個是第一個 evidence
另外一個 evidence 是你想想看你在 train GAN 的時候
你並不是每一次都重新 train discriminator
我們並不是每次都重 train discriminator
而是會拿前一個 iteration 的 discriminator
當作下一個 iteration 的 initialize 的參數
如果你的 discriminator 是想要衡量兩個 data distribution 的 Divergence 的話
你其實沒有必要把前一個 iteration 的東西拿來用
因為 generator 已經變了
保留前一個 iteration 的東西有甚麼意義呢
這樣感覺是不太合理的
也有人可能會說因為 generator update 的參數
他 update 的量是比較小的
所以也許把前一個 time step 得到的 generator
當作下一個 time step 的 initialization
可以加快 discriminator 訓練的速度
也說不定 這個理由感覺也是成立的
不過在文獻上我看到有人在 train GAN 的時候他有一招
每次 train 的時候他不只拿現在的 generator 去 sample data
他也會拿過去的 generator 也 sample data
然後把這些各個不同 generator sample 的 data 通通集合起來
再去 train discriminator
可以得到的 performance 會是比較好的
如果 discriminator 是在 evaluate 現在的 generator
跟 data distribution 的差異的話
好像做這件事情也沒有太大的意義
因為現在量 generator 跟 data 之間的差異
拿過去 generator 產生的東西
有甚麼用，沒什麼用 為甚麼要這麼做，但是
在實作上發現拿過去 generator 產生的東西
再去訓練 discriminator 是可以得到比較好的成果
所以這樣看起來，也許這是另外一個 support 支持也許 discriminator 在做的事情
並不見得是在 evaluate 兩個 distribution 之間的 Divergence
不過至少 Ian Goodfellow 一開始是這麼說的 所以我們把 GAN 最開始的理論告訴大家
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
