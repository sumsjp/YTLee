臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
各位同學大家好，今天要講 Generative Adversarial Network，縮寫是 GAN，就是 GAN
一開始要做的第一件事情是
要先知道 GAN 要怎麼正確的發音
所以就用 Google 小姐來唸一下 GAN 是怎麼發音的
所以其實是有非常多人在研究這個技術的
如果在路上聽到有人大聲的說ㄍㄢ四聲，他們其實是在討論這個技術
今天就要來講這個技術
首先先說一些抬轎的話，讓你知道這個技術有甚麼重要性
有一個人在 Quora 這個論壇上問
最近在 Unsupervised Learning 的領域 有甚麼樣的 breakthrough
然後 Yann LeCun 就親自來回答了
他說 Adversarial Training，今天要講的 GAN 的技術
是 the coolest thing since sliced bread
since sliced bread 是甚麼意思 這邊可以學到一個新的英文片語
since sliced bread 翻成中文的話可以翻成 有史以來 的意思
google 了一下，因為在過去
在賣吐司麵包的時候
是沒有切片的
所以家庭主婦買這個吐司麵包回去的時候要自己切片覺得很麻煩
後來有人就發明了切片的吐司，大家就覺得很高興
有一個好東西問世的時候
就會說 since sliced bread
可以翻譯成有史以來的意思
所以他說 GAN 這個技術是有史以來他覺得最酷的東西
這是另外一個問題 有人問
在 Deep Learning 領域，最近有沒有甚麼 breakthrough
Yann LeCun 他也親自來回答了
GAN 跟他的種種變形是
近十年來他覺得 ML 的領域最有趣的 idea
所以 Yann LeCun 他給 GAN 這個技術非常高的評價
在網路可以找到 GAN 的動物園
就直接 google GAN 加上 zoo GAN、動物園就可以找到各式各樣相關的技術
因為現在如果發明了一個新的跟 GAN 有關的技術
你就會在 GAN 前面加一些英文的字
可是英文的字母只有 26 個
所以很快的名字就通通被用盡了
這個名字通通都撞在一起 比如說有兩個 LSGAN
一個是 Least Sqaure GAN 一個是 Loss Sensitive GAN
完全是不一樣的東西但因為英文字母是有限的
很快的名字就都被用盡了
這個圖是甚麼？這個圖是講說
這個 GAN 的動物園裡面
收錄了各種有名有姓的 GAN
你可以自己去查查看，裡面光 SGAN 就有四個以上
它就統計了一下，到目前為止
已經有接近三百種不同的 GAN 了
因為英文字母是有限的所以會發生這樣的情形
這邊是 Variational Approaches for Auto-Encoding Generative Adversarial Networks
按照他的名字他應該叫 AGAN 或者是 AEGAN
作者在 paper 裡面寫說 AEGAN 已經被用掉了
看起來其他的英文字母也通通被用掉了
他只好把它叫做 alphaGAN
在其他領域，不止是 Machine Learning 的領域，當然 GAN 是非常的重要的
在其他領域，GAN 其實也有很多的應用
我知道在 Image Processing 上會看到很多 GAN 應用
但在其他和 Image Processing 沒有那麼直接相關的領域
也可以看到很多 GAN 的應用
舉例來說我最近才剛去了 ICASSP
ICASSP 是 Signal Processing 的 conference
在 ICASSP 裡面我給了一個 GAN 的 tutorial，在 tutorial 的開場
我就統計了一下近年 ICASSP 跟 GAN 有關的 paper
我用關鍵字看看那些 paper 有包含這些關鍵字
看看那些 paper 是跟這些關鍵字是有關係的
我用 generative 這個關鍵字會發現從 2012 年到 2017 年
和 generative 有關的 paper 都很少，當然還是有一些啦
因為 generative 的 model 不是只有 GAN 而已 他們用其他的 generative model 但是沒有非常多
如果用 adversarial 這個詞彙
在 2013 年的時候有兩篇 paper，他的 title 有 adversarial 這個詞彙，不過他跟 GAN 是完全沒有關係的
2016 也有一篇，他跟 GAN 也是沒有關係的
2017 有兩篇，他們確實跟 GAN 有關係
但到今年 2018 年就有四十篇了所以他成長的速度是 20 倍
按照這個速度明年應該要有八百篇
我其實用了 reinforcement 這個詞彙當作對照組
就會發現 reinforcement 這個詞彙他的成長速度就沒有 adversarial 成長速度這麼快
GAN 他變成一個非常重要的技術
接下來的四周都要來講 GAN 這個技術
今天要講的是最 basic 的 idea
給你一個概念假設你不知道 GAN 是甚麼的話
給你一個概念讓你知道這個技術運作起來大概是甚麼樣子
我們就從 GAN 最基本的概念開始說起
在 GAN 裡面想要讓機器做到的事情
是要讓機器來生成東西
舉例來說讓機器生成影像
或者是假設在文字處理的領域，你會讓機器
來寫詩、讓他產生句子、讓他產生文章
在 generation 這樣的 process 裡面
你需要做的事情就是訓練出一個 generator
如果你要做的是要影像生成 那這個 generator 要做的事情就是
你隨便給他一個輸入，舉例來說你 random sample 一個 vector
有一個 Gaussian Distribution 從 Gaussian Distribution 裡面
random sample 一個 vector，把這個 vector 丟到 generator 裡面
generator 就要產生一張 image
丟不同的 vector 就應該產生不同的 image
這個是 image 的 generation
在文字的 generation、sentence 的 generation 也是一樣
丟出一個 vector，generator 就輸出 How are you?
丟另外一個 vector 他就說 Good morning.
丟另外一個 vector 他就輸出 Good afternoon. 等等
我們要用 GAN 來達成的目標
就是要訓練出這樣的 NN 的 generator
你可能會有點困惑說，輸入一個 random 的 vector
他讓 output 一張 image 或者是 output 一段詞彙
有甚麼用，具體而言就是沒有甚麼用
我認為比較有用的是 Conditional Generation
也就是可以輸入一些條件
比如說輸入文字讓機器產生對應的圖片
輸入圖片讓機器產生另外一張對應的圖片 這之後會講到
如果不是輸入 random 的東西
而是輸入一個你了解那是甚麼、可以 control 的東西比如說文字
或者是影像，讓機器產生對應的東西
這個技術就有非常多的應用
這個之後再提
今天就只 focus 在讓機器吃一個隨機的向量
他就要 output 你想要的 object
這樣子的 application 上
剛才講過在 GAN 裡面，想要訓練的東西
想要找出來的東西
就是一個 generator
這個 generator 是一個 Neural Network
我們都知道所謂的 Neural Network 他就是一個 function
input 一個東西，output 一個東西
在 GAN 裡面他的 input 就是一個 vector
如果是影像的生成他的 output 就是一張 image
或是講得更具體一點
在影像生成的話，generator output 就是一個 high-dimensional 的向量
generator output 是一個向量
這個向量非常非常的長
這向量的每一個 dimension 就對應到影像中的一個 pixel 的顏色
把這個 high-dimensional 向量排成一張影像的樣子
就可以讓 generator 產生一張圖片
或者是講得更具體而言
假設想要讓機器做二次元頭像的生成
那得到的結果可能就是這樣，有一個 generator
隨便給他一個向量，他的輸出就是一個二次元人物的頭像
這張圖是機器真正生成的 是用右上角這個程式生成的
而通常輸入的向量他的每一個 dimension
會對應到圖片的某種特徵
也就是說改變了其中一個 dimension 的數值
就會發現產生出來的圖片的某種特徵有所改變
假設第一個 dimension 對應的是頭髮的長度
把這個 vector 他的第一個 dimension 的值從 0.1 調到 3
generator 的 output 就會是一個長頭髮的角色
或者是假設 input 的 vector
他的倒數第二個 dimension 對應到頭髮是不是藍色的
值越大代表頭髮越藍
把這個值從 2.4 調到 5.4
產生出來的角色就會變成藍頭髮
這兩個角色看起來非常像
因為只改了倒數第二維而已 其他維度的值固定不變的
只改了倒數第二維而已
所以他只改變了頭髮的顏色，其他的特徵
仍然會是很相似的
或者是說假設最後一個維度代表是嘴巴的大小
本來這個值很小，所以他是無口的狀態
把這個值調大，然後他就笑起來了，笑口常開這樣
這個是 generator，在 GAN 裡面比較神奇的地方
就是同時會訓練一個 discriminator
等一下會講這個 discriminator 和 generator 之間
有甚麼樣的關係
先來看這個 discriminator 做的事情是甚麼
這個 discriminator 也是一個 Neural Network
剛才講過 Neural Network 就是一個 function
吃一個東西當 input，就輸出一個東西
discriminator 他是吃一張圖片
當作 input 假設產生的是圖片的話
他吃圖片當 input，假設要產生的不是圖片
是句子的話，他就吃句子當作 input
discriminator 吃一張圖片當 input
他的輸出是一個 scalar 是一個數值
這個數值代表甚麼意思 這個數值代表產生出來的這張圖片的 quality
這個數值越大，就代表產生出來的這張圖片的 quality 越高
他看起來越像是真實的圖片
他看起來越 realistic
這一句要講的是產生出來的數值越大
discriminator output 數值越大
就代表輸入的圖片越真實
假設要做二次元人物頭像的生成
讓機器吃這張圖片，因為畫得很好所以就是 1.0
這個也畫得很好所以 output 1.0 假設 1.0 就是他可以輸出最大的值
假設這個畫得很差，機器就給他 0.1 分
這個也畫得很差，機器就給他 0.1 分
這個就是 discriminator 做的事情
等一下第三堂課助教會來講一下作業
作業三做的是二次元人物頭像的生成
一樣分成 3-1、3-2、3-3 這樣子
3-1 就是做二次元人物頭像的生成 等一下細節就交給助教來講
在 GAN 裡面有一個 generator
有一個 discriminator
他們之間的關係就好像是獵食者跟他的獵物之間的關係
怎麼說呢
右上角這個是一隻枯葉蝶，這不是一個枯葉，是一個枯葉蝶
枯葉蝶跟枯葉長得非常的相似
為甚麼枯葉蝶會長的跟枯葉非常的相似呢
那是因為有天擇的壓力
枯葉蝶的祖先也是彩色的
因為麻雀會吃枯葉蝶
所以枯葉蝶在天擇的壓力之下就變成棕色的
因為麻雀判斷蝴蝶能不能吃的標準就是他是甚麼顏色
如果是彩色就會被吃掉 如果是棕色就不會被吃掉
天擇的壓力下，枯葉蝶的祖先就變成是棕色
但是枯葉蝶天敵也是會演化的
這個東西他是波波
波波進化就會變成比比鳥
如果說錯了等下記得糾正我
還是比比鳥會進化變波波
是比比鳥對不對，我記得的是對的 這個是比比鳥
波波後來就進化成比比鳥
比比鳥判斷一個東西能不能吃的標準並不是看顏色 而是看有沒有葉脈的紋路
如果沒有葉脈的紋路還是會被吃掉的
所以枯葉蝶的祖先在天擇的壓力之下就產生了看起來像是葉脈的條紋
他可以騙過比比鳥
其實比比鳥也會再進化
他再進化，他可能有別的標準來判斷這個東西是不是可以吃的
枯葉蝶也會再不斷地進化
所以獵食者和天敵就會在互相拮抗之中變得越來越強
而這個枯葉蝶就像是 generator
而他的天敵就像是 discriminator
所以假設要讓機器做二次元人物頭像的生成
首先要準備一個 database
這個 database 裡面有很多真實的二次元人物的頭像
generator 就是一個 network
但一開始他的參數是隨機的
所以一開始 generator 也不知道怎麼產生二次元人物的頭像
他只能產生看起來像是雜訊的東西
discriminator 做的事情就是給他一張圖片
判斷這張圖片像是 generator 生成的還是像是真實的圖片
接下來 generator 就是要想辦法騙過第一代的 discriminator
第一代的 discriminator 可以分辨第一代 generator 的 output 和真實圖片之間的差異
他可能就用有沒有顏色來判斷他是真實的還是被生成的圖片
所以第二代的 generator 進化了 他想要騙過第一代的 discriminator
所以他就會產生有色彩的圖片
但是 discriminator 跟著也會再進化
第一代的 discriminator 會被第二代 generator 產生的圖片騙過
但是第二代的 discriminator 他會學著去分辨這兩種圖片之間的差異
他可能會發現真實的圖片是有嘴巴的
如果是第二代 generator 產生的圖片是沒有嘴巴的
他就用這個標準來判斷一張圖片是不是真正的圖片
是不是真正人畫的二次元人物的頭像
generator 就會跟著再進化
變成第三代的 generator
第三代的 generator 產生出來的圖片
會變過第二代的 discriminator
一旦是第二代的 discriminator 會進化成第三代的 discriminator
所以 generator 和 discriminator 他們就會不斷的進化
所以 generator 產生出來的圖片就會越來越真實
因為 generator 和 discriminator 有一個對抗的關係
他們像是天敵與被獵食者之間的關係
所以用 adversarial 這個詞彙來命名這個技術 adversarial 就是對抗的意思
叫做 Generative Adversarial Network
但有人就會問為甚麼是讓兩個 network 互相對抗
為甚麼不能彼此合作 為甚麼世界不是充滿愛與和平
這個東西只是一種擬人化的說法而已
現在這個講法讓你覺得他們是在對抗的
GAN 這個技術是 Ian Goodfellow 在 14 年提出來的
原始的 paper 他是用作假鈔跟警察的例子
generator 不斷的在做假鈔，他是壞人
discriminator 是警察，他要去判斷這張鈔票是真鈔還是假鈔
最後 generator 做的鈔票會越來越像真鈔
直到 discriminator 完全沒有辦法分辨為止
這個例子我沒有很喜歡，因為是充滿暴力犯罪的例子
從那個例子看起來 generator 和 discriminator 是對抗的關係
但是只要換一個例子，generator 跟 discriminator 其實可以看作是合作的關係
可以想成 generator 是學生 discriminator 是老師、是指導教授
generator 要學習怎麼畫二次元人物的頭像
discriminator 看過很多畫二次元人物的頭像
他知道二次元人物的頭像應該長甚麼樣子
所以一開始第一代的 generator 就是一年級的學生，他不知道怎麼畫二次元人物的頭像
所以他畫出來的東西就非常的模糊、非常的奇怪
他就把這些圖片拿給老師看
一年級的老師會給他 feedback 告訴他
你這些圖片
跟真實圖片差異是真實圖片有兩個圈圈 當然這只是一個擬人化的講法
等一下會具體的告訴你實際上在 train network 是甚麼樣子
這個 network 不要以為他會講話 他不會講話
這個只是個比喻的講法 等一下會講實際上 training 是甚麼樣子
discriminator 發現這兩種圖片的差別是這個有兩個圈圈 他都沒有圈圈
他就會把這個資訊 feedback 給 generator 告訴 generator 你畫的這些圖片跟真實圖片的差異
是你沒有畫兩個圈圈
這個 generator 接下來就升上二年級
他會記得老師的教誨，他知道在畫二次元人物頭像的時候
應該要把兩個圈圈點上去
然後他就把畫出來的頭像再給二年級的老師看
他本來以為老師會說他好棒
但其實老師只會說他好棒棒而已
因為二年級的老師就變得更嚴格了
二年級的老師會告訴他
你畫的跟真實的圖片仍然有很大的差異
因為真實的圖片是彩色的 你畫的是沒有彩色的
所以 generator 接下來三年級以後他產生的圖片就會變成彩色的
generator 就會不斷的進步
discriminator 就會變得越來越嚴格
學生畫的越來越好，老師越來越嚴格
最後學生就可以畫出非常像是真的人所畫的二次元人物的頭像
在互動的過程中
其實會發現會有兩個問題
第一個問題是為甚麼 generator 沒有辦法自己學呢
為甚麼一定要有一個 discriminator 介入
為甚麼 generator 沒有辦法直接從這些範例裡面
學習怎麼產生二次元人物的頭像
為甚麼一定要透過 discriminator 才能學習呢
等一下會試著來回答這個問題
第二個問題是 discriminator 這麼會批評
為甚麼他不自己做呢
我想大家都有這個困惑對不對
老師為甚麼都不自己 coding 呢
老師為甚麼都只用嘴巴 coding 呢
等一下要來回答這個問題
所以 generator 跟 discriminator 之間的關係
他們就是寫作敵人，唸作朋友
寫作敵人，唸做朋友的意思知道嗎
就是像塔矢亮和進藤光的關係
或者是像是佐助與鳴人的關係
所以他們是朋友也是敵人
接下來就來正式講一下
Generative Adversarial Network 他的演算法是怎麼運作的
我們之後會講到他的原理
還有他背後的理論，今天先不講理論，就只講他操作起來看起來像是甚麼樣子
就算你對他的理論還沒有任何的了解
其實從這個操作的過程、演算法 其實也可以體會為甚麼他是個有用的方法
有一個 generator，有一個 discriminator 他們都是 network
我們知道 train network 一開始參數 random initialized 的
random initialized generator 跟 discriminator 的 network 的參數
接下來要 iterative 的去 train 這個 generator 和 discriminator
要跑很多個 iteration
在每一個 iteration 裡面要做兩件事 有兩個步驟
第一個步驟，把 generator fix 住
把 generator 參數固定住
只去調 discriminator 參數
只 train discriminator，把 generator 固定住
怎麼做呢 有一個固定住的 generator
然後把一大堆 random vector 丟到 generator 裡面
這個 generator 就會很產生很多圖片
因為一開始 generator 參數是隨機的
所以產生出來的圖片並不會特別好，可能是非常糟的
接下來你有一個 database，剛才講過如果要讓機器產生某種東西
你要蒐集那種東西的範例 你要讓他產生二次元人物的頭像
你要蒐集很多二次元人物的頭像當作範例
你要讓機器寫詩，你要蒐集很多的詩詞作為範例
有一個 database 裡面都是二次元人物的頭像
從這個二次元頭像裡面 sample 出一些 example
現在有兩組圖片，一組是從 database 裡面 sample 出來的
另外一組圖片是 generator 所生成的
接下來就要去訓練 discriminator，去調整 discriminator 的參數
怎麼調 discriminator 參數
目標就是，如果這個 image 是 realistic 的
就給他比較高的分數
如果這個 image 是 generator 所產生的
就給他比較低的分數
如果是從 database sample 出來的 image 就是高分
從 generator 產生出來的 image 就是低分
可以把它當作是 regression 的 problem
可以把它當作是 classification 的 problem
反正不管怎麼做，就是要訓練這個 network
把這組圖片丟進去
output 的分數就是大的
把這組圖片丟進去，output 的分數就是小的
講得更具體一點，訓練的目標就是
把這四張圖片丟進去 discriminator，output 的值要離 1 越接近越好
把這四張圖片丟進去 discriminator，output 的值要離 0 越接近越好
就用這 criteria 去訓練 discriminator
我相信這個在實作上對大家來說
都不是問題，就跟一般訓練 network 作 regression，或是訓練一個 network 作 classification 意思是一樣的
下一步要固定住 discriminator
我們只去調 generator 的參數
前一步是固定 generator 只調 discriminator
discriminator 訓練好了固定住 discriminator
只調 generator
怎麼調 generator 的參數
先把一個 vector 丟到 generator 裡面
generator 會產生一張圖片
接下來把這張圖片丟到 discriminator 裡面
discriminator 會給他一個分數
generator 訓練的目標就是要去騙過 discriminator
但所謂的騙是一個擬人化的講法
實際上做的事情是
希望 generator 產生出來的圖片
discriminator 可以給他比較高的分數
固定住 discriminator 的參數
只去調 generator 的參數
希望 generator 的 output 丟到 discriminator 以後
他 output 的值可以越大越好
那你可以想見說
剛才在前一步驟已經把 discriminator 訓練好了
這個訓練好的 discriminator
看到好的 image 就會給他比較大的分數
既然 generator 可以調整他的參數
使得他 output 的 image，discriminator 給他高分
但顯然 generator 產生出來的 image
會是比較真實的
因為 discriminator 是看到真實的圖片才給他高分
generator 既然可以調整參數產生出來的圖片是 discriminator 會給高分的
但顯然 generator 產生出來的圖片會比較真實
實際在 implement 這個 code 怎麼做呢
實際上在 implement 的時候
你會把 generator 跟 discriminator 合起來
當作是一個巨大的 network
大家知道意思嗎 假設 generator 是五層
discriminator 也是五層
就是把前面的五層跟後面的五層接在一起
變成一個有十層的 network
這個十層的 network input 是一個 vector
他的 output 就是一個數字
但是在這個十層的 network 裡面其中的 Hidden Layer
他很寬，他的 output 就是一張 image
大家了解我意思嗎 假設這個是 64 x 64 的 image
那已就會有其中一個 Hidden Layer 他的 output 會 output 64 x 64 個數值
他會 output 64 x 64 維
把那個 Hidden Layer 拿出來
就可以把他看作是一張 image
在 train 這個 network 的時候
就是固定最後幾個 Hidden Layer
只調前面幾個 Hidden Layer
他讓 output 的值越大越好
因為我們現在是讓他 output 越大越好
所以不是 Gradient Descent，Gradient Descent 是讓你的目標越小越好
你做的事情其實是 Gradient Ascent
不過 Gradient Descent 跟 Gradient Ascent 其實意思是一樣的
對不對 只是把 Objective Function 減一個負號而已
所以實際上在做的時候
就是把 generator 跟 discriminator 接起來變成一個巨大的 network
然後把巨大的 network 最後幾個 layer fix 住
只 train 前面幾個 layer
目標是要讓整個 network output 的值越大越好
你會發現因為你的目標是要讓整個 network 的值 output 越大越好
所以固定住最後幾個 layer
是非常有道理的
假設不固定住最後幾個 layer 會發生甚麼事
因為目標是要讓 output 越大越好
其實他只要調最後這個 output 一個 scalar
只要調最後一個 layer 的 weight
讓他的值越大越好
馬上就可以讓會後的 output 爆表
但是因為最後這幾個 layer 是固定住的
只能夠調前面幾個 layer
想辦法讓最後的 output 越大越好
等一下講完這一頁以後停下來問大家有沒有甚麼問題
這邊正式的把這 algorithm 再講一次
有一個 discriminator 參數是 θd
有一個 generator 參數是 θg
整個演算法就是這個樣子
摳一下這個演算法就可以完成作業 3-1 了
這個演算法是這樣
有一個 database，這個 database 在作業 3-1 是我們提供的
提供一個很大的 database，二次元人物頭像的 database 裡面有好幾萬張的圖片
接下來從這個 database 裡面
sample 出 m 筆 example sample 出 m 張 image
這個 m 其實就是 batch size
就像 train network 的 batch size
m 要調一下，32、64，他是 batch size
同時有一個 distribution，這個 distribution 我個人覺得沒有這麼重要
所以可以在作業裡面 verify 一下這個 distribution 對你的結果有多大的影響
這個 distribution 可以是一個 Uniform Distribution
可以是 Gaussian Distribution 都可以，假設他是 Gaussian Distribution
從 Gaussian Distribution 裡面 sample 出 m 個 vector
至於這個 vector dimension 要多少，要五維、十維、還是一百維
這個你自己決定，這個一個參數要調的
你就 sample 出 m 個 vector 從 Gaussian Distribution 裡面
接下來就根據這 m 個 vector 會去產生 m 張 image
剛才有說 generator 就是吃一個 vector output 一個 image
把 generator 產生出來的 image 用 x tilde 來表示
把這 m 個 vector 丟到 generator 裡面讓他產生 m 張圖片
接下來就要去調整 discriminator 前半部是在訓練 discriminator
怎麼調 discriminator
底下這個式子只是一個範例
你可以用這個式子也可以用別的 之後會講也許用別的結果會更好
這個只是最原始的 GAN 的 paper
他的式子是這樣寫的
他說要去 maximize 這個 Objective Function
這個 Objective Function 是甚麼意思
首先把 m 張真實的圖片拿出來
把他們都通過 discriminator 得到分數
然後取一個 log，再把 m 個圖片得到的分數通通平均起來
我們要讓這個 Objective Function 的值越大越好
意味著要讓 log D(x) 越大越好
也就是要讓 D(x) 越大越好
所以這個式子告訴我們要訓練 discriminator 讓他可以給這些真實的 image 的值越大越好
這是第一項，第二項是甚麼
第二項是把這些假的圖片，x tilde generator 產生出來的圖片 x tilde
丟到 discriminator 裡面產生出一個 value
這邊 discriminator 其實，output 會通過 sigmoid
他的值會介於 0 到 1 之間
不要 sigmoid 也可以，不過這邊如果沒有 sigmoid 的話
1 在減掉大於 1 的值再取 log 會有問題
所以這邊就給一個 sigmoid
D 的值一定是落在 0 到 1 之間 你可能會問為甚麼一定要這樣
不一定要這樣，這樣做沒有比較好
之後在接下來的課程會告訴你這樣做其實不是最好的方法
這個只是最原始的方法
用這個方法是做得出來作業 3-1 的
今天把這個 generate 出來的 image 丟到 discriminator 裡面，他還會給他一個分數
把 1 減掉這個分數再取 log 然後取平均值 希望這一項越大越好
希望這一項越大越好的意思就是 希望 1 - D( x tilde ) 的值越大越好
希望 1 - D(x) 的值越大越好就是希望 D( x tilde ) 越小越好
第二項的意思是希望訓練 discriminator
這些 discriminator 如果把 generate 出來的 image 當作 imput 的話
他 output 的值要越小越好
你有加一個 Objective Function
要去 maximize 這個 Objective Function
怎麼 maximize 這個 Objective Function 就套一下 Gradient Ascent
如果是 Gradient Descent 這邊是減的
如果要讓 Loss Function 越小越好的話
會取 gradient 然後乘 Learning Rate 然後把他減掉
但是現在要讓他越大越好 所以這邊是加的，對你的 Objective Function
算他的 gradient
然後乘上 Learning Rate 然後再加上原來的參數
就得到新的參數 θd
至於 Learning Rate 要怎麼調，永遠可以用一些 Adam 等等進階的技術來設定 Learning Rate
這邊在這個式子裡面
我們只寫把 θd update 一次參數
至於要 update 幾次參數這是另外一個 hyperparameter
是你要調的，你可以說在這邊，我執行這一項
執行這一項三次，執行這一項五次都可以 這是個參數你要去調他的
這個是訓練 discriminator，把 discriminator 訓練好以後
接下來要訓練 generator
怎麼訓練 generator
一樣去 sample 出 m 筆 data
m 個 random vector
這 m 個 random vector 不需要跟這 m 個 random vector 一樣，他可以都是另外 sample m 個 random 的 vector
剛才說 generator 要想辦法騙過 discriminator
把它的式子寫出來就這樣
把這個 random vector 丟到 generator 裡面
generator 會產生一張 image
這邊看起來有點複雜， log ( D ( G ( z) ) )
但我們一項一項來看
G(z) 就是一張圖片，把 z 丟到 generator 讓他產生一張圖片
G(z) 是一張圖片
把這張圖片丟到 discriminator 裡面
D ( G ( z) ) ) 是一個數值
然後再把它取 log，再對所有 sample 出來的 data、一個 batch 裡面的 data 取平均
希望這個值越大越好
也就是希望 generator output 出來的這個 image
丟到 discriminator 以後
輸出來的值越大越好
這個是要訓練的目標
接下來用 Gradient Ascent 去調 generator 參數，希望它可以讓 Objective Function 的 output 值越大越好
紅色的部分就是訓練 generator
這兩個步驟就會反覆的執行
訓練好 discriminator，接下來訓練 generator
再回頭去訓練 discriminator
再訓練 generator
這兩個步驟會反覆的執行
講到這邊有沒有針對這個 algorithm 要問的呢
沒有的話就實際看一下你應該要作出甚麼樣的結果
這個是我實際上作一下 Anime Face Generation
網路上可以找到 database 連結再下面
在做的其實用的不是這個 database，等一下告訴你那個 database 是哪來的
載了一個 database 下來
就可以摳 GAN 開始去 train 它
這個是 update 一百次參數以後的結果
看起來像是這個樣子
update 一千次，這個時候 generator 就知道二次元的人物
應該是有眼睛的，所以它就把眼睛點出來
update 兩千次，這個時候
我發現它把嘴巴也點出來
update 五千次以後
這個時候 machine 發現動畫人物就是要有水汪汪的大眼睛
這個眼睛都變得很大，都有一個反白
update 一萬次得到的結果像是這樣
看起來像是水彩畫的感覺 他有很多地方都暈開了
看起來比較有二次元人物頭像的樣子
只是感覺沒有畫得很好 是用水彩畫得所以有一點暈開的感覺
這個是 update 兩萬次的結果
這個是 update 五萬次的結果
就停在 update 五萬次的地方
會發現這邊有很多頭像已經看起來非常真實了
這個並不是真的做得特別好的
這個是上學期同學交給我的結果
所以理論上你應該要可以做到這樣
他們其實用了自己蒐集的 data
這學期用的就是他們蒐集的 data
感謝他們提供他們蒐集的 data 給我們
理論上這學期做出來就應該要像這個樣子
這個看起來非常的真實對不對
比很多會崩壞的動畫公司畫的都還要好
還是有一些崩壞 但看可不可以做的更好一點
這個是二次元人物的生成
這個就是作業 3-1
當然也可以做三次元人物的生成
可以做真實人臉生成 這些人臉都是機器生成的
網路上有名人臉的 database 就載下來就可以讓機器學習產生真實的人臉
你可能會問產生真實的人臉有甚麼用
基本上沒有甚麼用
隨便去路邊拍一個人都會比機器產生的更加真實
有趣的是機器可以產生你沒有見過的頭像
剛才有說 input 的 vector
代表了輸出圖片的特性
這個只是舉例，實際上 input 的 vector 不會是二維 至少做個十維、五十維之類的或者是一百維
假設 input 是 [ 0, 0 ] output 是這個人
input [ 0.9, 0.9 ] output 是這個人
接下來可以 input 這兩個 vector 之間的內差
input 這兩個 vector 之間的 interpolation
就會得到這樣的 output 結果
就會看到這兩個人臉之間的連續的變化
上面是更多的例子
機器真的可以學到說 這個人臉他是朝右看的
這個人臉是朝左看的
當機器要產生這個朝右看的人臉和朝左看的人臉之間的內差的時候
他並不是把兩張臉疊起來變成一個雙面人
他自己知道朝右看的臉跟朝左看的臉如果內差的話
就是朝正面看 所以機器自己知道說把這個臉轉正
然後再轉過來
這邊有更多的例子
機器要學到這件事情完全不需要 handcrafting
就並不需要規則、物理模型 都不用
看很多真實的照片以後
他自己就可以學到這些事情了 這個是滿神奇的
剛才講的是 GAN 的操作 如果你知道那些操作就可以做出作業 3-1 了
接下來想要花一些時間從概念上講一下 GAN 的原理
為甚麼他是這樣運作
開學的時候就有講過 GAN 其實可以被視為一種 Structured Learning 的技術
甚麼是 Structured Learning 其實開學就有講過了，但我們非常快的複習一下
所謂 Structured Learning 的意思是我們都知道 Machine Learning 就是
找個 function，input 一個東西，output 另外一個東西
如果是 regression task，machine 就是 output 一個數值
如果是 classification task，machine 就 output 一個 class
如果遇到問題是更複雜的
要機器的 output 不是一個數值也不是一個 class
他可能是一個 sequence、可能是一個 matrix
可能是一個 graph、可能是一個 tree
這個時候這個任務就叫做 Structured Learning
舉例來說，translation 是 Structured Learning 的問題
因為 machine 要輸出一個句子
語音辨識是 Structured Learning 的問題 machine 要輸出一個句子
chatbot，在作業 2-2 裡面已經有做了 chatbot
chatbot 其實也是一種 Structured Learning 的問題
所以也是 input 一個 sequence output 一個 sequence
你可能會想說 GAN 是一個可以用在 Structured Learning 的技術
可不可以把 GAN 用在 chatbot 上呢
可以，如果 sequence to sequence 如果 train 得起來的話
其實可以再加上 discriminator
可以讓他的回答更好
要先把 sequence to sequence train 到 OK 這樣子
不知道大家做得怎麼樣了
也可以輸出讓機器產生一個 matrix
甚麼時候要機器產生 matrix 呢
如果要讓機器畫一張圖
那就是產生 matrix，之前有講過如果輸入這種圖案
那他產生這樣真實的房子 或是輸入黑白的圖片，讓他產生彩色的圖片
甚至可以輸入文字讓機器產生 image
所以在作業 3-2 要做的就是要大家做 輸入一些二次元人物頭像的特徵
比如說頭髮顏色、眼睛的顏色 要輸出對應的二次元人物的頭像
這個是作業 3-2 要大家做的事情 細節就下周再公告
為甚麼 Structured Learning 是一個特別具有挑戰性的問題呢
首先我覺得 Structured Learning 它可以被視為是一個 One Shot Learning 或者是 Zero Shot Learning
甚麼叫 One Shot Learning 或者是 Zero Shot Learning 呢
假設有一個分類的問題
在做分類問題的時候每一個類別都要給機器一些例子
舉例來說要機器分別蘋果和橘子之間的差異 你就要給他一百張蘋果的圖片、一百張橘子的圖片
他才能夠分辨，給他一個水果他是蘋果還是橘子
所謂 One Shot Learning 或是 Zero Shot Learning 的意思是假設有些類別根本沒有任何範例
或者是只有非常非常少的範例
那能不能夠做得起來
我覺得 Structured Learning 這個問題他可想成是一個極端的 One Shot Learning 或 Zero Shot Learning 的 problem
因為在 Structured Learning 裡面 output 的東西是一個 structure，比如說一個句子
在整個 training data 裡面，沒有任何句子是重複的
testing data 跟 training data 他們的句子可能也是完全沒有重疊的
假設把每一個不同的句子 假設今天做的是 Structured Learning 是 output 一個句子
比如說翻譯
假設把各種不同可能的每一種 output
都視為一個 class 的話
在 training data 裡面每一個 class 可能就只出現一次
testing data 出現的那些 class 更慘 他根本在 training data 裡面根本就沒有出現過
假設把每一種機器可能的 output
視為一個 class 的話，其實 Structured Learning 是一個極端的 One Shot Learning 或者是 Zero Shot Learning 的 problem
所以因為這些 class 他都只會出現一次
所以在這種 Structured Learning 的 task 裡面
如何學到一般化、如何學著去輸出
從來沒有看過的東西
就變成一個很重要的問題
你可以想像要讓機器做到這件事情
要讓機器可以輸出他在 training 的時候 從來沒有看過的東西
那這個機器是需要有一定程度的智慧的
或者講得更擬人化一點 講得更像農場文一點的話
機器必須要要學會創造 他才能夠解 Structured Learning 的問題
因為他在 testing 的時候，他需要輸出的正確答案
很有可能是 training 的時候 他一次也沒有看過的
這個東西就可以把他視為是創造
如果機器也解決 Structured Learning 的問題
他必須要有規劃的概念
他必須要有大局觀
因為機器要產生很複雜的物件
而這個複雜的物件，是由幾個比較簡單的 component 所組成
如果是影像生成的話
機器是產生一個一個 pixel
但是所有的 pixel 合起來
必須要能夠變成一張人臉
那機器在產生這張圖片的時候
他一定要在心裡分辨清楚說
我點這個 pixel 上去代表是眼睛
點這個 pixel 上去代表是嘴巴
才不會變成畫三隻眼睛、畫兩張嘴巴等等
所以在 Structured Learning 裡面
真正重要的不是產生了甚麼 component
而是 component 和 component 之間的關係
假設要讓機器學會寫一個數字出來
機器一開始在整張圖上面中間點一個點
點一個點這件事情本身是中性的
他不見得代表結果會是好的
也不見得代表結果會是不好的
因為假設機器最後畫出來的數字長這樣
那結果是好的
畫出來的數字長這樣，那整個就是壞掉的
文字的生成也是一樣
機器要產生的是一個完整的句子
甚至是一篇完整的文章
單看生成的一部份沒有辦法判斷他是好的還是不好的
這讓我想到一個紀曉嵐的故事
紀曉嵐故事是說，有一天紀曉嵐去幫翰林的老婆祝壽
然後就寫了一個詩
詩的開頭就是：這個婆娘不是人
然後大家都生氣了
還有下一句：九天玄女下凡塵
然後大家就高興了
這就告訴我們如果只看第一個句子
他是一個負面的句子
但是把第一個句子和第二個句子合起來
如果有大局觀的話，如果可以看整個完整輸出的話
他就變成一個正面的句子
而這個東西是機器在做 Structured Learning 的時候
他必須要學會的
所以這邊想要表達的是 Structured Learning 有趣而富有挑戰性的問題
我覺得 GAN 他其實是一個 Structured Learning 的 solution
在傳統 Structured Learning 的文件裡面
有兩套方法
一套方法是 Bottom Up 的方法
一套方法是 Top Down 的方法
所謂 Bottom Up 的方法是我們要產生一個完整的物件
機器是一個一個 component 分開去產生這個物件
這樣的缺點就是很容易失去大局觀
所謂 Top Down 的方法是從產生完一個完整的物件以後
再去從整體來看看這個產生的物件好不好
這樣講有點抽象等下會具體地告訴大家這件事是怎麼做的
這邊的壞處是用這個方法很難做 generation
Generator 可以視為是一個 Bottom Up 的方法
Discriminator 可以視為是一個 Top Down 的方法
把這兩個方法結合起來就是 Generative Adversarial Network，就是 GAN
接下來想要分享的是
剛才不是說兩個問題
第一個問題是為甚麼 generator 不能夠自己學
就來看看 generator 是不是可以自己學
實事上 generator 是可以自己學的
generator 的學習就是 input 一個 vector
output 一個 image 假設用手寫數字當作例子
output 一個 vector output 一個數字的圖片
output ( 應該是 input ) 就要產生不同的圖片
要訓練這樣一個 network 的 generator
訓練這樣 NN 的 generator 怎麼做呢
我們知道在傳統的 Supervised Learning 裡面
就給 network input 跟 output 的 pair
然後 train 下去就得到結果了對不對
今天要 generator 輸入就是 vector 輸出就是圖片
能不能夠蒐集這樣的 pair 呢
當然可以蒐集這樣的 pair
因為假設有一個 database 裡面都是一大堆數字的圖片
接下來給一個數字 assign 一個 vector
就結束了
因為接下來你就可以說 我 train 一個 network
然後看這個 1 他的 vector 是 [ 0.1, 0.9 ]
所以輸入 [ 0.1, 0.9 ] 丟到這個 generator 裡面
就要 output 一張圖片，這個圖片跟他的目標也就是這個 1 越接近越好
這完全跟一般 train Supervised Learning 是一模一樣的
就用 Gradient Descent train 下去
就結束了 相信大家都可以秒 implement 這種 network
這個跟 train 一個 classifier 是一樣的
只是有點反過來 因為這邊是輸入一個 vector
輸出一張圖片，雖然說平常不會做輸出圖片這件事
但實際上做的就只是輸出一個很長的向量而已
一般的分類就相反了，一般的分類是輸入一個圖片，然後輸出一個向量
這個向量每一個維度代表對應到的某一個數字
這兩種 generator training 和 classifier training 其實根本可以用同樣的方式來 train 他
但這邊的問題是怎麼產生這些數字呢
你可以隨機產生，但是如果隨機產生的話
到時候這個 generator training 可能非常困難，因為這兩個 1 是很像的
但如果他們 input vector 非常不一樣的話
可能很難 learn 出一個 network，input 非常不一樣的東西卻 output 非常像的東西
你可能會希望這兩張圖片如果有共同的特徵
他們對應到的這個 vector
就應該有某些相似之處
舉例來說在這邊在這個 vector 的時候
1 第一維都給他是 0.1，2 的第一維給他 0.2，3 的第一維給他 0.3
向左斜第二維就給他負的值，向右斜第二維就給他正的值等等
你可能會希望你 input 的 vector 他跟 output 東西的特徵還是有關係的
這件事情怎麼做到
怎麼樣產生這樣的 vector 呢 還是有辦法的
可以 learn 一個 encoder，這個 encoder 是給他一張圖片，他把這個圖片的特徵用一個向量來表示
這個向量就是這邊的 code
給他一個圖片，他把這個圖片的特徵用向量來表示
這個向量就是這邊的 code
怎麼 train 這樣一個 encoder 呢
記不記得在講 Machine Learning 的時候
有講過一個技術叫做 Auto-encoder
這個我想大家都記得 我只是很快地複習一下
Auto-encoder 做的就是給他一張圖片，他把它變成一個 code
Auto-encoder 裡面有一個 encoder 有一個 decoder
encoder 做的事情是給他一張圖片，他把這個圖片變成一個 code
但是 encoder 本身不能夠自己 train
一定要再加一個 decoder 才有辦法 train
decoder 吃一個 code，他會把這個 code 變成一張圖片
在 training 的時候給一張 image
這張 image 被 encoder 變成一個 vector
decoder 會把這個 vector 解回原來的 image
希望 input 跟 output 越接近越好
在 train Auto-encoder 的時候就隨便選一張圖片
這張圖片變成 code
這個 code 透過原來的 decoder 變回原來的 image
會希望 input 跟 output 越接近越好
你仔細想想這個 decoder 其實就是一個 generator
剛才說那個 generator 做的就是給他一個 code
要他產生某一張對應的圖片
現在已經告訴你有一個 encoder 他的工作就是產生一個圖片的 code
這張圖片他對的 code 就是這個
decoder 的學習就是看到這個 code 要產生那個 code 對應的圖片
這個 decoder 根本就是我們要學的 generator
事實上 learn 好一個 Auto-encoder 以後
把 decoder 拿出來就是我們的 generator
他就可以拿來產生 image
你就可以隨便丟一些東西 他就會 output 你想要的 object
舉例來說，你完全可以 learn 一個數字的產生器
這個非常簡單，你回去一秒鐘就可以做出來
就 learn 一個 Auto-encoder 他的中間的 code 是兩維
然後把 decoder 拿出來隨便給他一個兩維的 vector
他 output 就是一個數字
假設給他 [ -1.5, 0 ] 這是真實的例子
他就輸出這樣子的 image
給他 [ 1.5, 0 ]，他就輸出這樣子的 image
如果在四方形的範圍內，等距的 sample
就可以看到一堆數字的連續的變化
舉例來說第一維他可能跟有沒有圈圈有關
越往左就有圈圈 往右就是棍子
如果是看縱軸的變化，可能跟他的方向有關
舉例來說本來朝左偏的，往上以後就會變成朝右偏的
這個是 Auto-encoder 可以做的事情
那用 Auto-encoder 會有甚麼樣的問題呢
你可能會遇到這樣子的一個問題
因為 training data 裡面的 data 是有限的
generator 可能可以 learn 到看到 vector a 產生這張圖片
看到 vector b 產生這張圖片
但是看到 vector a 跟 vector b 的平均
他到底會產生甚麼樣的圖片呢
你可能覺得 vector a 對應到的 1 是向左的
vector b 對應到的 1 是向右的
假設兩個合起來應該是產生正的 1
但是實際上並不是這個樣子
因為 NN generator 是一個 network
他是非線性的，a 可以產生這個圖片
b 可以產生這個圖片，把他們平均以後丟進去
未必產生出來的就是數字，可能 output 出來的就是 noise
實際 train train 看，很有可能發生這樣子的狀況
要怎麼解決這個問題呢
這個也是在 Machine Learning 那門課講過的技術
這個技術就是 Variational Auto-encoder 也就是 VAE
那在 Variational Auto-encoder 裡面，encoder 不只是產生一個 code
這邊這個 m 代表他產生出來的 code
他不只是產生一個 code 他不只是產生一個 vector
他還會產生每一個 dimension 的 variance
接下來從 normal distribution 裡面去 sample 一堆 noise 出來
把這個 noise 跟 variance 相乘，把這個 noise 加到 code 上面去
再把有加 noise 的 code 丟到 decoder 裡面
decoder 要跟具有 noise 的 code 還原出原來的圖片
如果有這個技術的話，machine 就會知道它不只看到 vector a 要產生數字
看到 vector b 也要產生數字 看到 vector a 加一些 noise
看到 vector b 加一些 noise 產生出來的東西也必須要是數字
所以有了 Variational Auto-encoder，可以把你的 decoder train 的更加穩定
可以讓你的 decoder 就算 input 這個 vector
是在 training 的時候從來沒有看過的 vector
他 output 的東西仍然可能是合理的 object
這個都是複習在 Machine Learning 那門課曾經講過的東西
接下來要講的是這整套技術 他少了甚麼樣的東西
講到這邊不知道大家有沒有問題想要問的呢
那個是你自己決定的 他就跟 network 的參數一樣是你要調的
但是通常 code 他會是一個 low dimension 的東西
因為我們的假設通常是這樣子 假設你今天做的是 image 的 generation
你的 decoder output 是 image
雖然 image 是一個 high dimension 的 vector
我們相信這個 image 他在 high dimension 當中 他其實是一個 low-dimensional 的 variable
本質上他的分布是 low dimension 的
所以今天要產生這個 image 你 input 的 code
不需要是 high dimension 的東西 他只需要是一個 low dimension 的 vector 就好了
但是 dimension 到底應該是多少 五維、十維還是五十維，這個東西是需要調一下的
train 不起來，增加 dimension 會有效
但是增加 dimension 以後未必會得到你要的東西
因為 train 的是一個 Auto-encoder
訓練的目標是要讓 input 跟 output 越接近越好
要達到這個目標其實非常簡單
把中間那個 code 開得跟 input 一樣大
那你就不會有任何 loss 因為 machine 只要學著一直 copy 就好了
但這個並不是我們要的結果
雖然說 input 的 vector 開得越大
loss 可以壓得越低，但 loss 壓得越低並不代表 performance 會越好
所以這個東西是需要調一下的
為甚麼 sigma 要是 train 的
所以假設沒有任何額外的 constrain
我們只想要 minimize Reconstruction Error
最後 train 出來的結果 sigma 就會變成 0
但是實際上在 training 的時候還有另外一個條件
這個條件是這些 sigma 的值不能夠太小
在 train 的時候 criterion 是這些 sigma 的值越接近 1 越好
你不希望 sigma 太大，但是他也不可以太小
所以在這個前提之下，最後 learn 出來 sigma 並不會變成 0
這樣有回答到大家的問題嗎
大家如果對這個東西有困惑的話
你可以去看一下 Machine Learning 的錄影 這個在 Machine Learning 那堂課有說過的
大家還有沒有甚麼問題想要問的呢
OK 的話要繼續喔
接下來講的是說
這個 Auto-encoder 的 training 他到底少了甚麼樣的東西
你仔細想想看
generator 在 train 的時候他的目標是希望他的 output 跟某一張圖片越像越好
舉例來說這個 2 是你 input 的圖片
希望 generator 的 output 跟這個 2 越像越好
甚麼叫做越像越好呢
通常計算的就是這兩張圖片他們 pixel by pixel 的差距
通常每一個 pixel 他就是一個數字
所以真的在算這兩張圖片的相似度做的事情就是
把這兩張圖片表示成兩個 vector
接下來就算這兩個 vector 的比如說 euclidean distance
這個東西就是要去 minimize 的對象
這兩個 vector euclidean distance
就代表這兩張圖片的差異的程度
就希望這兩張圖片他們的 L1 distance、L2 distance 越小越好
假設 generator 他確實可以完全 copy 你的 target
可能就沒有甚麼太大的問題
真正在 training 的時候，generator 是會犯一些錯的
generator 的 capacity 不會大到他 output 的 image 一定跟他的 target 一模一樣
他勢必會有一些取捨
他沒有辦法完全 copy 這個 output
他會選擇在某些地方不得不做一些妥協
沒有辦法跟他的目標一模一樣
但是這個時候選擇在甚麼地方做妥協
就會變的非常的重要
舉例來說這個是你的目標
有四個不同的 generator，他們產生四張這樣子的圖片
如果是看這個圖片跟這個圖片在 pixel 上相似的程度
你會發現這兩張圖片差了一個 pixel
這兩張圖片差了一個 pixel
而下面這個圖片跟他插了六個 pixel
這個圖片跟他差了六個 pixel
對一個 generator 來說，假設 learning 的時候是希望 output 的圖片跟目標越像越好
如果他不得不犯一些錯誤
他會傾向於產生這樣的圖片
這樣子的圖片他的錯誤只有一個 pixel
這樣的圖片他的錯誤還有六個 pixel
但事實上假設從人的觀點來看你會知道
這個是不行的 這個錯一個 pixel 整個圖片看起來就不對了
整個看起來就不像是人手寫的數字 看起來就是錯的
但是下面這個 case 他只是把筆畫弄得長一點而已
所以其實你是可以接受的 這個你是覺得可以的
所以變成說你不能夠單純的去讓你的 output 跟目標越像越好
單純的讓你的 output 跟目標越像越好，可能 generator 就會產生這種圖片，而不是這種圖片
而在做 Structured Learning 的時候
我們講過 Structured Learning output 就是個比較複雜的結構
裡面有很多很多 component
component 和 component 之間的關係是非常重要的
我們覺得這張圖片是不行的
並不是因為這邊放了一個 pixel 有甚麼不好
在這邊放一個 pixel 這件事情本身是沒有錯的
因為如果這邊放一個 pixel 但是可以把這邊補滿
他仍然像是一個人手寫的數字
並不是說在這邊塗黑是有錯的 而是把這邊塗黑在相鄰的地方沒有把他跟著塗黑
所以在一個 Structured Learning 裡面 component 和 component 之間的關係是非常重要的
但其實在 train 一個 generator 去生成圖片的時候會發現 一個 network 的架構其實沒有那麼容易讓我們把
component 和 component 之間的關係放進去
假設你是做圖片的生成
假設 layer L 就是整個 generator 的最後一個 layer
這個 layer L 他生廚來的就是一張圖片
這個 layer L 的每一個 neural
他顯然就對應到圖片的每一個 pixel
他 output 的數值就是那個 pixel 圖的顏色的深淺
你會發現在這整個架構裡面
假設 layer L - 1 的值是給定的
那事實上每一個 layer 的 output 假設 weight 已經給定了
前面 layer L - 1 的輸出已經給定了
事實上每一個 dimension 他的 output 其實是 independent
假設這個 neural 他產生了顏色
他希望它旁邊的人也跟著產生顏色
產生像是 realistic 的 image
實際上這件事情是沒有辦法做到的
他們之間並沒有辦法互相影響 他就自己產生自己的
他們並沒有辦法互相配合去產生一個好的 image
所以這個就是單純的 learn 一個 generator 困難的地方
這個問題也不是沒有辦法解的
雖然只看一個 dimension
你沒有辦法考慮 pixel 和 pixel 之間的 correlation
如果再多加幾個 hidden layer
就可以把這種 correlation 考慮進來
如果你不想要用 discriminator
只單純的用 Auto-encoder 的技術想要做 generation 這件事情
根據我們的經驗，如果有同樣的 network
一個是用 GAN train 一個是用 Auto-encoder train
往往就是 GAN 的那個可以產生圖片，但是 Auto-encoder 那個
需要更大的 network 才能夠產生跟 GAN 接近的結果
所以如果你要把 correlation 考慮進去 你會需要比較深的 network
這個是一個 toy 的 example
這個實驗要做的是 train 一個 generator
generator 的 input 是一個二維的 Gaussian 的 noise
他的 output 就是綠色的這些點 ( 講錯 )
他在 output 的時候他的目標 希望他能夠學會 output
generator 的 output 是藍色這些點
綠色的是他學習的目標
我們希望 generator 產生出來的是像綠色這樣的 distribution
如果用 Variational Auto-encoder 的技術 learn 下去以後
你會好只能夠讓這個 generator 產生藍色的這些點
因為對 generator 來說要考慮 pixel 和 pixel
也就是 dimension 1 和 dimension 2 之間的 correlation 是有點困難的
他並不知道如果在 x1 值很大的時候
x2 如果值很大是好的 如果值很小也是好的
如果值介於不大小中間是不好的 他不太容易學到這件事
你就會發現在這個 distribution 跟這個 distribution 之間 還有一大堆的點散布
而這兩個 distribution 他們的 mixture 靠得太近了
generator 根本就沒有辦法把他們區分開來
這個是用 Variational Auto-encoder 可能會遇到的問題
在休息之前想給大家看一個東西
一邊 train 還是可以一邊講的
接下來問的第二個問題就是為甚麼 discriminator 他沒有辦法自己產生 image
其實 discriminator 他可以自己產生 image
只是他非常的卡
複習一下 discriminator 是甚麼 discriminator 就是輸入一個 object 輸出一個分數
這個分數代表輸入的東西有多好
事實上這個 discriminator 在不同的文獻上他可能有不同的名字
他可能叫做 Evaluation Function
他可能叫 Potential Function
他可能叫 Energy Function
如果在別其他的領域曾經看過這些名字、function，比如說 Potential Function，你想想看
他是不是也是吃一個 input 然後就 output 一個 scalar
這個 scalar 就決定這個 input 有多好或是多不好
所以 discriminator 在不同的領域其實是有不同的名字
能不能用 discriminator 來生成 object
其實是可以的
怎麼用 discriminator 來做 generation
就套下面這個式子
不過在講他怎麼做之前
先來講 discriminator 相較於 generator 有甚麼樣的優勢
剛才有說過 generator 在產生 object 的時候
他是每一個 component 一個一個獨立去生成
所以對他來說要考慮 component 和 component 之間的 correlation 是比較困難的
但對 discriminator 來說，要考慮 component 和 component 之間的 correlation 就比較容易了
對 discriminator 來說，因為是產生完一張完整的 image 以後
再把這張 image 丟給 discriminator
讓 discriminator 去給他評價看他好還是不好
所以對 discriminator 來說他可以輕易地告訴你這張圖片就是不好的，應該得到低分
給他這張圖片，是好的，就應該拿到高分
實際上怎麼做到這件事情呢
可能 discriminator 也是一個 Convolutional Neural Network
這 Convolutional Neural Network 有一個 filter 是長這樣的 filter
這個 filter 會去 detect 有沒有 isolated 的 pixel
有沒有 pixel 他的周圍都沒有其他 pixel
如果有這種就給他低分
所以對 discriminator 來說當產生完一張完整的圖片以後
要檢查這張圖片裡面的 component 和 component 之間的 correlation 對不對
是比較容易的 在生成的時候因為是一個一個 component 獨立生成
不容易考慮他們之間的關係 但是等整張圖片已經生成完以後
要再檢查這關係對不對，是比較容易的
這個就是 discriminator 所佔到的優勢
接下來要講怎麼使用 discriminator 來產生東西
就套用下面這個式子
假設已經有一個 discriminator
這個 discriminator 他確實可以鑑別 input 一個 x 他是好的還是不好的
怎麼拿這個 discriminator 來做生成
窮舉所有可能的 x
一個一個丟到 discriminator 裡面
看哪一個 x discriminator 會給他最高的分數或給他很高的分數
discriminator 會給他高分的 x 就是生成的結果，結束
你可能會覺得非常的 surprise 有可能窮舉所有的 x
一個一個去檢查他丟到 discriminator 以後會得到高分還是低分，假設 x 是一張 image
image 就是由一堆 pixel 所組成的
有可能窮舉所有 pixel 顏色的組合
看怎麼樣 pixel 顏色的組合會得到高分嗎
仔細想想好像有一些難度 但這邊要給你的答案就是
不是這個問題，先假設這一個窮舉所有的 x
在哪一個 x 可以得到高分這件事情
somehow 就是有某一個演算法
可以做到這件事情 假設你很仔細的思考以後
也許你可以想出一個演算法 來解這個 arg max 的 problem
如果你可以解這個 arg max 的 problem 就可以用 discriminator 來做生成
但是這個生成是非常痛苦的
因為這個 discriminator 擅長的就是批評
他不擅長做有建設性的鑑別 他只擅長批評就跟政論節目的名嘴一樣
你給他甚麼東西他都說這個是不好的
你叫他真的想一個好的東西 他是很難想出來的
那這很痛苦
假設說他就是有辦法生成東西 接下來的問題是
在他有辦法生成東西的前提之下
我們怎麼樣訓練這個 discriminator
當我們在訓練 discriminator 的時後 簡單來說就是要給他很多好的 example
告訴他這好的 example 是高分的
給他一大堆爛的 example 告訴他爛的 example 就是低分的
但實際上手上只有好的 example
手上真正有的 假設做二次元人物的生成
手上的 data 是人生成的 data 是人畫出來的二次元人物的頭像
這些東西通通都是好的 這些東西 discriminator 都應該給他高分
但是這個時候 discriminator 只有 positive 的 example
只有正面的例子 完全沒有反面的例子
如果只拿正面的例子去 train discriminator
會發生甚麼樣的問題
你會發現這個 discriminator 之後學到看到甚麼東西 他就會覺得是正面的例子，都給他高分
他訓練的時候只有高分的東西 從來沒有看過任何低分的東西
他就會學到看到甚麼東西，都給他高分就是對的
這個顯然不是我們要的
所以怎麼辦 需要給 machine 一些 negative example
但是從哪裡找 negative example 就變得非常的關鍵了
如果找出來的 negative example 非常的差
你就跟機器說人畫的就是好的，就是要給高分
然後隨機產生一大堆的 noise 這些 noise 就是要給他低分
對機器來說當然可以分辨這兩種圖片的差別
看到這種給他高分 看到這種給他低分
但之後給他這種圖片 也許畫得很差
但是他覺得這個還是比 noise 好很多
也會給他高分 這個不是我們要的
所以怎麼產生好的 negative example 就變得很重要
假設可以產生非常真實的 negative example
他這個還是有些錯，比如說這兩隻眼睛的顏色不一樣
你可以產生非常好的 negative example
這樣 discriminator 才能夠真的學會鑑別好的 image 跟壞的 image
現在問題就是怎麼產生這些非常好的 negative example
要產生這些好的 negative example
也需要一個很好的 process 去產生這些 negative example
現在就是不知道怎麼產生 image 才要 train model 這樣就變一個雞生蛋，蛋生雞的問題
要有好的 negative example 才能夠訓練 discriminator
要有好的 discriminator 才能夠幫我們找出好的 negative example
這樣就陷入一個雞生蛋，蛋生雞的問題
實際上怎麼解這個問題
用 iterative 的方法來解這個問題
要怎麼訓練 discriminator
假設有一堆 positive example
假設有一堆 negative example
一開始 positive example 是人畫的 image
negative example 是 random sample 出來的一堆 noise
在每一個 iteration 裡面
discriminator 學會做的事情就是給這些 positive example 高的分數
給這些 negative example 低的分數
接下來當你學出一個 discriminator 以後
可以用這個 discriminator 去做 generation
我們剛才說 discriminator 是可以做 generation 的
只要會解這個 arg max 的 problem
就可以用這個 discriminator 做 generation
就用這個 discriminator generate 出一堆他覺得是好的 image
這些 image 我們用 x tilde 來表示他
有了這些原來的 discriminator 覺得是好的 image 以後
在下一個 iteration 把原來 random 的 image 換成這些第一代的 discriminator 覺得是好的 image
接下來再 update discriminator 參數告訴他這些是好的
這些是不好的
用了新的 discriminator
新的 discriminator 再解一次 arg max 的 problem 因為 discriminator 變了
所以他可能會產生更好的 image
這個 process 就一直反覆的循環下去
只有一個 discriminator 他去分辨圖片的好壞
他參數 update 以後他可以去產生更好的 image
接下來就可以 learn 更好的 discriminator
不斷的反覆這個 process
這邊是一個圖示化的方式來講這個運作看起來像是甚麼樣子
這個紅色的線代表的是 discriminator 的 value input 一個 object，這個 object 如果是 image 的話
他是分布在一個很高維的空間中
現在為了簡化起見，就假設 object 分布在一維中
object 隨著分布的位子不同
discriminator 會給他不同的分數
那你的 real example 假設是落在這個地方
discriminator 當然要給落在這個區域的東西高的分數
他應該要給其他的區域，不在這個高分的區域低的分數
實際上這整個 object 可以分布的 space 是非常巨大的
如果在一維空間裡面你可能會覺得 反正這個地方是高分的
那兩邊就應該給他低分的
但是如果是一個高維的空間
高維空間裡面沒有出現 real example 的地方的分數
都把它壓低
所以實際上怎麼做
實際上的做法看起來像這個樣子
剛才講說 discriminator 在 train 的時候 他是 iterative 去 train 的
假設一開始 real data 分布長這個樣子
有一些 generate 出來的 data
有一些 negative example 他的分布是藍色的這個
接下來 discriminator 會去學著給綠色的點高分 給藍色的點低分
因為它只知道給這個區域高分
給這個區域低分
他可能沒有學到要給這個區域多少分數
所以搞不好 learn 完以後，這個區域的分數還比 real data 分數要高
這個是有可能的，因為並沒有給機器 constrain 這個地方的分數是怎樣，你只說這邊分數要高
這邊分數要低
這個地方要怎樣其實是不知道的
接下來 learn 出第一個 discriminator 以後
用這個 discriminator 去產生 example
也就是說去找出這個 discriminator 的弱點
剛才說在這個 iterative 的 process 裡面 learn discriminator
接下來用 discriminator 去產生 negative example
用 discriminator 去找出自己的弱點
用 discriminator 產生 negative example 的時候 我們有說怎麼讓 discriminator 做生成
就是看那些圖片 discriminator 會給他高分，那些東西就是 negative example
如果是看這個例子的話
discriminator 是給這些圖片高分 如果看這個 discriminator
它其實在這邊分數是特別高的
所以他是給這些圖片高分
這些圖片就是 discriminator 自己產生出來的 negative example
在下一個步驟裡面，discriminator 產生出這些 negative example 以後
它又要學到它給這些 example 低分，這些 example 高分
discriminator 形狀就會改變，可能就變成這個樣子
這個 process 就反覆繼續下去
這就好像是 discriminator 不斷去尋找它的這個 function 裡面的弱點
看看哪邊分數特別高，就某個地方如果不是 real example
它又凸起來，在那邊 sample 一些 negative example
然後在下一個 iteration，discriminator 就會把那個區域的值壓下去
大家聽得懂我的意思嗎 大家有問題要問嗎
這樣久不會 overfit 嗎
這個問題問得很好 這個問題問的還滿難回答的
因為 machine 在做生成的時候
它就是看它的 real data 長甚麼樣子
它要產生像 real data 的東西
所以如果你的 data 很少，確實有可能 overfit
train 得起來
但是那些結果就是 database 裡面的那些圖片
你會希望你給他的圖片夠多
他可以學到 generalize 的東西產生 database 裡面沒有的圖片
這個又跟一般的 training 和 testing 不太一樣
所以在做 GAN 的生成的時候
其實很難知道到底有沒有 overfit
大家還有甚麼問題要問嗎
最後就希望訓練到
對 discriminator 來說在這個 input space 上面
只有出現 real data 的地方
分數才是高的
這個時候 negative example 跟 positive example 他們的 distribution 就會重合在一起
當 negative example 和 positive example 他們的 distribution 重合在一起的時候
training 的 process 就會停下來
這個是 discriminator 的 training
假設知道 discriminator 可以拿來做生成
其實根本就不需要 generator，光憑藉著 discriminator 也可以做生成這件事
你可能會想說有人真的拿 discriminator 做生成嗎
有的，其實有滿坑滿谷的 work
都是拿 discriminator 來做生成
假設你熟悉整個 graphical model 的 work 的話
你仔細回去想一下，剛才講的那個 train discriminator 的 process 其實就是 general 的 Graphical Model 的 training
只是在不同的 method 裡面講法會略有不同而已
因為我不知道大家對 Graphical Model 熟不熟
Graphical Model 其實就是 Structured Learning 的一種
然後 Graphical Model 裡面又分成很多類 比如說有 Bayesian Network
比如說有 Markov Random Field 等等
然後有很多很多的基礎這樣子
這邊其實沒有列完所有和 Graphical Model 有關的技術
這邊列的是過去 MLDS 會講的東西
MLDS 的名字是 Machine Learning Having it Deep and Structured
本來這門課是有一半的時間會講 Structured Learning 這個技術
只是發現講到後來大家都不想聽了
大家都只想聽 Deep Learning
Structured Learning 大家都不知道是甚麼東西 大家其實是比較不想聽的
所以後來就不太講 Structured Learning 的東西
但是 GAN 其實也可以被視為是 Structured Learning 的一種技術
而在 Structured Learning 的技術裡面，其中非常具有代表性的東西就是 Graphical Model
如果你熟悉 Graphical Model 比如說 Markov Random Field 或 Bayesian Network 的話
你想想看在 Markov Random Field、Bayesian Network 裡面
你是定一個 graph，這個 graph 上面有一個 Potential Function
這個東西就是你的 discriminator
那個 graph 就是一個 discriminator
然後你輸入你的 observation 那個 graph 會告訴你這組 data 產生出來的機率有多少
那個機率就是 discriminator assign 的分數
假設你不熟 Graphical Model 的話這邊你聽不懂沒有關係 但如果你熟悉的話你回去比較一下，是不是
Graphical Model 裡面的那個 graph、你的 Potential Function、你的 Markov Random Field
你的 Bayesian Network 其實就是 discriminator
再回想一下當你去 train Markov Random Field 或你 train Structured SVM、train 種種 Graphical Model 的時候
種種和和 Structured Learning 有關的技術的時候
是不是 iterative 的去 train 的
你做的事情是不是有 positive 有 negative example 訓練出你的 model
接下來用 model sample 出 negative example 再去 update model
就跟我剛才講的 training discriminator 的流程其實是一樣的
只是把同樣的事情換個名詞來講，讓你覺得不太一樣而已
但你仔細想想，他們就是同一回事
這邊就講了 generator 跟 discriminator
來比較一下 generator 和 discriminator 各自所遇到的問題
generator 的優勢就是
它很容易做生成，generator 在生成很快
這是個 Feedforward Network，很快就可以生一個東西
它的缺點就是它不容易考慮 component 和 component 之間的 correlation
它在學習的時候他只是去模仿某一個目標 所以他只學到了那個目標的表象
它沒有學到它的精神 講擬人化一點就是它只學到表象
因為它只學 pixel 和 pixel 之間相似的程度
它學不到大局 學不到它的精神
如果看 discriminator 的話
discriminator 的優勢就是可以考慮大局
它的劣勢就是你要叫 discriminator 生一個東西
這個是千難萬難 我們要去解一個 arg max 的 problem
而要解那個 arg max 的 problem 勢必就必需要對你的 discriminator 的 model 做一些假設
在傳統的文獻裡面
都必須要假設 discriminator 的 model 是線性的
才有辦法解那個 arg max 的 problem
你限制它是線性的意味著你限制了它的能力
如果它是非線性的，你不知道要怎麼解
那個 arg max 的 problem 所以這個就是一個大問題
過去在講 Structured Learning 的時候講到這段要解 arg max 的 problem
同學都會問我說怎麼解 我通常只能說你就假設
你可以解，大家聽了生氣了，所以後來都沒有人要聽這一段
現在不一樣的就是我們有了 generator
generator 做甚麼事情 generator 就是取代了這個 arg max 的 problem
想像成本來要想要一個 algorithm
來解這個 arg max 的 problem 往往我們都不知道要怎麼解
那個 arg max 的 problem
使得這一套 framework 假設可以解 arg max problem
聽起來沒有問題但就是因為你不能解，所以聽起來就有很多的問題
但現在用 generator 來產生 negative example
用 generator 來解 arg max 的 problem
我們說 generator 它就可以產生出 x tilde
它產生出來的 x tilde 就是那些可以讓 discriminator 給他高分的 image
記不記得 generator 是怎麼 train 的
generator 在 training 的時候 它是不是就是去學著產生一些 image
這些 image 是 discriminator 會給他高分的
所以可以想成 generator 在學怎麼解 arg max 這個 problem
它在學習的過程中
它就是在學怎麼產生 discriminator 會給他高分的那些 image
過去是解這樣一個 optimization 的 problem
現在比較不一樣，是用一個 intelligent 的方法
說它比較 intelligent 是因為它是個 network
network 來解這個 arg max 的 problem
GAN 有甚麼好處 從 discriminator 的角度來看
過去不知道怎麼解 arg max 的 problem 現在用 generator 來解 arg max 的 problem
顯然是比這個方法更加有效，而且更容易一般化的
對 generator 來說它在產生 object 的時候
仍然是 component by component 的產生
但是他得到的 feedback 不再是 L1 L2 的 loss 不再是 pixel by pixel 的去算兩張圖片的相似度
它的 loss 將是來自於一個有大局觀的 discriminator
希望透過 discriminator 帶領 generator 可以學會產生有大局觀的結果
這是一個用 GAN 來產生的 toy example 這個 example 跟剛才講 VAE 看到的 example
其實是一模一樣的
只是換了一下顏色而已
剛才是藍色跟綠色 這邊換成藍色跟紅色
藍色的點是我們要 generator 去產生的 distribution
是 generator 學習的目標
紅色的點是 generator 最終可以得到的結果
這邊用的 generator 的架構跟前面一頁的 VAE 用的 generator 架構是一樣的
但你發現在學習之後有了 discriminator 這邊的 generator 學出來的結果是比 VAE 的 generator 還要更好的
你會發現這個 mixture 和 mixture 之間是幾乎沒有點的
而對應到真實的應用，假設要讓 machine 產生圖片
產生人臉，如果用 VAE 產生的人臉就會比較糊
假設真實的人臉、親戚的人臉是一個 mixture
因為 VAE 產生的會產生那種 mixture 和 mixture 之間的 sample
所以他就會產生這些比較糊的人臉
如果是用 GAN 就會產生比較清晰的人臉
這一頁是要比較一下 GAN 跟 VAE 之間的差別
這是來自於 Google 的一篇 paper
這篇 paper 主要的內容是想要比較各種不同 GAN 的技術
它比較了，這個我們之後會再提到這些
它比較了 MM GAN、NS GAN、LSGAN、WGAN、WGAN GP、DRAGON 還有 BEGAN，各式各樣的 GAN
它得到的結論是農場文最喜歡的那種
它得到的結論是所有不同的 GAN 其實 performance 都差不多
之前做的事情都是白忙一場
農場文最喜歡的結論 這個圖怎麼看
這個縱軸是算一個 FID Score，這個之後再講
這邊做的都是 image generation
FID Score 越小代表產生出來的圖片越像真實的圖片
這邊的值是越小越好
對於不同的 GAN 他們都試了各種不同的參數
GAN 在 training 的時候是非常的 sensitive 的
往往可能只有特定某一組參數才 train 得起來
它會發現 GAN 用不同的參數它的 performance 有一個非常巨大的 range
看不出說他們做兩個不同的 corpus，一個是 MNIST，一個是 CIFAR10
生成數字跟生成十種不同類別的圖案 他們做 MNIST 跟 CIFAR10
發現如果比較這兩個 corpus，不同方法之間的差距 其實看不出不同的 GAN 有甚麼樣的不同
只知道他們的 range 都非常大，可以產生很好的圖也可以產生很壞的圖
有件事情他們 paper 沒有強調但我覺得是滿有意思的是
如果比較 VAE 跟這些 GAN 的話可以發現，VAE 倒是明顯的跟 GAN 有非常大的差別
甚麼樣的差別 首先 VAE 比較穩
發現給他不同的參數，VAE 的分數是非常的集中
但是假設我們比較各種不同的 model
可以產生的最好的結果的話
剛才講 VAE 產生的圖片畢竟是比較糊模的 雖然他比較穩，但它比較難做到最好
所以比較每一個 model 可以產生的最好的結果的話
會發現 VAE 相較於 GAN 還是輸了一截的
剩下還有一些投影片但我覺得下次再講好了 今天講的是一些直觀的東西
下一堂課開始就是要講一些有數學的、比較理論的東西
如果可以的話你先去預習一下 我把之前上課了錄影放在這邊
因為是比較困難的問題所以建議你先預習一下
等一下助教也會提到一些新的技術 今天這個課沒有 cover 的技術但都是未來會講到的
你聽到這些新的技術的話也不用太驚慌
作業 3-1 不用到那些新的技術應該也是可以過得了 baseline
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
