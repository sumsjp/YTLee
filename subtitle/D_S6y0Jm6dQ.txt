臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://ai.ntu.edu.tw/
去找最小的、最好的 function， 再來我們要問的問題是，我們上一次有看到說
如果你選擇不同的 function set
你就是選擇不同的 model
你在 testing data 上也會得到不同的error
而且越複雜的 model 不見得會給你越低的 error
你會發現說
1 到 5 分別代表說我們今天
做 linear regression 的時候
我們考慮的 input 是 1 次、1 次 2 次、 1 次 2 次 3 次一直到 1 次到 5 次
那你發現，最複雜的model， 其實它的 performance 是最差的
今天我們要討論的問題就是
這個 error 來自什麼地方。
其實 error 有兩個來源
一個是來自於 bias
一個是來自於 variance。
了解這個 error 的來源其實是重要的
因為你常常做一下 machine learning
然後做完就發現說，得到一個 error rate
比如說 60% 的 error rate
接下來你要怎麼 improve 你的 model 呢？
如果你沒有什麼方向的話
毫無頭緒的亂做，你就沒有效率
如果你今天可以診斷你的 error 的來源
比如說 error 可以分成兩種， 一種是來自 bias，一種是來自 variance
如果你可以診斷你的 error 的來源
你就可以挑選適當的方法來 improve 你的 model
我們在上週的時候
我們舉的例子是這樣
我們要做寶可夢進化後的 CP值的估測
也就是說我們要找一個 function
這個 function input 一隻寶可夢
output 就是他進化以後的 CP 值
那這個 function
理論上
有一個最佳的 function
這個理論上最佳的 function
我們寫成 f̂
那這個理論上最佳的 function 我們是不知道的
只有 Niantic 知道
Niantic 大家知道是甚麼嗎？就是做寶可夢的那個公司
因為他一定是用那個程式寫出來的
所以如果你知道那個程式的話
你就可以知道 input 一個寶可夢
照理說， output 他的進化後的 CP 值應該是甚麼
但是問題就是這個function，
f̂ 是你不知道的
那你能夠做的事情是
你有一些 training data
你實際去抓一些寶可夢
然後去找一個
根據你的 training data 所學出來、所找到的
最好的function f*
那這個 f* 並不會真的等於 f̂
因為根本不知道真的 f̂ 是什麼樣子。
那個 f* 可能不等於 f̂
這個 f* 呢，它就好像是一個 f̂ 的估測值一樣
它的 estimator 一樣
所以就想成說現在是在打靶
f̂ 是靶的中心點
你今天收集到一些 data 做 training 以後
你找到一個你覺得最好的 function f*
這個 f* 它不等於 f̂
它是在把紙上的另外一個位置
這個 f* 跟這個 f̂
它們中間有一段距離
這個距離來自於兩件事
它可能來自於 bias
也有可能來自於 variance
那一個 estimator 的 bias 和 variance 指的是甚麼呢？
我們先舉一個你在機率裡面看過的例子
這個地方在機率
我想應該是機率與統計，你應該是學過的
所以你可以很快地看過去
假設我們現在有一個 variable x
我想要估測它的 mean
怎麼做呢？
假設這個 variable x 它的 mean 是 μ
它的 variance 是 σ²
那我要估測 mean 的話
我怎麼做呢？
我就先 sample N 個點
我就對這個 variable sample N 個點
x^1, x^2....到 x^N
我們再把這 N 個點算平均值得到 m
這個N個點算出來的平均值會跟μ一樣嗎？
其實不會，對不對？
除非你 sample 無窮多個點
不然如果你只 sample 比如說 5 個點、10 個點， n = 5 跟 10
這個 μ 跟 m 它們不見得是一樣的
所以
假設這個是 μ 的 value
現在你做一次sample
你 sample n 個點算出來的 m 可能不會跟 μ 一樣。
做第一次實驗做出 m1，有可能跟 μ 不一樣
再做一次實驗 m2，也跟 μ 不一樣
m3 也跟 μ 不一樣，m4 也跟 μ 不一樣
m5 不一樣，m6 也不一樣，等等
你沒有辦法找到一個 m 正好 exactly 等於 μ
但是如果你今天把你的 m 的期望值算出來的話，
假如你算 E[m]
m 就是這個式子，把它代進來
然後用國小數學把 1 放進去
然後你就得到 x^n 的期望值 summation over n，取 1/N
反正得到的值，就是 μ 這樣。
所以今天每一個 m 雖然都不一定跟 μ exactly 一樣
但是如果你找很多 m
它們的期望值會正好等於 μ
所以用 m 來 estimate μ
m 這個 estimator
它是 unbiased
因為他的期望值會正好等於μ
就好像是說
如果你在打靶的時候
他的準心是瞄準 μ 的
但是因為種種比如說機械故障
或者受到其他各種風速的干擾等等
你會散落在你本來瞄準的位置的周圍
那這個散佈在周圍，會散的多開呢？
取決於
m 的 variance
那這個 Var[m] 就是 σ²/N
所以你就不要問怎麼來的
這個機率課本都有寫
那這個 variance 的值呢
它 depend on
你今天取了多少的 sample
如果你今天的 N 呢
嗯我發現一個錯耶，你有發現嗎？
我今天把 larger 和 smaller 放反了
不好意思
這個 larger 和 smaller 它們應該是反過來的
如果你有比較多的 N 的話
它的散佈就會比較集中
如果你只取比較少的 N 的話
你那個 m 就會分散的比較開
如果你要估測 variance 怎麼辦呢？
你就先用剛才的辦法估測 m
估測 m 以後
你再計算 (x^n-m)²
再取它們的平均值
你得到另外的值是 s²
這個 s² 可以拿來估測 σ²
這個 s² 它估測的怎麼樣呢?
當然每一次你算一個 s 出來
它們跟 σ
這邊我應該要把它取平方才對
因為 s² 才是 σ² 的估測值
假設我這邊有取平方好了
我們每一次取出來的 s
它會散佈在，它不會跟 σ 正好一樣
它散佈在 σ 的周圍
但是這個 estimator 它是 biased
也就是說如果你取 s² 的期望值的話
它算出來並不是正好等於 σ²
它是 N-1/N
所以你會發現普遍而言
s² 是比 σ² 還要小的
就是小的次數比較多
但因為有 variance 所以也有可能比較大
但是平均而言小的次數是比較多的
如果你 increase N 的話
如果 N 比較大的話
那 σ² 跟 s² 估測之間的差距就會變小
好，那說了這些
我們回到 regression 這個問題來
比如說我們現在要估測的是
靶的中心
也就是 f̂
這個是我們的目標
那你 collect 一些 data
做一次實驗
你找出來的 f* 可能是在這個位置
這個位置跟這個紅心之間
它們其實有發生了兩件事
它們這個 error 取決於兩件事
第一件事情是你瞄準的位置在哪裡
就是你這個 estimator 是不是 bias
怎麼知道 estimator 是不是 bias 呢？
你把這個estimator f*
假設你可以做很多次實驗
那你把這個 f* 的期望值算出來
我們這邊寫成 f\bar
bar 就是平均的意思
f* 的期望值算出來就是 f\bar
那你會發現說，假設我們用右下角這個例子來看
你做了很多次實驗，找了很多不同的 f\bar
你會發現它們的散佈是這些藍色的點
這個時候你的 f* 呢，可能是在這個地方
那也就是說你的這個 estimator
跟你的靶心中間是有一個 bias 的
也就是說你瞄的時候就沒有瞄準
你以為正中心在這邊，你瞄這個點
那實際上呢，靶心是在這個地方
你瞄的時候就沒有瞄準
但這還有另外一個 error
這個 error 來自於你瞄準的這個位置
但是你把子彈射出去以後呢
還是會有偏移的
你瞄準這個位置，但是射出去還是會有偏移的
所以你每次找出來的 f* 是不一樣的
而這個 f* 跟你瞄準的位置
也就是 f* 期望值 f\bar 中間的距離呢
就是 variance
所以你的錯誤來自於兩件事
一件事情是
你的 bias 有多大
另外一件事情呢，是你的 variance 有多大
所以最理想的狀況是
我們期待的是
你同時沒有 bias，variance 又小
這樣你每次做實驗，你找出來的每個 f* 都是好的
那如果說今天
你有可能遇到一個狀況是
你的 bias 很大，但 variance 很小
那你每一次找的 f* 都很像，但是都集中在這個錯的位置
那你總是有錯
那也有可能是
你今天找出來的 f\bar 呢，是沒有 bias 的
你瞄的位置是對的，但是你那個槍性能很差
所以它每次射出去以後呢，是散佈在
這個靶心的周圍的
那你也會得到一些 error，所以
error 來自於兩個地方，一個是你瞄準的位置在哪裡
另外一個是你今天的這個 variance 有多大
可是有的人會問一個問題
你不就只能做一次實驗嗎？
如果你上周有來的話
你不就 collect 了十筆 data，然後就找一個 f*，然後就結束了嗎？
你怎麼找很多個 f* 呢？
你怎麼知道它的 variance 跟 bias 有多大呢？
你怎麼找很多個 f* 呢？
所以，這個怎麼想
你就假設說這個世界上是有很多的平行的 宇宙的
我們知道有很多的平行的宇宙
在很多個平行宇宙，在每一個宇宙都不一樣
但是我們都在抓寶可夢這樣子
在每一個平行宇宙裡面
我們都想 estimate 進化後的 CP 值
所以在每個平行宇宙裡面呢
我都去抓了 10 個寶可夢然後來算 f*
我們抓到的寶可夢呢，是不一樣的
在不同宇宙裡面，抓到的 10 之寶可夢是不一樣的
這個是第一個宇宙中的我這樣子
然後抓到的是這 10 隻
這個是第二個宇宙中的我， 其實只是衣服換一個顏色而已
你抓到的是這 10 隻
這個是第三個宇宙中的我，這時候性別也換了 然後抓到的是這 10 隻
好那因為抓到的寶可夢是不一樣的
如果你拿不同的寶可夢來找你的最好的 function
就算你用同一個 model
假設我們現在都用 y = b + w * x_cp，這個 model
我們用同樣的 model，但你給它的 data 不一樣
那你找出來的最好的 function f* 就是不一樣的
所以在宇宙編號 123 號
我們抓到的這 10 隻寶可夢
用這個 model，我們找出來的 f* 是這樣
在宇宙編號 345 號裡面
我們找到另外 10 隻寶可夢
我們找到的 model 是這個樣子
這兩個 model 是不一樣的，在不同宇宙裡面 我們找到的 f* 是不一樣的
好現在我們的問題就是
每一個宇宙找出來的 f* 就像對著把只開一槍一樣
那我們現在就是要知道說
它的散佈是甚麼樣子的
好，所以我們就把 100 個不同宇宙裡面的 f* 都找出來
當然世界上並沒有真的平行宇宙
所以做這件事情其實就是
你就做 100 次實驗，然後 每次都抓 10 隻不同的寶可夢就是了
你了解我的意思
在 100 個平行宇宙裡面
我們都抓了 10 隻不同的寶可夢
然後，都去找一個 f*
那今天如果我的 model 是 y = b + w * x_cp
那這 100 個 f* 它們的分佈長甚麼樣子呢？
如果我們把這 100 個 f*
這 100 個 y = b + w * x_cp 畫出來，會長這樣
所以有 100 個不同的 w，100 個不同的 b
你把這 100 條直線都畫出來
它會長成這個樣子
這邊有 100 條直線
那如果我今天換另外一個 model
你換一個 model
這個 model 是考慮了 x_cp, (x_cp)^2, (x_cp)^3
你做 100 次實驗，在 100 個宇宙裡面找 出了不同的 b, w1, w2, w3
那你的這 100 條線長這個樣子
那你就會發現說有點像是散開了，像花一樣地散開了
好，那如果今天是
換一個最複雜的 model
例如：5 次的 model，那你就會發現說
做 100 次實驗以後，你把那 100 條虛線都畫出來
你就會發現是這樣子的，崩潰的
在 100 個宇宙裡面，每一件事情都是有可能會發生的
所以呢，如果我們看這個 model 之間的 variance 的話
如果你看你做 100 次的射擊以後
你的結果的散佈的話
你會發現說
簡單的 model，就是只有考慮一次的 model
它是比較集中的
如果你考慮 5 次的話
它散佈就非常的廣
所以如果你用一個比較簡單的 model 的時候
它的 variance 是比較小的
就好像說，你在射擊的時候 每次射擊的位置是差不多的
你每次找出來的直線呢
你每次找出來的最好的 function f* 呢
都是差不多的
但是如果你今天換一個比較複雜的 model
它的散佈就很開，就像這邊藍色的點一樣
它的 variance 很大，散佈就很開
這邊的每一條直線呢，都長得很不像
各種怪怪的線，都長得不一樣， 它的散佈呢，就非常的開
今天你可能會問一個問題， 為甚麼比較複雜的 model，它的散佈就比較開呢？
為甚麼比較簡單的 model，它就散佈的比較緊呢？
因為，你可以這樣想
簡單的 model 它比較不會受你的 data 的影響
在每個宇宙裡面，我們 sample 出來的
我們抓到的寶可夢都不一樣， 所以找出來的 model 都不一樣
那比較簡單的 model
它受到不同 data 的影響是比較小的
舉例來說，我們舉一個極端的例子
這個極端的例子是
我們的整個 model set 裡面呢
就我們整個 function set 裡面呢
那我們整個 function set 這個 model 裡面， 就一個 function f(x)，
output 就是 c，你不管抓怎麼樣的 training data
這個 function output 就是給你 c 這樣
給你一個 constant
這時候你就會發現說，你在不同的宇宙裡面
你找出來的 model 都是一模一樣的，因為你根本就沒找
你的不同宇宙裡面，找出來的 model 通通是一模一樣的
它的 variance 呢，是 0
所以如果給你一個最簡單的 model，它的 variance 是 0
當你給的這個 model 它的複雜度越來越高的時候呢
它的 variance 呢，就會越來越大
好，接下來呢，我們來看 bias
好，那 bias 是甚麼呢？
bias 的意思是說，我們有很多很多的 f*
假設我們把所有的 f* 平均起來，找它的期望值
也就是 f\bar 的話
這個 f\bar 跟我們的靶心 f̂ 它有多接近呢？
如果是一個大的 bias 的話
意思是說，你今天把所有的 f* 平均起來
你得到的 f\bar，它跟靶心是有一段距離的
如果是小的 bias 的話
意思是說你的 f* 可能分散得很開
它分散得多開我們不管，你要找它的平均值
它的平均值呢，跟靶心是接近的
不管它散的多開，它的平均值跟靶心是接近的
這樣叫 small bias
說到這邊的時候，我就卡住啦
我為甚麼卡住了呢？
因為我想要量：不同 function 間的 bias 有多大
那仔細想想根本沒有辦法量這件事情
因為我根本不知道那個 f̂ 長甚麼樣子阿
所以我就卡住了這樣子，所以我只好
胡亂自己假設一個 f̂
假設說 f̂ 就是長這條直線這樣子
好，那我們就假設說 f̂ 就是長這條直線
所以我們的寶可夢 data 呢
寶可夢呢，就是從這條虛線 sample 出來的
那每次我們就 sample 10 個點出來
那你就可以找一個 f*
好那這個呢，是實驗的結果
黑色的線代表的是我們剛才在前一頁投影片看到的
真正的 f̂，就是你的靶心的位置是這條黑色的直線
紅色的呢，代表了我們做 5000 次實驗
5000 次實驗每一次找出來的 f* 都是不一樣的
所以假設是一次的 model
最簡單的 model ，它長得
有很多，有 5000 條直線在這邊
你這邊畫出來就是紅紅的一大塊
好，如果是藍色的呢
藍色代表說我們這個是 f\bar
就是我們把 5000 個 f* 平均起來變成 f\bar， 就是藍色的這條線
好，果我們只考慮一次的話
你會發現說那 5000 條直線都差不多， 都差不多在這個地方
那他們的平均就是這條藍色的線
那它跟黑色這個 f̂
跟靶心是有一段差距的
如果你用 3 次式
3 次式的話，你會發現說你 5000 條直線畫出來會是這樣子
它的頭跟尾是很散的
所以它的頭跟尾都很散
但是如果你說平均找 f\bar
也就是說藍色這條線的話
你會發現說，你算每一次的 f* 都差很多
那平均起來這個藍色的線
跟黑色這個 f̂
其實相對於這邊
它是比較接近的
如果我們找 5000 條，如果我們用 5 次式
那你就發現說 5000 條線畫出來是這樣， 你要不要乾脆把整個圖都塗紅色這樣
你會發現說這時候一切都有可能
那雖然這個地方你完全看不出來說，哇
到底有甚麼直線，通通塗成紅色的
但是如果你把它平均起來
你把這 5000 條、5 次式的曲線平均起來， 你會發現說
它得到的是這條藍色的 f\bar
它的 f\bar 是這條藍色的
它跟我們真正的 f̂，它跟真正的 f̂ 是接近的
雖然她每次都差很多，但平均起來以後，是接近的
所以呢，我們看到說
如果是一個比較簡單的 model
它有比較大的 bias
如果是一個比較複雜的 model
每一次找出來的 f* 都不一樣
但它有比較小的 bias
所以今天左邊這個簡單的 model 它的 case
就像是這個樣子
每一次 f* 都差不多
它的分布比較小，但是它跟靶心是有差距的
那這個 case
就像是這邊這樣子
每一次找出來的 f* 都不太一樣，但平均而言，是在靶心附近
為甚麼會這樣子
我試著直觀的解釋給大家聽
我們說，我們的 model 就是一個 function set 對不對
那我們就用一個範圍呢，來表示這個 function set
當你定一個 model 的時候，你就已經設定好說
你最好的 function 就只能從那個 function set 裡面挑出來
如果是一個簡單的 model
它的 space 是比較小
所以這個比較小的 space， 它可能根本就沒有包含你的 target
如果再沒有包含 target 的情況下
你從這裡面，不管怎麼 sample
你平均起來都不會是這個 target 阿
因為你的這個 function set 裡面 根本就沒有包含那個 target 阿
但是如果今天你的 model 呢
是比較複雜的
你的 model 所代表的這個 function space
我們上次有講過說你從 1 次、2 次、3 次一直到 5 次
你的 function 是越來越複雜的
那簡單的 function 是包含在複雜的 function 裡面
所以如果你用 5 次的時候，這個時候呢
你的 function 的 space 是比較大
那它可能有包含這個 target
它可能有包含這個 target，只是它沒有辦法 找出這個 target 在哪裡
因為你給的 training data 不夠
你給的 training data 每一次都不一樣
所以它每次找出來的 f* 都不一樣
但如果它們是散佈在這個 target 附近的
那平均起來呢，你就可以得到 f\bar
好，所以我們回到我們上次看的那個 model
對這個 testing data, error 所畫出來的線
那比較簡單的 model
我們剛才有講說比較簡單的 model
它就是 bias 比較大，但是 variance 比較小
比較複雜的 model
就是 bias 比較小，但 variance 比較大
所以今天這個圖，由左到右
一方面呢，model 的 bias 是逐漸地下降
這是 bias 所造成的 error 是逐漸下降
也就是你瞄的越來越準、你瞄的越來越準
但是同時呢，同時呢，這個 variance 是越來越大的
現在，雖然你每次瞄的越來越準
但是你每次射出去以後，你的誤差呢，是越來越大
所以當這兩項同時被考慮的時候
你得到的就是藍色這條線
藍色這條線，也就是說
在某個地方，你可以找到一個平衡的點
讓你同時考慮 bias 和 variance 的時候
你得到的 error 是越小
但是當你的 model 越來越複雜的時候
你的 variance 增長的比較快
所以你的 model 的 error 就變得很大
所以今天如果是一個 variance 大的情形
如果你的 error 來自於 variance 很大
這個狀況呢，就是 Overfittng
如果今天你的 error 來自於 bias 很大
這個狀況呢，叫做 Underfitting
所以今天假設你遇到一個 error 的時候
你自己做一些 implement
比如說你碩士論文用到 machine learning 的技術
你做完得到一個結果，然後你後面寫了一些 future work
然後我都會問一個問題
如果你找我去考碩士、博士的話， 我都問這個問題
就是說，你覺得你現在的問題是 bias 大、還是 variance 大
你應該先知道這件事情，你才知道你的 future work
你要 improve 你的 model 的時候， 你應該要走哪一個方向
那怎麼知道現在是 bias 大還是 variance 大呢？
好，甚麼時候 bias 大？
如果今天你的 model 沒有辦法 fit 你的 training 的 examples
那代表說呢，你的 bias 是大的
就是如果我們只 sample 這幾個藍色的點
而你的 model even 沒有 fit 這少數幾個藍色的點
代表說你的 model 跟正確的 model 是有一段差距的
所以這個時候是 Underfitting
這個時候是 bias 大的狀況
如果今天是你在 training data 上
你可以 fit 你的 training data
你在 training data 上得到小的 error
但是在 testing data 上，你卻得到一個大的 error
這意味著你的 model 可能是 variance 比較大
這個時候呢，代表的是 Overfitting
那遇到 bias 大跟 variance 大的時候
你其實是要用不同的方式來處理它們
比如說，如果今天是 bias 大
那你要做的事情是甚麼呢？
你應該去 redesign 你的 model
bias 大代表說，你現在這個 model 裡面可能根本沒有包含你的 target
你的 f̂，它根本就不再你的 model set 裡面
那你要怎麼辦呢？
你要做的事情是：redesign 你的 model
比如說，你可能重寫你 model 的式子
把更多的 feature 加進去
比如說只考慮 CP 值可能不夠，你可能還要考慮 hp 值阿，或其他甚麼東西
或者是，你讓你的 model 更複雜
本來只考慮 1 次不夠，你可能要考慮 2 次、3 次等等
在這個狀況下，因為是你的 model 不好，沒有包含 f̂
所以如果你今天你 error 差是來自 bias
那你不要說我去 collect 更多 data， collect 更多 data 是沒有用的
今天這個狀況下，collect 更多 data，你也不會有幫助
因為你的 model、你的 function set 本來就不好
再找更多的 data 下來，也不會有幫助
好今天如果是另外一個 case
如果是 variance 大的話
那你應該怎麼辦呢？
一個方法就是增加你的 data
那我們看剛才的例子，如果是 5 次式，找 100 個 f̂
每次如果們只抓 10 隻寶可夢的話，那我們找出來的式子
是這個樣子的
找出來的 100 個 f* 的散佈是這個樣子
但如果每次抓 100 隻寶可夢的話
那 100 個 f*，你會發現說他們非常的集中
他們幾乎都集中在這個地方
所以增加 data 是一個很有效控制 variance 的方法
假如你 variance 太大的話，這個時候你要做的事情
collect data 幾乎是一個，像是萬能丹一樣的東西
它不會傷害你的 bias
但是它有可造成你的問題就是
你在實際上你沒有辦法 collect 更多 data
對不對，在 practical，collect data 很麻煩阿， 你不見得能 collect 更多 data
不只在學校實驗室沒有辦法
你可能以為在業界就可以說你要 collect 多少 data，其實你也不見得可以
比如說，有些人在業界想要做一些 AI 的東西
然後他就跟老闆說，我要 collect 一萬筆 labeled data
然後就被 reject，因為老闆說這個，機器會自己學習
所以你不需要 labeled data，不是機器會自己學習嗎？
為甚麼要 labeled data
就把他否決了這樣子
所以在業界，不是你想要 collect data 就可以的
會有各種 review，尤其是你的高層又不知道 machine learning 是什麼的時候
你就會很卡，所以有時候你根本就沒有辦法 collect data
所以你不見得能夠這麼做
那如果你不能這麼做，其實有一招
這招就是 generate 假的 training data
根據你對這個問題的理解，自己去製造更多 data
還是有這招，比如說，在做手寫數字辨識的時候
手寫辨識的時候，有人會說
因為每個人手寫的這個角度不一樣
所以我把所有 training data 裡面的數字 都左轉 15 度、右轉 15度
這樣是可以
或者是做影像辨識，你只有一個從左邊開過來的火車
沒有從右邊開過來的火車，怎麼辦？
把整個圖片翻轉你就有從有右邊開過來的火車啦
對不對，你可以把你的每張圖片都左右顛倒
這樣你就多一倍的 data 出來
或者是在語音辨識的時候
你說，你只有男生說你好，沒有女生說大家好
那你就把那個男生的聲音
用一個變聲器把它轉一下這樣
就變女生的聲音，女生的聲音用變聲器轉， 就變男生的聲音
你這 data 就多出來，而且是真的有人這麼做的
或者是說，你說我只有這個 clean speech
你在錄音室錄的聲音
可是我是要做真正的 detection
那是要讓你在公車上用的
那怎麼辦？
你就去公車上面，錄一些雜訊
然後呢，加到你在錄音室錄的聲音裡面
你馬上就有公車上面的雜訊了
所以你有各種方法可以用啦
比如說，還有人說，我今天要做 language understanding 的 task
那我今天要做 support 各種不同國家的 language understanding 的 task 的時候
我要做 10 種國家、我 10 種語言都要
那老闆只給你英文的 data
它自己會學這樣子
只給你英文的 data，它中文自己學就會學的會
那怎麼辦呢？你就可以做 translation
把英文通通硬翻成中文，結果還是跟你 trained 一樣
所以有各種不同的做法
好，那如果你沒有辦法 collect 更多data 的話
你還有這另外一招，叫 Regularization
這我們上次也有看到
就是我們在一個 loss function 裡面，後面呢，再加一個 term
這個 term 會希望你的參數，越少越好
也就是說希望你今天找出來的曲線呢，越平滑越好
然後那個新加的 term 前面可以有一個 weight
代表你希望你的曲線有多平滑
左邊這個圖是，沒有加 Regularization 的 test
這個圖跟這個圖是一樣的
如果你今天加了 Regularization 以後
因為你的所有曲線都會變平滑
本來這種怪怪的、很不平滑的曲線就不會再出現了
所有曲線呢，都集中在比較平滑的區域
都變成比較平滑的曲線
如果你再更增加它的 weight 的話
再考慮要讓你的曲線更平滑的話
那你得到的結果就是這樣
所以如果你加了 Regularization 以後
你強迫所有的曲線都要比較平滑
所以這個時候呢，也會讓你的 variance 變小
那這個時候，你會得到的一個可能的傷害就是
你有可能會傷害你的 bias
對不對，你調整了你的 function space
變成它只包含那些比較平滑的曲線
那你可能就沒有辦法包含你的 f̂
那你可能就沒有辦法包含你的那個目標的 function
你就可能傷害了你的 bias
所以當你做 Regularization 的時候， 你要調整一下 Regularization 的 weight
在 variance 和 bias 之間呢，取得平衡
好，所以我們現在會遇到的問題往往是這樣
我們有很多個 model 可以選擇
那在這還有很多的參數可以調， 比如說，Regularization 的 weight
那通常我們是在 bias 跟 variance 之間呢， 做一些 trade-off
做一些平衡，我們希望找一個 model
variance 夠小、bias 也夠小
這兩個合起來，給我們最小的 testing data 的 error
我們通常需要選擇一個最好的 model
但是以下這件事情，是你不該做的
或是你最好、就是你不要這麼做，這個事情是怎樣呢？
就是你手上有 training set 、有 testing set
然後接下來你想要知道說：model 1、2、3 裡面
你應該選哪一個 model？
你就分別用 model 1、2、3 呢，分別去找一個 best function
我們 train 出一個 model，train 出一個 function
好接下來你把它 apply 到 testing set 上面
model 1給你 error 0.9、model 2給你 error 0.7 model 3給你 error 0.5
那很直覺的就是 model 3 最好這樣子
但是，你現在可能的問題是
這 testing set 是你自己手上的 testing set
是你自己拿來衡量 model 好壞的 testing set
真正的 testing set 是你沒有的
真正的 testing set 的時候呢，假設我們
今天把我做的寶可夢的預測，放到網路上這樣
然後看看有沒有人要用
那新進來的 data 我是從來沒有看過的
那因為你在挑 model的時候
你考慮了你自己手上的這一筆 testing set
而你自己手上的這筆 testing set，它有一筆 bias
就是你手上這筆 testing set，它有自己的一個 bias
那現在講的這個 bias 跟之前講的 bias 是有一點難解釋，是有關係，但意思略有不同
這個 testing set 有自己的 bias
所以你今天拿這個 testing set 來選這最好的 model 的時候
它在真正的 testing set 上，不見得是最好的 model
通常都是比較差的，所以你可能會得到的 error 是大於你在自己的 testing set 估測的 0.5
好這樣講甚麼自己的 testing set，你可能有一點困惑
那我們就直接拿我們的作業來舉例
你可能已經做了作業，那我們就是希望大家 做了作業以後，再來講這個東西
這個是這樣
你手上有 training set
那你有 testing set
那 testing set 其實有兩組
一組是 public set，一組是 private set
你今天上傳你的結果到
Kaggle 的 leaderboard 的時候
你只能看到 public set 的分數， 你沒有辦法看到 private set 的分數
private 的分數要等到作業 deadline， 你沒有辦法在上傳以後
你才會在一瞬間看到你 private set 的分數
你那個本來 ranking 上面秀的是 public 的分數
它一瞬間翻過來變成那個 private 的分數
然後，如果你今天做的是下面這個狀況
我用我的 training data，train 了這三個 model
我想知道哪一個結果是最好的， 所以我把 3 個 model 的結果通通傳到 Kaggle 上面
在 Leaderboard 上，它告訴我說， model 3 給我的 error 是最好的
你可能就覺得說，我做完了，我 beat the baseline !
但是，private set 你是看不到的阿
而 private set 的 error 通常是大於 public set 的 error 阿
所以你可能並沒有 beat baseline
所以這是有可能發生的
在下周五，那個作業 deadline 的時候，你可能就這樣
這個是有可能發生的，先跟大家講一下， 你不要太沮喪這樣子
比如說，第 3 名的搞不好現在排第 100
因為你知道，我是看得到 private set 的啦
我舉個例子，搞不好前 5 名的可能是在 100 名也說不定
然後也有比較勵志的故事，比如說現在第一名的， 他其實可在 40 幾名這樣
這個是真正的 example
這樣你 40 幾名的，你是不是就高興了呢這樣子
所以這個 public set 的結果，是不可靠的
所以，怎麼做才是比較可靠的呢？
你要做的事，你要這樣做就是 你要把你的 training set 分成兩組
其實大家也不用太在意那個排名， 那個占分也才一點點對不對
排名太差也不用太難過這樣子
好，那 training set 呢，你要把它分成兩組
這兩組呢，一組是真正拿來 train model
我們把它叫做 training set
另外一組，你不拿它來 train model
你拿它來選 model
你在這個 training set 上找出最好的 function f*
然後才用 validation set 來選擇你的 model
也就是你的做法應該是這樣子
你決定說，我到底應該用 model 1, model 2, 還是 model 3
然後你把這 3 個 model， 用你的 training set 去 train 好以後
接著看一下，它們在 validation set 上的 performance
假設現在 model 3 的 performance 是最好的
那你可以直接把這個 model 3 的結果拿來 apply在 testing data 上
那如果你擔心說
現在我把 training set 分成 training 跟 validation
感覺 training data 變少的話，那你可以這麼做
已經決定 model 3 是最好的 model
你就定住用 model 3
但是用全部的 data 在 model 3 上面再 train 一次
這樣你就可以使用全部的 training data
這個時候，如果你把這個 model
apply 到 public set 上面
你可能會得到一個大於 0.5 的 error
雖然這麼做，你得到的 error 表面上看起來是比較大的
但是這個時候，你在 public set 上面的 error
才能夠真正反映你在 private set 上的 error
這樣大家了解我的意思嗎？
當然我可以了解有一種狀況是
幾乎沒有辦法，就是在你的心情上
基本上沒有辦法避免這麼做就是
不建議你這麼做就是，因為通常你看到你的
public set 上的結果太差， 你就會想說回頭再去找些甚麼東西
那基本上是不建議你這麼做
因為如果你回頭再去搞點甚麼東西的話
你就變成又把這個 public testing set 的 bias
考慮進去了
你又把這個 bias 考慮進去
這樣會變成說，你在這個 public testing set 上
所看到的 performance 沒有辦法反映
你在 private set 上看到的 performance
但我知道說在心情上
你幾乎沒有辦法把持得住不這麼做
你可能看到說小毛 ranking 在前面
所以你就會想到說我再弄一個結果，擺在它前面這樣子
那其實你可以等到，等 private set 真正出來的時候
你搞不好就 rank 它前面這樣子
所以 public set 並不是最終的結果
那比如說，你看你在發 paper 的時候
有時候你會 propose 一個方法
那你要 attach 在 benchmark 的 corpus
當你要 attach 在 benchmark 的 corpus 上面的時候
如果你在 testing set 得到一個差的結果
你也幾乎沒有辦法把持自己
不回頭去調整一下你的 model 這樣子
你不會說，我在 testing set 上得到一個差的結果
只是寫一個 paper 告訴他說這個方法不 work 這樣子
你就會回頭去，因為搞點東、搞點西
然後硬是在 testing set 上把結果做起來
你幾乎沒有辦法避免做這件事情啦
那所以我想你能夠做的事情就是
你要 keep in mind，如果在那個 benchmark corpus 上面
所看到的 testing 的 performance
它的 error，你可以說是假的
或者是它大於在 real 的 application 上應該有的值
比如說你現在常常聽到說
在 image lab 的那個 corpus 上面
error rate 都降到 3%，那個是超越人類
但是，真的是這樣子嗎？
已經有這麼多人玩過這個 corpus
它已經有這麼多人試過告訴你說
前面那些方法都不 work
他們都幫你挑過 model 了，你已經用 testing set 調過參數了
所以，如果你把那些 model 真的 apply 到現實生活中
它的 error rate 應該會是大於 3%
好，那有人會擔心說
我這個分，如果分壞了怎麼辦？
分壞了，就是說如果這個 validation set 其實也有怪怪的 bias
怎麼辦呢？那你可以做下面這件事啦
這件事情是：N-fold Cross Validation
也就是說，如果你不相信某一次分
train 跟 test 的結果的話
那你就分很多種不同的樣子
比如說，如果你做 3-fold 的 validation
意思就是，你把你的 training set 分成 3 份
你每一次拿其中一份當做 validation set
另外兩份做 training
你拿某一份當 validation set，另外兩份當 training
接下來呢，如果你要知道 model 1, 2, 3 哪一份比較好的話
你就把這 3 個 model 通通在這一個情境下
由這兩個 set 做 training ，這個做 validation 的情境下
算一下它的 error
你在這個情境下，算一下它的 error
然後你算一下它的 average error
然後你會發現說，在這 3 個情況下的 average
是 model 1 最好
然後接下來呢， 你就把 model 1再 train 在你完整的 training set 上面
然後，再去 test 在你的 testing set 上面
那原則上就是，如果你少去太在意你在 public set
上面的分數，就是少去根據它調整
你的 model 的話，你往往會在 private set上面
得到的差距和 testing set 是比較小的
好那講到這邊呢，我們就先下課休息 5 分鐘， 然後我們就趕快回來這樣子
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
