臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
supervised learning 的話呢，有哪些 suggestion
所以，就算我們上課還沒有講到
也沒有關係，我相信對大家來說
應該不是一個問題
我們今天唯一需要做的就是
講完 CNN 的部分
我們都知道說，CNN 它常常被用在
影像處理上
如果你今天用 CNN 來做影像處理
比如說，你用 CNN 來
我當然可以用
一般的 neural network
來做影像處理，不一定要用 CNN
比如說，你想要做影像的分類
那你就是 train 一個 neural network
input 是一張圖片
那這張圖片你就把它表示成裡面的 pixel
也就是一個很長很長的 vector
那 output 就是看你，假設你有 1000 個類別
output 就是 1000 個 dimension
那我相信，根據剛才那堂課的內容，大家
應該都可以給你 training data，大概就可以秒做出來
但是
我們現在會遇到的問題是這樣子
實際上，如果我們 train neural network 的時候
我們會期待說，在這個 network 的 structure 裡面
每一個 neuron，其實就代表了一個最基本的 classifier
事實上，在文獻上呢
根據訓練的結果，也有很多人得到這樣的結論
舉例來說，第一層的 classifier
第一層的 neuron
它是最簡單的 classifier
它做的事情就是 detect 有沒有綠色出現
有沒有黃色出現，有沒有斜的條紋
那第二個 layer，它做的事情是
detect 更複雜的東西
根據第一個 layer 的 output
它如果看到直線橫線
就是窗框的一部分
如果看到棕色的直條紋就是木紋
看到斜條紋加灰色的
這個有可能是很多東西，比如說，輪胎的一部分等等
再根據第二個 hidden layer 的 output
第三個 hidden layer 會做更複雜的事情
比如說，它可以知道說
某一個 neuron 看到蜂巢，它就被 activate
某一個 neuron 看到車子，就被 activate
某一個 neuron 看到人的上半身
就被 activate
那現在的問題是這樣子
當我們直接用一般的
fully connected 的 feedforward network 來做影像處理
的時候，往往我們會需要太多的參數
舉例來說
假設這是一張 100*100 的彩色圖片
它解析度才 100*100，那這已經是很小張的 image 了
那你把它拉成一個 vector
它有多少的 pixel
它有 100*100*3
對不對，每個 pixel 其實需要
3 個 value 來描述它，如果是彩色的圖的話
是三萬維，那 input vector 如果是三萬維
這個 hidden layer 假設 1000 個 neuron 就好了
你的這個第一層 hidden layer 的參數
就已經有 30000*1000 了
這樣太多了
所以，CNN 它做的事情其實是
我們來簡化這個 neural network 的架構
我們把這裡面一些，根據人的知識
我們根據我們對影像處理的理解，就知道說
某些 weight 其實是用不上的，我們一開始
就把它濾掉
我們一開始就想一些辦法， 不要用 fully connected network
而是用比較少的參數
來做影像處理這件事情
所以，CNN 其實是比一般的 DNN
還要更簡單的
等一下，我們講完以後你就會發現說
你可能覺得說，CNN 看起來
它的運作很複雜
它應該是個比較複雜的東西
但事實上，它的模型呢
是比 DNN 還要更簡單的
我們就是用 prior knowledge
去把原來 fully connected 的 layer 裡面的一些參數拿掉
就變成 CNN
我們先講一下，為甚麼
我們有可能把一些參數拿掉
為甚麼我們有可能只用比較少的參數
就來做影像處理這件事情
那這邊有幾個觀察，第一個是
在影像處理裡面
如果我們說，第一層的 hidden layer
那些 neuron 要做的事情就是偵測某一種 pattern
有沒有某一種東西，有沒有某一種 pattern 出現
那大部分的 pattern 其實是比整張 image 還要小
所以，對一個 neuron 來說
假設它要知道說，一張 image 裡面
有沒有某一個 pattern 出現
它其實不需要看整張 image
它只要看 image 的一小部分
它就可以決定這件事情了
舉例來說
假設我們現在，有一張圖片
那第一個 hidden layer 的某一個 neuron
它的工作是
要偵測有沒有鳥嘴的存在
那你可能
有一些 neuron 偵測有沒有鳥嘴的存在
有一些 neuron 偵測有沒有爪子的存在
有一些 neuron 偵測有沒有翅膀的存在
有沒有尾巴的存在，之後合起來
就可以偵測，圖片中有沒有一隻鳥
假設有某一個 neuron 它的工作是
要偵測有沒有鳥嘴的存在
那它其實並不需要看整張圖
因為，其實我們只要給
neuron 看這樣一個小的部分
這個小的紅色框框裡面的區域
它其實就可以知道說
它是不是一個鳥嘴
對人來說也是一樣，只要看這個小的區域你就會知道說
這是鳥嘴，不需要看整張圖才知道這件事情
所以，每一個 neuron 其實只要連接到
一個小塊的區域就好，它不需要連接到
整張完整的圖
那第二個觀察是這樣子
同樣的這個 pattern
在 image 裡面，它可能會出現在
image 的不同的部分
它會出現在 image 的不同的部分
但是，它們代表的是同樣的含意，它們也有同樣的形狀
它們可以用同樣的 neuron
同樣的參數，然後，detector 就可以偵測出來
比如說，在這張圖裡面，有一個在左上角的鳥嘴
那這張圖裡面，有一個在
中央的鳥嘴
但是，你並不需要說，我去訓練兩個不同的 detector
一個是專門偵測左上角有沒有鳥嘴
一個是偵測中央有沒有鳥嘴
如果這樣做的話呢，它就
太冗了，所以，我們要 cost down
所以，它不需要太多的冗員，因為這個
這個 neuron，偵測左上角鳥嘴的 neuron
跟中央的偵測有沒有鳥嘴的 neuron，他們
做的事情，其實可能就是一樣的
所以，我們並不需要有兩個 neuron
兩組參數，來做
duplicate 的事情，所以，我們可以
要求這兩個 neuron，他們就用同一組參數
它們就 share 它們的參數，它們就共用同一組參數
這樣你就可以減少，你需要的參數的量
那第三個，是我們知道一個 image
你可以對它做 subsampling
你把一張 image 的奇數行
偶數列的 pixel 拿掉
變成原來的 1/10 的大小
它其實部會影響人對這張 image 的理解
對你來說，這張 image 跟這張 image
看起來可能沒有太大差別
你都可以辨識裡面有甚麼物件
所以，做 subsampling 這件事情
對影像辨識來說，能是沒有太大的影響的
所以，我們可以用這個概念把 image 變小
這樣，你就可以減少你需要用的參數
所以，整個 CNN 的架構是這樣
等一下，我們會一個一個解釋
在 CNN 的整個架構裡面
每一個 block 它做的事情是什麼
首先，input 一張 image 以後呢
首先，這個 image 會通過
convolution 的 layer
然後，接下來，做 Max pooling 這件事
那這每一件事，我們等一下都會解釋
然後，再做 convolution 這件事
然後，再做 Max Pooling 這件事
那這個 process 可以反覆數次
那反覆的次數，你覺得夠多以後呢
但反覆幾次這個你要事先決定
它就是 network 的架構，就好像 network 有幾層一樣
你要做幾次 convolution，做幾次 Max Pooling
你在定你那個 network的架構時，就要事先決定好
那你做完
你做完你決定要做的 convolution 和
Max Pooling 的次數以後，那你會做另外一件事情
你要做一件事情叫 Flatten
那做完 Flatten 以後，你把 Flatten output
丟到一般的 fully connected 的 network 裡面去
然後，得到最後影像辨識的結果
那我們剛才講說
這個我們基於
3 個對影像處理的觀察
所以，設計了 CNN 這樣的架構
那第一個觀察是
同樣的 pattern
要偵測一個 pattern，你不需要看整張 image
你只要看 image 的一個小部分
第二個是，同一個 pattern 它
不出現在一張圖片的不同的區域
第三個是，我們可以做 subset
前面這兩個 property 呢
它就是用 convolution 的 layer
來處理掉
最後這個 property
是用 Max Pooling
來處理，那等一下，我們就要介紹一下
每一個 layer 在做的事情
那我們就先從 convolution 開始看起
假設現在
我們的 network 的 input 是一張 6*6 的 image
假設這是黑白的
如果是黑白的，每一個 pixel 就只需要用一個 value
來描述它
比如說，1 就代表有塗墨水
0 就代表，沒有塗到墨水
那在 convolution layer 裡面
它有一組 Filter
它有一堆 filter
那這邊的每一個 filter
我等一下會講說，它其實就等同於是
fully connected layer 裡面的一個 neuron
我們等一下會講，現在先想說，我們有
一組 filter
那每一個 filter，其實就是一個 matrix
比如說，這邊的每一個 filter
都是 3*3 的 matrix
那這邊的每一個 filter 裡面的參數
這個 matrix 裡面的每一個 element 的值
就是 network 的 parameter
它就跟那些 neuron 的 weight 跟 bias 一樣，它們是
network 的 parameter
它們是必須學出來的
根據 training data 學出來，並不是人去設計的
所以，每一個 filter
它裡面的值是做甚麼
它裡面的值是什麼，要做甚麼事情
也是自動被學出來的
這邊呢，我們
每一個 filter，如果你是 3*3 的 size
意味著它就是在偵測
一個 3*3 的 pattern
它在偵測一個 pattern 的時候，它不看整張 image
它只看一個 3*3 的範圍內
就可以決定有沒有某一個 pattern 的出現
這個就是我們考慮的第一個 property
整個 pattern 其實比整張 image 還要小
那這個 filter 怎麼跟這個 image
做 operation 呢
這個 operation 的 process 是這樣
首先，你有第一個 filter
它是一個 3*3 的 matrix
那你把這個 filter 放在 image 的左上角
那我猜你可能會很困惑說
突然出現甚麼 filter 阿，放在左上角阿
跟我們之前講的 neural network 都不一樣
等一下其實會告訴你說，這個就是一個 neural network
那 training 就跟之前那個 Backpropagation 是一模一樣的
那我們現在只是從 convolution 的角度來看
它是怎麼運作的
它運作的方式是這樣
我們把一個 filter 放在一個 image 的左上角
然後，你把這 9 個值
跟這 9 個值
做內積
所以，內積的結果，這邊是 1, 1, 1
這邊是1, 1, 1，內積的結果你就得到 3
接下來，你挪動一下，你的 filter 的位置
那至於要挪多少，這個你要事先決定好
那這個挪動的距離
欸，大家有問題嗎？
講道這邊，如果大家沒有問題的話，我們就繼續
這個挪動的距離
叫做 stride
這個 stride 等於多少，你要自己設啦
所以，你設 stride = 1
那 filter 就放在這邊，所以，1, 1, 1
乘上 -1, -1, 1
心算一下，得到是 -1
你可以設 stride = 2
stride = 2 的話，你就得到 -3
那 filter 移到這邊，1, 1, 1
-1, -1, -1 得到 -3
那我們等一下就設 stride = 1
所以，設 stride = 1
你把 filter 往右移一格，得到 -1
往右移一格，得到 -1；再往右移一格，得到 -3
再往右移一格，得到
這邊是 1, 1, 1，這邊是 -1, 1, -1，得到 -1
然後，你接下來往下移一格
得到 -3，就這樣，以此類推
把這件事情，就每一次都
stride = 1，就每次都移動一格
那最後，你就會得到一個
最後，直到你把 filter 移到右下角的時候
這邊是 1, 1, 1，這邊是 -1, 1, -1
你就得到 -1
所以，做這件事情以後
本來是一個 6*6 的 matrix
經過這個 convolution process，就得到一個
4*4 的 matrix
如果你看這個 filter 的值
它的斜對角的地方是 1, 1, 1
所以，它的工作就是 detect 有沒有 1, 1, 1
有沒有這個連續的，左上到右下的 1, 1, 1
出現在這個 image 裡面
比如說，它出現在這個地方
所以，這個 filter 就會告訴你說
你看現在左上跟左下
出現最大的值
就代表說，這個 filter 要偵測的 pattern
它出現在這個 image 的左上角
所以，左上角最大值跟左下角
有最大的值，這件事情呢
就考慮了 property 2
因為，同一個 pattern
它出現在左上角的位置，跟出現在左下角的位置
我們都用 filter 1 就可以
偵測出來，我們不需要用不同的 filter 來做這件事情
我們用同一個 filter 就可以把它偵測出來
在一個 convolution 的 layer 裡面，它會有
一打 filter，它會有一大堆的 filter
那剛才只是一個 filter 的結果
會有另外一個 filter，它裡面會有不一樣的參數
比如說，這裡會有一個 filter 2
會有不一樣的參數，那它也做跟 filter 1
一模一樣的事情
你就先把 filter 2 放在左上角
再做 inner product 得到 -1
再挪動一格，得到 -1，就這樣，以此類推
所以，你把 filter 2 跟 input 的 image
做完 convolution 以後
你就得到另外一個 4*4 的 matrix
那這個紅色的 4*4 的 matrix 跟
藍色的 4*4 的 matrix 合起來
就叫做，他們叫做 Feature Map
這個東西叫做 Feature Map
那看你有幾個 filter，你就會得到多少的 image
比如說，你有 100 個 filter
那這邊你會得到 100 個 image
講到這邊大家有沒有甚麼問題想要問呢？
沒錯，因為現在每一個 filter size 都是一樣的
意味著說，如果你今天有同一個 pattern
它有不同的 size，有大的鳥嘴，也有小的鳥嘴
它必須要用
如果你可以事先知道的話，你當然可以用 normalize
但是，input 一張 image，你沒有辦法事先知道
知道它是大的鳥嘴還是小的鳥嘴，所以
你也沒辦法 normalize
所以，CNN 並不能夠自動處理這個問題
對它來說，這種不同 scale 的東西，它其實
不見得能夠處理
那你其實可以看看這個
DeepMind 最近有解一篇 paper
是當你 input 一張 image 的時候
它在 CNN 前面，再接另外一個 network
這個 network 做的事情是甚麼呢？
這個 network 做的事情是
它 output 一些 scalar
告訴你說，它要把這個 image 的
裡面的哪些位置
做旋轉、縮放
然後，再丟到 CNN 裡面
這樣你其實會得到比較好的結果
大家還有甚麼問題嗎？
那剛才舉的例子是
黑白的 image，所以你 input 的是一個 matrix
如果今天是彩色的 image 怎麼樣呢？
我們知道彩色的 image 就是
RGB 組成的
對不對，RGB 組成的
所以一個彩色的 image，它就是好幾個 matrix 疊在一起
它就是一個立方體
如果我今天要處理彩色的 image
我們要怎麼做呢？
這個時候你的 filter，就不是一個 matrix
你的 filter 也是一個立方體
如果你今天是 RGB 這三個顏色來表示
一個 pixel 的話
那你的 input 就是 3*6*6
那你的 filter 就是 3*3*3
你的 filter 的高就是 3
你的 filter 高就是 3
你在做這個 convolution 的時候
你就是把這個 filter 的 9 個值
跟這個 image 裡面的 9 個值
做內積
了解嗎？我們並不是把每一個
把每一個 RGB 顏色都分開算
那其實這個在影像上，我們叫做 channel
並不是把每一個 channel 分開來算
而是，合在一起算
每一個 filter 同時就考慮了
不同顏色所代表的 channel
講道這邊大家聽得懂嗎？
那我們現在要講的東西就是
這個 convolution 跟 fully connected
有什麼關係？
你可能覺得說，它是一個很特別的 operation
感覺跟 neural network 沒半毛錢的關係
其實，它就是一個 neural network
怎麼說呢？我現在要講的就是
這個 convolution，這件事情
其實，它就是一個
fully connected 的 layer 把一些 weight 拿掉而已
怎麼說呢？
我們假設這邊這個 output
這個 feature map 的 output
其實就是
一個 hidden layer 的 neuron 的 output
如果你把這兩個東西 link 在一起的話
這個 convolution 其實就是一個
fully connected 的 layer 拿掉一些 weight 的結果
怎麼說呢？
我們在做 convolution 的時候
我們把 filter，假設我們今天考慮 filter 1
我們把 filter 1 放在左上角
然後，你做 inner product，得到一個值 3
這件事情等同於
我們現在把這個 6*6 的 image 拉直
拉直變成這樣子
然後，你有一個 neuron 的 output 是 3
那這個 neuron 的 output 怎麼來的呢？
這個 neuron 的 output 它是考慮了
你看這個 filter
它把它放在左上角
它在左上角
所以，這個 filter，它考慮的 pixel
是 1, 2, 3、1, 2, 3
這邊是 4, 5, 6
欸，不是 4, 5, 6
這邊 1, 2, 3, 4, 5, 6，所以這邊是 7, 8, 9
這邊是 7, 8, 9
這邊是 13, 14, 15
假設你把這一個 6*6 的 image 的 36 個 pixel 拉成
直的
那這 9 個 pixel 分別就是
編號 1, 2, 3 的 pixel 跟 7, 8, 9 的 pixel
跟 13, 14, 15 的 pixel
那如果我們說這個 filter 做 inner product 以後的 output 3
就是某一個 neuron 的 output 3 的話
就代表說有 1 個 neuron
這個 neuron 的 weight
只連接到 1, 2, 3
7, 8, 9 跟 13, 14, 15
這 3 個 pixel 而已
而這個 neuron 它的這 9 個 weight
就是 filter 這個 matrix 裡面的這 9 個 weight
花很多時間故意把它用同樣的顏色
這樣看的出來嗎？這個 1 是
框棕色，所以這邊才是棕色的
這個框紅色，這真的搞很久，所以這是紅色
這個橙色的
這邊有 9 個不同的顏色，所以
這 9 個不同顏色裡面框起來的 weight
分別就是這 9 個不同的 weight
大家看的懂嗎？
所以，現在是這樣子的
我們應該在 fully connected 的 layer 裡面
一個 neuron，照理說是連接到所有的 input
你有 36 個 pixel 當作 input
那這個 neuron 本來應該連接到 36 個 input
但是，我們現在只連接 9 個 input
只連接 9 個 input，因為我們知道說
要 detect 一個 pattern，我們不需要看整張 image
我就看 9 個 input 就好
所以，當我們這麼做的時候，你就用了
比較少的參數，你就用了比較少的參數
當我們移動一格，把 filter 做 stride = 1 的移動的時候
發生甚麼事呢？
我們得到另外一個值 -1
我們假設這個 -1 是另外一個
neuron 的 output
那這個 neuron 連接到哪些 input 的 weight 呢
這一個框起來的地方啊
這個框起來的地方，它正好就對應到 pixel 2, 3, 4
2, 3, 4，這個是 8, 9, 10
8, 9, 10 跟 14, 15, 16
跟 14, 15, 16，你會發現說這邊呢
同樣的 weight 代表同一個顏色，所以
這 9 個 matrix
這 9 個在這個 filter 所對應的matrix 裡面的 weight
就是這個圖上 9 個不同的顏色
所以，當我們做這件事情的時候，意味著說
這裡個 neuron
本來在 fully connected layer 裡面
每一個 neuron 都有獨立、自己的 weight
但是，當我們做這個
convolution 的時候
首先，我們把每一個 neuron 它前面連接的 weight 減少
再來，我們強迫說
某些 neuron、這兩個 neuron
他們一定要共用同一組 weight
他們的 weight 永遠都必須是一樣的
它連接到 pixel 1 的 weight
要等於它連接到 pixel 2 的 weight
它連接到 pixel 2 的 weight
要等於它連接到 pixel 3 的 weight
它連接到 pixel 3 的 weight， 要等於它連接到 pixel 4 的 weight
我故意用同樣的顏色來表示，希望你可以看的出來
這件事情叫做 weight 的 sharing
當我們做這件事情的時候，我們用
用的這個參數呢
又比原來又更少
我們強迫一些 weight
一定要 share 在一起
我們用的 weight 就更少
這邊有一些事情是投影片上沒有講的
可能會問說
這怎麼 train
首先，第一件事情就是這都是用 toolkit 做的
所以，你大概不會自己寫
如果你要自己寫的話
它的做法就是，你就跟原來的 Backpropagation
用一模一樣的作法
只是有一些 weight
就永遠是 0，你就不 train 它，它就永遠是 0
然後，再來呢
你說怎麼讓這個 weight 的值永遠都是一樣的
你就用一般的 Backpropagation 的方法
然後，這個 weight 你算出一個 gradient
這個 weight 你算出一個 gradient
再把本來要 tight 在一起
要 share weight 的那些 weight 的 gradient 平均
然後，他們 update 同樣的值，就結束了
你聽不懂沒有關係，因為
你大概沒有機會自己實作這個東西
如果你真的有空的話，等一下下課可以跟我討論
這件事情呢
再來，接下來要做 Max pooling
Max pooling 是甚麼呢？
相較於 convolution，max pooling 是比較簡單的
它就是做 subsampling
根據 filter 1
我們得到一個 4*4 的 matrix
根據 filter 2，你得到另外一個 4*4 的 matrix
接下來，我們做甚麼事呢？
我們說，把這個
output，4 個一組，4 個一組
4 個一組，4 個一組
每一組裡面，你可以選他們的平均
或者是你可以選最大，其實都可以
你就是把原來 4 個 value 合成 1 個 value
那你可以用自己想要的方法來做這件事情
這件事情就可以讓你的 image 縮小
比如說，假設我們現在就是選 4 個裡面
最大的那個保留下來
所以，3, -1, 3, 1，我就選 3
就選最大的保留下來，那你這邊可能會有一個問題就是
把這個東西放到 network 裡面，你不就沒辦法微分了嗎
max 這個東西，感覺不能微分阿
它其實可以的
我們之後講 Maxout network 的時候，再來跟大家講
這個，其實有辦法用微分的方式來處理它
所以，結論是這樣
結論是這樣
我們現在，這邊有 4 個值，這邊有 4 個值
所以，做完一次 convolution
加一次 Max pooling
我們就把原來 6*6 的 image
變成一個 2*2 的 image
至於這一個 2*2 的 image，它每一個 pixel 的深度
它的這個深度
每一個 pixel 用幾個 value 來表示
depend on 你有幾個 filter，如果你有 50 個 filter
這邊就是 50 維
兩個 filter，這邊就 2 維
所以，這個就是一個
新的，但是比較小的 image
那每一個 filter 就代表了一個 channel
這一件是可以 repeat 很多次
你得到一個、你通過一個 convolution
再加一個 Max pooling
你就得到一個新的 image
那它是一個比較小的 image
所以，你可以把這個比較小的 image，再做一樣的事情
再通過 convolution
再通過 Max pooling，再得到一個更小的 image
那我這邊舉的例子
input image 已經夠小了
所以，再做一次就不見了
我就沒有再做一次
講到這邊，大家可以了解我意思嗎？
有甚麼問題要問的嗎？
其實我講到這邊的時候，我常常會
被問到、遇到一個問題
大概是我講 deep learning 的 talk 已經太多了
我都可以 predict 聽眾的問題
這邊每次都會有人問我一個問題，就是
如果我這邊有 25 個 filter
我得到 25 個
feature map
假設我第一個 convolution 有 25 個 filter
我得到 25 個 feature map
第二個 convolution 也有 25 個 filter
那這樣做完，我是不是得到
25 平方個 feature map
是這樣嗎？
其實不是這樣，就是說
你這邊做完一次 convolution，你得到 25 個 feature map
你這邊做完，還是得到 25 個 feature map
這樣大家了解我意思嗎？因為你在這邊
假設你這邊有
第一層 filter 有兩個好了
那第二層的 filter
它在考慮這個 input 的時候
它是會考慮深度的
它並不是每一個 channel 分開考慮
它是一次考慮所有的 channel
所以，你 convolution 這邊有多少個 filter
你 output 就有多少個 filter
你這的25 個 filter
output 就 25 個 filter
你這邊有 25 個 filter，output 還是 25 個 filter
只是這邊的每一個 25 個 filter
它都是一個 cubic
它都是一個立方體
它的高有 25 個 value 那麼高
這樣大家有問題嗎？
如果大家沒有問題的話呢
我們就繼續
然後，有一個，再來就是
最後這個 flatten 跟 fully connected 的部分
這個就很簡單，這個怎麼做呢？
flatten 的意思就是，我把
這個 feature map 拉直
這邊完全沒有學問在，我就把它拉直
拉直以後，你就把它丟到一個 fully connected 的
feedforward network，然後
就沒有然後，就結束了
接下來，剩下一點時間，我就要
秒講一下，怎麼用 Keras
來 implement CNN
那在 training, compile 跟 fitting 的部分
其實是一模一樣
你唯一需要改的只有說
你要改一下你的 network structure
還有 input 的 format
本來在原來的 DNN 裡面，input 是一個 vector
現在如果是 CNN 的話
它是會考慮 input 的 image 的幾何空間的
所以，不能 input 給它一個 vector
你要 input 給它一個 tensor 這樣
tensor 就是高維的 vector 啦
你要給它一個三維的 vector
為什麼三維的 vector 呢
因為一個 image 的長寬各是一維
如果它是彩色的話，RGB 就是第三維
所以，你要給它三維的 vector
你 assign 一個三維的 matrix
這個高維的 matrix 就叫做 tensor
那怎麼 implement 一個 convolution 的 layer 呢
你就這麼做
model.add
剛才是 dense，現在就改成 convolution2D
它其實也有 1D 的，現在就改成 2D
然後，這邊 25, 3, 3 是甚麼意思呢？
這邊 25, 3, 3 的意思就是說
你有 25 個
25 代表 25 個 filter
後面的 3, 3 就代表，你的 filter 是一個 3*3 的 matrix
你的 filter 都是 3*3 的 size
那 input 呢？
你要告訴它 input shape 要是甚麼樣子
假設我現在是要做手寫數字辨識
input 是 28*28 的 image
它的每一個 pixel 都是
都是只有單一顏色
所以，你 input 的 shape 就是 1*28*28
前面這個 1 阿，如果你是黑白的話，它就是 1
如果你是彩色的圖，每個 pixel 用 3 個值來表示
這邊你就要放 3，代表 RGB 3 個顏色
那 28*28 就代表這個 image 總共 28*28 個 pixel
那 Max pooling 也很簡單
就 add 一個 Max pooling 的 layer
那這邊的 (2, 2) 的意思是說呢
我們把 2*2 的這個
feature map 裡面的 pixel 拿出來
然後，每次就選最大的那一個
所以，假設我們 input 是一個
1*28*28 的 image
那你就這樣寫 add(Convolution2D(25, 3, 3,
input_shape = (1, 28, 28)))
那通過 convolution 以後
你得到的東西是甚麼呢？
你得到的 output 是甚麼呢？
你得到的 output，首先，你這個
channel 的數目會是 25
也就是 25 個 filter
你得到的 channel 的數目就是 25
然後，因為你現在的 filter 的 size 是 3
所以，本來 28*28 的 image
通過 3, 3 的 filter
就假設你那個邊邊的地方沒有考慮的話
就會變成 26*26
這樣大家了解我意思嗎？
當然你也可以考慮邊邊啦
如果你想要考慮邊邊的話
你就在原來的 image 旁邊
補 0，把它變成比較大的 image
然後，接下來你做 Max pooling
你做 Max pooling，把 2*2 的
這個 pixel 一組
然後，裡面選一個最大的
做完以後，你就變成 25*13*13
變 25*13*13
然後，接下來
你再做一次 convolution，假設我這次選
50 個 filter
然後，每個 filter size 是 3*3 的話
那現在變成 output 的 channel 就有 50 個
那 13*13 的 image
通過 3*3 的 filter
就會變成 11*11
我們剛才舉的例子，裡面是 6*6 的 image
通過 3*3 的 filter，變成 4*4
所以，你通過 3*3 的 filter 都會是
長跟寬都會減 2
所以，本來是 13*13 的 image
通過 3*3 的 filter，就變成 11*11
然後，你接下來再做 Max pooling
2*2 的 Max pooling 變成 50*5*5
那這邊呢，就問一下大家
在第一個 convolution
的 layer 裡面
每一個 filter，它有多少個參數呢？
它有多少個參數
是不是 9 個參數
因為，它就是一個 3*3 的 matrix 嘛，就是 9 個參數
但是，在第二個 convolution layer 裡面
雖然，你每一個 neuron
每一個 filter 都是 3*3，但它其實不是
3*3 個參數
因為，它 input 的 channel 有 25 個
所以，它的參數是 3*3*25
它的高是 25，所以這邊是 225
這樣大家有問題嗎？
如果大家沒有問題的話
我們就繼續看下去
所以，通過兩次 convolution、兩次 Max pooling
原來 input 是 28*28
做完這些事以後，變成 50*5*5
50*5*5
那做 flatten 就是
把這一個東西拉直
那你只要 call 一個 add flatten 就好
把它拉直
拉直以後就變成一個 1250 維的 vector
你再把 1250 維的 vector
丟到一個 fully connected 的 network 裡面
fully connected 的 network 大家應該都很熟悉，就跟
我們剛才 demo 的是一樣的
然後就得到 output，我們就現場實作
秒做一下 CNN 這樣
那這 code 你只要再胡亂改一下，就可以交作業三
我們的 CNN 的架構
我們很快、非常非常快地來複習一下
比如說，我們現在要做手寫數字辨識
那 input 呢，哦，忘了開聲音
假設我們要做手寫數字辨識，input 是一張
28*28 的影像
然後，通過 convolution layer 以後呢
假設我們現在有 25 個 filter
然後，每個 filter 的 size 是 3*3
那 input 28*28 的 image，它的 output 呢
通過 3*3 的 filter 以後
你得到 image size 就是 26*26
那這個 26*26 的 image，它的每一個 pixel
都是由一個 25 維的 vector 來表示
如果你有 25 個 filter 的話呢
這是 25 維的 vector
然後做 Max poling
就把原來 26*26 的 image 變成 13*13
然後，你可以再加另外一層 convolution
另外一層 convolution，假設它是 3*3 的話
做完 convolution 就是 11*11
因為有 50 個 filter，所以
你的每一個 pixel 現在是用 50 個 value 來描述
然後，你可以再做 pooling 等等
最後，把這個結果接進一個 fully connected layer 得到
最後的 output，上次也示範說
如果你要用一個 Keras 來實作一個 CNN 的話
你要怎麼秒做
接下來，我想要講的是
大家、很多人常會說
deep learning 就是一個黑盒子
然後，你 learn 完以後，你不知道它得到了甚麼
所以，有很多人不喜歡這種方法
其實，我是覺得，今天有一個方法
它可以讓你輕易地理解
它為甚麼會下這樣子的判斷
為甚麼個方法會下這樣子的決策的話
那其實這個方法，你就會覺得它不夠 intelligent
因為你可以輕易地理解它
那今天如果它非常 intelligent 的話
它就必須要是你無法理解的東西
這樣，它才夠 intelligent，至少你會感覺它夠 intelligent
所以，大家常說 deep learning
就是一個黑盒子，你 learn 出來以後，你根本不知道
為甚麼是這樣子
但是，其實還是有很多方法可以分析的
比如說，今天這邊我們來示範一下
怎麼分析 CNN
它到底學到了甚麼
那我今天的例子，不一樣就是做在 MNIST 上面
那你其實可以在你的作業三
在 CIFAR-10 上面呢，複製看看 (一個語料庫的名字)
你能不能看到類似的結果
那要分析第一個 input layer 的 filter 是比較不容易的
因為第一個 layer 裡面，每一個 filter
它就是一個 3*3 的 matrix
它對應到 3*3 的範圍內的 9 個 pixel
所以，你只要看這個 filter 的值，就可以知道說
它在 detect 甚麼東西
所以，第一層的 filter 是很容易理解的
但是，你比較沒有辦法想像它在做甚麼事情的
是第二層的 filter
在第二層，我們也是 3*3 的 filter，有 50 個
但是，這些 filter 的 input 並不是 pixel
這些 filter 的 9 個 input
它的 3*3 的 input 並不是 pixel
而是做完 convolution，再做 Max pooling 的結果
所以，這個 3*3 的 filter，你就算把它的 weight 拿出來
你也不知道它在做甚麼
另外這個 3*3 的 filter，它考慮的範圍並不是
3*3 個 pixel，並不是 9 個 pixel
而是比 9 個 pixel 更大的範圍
不要忘了它的 input
這 3*3 個 element 的 input
是做完 convolution 再加 Max pooling 的結果
所以，它實際上在 image 上看到的範圍
是比 3*3 還要更大的
那我們怎麼來分析一個 filter 它做的事情是甚麼呢？
以下，是一個方法
那你可以這樣做
我們知道說
現在在這 convolution layer 裡面的
50 個 filter
每一個 filter 的 output
就是一個 matrix，對不對？
每一個 filter 的 output 就是 11*11 的 matrix
假設，我們現在把第 k 個 filter 拿出來
我們把 input 一張 image 的第 k 個 output 拿出來
它可能長這樣子，是一個 11*11 的 matrix
那裡面每一個 element
我們就叫它 a上標 k，下標 i, j
上標 k 的意思是說，這是第 k 個 filter
i, j 代表說它在這個 matrix 裡面的
第 i 個 row，第 j個 column
接下來，我們訂一個東西叫做
Degree of activation of the k-th filter
我們訂一個值代表說
現在的第 k 個 filter
它有多被 activate、它有多被啟動
現在 input 的東西
跟第 k 個 activate 有多相近
有多 match
那這個第 k 個 filter 呢
第 k 個 filter，它被啟動的 degree 呢
我們這邊就定義成
它的 11*11 matrix 裡面的
這些全部 element 的 summation
這個 filter 呢
就我們 input 一張 image
然後，看這個 filter 它 output 的 11*11 個值
把它全部加起來
當作說，現在這個 filter 被 activate 的程度
接下來，我們要做的事情是這樣子
我們想要知道
這個第 k 個 filter 它的作用是甚麼
所以我們想要找一張 image
這一張 image 它可以讓第 k 個filter
被 activate 的程度最大
怎麼做到這件事情呢？
假設 input 的 image 我們稱之為 x
那我們現在要解的問題就是
找一個 x
它可以讓，現在我們定義的這個
activation 的 degree a, 上標 k
它可以讓我們定義的這個 activation 的 degree 最大
那這件事情要怎麼做到呢？
你其實就是用 gradient descent
因為我們現在要 maximize
如果是 minimize，你可以用 gradient descent
那 maximize，你用 gradient ascent
你就可以做到這件事了
就結束了
這樣大家聽得懂嗎？
我覺得還頗神妙
因為，我們現在是把 x 當作我們要找的參數
對它去用 gradient descent 或 gradient ascent
做 update
原來在 train 這個 CNN
在 train neural network 的時候
input 是固定的
那你的這個 model 的參數
是要用 gradient descent 去找出來的
用 gradient descent 找一組參數
可以讓你的 loss 可以被 minimize
但是，現在這個立場是被反過來的
現在，在這個 task 裡面呢
model 的參數是固定的
那我們要用這個 gradient descent 去 update 這個 x
或是，我們用 gradient ascent 去 update 這個 x
我們 update 這個 x，讓它可以讓這個
activation function 的這個 degree of activation
是最大的
這邊大家有問題嗎？
沒有哦，這個還滿神妙的
這個是得到的結果，如果我們
隨便取 12 個 filter 出來的話
那每一個 filter 呢，我們說我們對每一個 filter
都去找一張 image
這個 image 可以讓那個 filter
它的 activation 最大
那現在有 50 個 filter
所以，理論上可以找 50 張 image
它可以讓這些 filter 的 activation 最大
那我就隨便取了前 12 個 filter
可以讓它最 activate 的 image 出來
可以看它的結果長這樣子
那這些 image 它有一個共同的特徵就是
它是某種 texture
它是某種紋路
在圖上不斷地反覆
為甚麼呢？為甚麼會這樣呢
比如說，我們看看
這一張 image 好了
這一張 image 上面，第三張圖上面呢
它都是小小的斜條紋
這意味著甚麼事？這意味著
第三個 filter 它的工作就是 detect 圖上
有沒有斜的條紋
那不要忘了說，現在每一個 filter
其實它考慮的範圍，都是每一個圖上的
小小的範圍而已
所以，今天一個圖上如果出現一個
小小的，隨便一個斜的條紋的話
這一個 filter
就會被 activate，這個 filter output 的值
就會比較大、就會很大
如果，今天讓圖上
所有的範圍通通出現這個小小的斜條紋的話
那這個時候，它的 activation
它的 degree of activation 會是最大
因為它的工作就是，偵測有沒有一個斜的條紋
所以你給它一個完整的數字的時候，它不會最興奮
你給它通通都是斜的條紋的時候，這個時候它最興奮
雖然，它完全不是一個數字
所以，你就會發現說，每一個 filter 它的工作就是
detect 某一種 pattern
detect 某一種線條
比如說，第 3 個圖它 detect 斜的線條
第四個圖 detect 短的、直的線條
這個 detect 這個方向斜的線條
這個也是 detect 這個方向斜的線條
不過跟這個 degree 可能有點不一樣
它這個 degree 比較正，這個也是
detect 斜的線條，但是它比較平
這個 detect 是直的線條，等等
你會發現每一個 filter 做的事情
就是 detect 不同角度的線條
如果今天 input 有不同線條的話
你就會讓某一個 activation function
某一個 filter 它 output 的值最大
我們接下來可以分析這個
fully connected 的 layer
我們做完 convolution 和 Max pooling 以後呢
接下來，我們會做一件事情叫做 flatten
然後，把 flatten 以後的結果
丟到 neural network 裡面去
那我們也會想要知道說，在這個 neural network 裡面
每一個 neuron 它的工作是什麼
所以，我們就如法炮製剛才的作法
我們要做的事情是這樣子
我們定義第 j 個 neuron
它的 output 叫做 a_j
接下來，我們要做的事情就是
找一張 image x
用 gradient descent 的方法去找一張 image x
這個 image x，你把它丟到這個 neural network 裡面去
它可以讓 a_j 的值被 maximize
那找到甚麼樣的結果呢
我們找到的結果就是這樣
就是隨便取前 9 個 neuron 出來
隨便取 9 個 neuron 出來
那甚麼樣的圖丟到 CNN 裡面，可以讓這 9 個 neuron
最被 activate，output 的值最大呢？
就是這 9 張圖
你會發現說，跟剛才的
filter 所觀察到的情形，是很不一樣的
在剛才的 filter 裡面，我們觀察到的是
類似紋路的東西
在整張圖上，反覆同樣的紋路
那是因為每一個 filter，它考慮的只是一個
小小的 region，圖上的一部份的 region
所以，它 detect 是某一種 texture
但是，現在每一個 neuron
在你做 flatten 以後，每一個 neuron 它的工作
就是去看整張圖
它不再是只看整張圖的一小部分
它現在的工作是看整張圖
所以，每一個 neuron 你可以讓它最 activate 的圖
並不再是 texture 那個樣子，而是一個完整的圖形
而是一個完整的圖形，雖然它看起來完全
不像數字，比如說，這個看起來像是
千年眼這個樣子
算了，沒有人知道我在說甚麼
就是，某一個 neuron，像這個 neuron
這個會偵測千年眼的 neuron 呢
它的工作其實就是
看到這樣子的線條
或到這樣子的線條
或看到小小的圓圈
就可以讓它被 activate
所以，它偵測的也是一個完整的數字
是一個比較大的 pattern
接下來，我就會想要知道說
如果我們考慮的是 output 呢
如果我們今天考慮的是 output 呢
如果我們今天把，output 就是 10 維嘛
把每一維都對應到一個 digit
那我們把某一維拿出來
然後，我們說找一張 image
讓那一個維度的 output 最大
那我們會得到甚麼樣的 image 呢
你可以想像說，現在既然
每一個 output 的每一個 dimension
就對應到某一個數字
那我們現在如果把對應到數字 1 的那張圖
我們如果先找一張 image
它可以讓對應到數字 1 的那個 output layer 的 neuron
它的 output 最大
那一張 image 顯然看起來像是個數字 1
對不對，這樣大家了解我意思嗎？
你可以期待說，搞不好我們用這個方法就可以
讓 machine 自動畫出數字
但是，實際上我們得到的結果是這樣子
得出來的結果是這樣子
那這邊呢，每一張圖
分別代表數字 0, 1, 2 到 8
我就只畫了 9 個，實際上 output 有 10 個
也就是說，我們找出來可以讓
對應到 0 的那個
output layer 裡面對應到 0 的那個 neuron
它的 output 最大的 image 其實是長這個樣子
可以讓 1 的 neuron output 最大的 image 其實是長這樣
2 的其實是長這樣，以此類推，每張看起來都差不多
都像是電視壞掉的樣子
你可就會有個疑惑，為甚麼會這樣
是不是程式有 bug
為了確定程式沒有 bug，所以我就再做了一個實驗是
我把這每一張 image
都真的丟到 CNN 裡面
然後，看說它 classify 的結果是什麼
那 CNN 確實就是說
它 classify 說這個是 0、這個是 1、這個是 2
一直到這個是 8，CNN 就覺得說
你如果拿這張 image
我們 train 出來的正確率有 98.2 給 CNN 看
它就會說，這個東西就叫做 8
所以，很神奇吧
所以，這個結果，其實已經在很多地方都被觀察到了
就是今天這個 neural network，它所學到的東西
跟我們人類是不太一樣的
那它所學到的東西
跟我們人類一般所想像認知是不一樣的
你可以看一下這段 video，那它也有對應的 paper
那裡面呢，machine 會把各種你看起來
不像企鵝的東西也是企鵝， 看起來不像公車的東西也是公車
不然像我們這邊看起來，這完全不像一個數字
但對 machine 來說，它就是這個數字 8
所以，這個 machine 它學到的東西
和我們人類，是非常不一樣的
我們就想說，那這樣我們沒有辦法畫一個數字
所以我們要把這個數字，我們有沒有辦法
讓這個圖看起來更像數字呢？
所以，這邊的想法是這個樣子
因為，我們知道說
一張圖是不是一個數字，它有一些
基本的假設
比如說，這些東西就算是
你不知道它是甚麼數字， 你也會知道說它顯然就不是一個 digit
人類手寫出來的東西，就不是長這個樣子
所以，我們應該對這個 y 做一些 Regularization
做一些 constraint，我們應該告訴 machine 說
說錯了，不是 y，我們應該對 x 做一些 constraint
我們應該對找出來的 x 做一些 constraint
我們應該告訴 machine 說
有一些 x，它雖然可以讓你的 y 很大
但是，它不是數字
我們天生、根據我們人的 required knowledge 就知道說
這些 x，它不可能是一個數字
那我們可以加上甚麼樣的 constraint 呢
比如說，最簡單的想法是說
今天這個圖上阿
白色的亮點
畫這個圖的時候，白色代表是有墨水的
有墨水就是有 ink、有筆畫的地方
是白色的，希望大家可以想像
對一個 digit 來說呢
塗白的部分，其實是有限的
塗白的部分不會太多
你整張圖都是白白的，它一定不是一個數字
那對數字來說
只有一整張圖的某一個小部分
會有筆畫
所以，我們應該要對這一個 x 做一些限制
對 x 做一些限制
比如說，這邊的限制是
我發現呢，我寫錯了
因為這邊是 max
所以，這邊這個加號應該是減號
不好意思，這邊加號應該是減號
因為我們這邊要做的事情是這樣子
假設這個 image 裡面的每一個 pixel
我們用 x_ij 來表示
所以，每一個 image 有 28*28 個 pixel
i 就是 1~28，j 就是 1~28
我們把所有的 pixel 的值
我們把所有今天 image 上面的 x_ij 的值呢
取絕對值加起來，如果你熟悉 machine learning 的話呢
這一項就是 L1 的 Regularization
那我們把這個 pixel 的值
全部加起來
然後，我們希望說，我們再找一個 x
它可以讓 y_i 最大的同時
這邊其實應該要是減號
它同時應該要讓 x_ij 的 summation
越小越好
也就是說，我們希望找出來的 image
大部分的地方，是沒有塗顏色的
沒有塗白色的、沒有筆畫的
只有非常少的地方
是有塗筆畫的
那如果我們加上這個 constraint 以後呢
我們得到的結果看起來就像是這樣
其實，跟左邊的圖比起來呢
你已經有些隱約可以看出來
它是一個數字，比如說
這個就有一點點像 6
雖然說，它這邊還多了一條，但它有一點點像 6
這個，有一點點像 8
這個，它好像找到了 5 的第一個筆劃
這個好像找到了 7 的第一個筆劃
等等，所以你加上了這些 constraint 以後呢
你看起來得到的結果
就比較像數字了
講到這邊，你可能會問一個問題
首先，我們還沒有講過 L1 的 Regularization
但是，我們等一下會講
再來你可能會有另外一個問題，這個有絕對值阿
怎麼微分，其實這個是可以微分的啦
這個我們下一堂課會講到
講到這邊，大家有沒有甚麼問題呢？
其實，我覺得說如果你再加上一些額外的 constraint
比如說，你希望相鄰的 pixel 是同樣的顏色等等
你應該可以得到更好的結果
不過，其實有更多很好的方法可以
讓我們自動去 generate
數字，或是 generate 它看到的東西
所以，這邊我就沒有興致再把它做得更好
其實，這個東西、這個想法
就是 Deep Dream 的精神
不知道大家知不知道 Deep Dream 是甚麼呢？
Deep Dream 是說，如果你給 machine 一張 image
它會在這個 image 裡面，加上它看到的東西
怎麼做這件事情呢
你就找一張 image
這個是我，後面這個不是 photoshop 上去的
然後，這邊我擺了一個很做作的姿勢
然後，你把這張相片丟到 CNN 裡面去
然後，你把它的某一個 hidden layer
你把某一個 layer 裡面的
filter，或是 fully connected layer 裡面
的某一個 hidden layer 拿出來
那它其實是一個 vector
你把某一個 hidden layer 拿出來
它其實是一個 vector，假設它這邊是
比如說，3.9、-1.5、2.3
接下來呢，你把
這個 filter 的值調大
你把本來是 positive 的 dimension 值調大
把 positive 的 dimension 值調大
negative 的 dimension 值調小
然後，你本來就是正的讓它更正
負的讓它更負
你把這個東西，當作是
新的 image 的目標
了解我意思嗎？就是
你把這個 3.9 的值變大
你把 -1.5 的值變得更負
你把 2.3 的值變得更大
然後，你找一張 image
用 gradient descent 的方法
讓它在這個 hidden layer 的 output
是你現在設下的 target
這樣大家聽得懂嗎？
你如果這麼做的話
你如果這麼做的話，意思就是說
讓 CNN 誇大化它看到的東西
它本來已經有看到
某一個東西了
你讓它看起來更像原來看到的東西
你讓它本來看起來是有一點像
某一個東西，它讓某一個 filter 呢
有被 activate，但你讓它被 activate 的更劇烈
就是你讓 CNN 誇大化它現在看到的東西
那如果你把這一張 image
拿去做 Deep Dream 的話
你看到的結果，就會是這樣子
背後出現很多念獸，要凝才看的到這樣
就是有很多念獸這樣
比如說，像這邊
這邊有一隻熊
你看這個熊，它原來是一個石頭
它原來是一個石頭，那你不覺得它這個石頭
哇！看起來其實也是有點像熊的嗎？
這個是耳朵，這個是眼睛、這個是鼻子
那對機器來說，它在看這張圖的時候
它本來就覺得，這個有點像熊
那你就更強化這件事
所，它看起來就真的變成了一隻熊
這個是 Deep Dream
那 Deep Dream 還有一個進階的版本
這個叫做 Deep Style
Deep Style 是讓，今天你 input 一張 image
你 input 一張相片，然後讓 machine 去修改這張圖
讓它有另外一張圖的風格
比如說，讓這個相片，看起來像是吶喊
那得到的結果就是這樣子
這畫的還滿好的
這驚人的好
那這個東西，是怎麼做的呢
這邊就不細講，就列一個 reference 給大家參考
那它這個做的精神是這樣子
你給它、把原來的 image
丟給 CNN，然後得到 CNN 的 filter 的 output
CNN 的 filter 的 output
代表這一張 image 裡面有甚麼樣的 content
然後，接下來你把吶喊這張圖
也丟到 CNN 裡面
也得到 filter 的 output
但是，這個時候我們考慮的不是
filter output 的 absolute 的 value
我們並不在意一個 filter output 的 value 是什麼
而是在意 filter 和 filter 之間 output 的 correlation
那這個 correlation 代表了一張 image 的 style
接下來，你就用同個 CNN
找一張 image，這張 image 呢
它的 content 像左邊這張相片
比如說，這張 image 它的 filter output 的 value
像左邊這張相片
同時呢，這張 image 的 style
像右邊這張相片
所謂的 style 像右邊這張相片是
你這個 image output 的 filter 間的 correlation
像右邊這張相片
那你找一張 image，同時可以
maximize 左邊這個東西， 也可以 maximize 右邊這個東西
那你得到的結果，就是像這樣子的一個圖
那你用的就是，我們剛才講的 gradient descent 的方法
找一張 image
maximize 這兩個 criteria 的結果，就是左邊這個圖
那我們現在知道說，CNN 可以被應用在很多不同的
應用上，不是只有影像處理
比如說，CNN 現在有一個非常
知名的應用，就是用在下圍棋上面
為甚麼 CNN 可以用在下圍棋上面呢
我們知道說，你要讓
machine 來下圍棋，你不見得要用 CNN
其實，一般 typical 的 neural network
也可以幫我們做到這件事情
你只要 learn 一個 network，也就是找一個 function
它的 input 是棋盤，output 是棋盤上的位置
也就是說，你下一步根據這個棋盤的盤勢
如果你下一步要落子的話
你應該落子的位置
你其實就可以讓 machine 學會下圍棋了
所以，你其實用 fully connected 的 feedforward network
也可以幫我們做到讓 machine 下圍棋這件事情
也就是說，你只要認知告訴它說 input
是一個 19*19 的 vector
vector 的每一個 dimension 對應到
棋盤上的某一個位置
如果那一個位置有一個黑子的話，就是 1
如果有一個白子的話，就是 -1
反之呢，就是 0
如果你把棋盤描述成一個 19*19 的 vector
丟到一個 fully connected 的 feedforward network
output 也是 19*19 個 dimension
每一個 dimension 對應到棋盤上的一個位置
那 machine 就可以學會下圍棋了
但是，實際上如果我們今天在這邊採用
CNN 的話
我們會得到更好的 performance
採用 CNN 是甚麼意思呢？
我們之前舉的例子都是把 CNN 用在影像上面
也就是 input 是一個 matrix
所以，現在你其實只要把 19*19 的 vector
表示成一個 19*19 的 matrix
一個棋盤可以很自然地表示成一個 19*19 的 matrix
對 CNN 來說，就是把它當成一個 image 來看
然後，再讓它 output 下一步要落子的位置
就結束了
那它 training 的 process 呢
是這個樣子的
這個我們講過，你就蒐集很多棋譜
比如說這個是進藤光和社青春的棋譜
初手下在 5 之五，然後再下在天元，再下在 5 之五
接下來，你就告訴 machine 說，看到落子在 5 之五
CNN 的 output 就是天元的地方是 1，其他的 output 是 0
看到 5 之五和天元都有子
那你的 output 就是 5 之五的地方是 1
其他都是 0，這個是
supervised 的部分，那其實呢
AlphaGo 還有 reinforcement learning 的部分
那這個我們就之後再講
我們知道說，大家都是
大家都說得一口 AlphaGo 啦
大家都是懂懂懂這樣子
自從 AlphaGo 用了 CNN 以後
大家都覺得說，好像 CNN 應該很厲害
所以有時候，如果你沒有用 CNN 來處理你的問題
人家就會問你說，比如你去面試的時候
你的碩士論文裡面沒有用 CNN 來處理問題
口試的人可能不知道 CNN 是甚麼
但是，他就會問你說為什麼不用 CNN 呢
CNN 不是比較強嗎？
這個時候你就可以嗆爆他這樣子
甚麼時候我們可以用 CNN 呢
你要有 image 該有的那些特性
我們之前在講 CNN 開頭的時候，我們有說，根據
3 個觀察，所以我們設計出了 CNN 這樣的 network 架構
它在處理 image 的時候
是特別有效的
那為甚麼這樣子的架構，也同時可以用在
圍棋上面呢
那是因為圍棋有一些特性，和影像處理是很相似的
第一個是
我們說，在 image 上面
有一些 pattern 是比整張 image 還要小的多
比如說，鳥的喙是比整張 image 還要小的多
但是，你只要看到一小個部分，你就會知道說
它是不是鳥的喙
在圍棋上，可能也有同樣的現象
我對圍棋知道得很少
知道的知識都沒有超過棋靈王所教我的範圍
但是我也知道說，比如說，這個東西、一個白子
被 3 個黑子圍住，這個叫做叫吃
如果黑子現在落在這邊，就可以把白子提走
那白子要接在這邊，才不會被提走
總之，這個是一個 pattern，你看到這個 pattern 應該會
做一些應收，做一些相應的事情
比如說，你會落子在這個地方
那現在你只需要看這個小小的範圍
你就可以偵測說，這個白子是不是屬於被叫吃的狀態
你不需要看整個棋盤，才知道這件事情
所以，這件事情跟 image 是有同樣的性質
那在 AlphaGo 裡面，它第一個 layer 的 filter
其實就是用 5*5 的 filter
顯然做這個設計的人，覺得圍棋上最基本的 pattern
可能都是在 5*5 的範圍內
就可以被偵測出來
並不需要看整個棋盤
才能夠知道這件事情
接下來，我們說 image 還有一個特性是，同樣的 pattern
會出現在不同的 region，而它們代表的是同樣的意義
在圍棋上，也可能有同樣的現象
像這個叫吃的 pattern，它可以出現在棋盤的左上角
也可以出現在右下角
它們都是叫吃，它們都代表了同樣的意義
這些同樣的 pattern，出現在不同的位置
它們也都代表同樣的意義
所以，你可以用同一個 detector
來處理這些在不同位置的同樣的 pattern
所以，對圍棋來說呢
它在第一個 observation 和第二個 observation
是有這個 image 的特性的
但是，讓我沒有辦法相通的地方，就是第三點
我們說，我們可以對一個 image
做 subsampling，你拿掉奇數行、偶數列的 pixel
把 image 變成原來的 1/4 的大小
但是，也不會影響你看這張圖的樣子
但是，因為基於這個觀察，所以
有 Max pooling 這個 layer
但是，對圍棋來說
你可以做這件事情嗎？
比如說，你可以對一個棋盤丟掉奇數行和偶數列
它還是同一個函式嗎？
顯然是不是的
就算我對圍棋甚麼都不懂，我也覺得說
這顯然不 work，那這件事就讓我相當地困擾
那我看網路上一些文章，有一些人覺得說
因為 AlphaGo 裡面可能有用了 Max pooling 這樣的架構
它是用 CNN ，所以裡面可能有 Max pooling 這樣的架構
所以，或許這是一個
它的弱點
你要針對這個弱點取攻擊它，就可以擊敗它
但是，AlphaGo 很強，它可能比李世乭還強
它可能比高永夏還強了，所以
它顯然沒有這個顯而易見的弱點了
它顯然沒有這個顯而易見的弱點了，所以
到底是怎麼回事呢，我就覺得相當地困惑
有一天，我突然領悟到
會不會在這個 AlphaGo 的 CNN 裡面
有甚麼特別的地方呢
我相信說，大家都讀過 AlphaGo 的 paper
這個 paper 也沒幾頁，好像就 6 頁吧，一下就看完了
但是，它後面有一個很長的附錄
那我們一般都是不看附錄的
它的 paper 裡面，從來沒有
它只說了一句說，它用 CNN
它沒有在正文裡面，仔細地描述它 CNN 的架構
會不會實際上它 CNN 的架構裡面有甚麼
特別的玄機呢
所以，就讀了一下它的附錄
附錄裡面，它描述了它 neural network 的 structure
它是這樣說的
它的 input 是一個 19*19*48 的 image
19*19 我們可以理解，因為一個棋盤就是 19*19
48 是怎麼來的呢
對 AlphaGo 來說呢
它把每一個位置都用 48 個 value 來描述它
它把每一個位置
都用 48 個 value 來描述它
那這裡面的 value 呢
就我們本來說，我們只要在一個位置描述說
它是不是白子，有沒有黑子就可以了
那其實 AlphaGo 它有加上了 domain knowledge
它不只是說有一個位置，它有沒有白子或黑子
它還會看說，這個位置是不是處於
叫吃的狀態呢，等等
所以，我們如果讀完這段的話，你會發現說
第一個 layer，它有做 zero padding
也就是說，它把原來 19*19 的 image
外圍補上更多 0，讓它變成一張
23*23 的 image
然後，它的第一個 layer 用的是
5*5 的 filter
總共有 k 個 filter，k 的值呢
它在 paper 裡面用的是 192
因為它有試 128 跟 256
接下來，它的 stride 是設 1
然後，它有用 ReLU 的 activation function
接下來，它有 2~12 層
apply 5*5 的 filter 以後，它變成 21*21 的 image
那接下來的 filter 都是 3*3 的 filter，它的 stride
都是 1，然後
你就會發現說，其實 AlphaGo 是沒有用 Max pooling 的
有沒有很神奇呢
它是沒有用 Max Pooling 的
所以，這個 neural network 架構的設計
是這個應用之道，存乎一心
雖然說，在這個 image 裡面
我們都會用 Max pooling 這個架構
但是，針對圍棋的特性來 設計 neural network 的架構的時候
我們是不需要 Max pooling 這個架構的
所以在 AlphaGo 裡面，它沒有用 Max pooling 這個架構
並不是疏失了甚麼之類的
而是，根據圍棋的特性，我們本來就不需要再
圍棋的 CNN 裡面，用 Max pooling 這樣的架構
那其實 CNN
也可以被用在其他的、很多的 task 裡面
比如說，CNN 也被用在影像處理上
那 CNN 也被用在影像處理上
舉例來說，這個是一段聲音
你可以把一段聲音表示成所謂的 spectrogram
所謂 spectrogram 的意思是說
這個橫軸是時間
這個縱軸是那一段時間裡面
聲音的頻率
比如說，假設我們看這一段時間
這個偏紅色就代表說，在那一段時間裡面
那一個頻率的 energy 是比較大的
那在這一段時間裡面，這一個頻率跟這一個頻率
跟這一個頻率的能量是比較高的
那這一張 image，其實是我說
你好，然後看到的 spectrogram
所以，這個東西是你，這個東西是好
如果有透過訓練的人呢，它其實可以看這張 image
就知道說這句話的內容是甚麼
我之前在 MIT 做 postdoc 的時候
MIT 的語音處理實驗室據說是
最早發明 spectrogram reading
的團隊，所謂 spectrogram reading 的意思就是
練習看這個頻譜，就知道說
它裡面內容是甚麼
然後，他們經年累月的在練習這件事情
就練習的很強
他們每周的 group meeting 都要練習做 spectrogram
就是老師會拿出一張 spectrogram
然後，大家就要判讀這張 spectrogram 的內容
老師就會指著一段說
這個 spectrogram，這一段聲音
你覺得它是哪一個 phone 呢？
大家把一段聲音
phone 就是類似音標的東西
大家把一段聲音的音標解譯出來以後
再套 language model 上去，把它解譯成文字
是這樣，通常都會答對
那你可能會覺得說
他們練到最後可能可以看一張 image
秒反映說它的結果是甚麼
那其實沒有辦法
通常這個解譯的過程大概要花一個小時
這個東西就像念球遊戲之類的，是個很厲害的技術
既然人可以看這個 image，就知道說
它是甚麼樣的聲音訊號
甚麼樣的 phoneme
我們也可以讓機器把這個 spectrogram
就當作一張 image
然後，用 CNN 來判斷說，input 這張 image
它是對應甚麼樣的聲音訊號
那這邊通常判斷的單位，比如說是
phoneme，類似音標這樣子的單位
也有可能是 phoneme之類的
但是，這邊神奇的地方就是
當我們把一段 spectrogram
當作 image，丟到 CNN 裡面的時候
在語音上，我們通常只考慮
在 frequency 方向上移動的 filter
也就是說，我們的 filter 是這樣，是長方形的
是長方形的
它的寬，就跟我們 image 的寬是一樣的
那我們在移動 filter 的時候呢
我們是移這個方向
我們只移這個方向
為甚麼是這樣子呢？
當然也有人試過說，把 filter 移時間的方向會怎樣呢
結果是沒有太大的幫助
會這樣的原因，我覺得是因為在語音裡面
這個 CNN 的 output 後面都還會再接別的東西
比如說，再接 LSTM 阿，等等
他們都已經有考慮 typical 的 information
所以你在 CNN 裡面，你再考慮一次時間的 information
其實，沒有甚麼特別的幫助
但是，為甚麼在頻率上的 filter 有幫助呢
想想看，我們說我們用 filter 的目的
是為了要 detect 說同樣的 pattern
出現在不同的 region
我們都可以用同一個 filter 把它 detect 出來
但在聲音訊號上面
雖然，比如說，男生跟女生發同樣的聲音
男生跟女生同樣說你好
看起來這個 spectrogram 是非常不一樣的
但實際上他們的不同，只是一個頻率的 shift 而已
男生說的你好跟女生說的你好
他們的 pattern 其實是一樣的
比如說，你看這個 spectrogram 變化的情形
其實，可能是一樣的
那男生跟女生的差別，可能只是頻率上的 shift 而已
你就只是把這個 pattern
放在 image 上的不同位置而已
所以，今天我們把 filter
在 frequency 的 direction 上移動是有效的
但是，在 time domain 上的移動
是沒有必要，是沒有太大幫助的
所以，這又是另外一個例子，就是
當你把 CNN 用在另一個 application 的時候呢
你永遠要想一想說
這個 application 的特性是什麼
而根據那個 application 的特性
來 design 你的 network 的 structure
那我們也知道說，CNN 會
被用在文字處理上面
這個是從 paper 上面截下來的圖
在文字處理上面，假設你 input 一張
一個 word sequence，假設你要做的事情是
讓 machine 偵測說，這個 word sequence
它代表的是 positive 的意思還是 negative 的意思
首先，input 一個 word sequence
你把這個 word sequence 裡面的每一個 word
都用一個 vector 來表示
那這邊的每一個 vector
它代表的這個 word，它本身的 semantic
那如果兩個 word 本身涵義越接近的話呢
他們的 vector 在高維的空間上
就越接近，這個東西叫做 word embedding
那如果你不知道 word embedding 是什麼的話
也沒有關係，你就記得說現在每一個
word 都會用一個 vector 表示
都會用一個 vector 表示
當你把每一個 word 都用一個 vector 來表示的時候
你把一個 sentence 裡面所有的 word 排再一起
它就變成一個 image
它就變成一張 image
那你可以把 CNN
套用在這個 image 上面
怎麼做呢？
當我們要把 CNN 用在文字處理上的時候
你的 filter 其實是長這樣子
你的 filter 是長這個樣子
它的高跟 image 的高
是一樣的
然後，你把你的 filter
沿著 word 的順序
沿著句子裡面詞彙的順序來移動
然後，你就會得到一個 vector
不同的 filter 就會得到不同的 vector
然後，接下來做 Max pooling
把 Max pooling 的結果丟到 fully connected layer 裡面
你就會得到最後的 output
那在文字處理上呢
這個 filter 只在時間的序列上移動
而不在這個 embedding 的 dimension 上移動
你不會設計 filter，它移動的方向是
這個方向的
為甚麼呢？如果你有
做過類似的 task
如果你有做過文字處理的 task
知道這個 embedding 的 dimension 指的是甚麼的話
知道 word vector 指的是甚麼的話
你就會知道說
其實在這個方向上移動，是不 make sense 的
因為在 word embedding 裡面呢
每一個 dimension 的含意其實是獨立的
所以，如果當我們今天使用 CNN 的時候
你會假設說，第二個 dimension
跟第一個 dimension 有某種特別的關係
那第四個 dimension 跟第五個 dimension
有某種特別的關係
而這個關係，我們是可以被
如果這個關係是重複的
這個同樣的 pattern 出現在不同的位置
它們代表的是同樣的意思
但是，在 word embedding 裡面呢
不同 dimension，它們是 independent ，它們是獨立的
所以，在這個方向上面
移動 filter，是沒有意義的
所以，如果你在做文字處理的時候
你只會在 sentence 的順序上面移動 filter
而不會在 word embedding 的 dimension 去移動 filter
所以，這個又是另外一個例子
雖然，大家覺得 CNN 很 powerful
你可以用在各個不同的地方
但是，你用在一個新的 task 的時候
你要想一想你的新的 task
在設計 CNN 的架構的時候，你要怎麼做
如果你想要知道更多有關 Regularization 的事情的話
以下是一些 reference
我們剛才看到說，如果你想要用
Deep Dream 的方法
來讓 machine 自動產生一個 digit 這件事情
是不太成功的
但是，有很多其他的方法
可以讓 machine 畫出非常清晰的圖
而其他方法可以讓 machine 看過 MNIST 裡面的那些
數字以後，就學會畫出以假亂真的數字
這邊列了幾個方法，比如說有 PixelRNN
或者是 VAE, GAN，給大家參考
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
