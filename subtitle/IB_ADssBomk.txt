臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://ai.ntu.edu.tw/
下周會請中研院曹昱博士講一下 GAN 在語音上的應用
除了 GAN 在語音上的應用以外
這個投影片就是 GAN 的最後要跟大家講的東西 就是怎麼做 Evaluation
講完這個部分，GAN 的地方就講完 今天就提早下課
Evaluation 是要做甚麼？我們要講的是怎麼 evaluate 用 GAN 產生的 object 的好壞
比如說在作業 1 2 3 裡面你用 GAN 產生了 image
怎麼知道你的 image 是好還是不好
我覺得最準的方法就是人來看
但是在人來看往往不一定是很客觀 如果你在看文獻上的話
很多 paper 只是秀幾張它產生的圖
然後加一個 comment 說你看到我今天產生的圖
我覺得這應該是我在文獻上看過最清楚的圖 然後就結束了
你也不知道是真的還是假的
今天要探討的就是有沒有哪一些比較客觀的方法
來衡量產生出來的 object 到底是好還是不好
在傳統上怎麼衡量一個 generator？
傳統衡量 generator 的方法是算 generator 產生 data 的 likelihood
也就是說 learn 了一個 generator 以後 接下來給這 generator 一些 real data
假設做 image 生成 已經有一個 image 的生成的generator
接下來拿一堆 image 出來，這些 image 是在 train generator 的時候 generator 沒有看過的 image
然後去計算 generator 產生這些 image 的機率
這個東西叫做 likelihood
這邊有一大堆的 image xi 然後算 PG 這個 generator
產生 xi 這張 image 的機率
算出 PG( xi )，你可能會取 log
然後所有這些 real data，這些其實是你的 testing data 的 image 的 likelihood 通通算出來做平均
就得到一個 likelihood
這個 likelihood 就代表了 generator 的好壞
因為假設 generator 它有很高的機率產生這些 real data
就代表這個 generator 可能是一個比較好的 generator
但是如果是 GAN 的話，假設你的 generator 是一個 network 用 GAN train 出來的話
會遇到一個問題就是沒有辦法計算 PG( xi ) 為甚麼？
因為 train 完一個 generator 以後，它是一個 network
這個 network 你可以丟一些 vector 進去 讓它產生一些 data
但是你無法算出它產生某一筆特定 data 的機率
它可以產生東西
但你說指定你要產生這張圖片的時候
它根本不可能產生你指定出來的圖片 所以根本算不出它產生某一張指定圖片的機率是多少
所以如果是一個 network 所構成的 generator
要算它的 likelihood 是有困難
假設這個 generator 不是 network 所構成的 舉例來說這個 generator 就是一個 Gaussian Distribution
Gaussian Distribution 我想大家都應該知道吧
或是這個 generator 是一個 Gaussian Mixture Model Gaussian Mixture Model 大家應該知道吧
如果是一個 Gaussian Mixture Model，給它一個 x
Gaussian Mixture Model 可以推出它產生這個 x 的機率
但是因為那是 Gaussian Mixture Model 它是個比較簡單的 model
如果 generator 不是一個簡單的 model 是一個複雜的 network
你求不出它產生某一筆 data 的機率
但是我們又不希望 generator 就只是 Gaussian Mixture Model
我們希望我們的 generator 是一個比較複雜的模型
所以遇到的困難就是如果是一個複雜的模型
我們就不知道怎麼去計算 likelihood
不知道怎麼計算這個複雜的模型 產生某一筆 data 的機率
怎麼辦？在文獻上一個 **** solution 叫做 Kernel Density Estimation
也就是把你的 generator 拿出來
讓你的 generator 產生很多很多的 data
接下來再用一個 Gaussian Distribution 去逼近你產生的 data，甚麼意思？
假設有一個 generator 你讓它產生一大堆的 vector 出來
假設做 Image Generation 的話
產生出來的 image 就是 high dimensional 的 vector
你用你的 generator 產生一堆 vector 出來
接下來把這些 vector 當作 Gaussian Mixture Model 的 mean
然後每一個 mean 它有一個固定的 variance
然後再把這些 Gaussian 通通都疊在一起
就得到了一個 Gaussian Mixture Model
有了這個 Gaussian Mixture Model 以後，你就可以去計算這個 Gaussian Mixture Model
產生那些 real data 的機率
就可以估測出這個 generator 它產生出那些 real data 的 likelihood 是多少
要幾個 Gaussian 對不對
你的問題是，我們現在要做的事情是 我們先讓 generator 先生一大堆的 data
然後再用 Gaussian 去 fit generator 的 output
到底要幾個 Gaussian？32 個嗎？64 個嗎？ 還是一個點一個？
問題是你不知道，所以這就是一個難題
而且另外一個難題是你不知道 generator 應該要 sample 多少的點
才估的準它的 distribution
要 sample 600 個點還是 60,000 個點你不知道
所以這招在實作上也是有問題的
在文獻上你會看到有人做這招
結果就會出現一些怪怪的結果 怪怪的結果就是
舉例來說，你可能會發現你的 model 算出來的 likelihood 比 real data 還要大
你會算出很多奇奇怪怪的結果就對了
總之這個方法也是怪怪的，因為裡面問題太多了
你不知道要 sample 幾個點
然後你不知道要怎麼估測 Gaussian 的 Mixture 有太多的問題在裡面了
還有接下來還有更糟的問題
我們就算退一步講說你真的想出了一個方法
可以計算 likelihood
likelihood 本身也未必代表 generator 的 quality
為甚麼這麼說？因為有可能第一個 likelihood 確有高的 quality
舉例來說有一個 generator，它很厲害 它產生出來的圖都非常的清晰
所謂 likelihood 的意思是計算這個 generator 產生某張圖片的機率
也許這個 generator 雖然它產生的圖很清晰
但它產生出來都是涼宮春日的頭像而已
如果是其他人物的頭像，它從來不會生成
但是 testing data 就是其他人物的頭像
所以如果是用 likelihood 的話
likelihood 很小，因為它從來不會產生這些圖 所以 likelihood 很小
但是又不能說它做得不好
它其實做得很好，它產生的圖是 high quality 的 只是算出來 likelihood 很小
所以 likelihood 並不代表 quality 他們倆者是不等價
反過來說，高的 likelihood 也並不代表你產生的圖就一定很好，你有一個 model 它 likelihood 很高
它仍然有可能產生的圖很糟，怎麼說？
這邊舉一個例子
裡面有一個 generator 1，generator 1 很厲害
它的 likelihood 很大，假設我們不知道怎麼回事 somehow 想了一個方法可以估測 likelihood
雖然之前我們在前期的投影片已經告訴你 估測 likelihood 也是很麻煩，不知道怎麼做
現在 somehow 想了一個方法可以估測 likelihood
現在有個很強的 generator
它的 likelihood 是大 L
它產生這些圖片的機率很高
現在有另外一個 generator generator 2 它有 99% 的機率產生 random noise
它有 1% 的機率，它做的事情跟 generator 1 一樣
如果我們今天計算 generator 2 的 likelihood
generator 2 它產生每一張圖片的機率是 generator 1 的 1/100
假設 generator 1 產生某張圖片 xi 的機率是 PG( xi )
generator 2 產生那張圖片的機率 就是 PG( xi ) * 100
因為 generator 有兩個 mode 它有 99% 的機率會整個壞掉
但它有 1% 的機率會跟 generator 1 一樣
所以 generator 1 產生某張圖片的機率如果是 PG
那 generator 產生某張圖片的機率就是 PG / 100
現在問題來了，假設把這個 likelihood 每一項都除以 100
你會發現你算出來的值，也差不了多少 因為除一百這項把它提出來
就是 - log( 100 )，- log ( 100 ) 才減 4.65 而已
可以說那個 likelihood，如果看文獻 likelihood 算出來都幾百，差了 4 你可能會覺得沒什麼差別
但是如果看實際上的 generator 2 跟 generator 1 比的話
generator 1 你會覺得它應該是比 generator 2 好一百倍的
只是你看不出來而已
數字上看不出來
所以 likelihood 跟 generator 真正的能力其實也未必是有關係的
今天這個文獻上你常常看到一種 Evaluation 的方法
常常看到一種客觀的 Evaluation 的方法
是拿一個已經 train 好的 classifier 來評價現在 產生出來的 object
假設要產生出來的 object 是影像的話
你就拿一個影像的 classifier 來判斷這個 object 的好壞
就好像在作業裡面，我們是拿一個人臉的辨識系統
來看你產生的圖片，這個人臉辨識系統能不能夠辨識的出來
如果可以就代表你產生出來的是還可以的
如果不行就代表你產生出來的真的很弱
今天這個道理是一樣的
假設你要分辨機器產生出來的一張影像好還是不好
你就拿一個 Image Classifier 出來
這 Image Classifier 通常是已經事先 train 好的
舉例來說它是個 VGG，它是個 Inception Net
把這個 Image Classifier 丟一張機器產生出來的 image 給他
它會產生一個 class 的 distribution
它是個已經 train 好的 Image Classifier
給他一張圖，它會產生一個 class 的 distribution
它給每一個 class 一個機率
如果產生出來的機率越集中
代表產生出來的圖片的品質越高
因為這個 classifier 它可以輕易的判斷 現在這個圖片它是什麼樣的東西
它是個狗，還是貓，還是人 它可以輕易的判斷出這張圖片是什麼樣的東西
所以它給某一個 class 機率特別高
代表產生出來的圖片是這個 model 看得懂的
但這個只是一個衡量的方向而已
你同時還要衡量另外一件事情
因為我們知道在 train GAN 會遇到一個問題就是
mode collapse 的問題
你的機器可能可以產生某張很清晰的圖
但他就只能夠產生那張圖而已
這個不是我們要的
所以在 evaluate GAN 的時候還要從另外一個方向 還要從 diverse 的方向去衡量它
甚麼叫從 diverse 的方向去衡量它呢？
你讓你的機器產生一把
這邊舉例的時候就產生三張
把這三張圖通通丟到 CNN 裡面 讓它產生三個 distribution
接下來把這三個 distribution 平均起來
如果平均後的 distribution 很 uniform 的話
這個 distribution 平均完以後
它仍然很平均的話
那就意味著每一種不同的 class 都有被產生到
代表產生出來的 output 是比較 diverse
如果平均完發現某一個 class 分數特別高
就代表它的 output
你的 model 傾向於產生某個 class 的東西
就代表它產生出來的 output 不夠 diverse
所以我們可以從兩個不同的面向
用某一個 image train 好的，事先 train 好的 Image Classifier 來衡量 image
可以只給他一張圖
然後看產生出來的圖清不清楚
接下來給他一把圖，看看是不是各種不同的 class 都有產生到
有了這些原則以後
就可以定出一個 Score，現在一個常用的 Score
叫做 Inception Score，那至於為甚麼叫做 Inception Score，當然是因為他用 Inception Net 去 evaluate
所以叫做 Inception Score
我們之前有講怎樣的 generator 叫做好
好的 generator 它產生的單一的圖片
丟到 Inception Net 裡面
某一個 class 的分數越大越好
它是非常的 sharp
把所有的 output 都掉到 classifier 裡面
產生一堆 distribution，把所有 distribution 做平均
它是越平滑越好
根據這兩者就定一個 Inception Score 把這兩件事考慮進去
在 Inception Score 裡面第一項要考慮的是 summation over 所有產生出來的 x
每一個 x 丟到 classifier 去算它的 distribution
然後就計算 Negative entropy
Negative entropy 就是拿來衡量這個 distribution 夠不夠 sharp
如果越 sharp 的話，每一張 image 它 output 的 distribution 越 sharp 的話
就代表產生的圖越好
同時要衡量另外一項
另外一項就是把所有的 distribution 平均起來
如果平均的結果它的 entropy 越大也代表越好
同時衡量這兩項，把這兩項加起來
就是 Inception Score
其實還有其他衡量的方法，一個客觀的方法就是拿一個現成的 model 來衡量的你的 generator
這間介紹 Inception Score 給大家參考
還有另外一個 train GAN 要注意的問題
有時候就算 train 出來的結果非常的清晰
也並不代表你的結果是好的，為甚麼？
因為有可能 generator 只是硬記了 training data 裡面的 某幾張 image 而已
這不是我們要的，因為假設 generator 要硬記 image 的話，那直接從 database sample 一張圖不是更好嗎？
幹嘛還要 train 一個 generator
所以我們希望 generator 它是有創造力的
它產生出來的東西不要是 database 裡面本來就已經現成的東西
但是怎麼知道現在 GAN 產生出來的東西
是不是 database 已經現存的東西呢？
這是另外一個 issue，因為沒有辦法把 database 裡面每張圖片都一個一個去看過
database 裡面圖片有上萬張 根本沒辦法一張一張看過
所以根本不知道 generator 產生出來的東西是不是 database 裡面的
就 GAN 產生一張圖片的時候
就把這張圖片拿去跟 database 裡面每張圖片都算 L1 或 L2 的相似度
但光算 L1 或 L2 的相似度是不夠的，為甚麼？
以下是文獻上舉的一個例子
這個例子是想要告訴大家
光算相似度，尤其是只算那種 pixel level 的相似度
是非常不夠的，為甚麼這麼說？
這個例子是這樣
假設有一隻羊的圖
這個羊的圖跟誰最像，當然是跟自己最像，跟 database 裡面一模一樣的那張圖最像
這個圖上面有很多很多的線
這些線代表甚麼
就把 0 這邊每一個點就代表 database 裡面某一張圖片跟現在羊這張圖片的相似的程度
黑色這條線代表的是羊這張圖片
羊這張圖片跟自己的距離當然是 0
跟其他圖片的距離是比較大的
這邊每一條橫線就代表一張圖片
把羊那張圖的 pixel 都往左邊移一格 還是跟自己最像
但是如果往左邊移兩格，會發現最像的圖片 就變成紅色這張
移三格就變綠色這張
移四格就變這個看起來也不知道甚麼，魚還是海豚
這個羊跟這個圖片最像
假設 generator 學到怪怪的東西就是 把所有的 pixel 都往左移兩格
這個時候就算它 copy 了 database 你也看不出來
因為檢測的方法檢測不出這個 case
這邊也是一樣，把卡車的圖片往左移一個 pixel 跟自己最像
往左移兩個就變跟他最像
移三個 pixel 就變跟飛機最像
移四個 pixel 就變跟船最像
很難算兩張圖片的相似度
所以 GAN 產生一個圖片的時候，你很難知道他是不是 copy 了 database 裡面的 specific 的某一張圖片
這個也都是尚待解決的問題
所以有時候 GAN 產生出來結果很好
也不用太得意，因為它搞不好只是 copy 某一張圖片而已
這邊是另外一個 issue
在 train GAN 的時候會有一個問題叫做 Mode Dropping
假設 GAN 產生出來的是人臉的話
它產生人臉的多樣性不夠
怎麼檢測它產生出來的東西他的多樣性夠不夠
假設 train 了一個 DCGAN DCGAN 是甚麼
DCGAN 是 Deep Convolutional GAN 的縮寫
他的 training 的方法跟 Ian Goodfellow 一開始提出來 的方法是一樣的
只是在 DCGAN 裡面那個作者爆搜了各種不同的參數
然後告訴你怎麼樣 train GAN 的時候結果會比較好
有不同 network 的架構 不同的 Activation Function
有沒有加 batch，各種方法都爆搜一遍 然後告訴你怎麼樣做比較好
DCGAN 就是某一種 GAN Deep Convolutional GAN
怎麼知道 DCGAN，train 一個產生人臉的 DCGAN 它產生的人臉的多樣性是夠的呢？
一個檢測方法是從 DCGAN 裡面 sample 一堆 image
叫 DCGAN 產生一堆 image
然後確認產生出來的 image 裡面有沒有非常像的 有沒有人會覺得是同一個人
怎麼知道是不是同一個人
這個結果是來自於 ICLR 2018 的一篇 paper
他叫 "Do GANs learn the distribution?" 它裡面的作法是讓機器產生一堆的圖片
接下來先用 classifier 決定有沒有兩張圖片看起來很像
再把長的很像的圖片拿給人看
問人說：你覺得這兩個是不是同一個人
如果是，就代表 DCGAN 產生重複的圖了
雖然產生圖片每張都略有不同
但人可以看出這個看起來算不算是同一個人
這邊列出一些被人判斷是感覺是同一個人的圖片
DCGAN 會產生很像的圖片
右邊這個虛線裡面是把這個圖片拿去 database 裡面找一張最像的圖
會發像最像的圖跟這個圖沒有完全一樣
代表 DCGAN 沒有真的硬背了 training data 裡面的圖
但是不知道為甚麼他會產生很像的圖
他會產生很像的圖，但這個圖並不是從 database 裡面背出來的
他要衡量 DCGAN 到底可以產生多少不一樣的 image
他發現如果 sample 四百張 image 的時候
有大於 50% 的機率，可以從四百張 image 裡面 找到兩張人覺得是一樣的人臉
藉由這個機率就可以反推到底整個 database 裡面 整個 DCGAN 可以產生的人臉裡面
有多少不同的人臉
詳細反推的細節，你再 check 一下 paper
這個推法回去自己想一下，這個國中數學而已
有一個 database 有面有 M 張 image
M 到底應該多大才會讓你 sample 四百張 image 的時候 有大於 50% 的機率 sample 到重複的
這個問題就這樣，就反推這個 database 裡面到底有幾張 image
反推出 DCGAN 他可以產生各種不同的 image 其實只有 0.16 個 million 而已
只有十六萬張圖而已，覺得其實太少
有另外一個作法叫做 ALI，他就算出來 ALI 比較強
反推出來可以產生一百萬張各種不同的人臉
ALI 看起來可以產生的人臉多樣性是比較多的
但是不論是哪些方法都覺得他們產生的人臉的多樣性
跟真實的人臉比起來
還是有一定程度的差距
感覺 GAN 沒有辦法真的產生人臉的 distribution 這些都是尚待研究的問題
我們知道 GAN 他的一個 issue 就是它產生出來的 distribution 不夠大
它產生出來的 distribution 太 narrow
有一些 solution，比如說有一個方法，現在比較少人用
因為它 implement 起來很複雜，運算量很大，叫做 Unroll GAN
我們沒有打算講他，沒有打算講他為甚麼要放在這邊 等一下你就知道
有另外一個方法叫做 Mini-batch Discrimination
他的方法是這個樣子，我們簡單講一下就好
一般在 train discriminator 的時候 discriminator 只看一張 image
決定他是好的還是不好
Mini-batch Discriminator 是讓 discriminator 看一把 image
決定他是好的還是不好
看一把 image 跟看一張 image 有甚麼不同
看一把 image 的時候不只要 check 每一張 image 是不是好的
還要 check 這些 image 他們看起來像不像
discriminator 會從 database 裡面 sample 一把 image 出來
會讓 generator sample 一把 image 出來
如果 generator 每次 sample 都是一樣的 image
發生 **** 的情形，discriminator 就會抓到這件事
因為在 training data 裡面每張圖都差很多
如果 generator 產生出來的圖都很像
discriminator 因為它不是只看一張圖
它是看一把圖
他就會抓到這把圖看起來不像是 realistic
大家可以了解嗎 改了一下 discriminator 讓他看一把圖
還有另外一個也是看一把圖的方法
叫做 OTGAN Optimal Transport GAN
他的圖是彩色的畫得不錯就放在這裡
GAN 的東西就講到這裡
下課之前會 GAN 的部份下一個結論
這個是 GAN 的 from A to Z，from A to Z 是甚麼意思 google 一下這個英文片語
A to Z 的意思就是從頭到尾
但是這邊的 A to Z 就是字面上的意思
就是 A to Z
世界上有各式各樣的 GAN
當你發明一種新的 GAN 的時候
你就可以在前面加一個英文字母
你可以跟朋友玩一個遊戲 就是誰可以說出最多的 GAN
我今天早上查了一下 GAN 的 zoo
現在其實已經有超過 在課堂開始的時候有三百種不同的 GAN
剛才查了一下已經有 360 種不同的 GAN
數目是不斷的在增加的
今天就來複習一下在這門課裡面
提過的 GAN，然後從 A 開始講起
A 開頭的 GAN 有甚麼
你想的到 A 開頭的 GAN 嗎
這是一個你可以回去跟朋友玩的遊戲 雖然我覺得沒有人要跟你這個遊戲就是了
A 的 GAN 有甚麼？有 ACGAN
助教在講 3-2 的時候 Conditional Generation 有講到 ACGAN
B 有甚麼？
BiGAN，其實也有 BGAN，BGAN 還有兩個
現在所有的名字都已經混在一起了
你去看 GAN 的 zoo，光 SGAN 就有四個
SGAN 已經搞不清楚他到底是甚麼東西了
現在非常的混亂
C 有甚麼？C 有 CycleGAN
Conditional GAN，我忘了放 Conditional GAN
D 有甚麼
DCGAN，還有 DuelGAN DuelGAN 其實跟 CycleGAN 是一模一樣的東西
還有 dragon，你看一下他的名字還頗牽強 可能是想要先湊梗才想方法
他的 title 是 How To Train Your Dragon 他後來真的投到 ICLR 的時候，他又把他的 title 改掉了
E 有甚麼？E 有 EBGAN
EBGAN 還有一個變形沒有講到，叫做 BEGAN
就把 EB 反過來就變 BEGAN
F 有甚麼？F 就是 fGAN
G 有甚麼？就是 GAN
H 有甚麼？HGAN
我覺得 H 應該還滿好湊的不知道為甚麼沒有 H
等著你 propose
等著你湊梗
我覺得 H 應該滿好湊的，因為 **** 有 Hierarchical GAN
他縮寫就是 HGAN，就等著你來 propose 而已
I 有甚麼？InfoGAN
J 有甚麼？J 還真的沒有
K 有甚麼
K 還真的沒有
你查 GAN 的 zoo 有，有一些太 specific 所以就沒有講
有 KGAN、KEGAN，當然太 specific 就沒有講
L 有甚麼？有兩個 LSGAN
M 有甚麼？你想得出來嗎
有 MMGAN，MMGAN 就是一開始有講 在講 GAN 的 theory 我們說
有一個叫做 Min Max GAN
還有一個 N 開頭的就是 Non Saturation GAN
Ian Goodfellow 有說，大家在 paper 都會說 original GAN
我們跟 original GAN 比
不好好講那個 original GAN 到底指的是 MMGAN 還是 NSGAN
所以他特別幫他們取了名字 告訴我們以後最早的 GAN 叫做 MMGAN
實際上一開始 MMGAN Ian Goodfellow train 不起來 所以他用的是 NSGAN
O 有甚麼
O 就是 OTGAN，他為了硬湊梗才放了 OTGAN
P 有甚麼
是不是沒講到 Progressive GAN
沒講到 Progressive GAN
所以現在講一下 Progressive GAN 是甚麼
我們不是講過 **** GAN，可以小張的 image 產生大張的 image
Progressive GAN 是 NVIDIA 做的，他的概念完全一樣
就從小張的 image 一直生、一直生，生到大張的 他從 4x4 生到 8x8 到 16x16
最後生到 1024x1024
超大張的 image，連毛細孔都看的到的那種
非常的 realistic
Q 有甚麼
Q 還真的沒有，我覺得 Q 還滿好湊的
你把用在 Reinforcement Learning 上就可以產生 Q-learning base GAN 之類的
等著你 propose
R 有甚麼
R 有 Rank GAN 就是在講 Sequence Generation 意思是提了一個 Rank GAN 就只是想要湊梗而已
S 有甚麼
S 有 SeqGAN，他有很多，有 StackGAN 有 StarGAN 還有 SeqGAN
StarGAN 就是在講 Style Transfer 的時候有講到 StarGAN
T 有甚麼
在講 BiGAN 的時候，我順便提還有一個 Triple GAN
這也是為了硬湊梗而已
U 有甚麼
Unroll GAN，為了硬湊梗，應放了一個 Unroll GAN
V 有甚麼？V 有 VAEGAN
W 大家都知道我們有 WGAN
X 有出現在某個地方
有一個 XGAN
在講 Style Transfer 的時候那兩個 encoder 兩個 decoder 那個東西，他就是 XGAN
Y 還真的沒有
Z 其實也沒有
我覺得 Y 應該還滿容易湊梗的吧
Y 的詞彙很少，所以很難 propose 一個跟 Y 有關的 GAN
但是可以從形狀來想
XGAN 都是從形狀來想的所以 Y 一定可以從形狀來想的
這是一個 encoder 然後有兩個 decoder
就是一個 Y 甚麼之類的
怎麼會沒有我覺得這應該很好湊
今天要講的就是這個樣子，GAN 講得差不多了就下課
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
