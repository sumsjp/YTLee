好,來上課啦
好,那這個第一堂課啊
要告訴大家的就是
什麼是生成式人工智慧
那在講生成式人工智慧之前
也許我們需要先知道
什麼是人工智慧
Artificial Intelligence
AI
人工智慧從它的名字來看
聽起來就是人所創造出來的智慧
是機器所展現的智慧
不是人本身的智慧
從他的名字你可以知道他是機器的智慧
但是智慧又是什麼呢
當我們說人工智慧就是讓機器展現智慧的時候
我們只是從字面上去解釋
但是什麼又是智慧呢
講到這邊就已經卡住了
因為每個人心裡所想的智慧
通通都是不一樣的
我常常會接到有人請我講
我講跟AI相關議題的演講
那最近呢我通常是講ChatGPT
那大家也都蠻能接受說
這個ChatGPT就是一種人工智慧
但是我也有聽過有人抱持不一樣的想法
他說你講ChatGPT那個不叫做人工智慧
要一個機器人跑來跑去才算是人工智慧
或ChatGPT不是人工智慧
電腦要會選土豆才是人工智慧
所以每個人對於什麼叫做智慧
其實是有非常不一樣的想像的
所以人工智慧這個詞
它沒有一個標準的定義
每個人心裡所想的人工智慧
都是不一樣的
所以如果你讀人工智慧相關的論文
你會發現人工智慧相關的論文裡面
幾乎不會提人工智慧這個詞
因為它是一個沒有清楚定義的詞彙
但是不管你怎麼定義智慧這個詞彙
人工智慧可以說是一個目標
是一個我們想要達到的目標
它不是一個單一的技術
並沒有哪一個技術叫做人工智慧
人工智慧是一個目標
那什麼又是生成式人工智慧呢
通常翻譯成Generating AI
生成式人工智慧的定義就比較明確了
生成式人工智慧是要機器產生
複雜而有結構的物件
舉例來說
什麼東西是複雜而有結構的呢
比如說文章,文章也有一連串的文字所構成的
比如說影像,影像是由一堆像素所組成的
比如說語音,語音是由一堆取樣點所組成的
那如果你不知道取樣點是什麼也沒有關係
這個我們日後講語音的生成式AI的時候
再跟大家詳細說明
但是所謂的複雜有結構又是什麼意思呢
這個複雜到底應該要複雜到什麼程度呢
要複雜到沒有辦法窮舉
沒有辦法窮舉到底是什麼意思呢
我們來想像一個情境
今天你在ChatGPT上跟他說
用一百個字寫一篇中文的文章
標題是縫隙的聯想
那縫隙的聯想是今年學測（口誤）的作文題目啦
那ChatGPT當然可以寫一篇文章給你
但你有沒有想像過
當人工智慧寫一篇文章給你的時候
背後到底是做了什麼樣的事情
到底是解了一個多困難的問題
寫一篇文章到底有多困難呢
想想看假設你要寫一篇100字的文章
到底有多少種可能性
你要把各種不同各式各樣的中文的字
組起來組成100字的文章
到底有幾種可能呢
這個都是一個我們高中學過的排列組合的問題
我們假設中文常用的字是一千
當然中文實際上常用字是遠超過一千啦
為了計算方便就假設是一千
那一百字的文章有多少可能性呢
就是把一千連成一百次
一千連成一百次是多少
是一千的一百次方
也就是十的三百次方
十的三百次方是一個很大的數目嗎
它是一個大到不可思議的數目
宇宙中原子的數目估計只有10的80次方而已
所以今天當機器要寫一個100字的文章的時候
它的可能性有10的300次方那麼多
而機器要從10的300次方裡面
挑出一個合理的答案
作為它給你的答覆
所以這顯然是一個非常困難的問題
當機器解這個深層式AI的問題的時候
它是要從近乎無窮的可能中
找出一個適當的組合
那也許我們可以反過來說
什麼樣的問題
不是生成式AI的問題
這樣可以讓你更瞭解什麼是生成式AI
這邊舉一個例子
分類它的英文是classification
它就不是生成式AI的問題
分類這個問題裡面
是要讓機器從有限的選項中去做選擇
你已經告訴機器說有哪幾個選項是可以選的
當機器從有限的選項中做一個選擇的時候
這不是一個生成式AI的問題
有什麼樣的問題可以歸類為分類的問題呢
舉例來說
Gmail有這個垃圾郵件偵測的功能
有時候他如果偵測到一封信是垃圾郵件
會自動放到垃圾郵件夾裡面
Gmail在做垃圾郵件偵測的時候只有兩個選項
給他一封信
他只有兩個可能的答覆
是垃圾郵件或不是垃圾郵件
這種選項有限的情況下
就不是生成式AI
或你做一個影像辨識系統
這個影像辨識系統只能夠
分類一張圖片裡面
有貓還是有狗
它只會說有貓或有狗
只有兩個可能的答案
從有限的選項中做選擇
這不是生成式人工智慧
所以從有限的選項中做選擇這種問題
今天叫做分類
它不是深層式人工智慧的一種
所以我們已經知道說深層式人工智慧是什麼
它是一個目標
要機器產生複雜而有結構的物件
所以深層式人工智慧是人工智慧的一種
人工智慧是一個虛無縹緲的目標
每個人的想像都不太一樣
而深層式人工智慧
是人工智慧眾多可能的目標之一
讓機器可以產生複雜有結構的物件
比如說文字比如說圖片
比如說一段聲音
那在繼續深入探討深層次人工智慧之前
我們來介紹另外一個
跟人工智慧常常一起被提到的概念
叫做機器學習
他的英文是Machine Learning
什麼是機器學習呢
機器學習講起來就很明確了
機器學習是讓機器可以自動從資料裡面
找出一個函式
如果你覺得這句話講起來很抽象的話
那我直接舉一個具體的例子告訴你
什麼叫從資料裡面找一個函式
以下這個問題是你在國中的時候一定做過的問題
你在國中的數學課本裡面是不是有這樣的問題
我給你一個函式
這個函式的輸出叫做 y
輸入叫做 x
這個函式我們用 f of x 來表示它
這個函式裡面長什麼樣子呢
當 x 輸進去的時候
它會先乘上 a 再加上 b
這個函式寫成AX加B
那接下來題目裡面就往往有這樣的敘述
假設輸入等於4的時候
X等於4的時候
輸出Y等於5
假設輸入X等於2的時候
輸出Y等於-1
問你AB應該多少
然後呢
你就經過一番運算
你忘了怎麼運算也沒有關係
反正解出來
A等於3
B等於-7
那A跟B這兩個未知數
在機器學習的領域裡面
我們又叫做參數
它的英文是parameter
所以如果我今天提到參數的時候
我指的就是我們要找出來的那個未知數
那有了這個 3 跟負 7 以後
你就可以代入新的 x 算出 y 是什麼
有一個新的 x 等於 1
你就把 1 乘以 3 減 7 得到負 4
你就知道輸入 x 等於 1 的時候
y 輸出應該是負 4
這整個問題都非常的簡單
這你國中的時候一定已經學過
那機器學習跟你國中的時候解的這個問題
有什麼不一樣的地方呢
他唯一的不同是國中的時候
你是用人力去算出這個參數
而機器學習是一系列的方法
自動的把參數算出來
把題目給好以後
參數就可以自動被算出來
但為什麼我們不用人力解
要讓機器自動找參數呢
因為我們真正要面對的問題
往往比我們國中的時候學過的
f of x 等於 ax 加 b 還要複雜的多
假設我們今天要叫機器學會分辨
一張圖片裡面是有貓還是狗
那你需要的可能是這樣一個函式
這個函式叫做 f of 圖片
這個函式的輸入是一張圖片
那至於函式怎麼把一個圖片作為輸入
那這個我們日後再講
今天就想像有一個函式叫做F
它的輸入是一張圖片
它的輸出只有兩個可能
貓跟狗
那如果你可以找到這個函式
你就可以拿它來辨識一張圖片
是貓還是狗
那這樣子的函式顯然非常的複雜
如果我說這個函式只等於ax加b
它顯然不可能可以辨識貓跟狗
它非常的複雜
裡面可能需要有上萬個參數
那我這邊用abcd來表示參數啦
不過用abcd英文字母作為符號來表示參數
顯然是不夠的
我們這邊可能這個式子裡面
會有上萬個參數
所以一個有上萬個參數的式子
到底長什麼樣子呢
你可能這輩子從來沒有看過一個
有上萬個參數的數學式
它到底應該長什麼樣呢
等一下會再告訴你
你現在就心裡想像有一個上萬個參數的式子
那這個有上萬個未知參數的函式又叫做模型
那我知道說模型這個詞彙其實在不同的文獻上
往往有不同的稱呼
就算是指在機器學習的領域裡面
往往不同人提到模型的時候
他指的是不一樣的東西
但在這門課裡面
當我講模型的時候
我指的是一個帶有大量未知參數的函式
好那接下來呢就要給你這個題目的敘述啦
這個題目的敘述是
如果這個函式的輸入是這隻白色的貓的話
輸出就要是貓這個答案
輸入是棕色的狗輸出就是狗
輸入是這個超人貓輸出就要是貓
輸入是這個黑色的狗輸出就要是狗
有了這些輸入跟輸出的關係以後
接下來機器學習這個技術就可以幫助你
把上萬個參數給他找出來
這裡有上萬個參數
人類都沒有辦法想像
這個函式應該長什麼樣子
但是機器學習這個技術
可以幫助你在給定這些輸入輸出的條件
限制的情況下
把這上萬個參數找出來
你說這個機器學習的學習到底在哪裡
這個學習指的就是把這個上萬個參數
找出來的過程
這個把上萬個參數找出來的過程
又叫做細訓練
training
或者是又叫學習
learning
所以我們講機器學習的時候
所謂的機器學習指的就是
把這個上萬個參數找出來的過程
好 那這個幫助你找出上萬個參數的輸入輸出的限制
就叫做訓練資料
那找出這上萬個參數以後
你就可以把這些參數
帶入剛才的模型裡面
你就知道這個函式長什麼樣子
有一張新的圖片進來
正在打電腦的貓
期待機器就可以給出正確的輸出
那找出參數以後
給這個函式一個新的圖片
看看它會輸出什麼
這件事情叫做測試
Testing
或又叫做推論Inference
這邊就跟大家講完了
機器學習的基本概念
有上萬個未知數的這個函式
你非常難想像它是什麼
而今天在機器學習的領域
通常怎麼表示這個有上萬個參數的暗示呢
今天往往它被表示成一個
類神經網路
也就是 Neuronetwork
那有人可能會想說類神經網路
聽起來就跟人類的大腦好像很有關係
類神經網路不是應該是什麼
哎呀 模仿人類的大腦學習的嗎
我告訴你這個講法就是騙你的
你知道嗎
這農場文隨隨便便講出來騙麻瓜的
其實一個類神經網路
就是一個有非常大量參數的函式
當你今天把你的這個有大量參數的函式
表示成一個類神經網路
然後把這些參數解出來
這個技術就叫做深度學習
deep learning
所以深度學習是機器學習的一種
你當然有其他方法來描述這個函式
但是當你用類神經網路來描述它的時候
你做的事情就是深度學習
那這頁投影片講的是機器學習跟深層次人工智慧的關係
機器學習它是一種手段
所以它跟生成式人工智慧的關係我是畫成這樣的
它們有交集的部分但也有各自獨立的部分
生成式人工智慧你當然可以用機器學習來解
但你也可以用非機器學習的方法來解
機器學習不是隻能解生成式人工智慧
也可以解其他的問題
比如說分類的問題
而深度學習是機器學習的一種
那我相信你在網路上更常看到的
生成式人工智慧、深度學習、機器學習的關係
是畫成這個樣子
那你把生成式人工智慧放在機器學習裡面
我也勉強能夠接受
因為今天深層次人工智慧是一個非常困難的問題
也許其他手段都不足以達成讓你滿意的結果
所以今天生成式人工智慧
通常都是以深度學習技術來達成的
所以如果你看網路的文章
在描述機器學習、深度學習、深層次人工智慧關係的時候
往往會說生成式人工智慧是深度學習的一種
這我也可以接受
雖然他們所要講的是不一樣的東西
深度學習是一個技術
生成式人工智慧是一個目標
但是今天通常會用機器學習的
都通常會用深度學習的技術
來達成生成式人工智慧
所以我也可以接受
你把生成式人工智慧放在深度學習裡面
好那到底深度學習
機器學習要來怎麼解
深層次人工智慧的問題呢
想一想
ChatGPT按照機器學習深度學習的概念
他可能是怎麼被打造出來的
其實ChatGPT也可以想像成是一個函式
這個函式的輸入就是一段文字
輸出就是ChatGPT給你的回覆
但像ChatGPT這麼厲害的人工智慧
你問什麼他都能夠有問必答
他顯然背後的函式非常非常的複雜
複雜到什麼地步呢
複雜到他裡面可能有上億個或數十億個參數
他的模型裡面可能有上億個參數
那這個有上億個參數的模型
也就是類神經網路
今天有一個特別的名字叫做Transformer
ChatGPT背後用的模型叫做Transformer
它是類神經網路的一種
那我們在往後的課程會再跟大家介紹
那就機器學習的概念而言
要打造ChatGPT這樣子的人工智慧
要找出一個可以做像ChatGPT這樣事情的函式
也許你需要的就是準備一大堆的輸入跟輸出
告訴你的模型說 輸入人工智慧
輸出就要是這樣
輸入這樣 就要輸出這樣
也許準備一大堆輸入跟輸出的關係
讓機器學習或深度學習的技術
把上億個參數找出來
我們就可以打造出一個全區域體
或者是用同樣的概念
也可以打造一個可以畫圖的AI
今天有很多可以畫圖的AI
比如說 Stable Diffusion
比如說Midjourney 比如說DALL-E
這些可以畫圖的AI
你也可以把它想成是一個函式
這些函式的輸入是什麼
輸入就是一段文字
輸出是什麼
輸出就是一張圖片
而這個函式顯然也會非常的複雜
顯然也該有上億個參數
那怎麼把這個函式找出來呢
我們就需要告訴機器
輸入跟輸出之間的關係
現在是輸入文字輸出圖片
所以你就要告訴機器說
如果有人告訴你彩色的卡通貓
那你輸出應該長這樣
有人輸入奔跑的貓輸出應該長這樣
有人輸入海濱的黑狗應該長這樣等等等等
你收集一大堆文字跟他對應的圖片
然後就可以交由深度學習的技術
找出函式把上一個參數找出來
你就可以找出一個函式
就可以讓機器輸入一段文字
輸出一張圖片
那其實生成這件事啊
我在課堂上過去的機器學習課堂一直都是有提到的
這一頁投影片是來自五年前
2019年機器學習課堂的投影片
這一頁投影片是這樣講的
大家不知道有沒有看過獵人這個漫畫
獵人是這樣子的一個故事的
你以為的五大洲並不是世界的全部
這只是世界的一小部分
其實我們都是活在一個很大的湖裡面
湖外面才是真正的世界
叫暗黑大陸
裡面有各式各樣的神奇生物
而就機器學習的領域而言
分類這種從有限的答案中去得到一個選項的這種問題
就是你所熟知的世界
但是外面還有更困難更有挑戰性的技術
過去我說就是讓機器產生有結構的複雜東西
比如說文具圖片
它就是生存
那如果機器可以成功做到生成
我在2019年的時候就說
用擬人化的講法可以說他學會了創造
我在2019年的時候我會說暗黑大陸
離我們還很遙遠
就像庫拉皮卡
不知道什麼時候才會登陸暗黑大陸一樣
但現在已經是2024年了
庫拉皮卡離暗黑大陸還遙遙無期
但是我覺得現在
可以說是已經見到暗黑大陸的守門人了
那到底生成式AI的挑戰是什麼呢?
按照剛才的想法
我們只要收集夠多的資料
找出一個函式
就可以做生成式AI
但你再仔細想一想
我們的訓練資料
也許怎麼收集都是不夠的
今天對生成式AI而言
人類在測試的時候
可能會問任何的問題
機器的答案
需要跟訓練機器
需要得到的答案
可能跟訓練的時候完全不同
今天有人問叫你寫一篇跟縫隙的聯想有關的文章
今年指考的作文
這個要求過去可能在你的訓練資料裡面
一次都沒有出現過
因為如果出現過的話
那就洩體了嘛
所以這是一個全新的問題
在訓練資料裡面一次都沒有出現過
但如果你的模型要得到正確的答案
他顯然需要創造全新的文具
是訓練的時候一次都沒有出現過的文具
那到底機器要怎麼做到這件事呢?
如果機器可以做到在測試的時候
產生訓練的時候從來沒有出現過的文具
也許我們就可以說機器具有某種程度的創造力
當然我這邊是加了一個引號啦
也許有人並不認同
只要能夠產生訓練的時候沒有看過的文具
就算是有創造力
也許這樣的定義不是每個人都可以認同的
但我這邊創造力指的意思就是
機器可以產生它訓練的時候
一次都沒有看過的答案
那今天
像ChatGPT這樣子的人工智慧
是怎麼做到產生一次都從來沒有看過的答案的呢
這邊我先用一頁投影片跟大家說明
未來我們還會講得更仔細一點
那之所以需要先說明
是為了往後的課程
為了讓你能夠聽懂
能夠更瞭解課程的內容
我們還是需要用業圖影片
先跟你講一下
ChatGPT背後的原理
那ChatGPT背後的核心精神是什麼呢
他的核心精神可以用四個字來概括
就是文字接龍
原本我們在做生成式 AI 的時候
覺得是一個很難的問題
因為一段文句的可能性是無法窮盡的
但是在ChatGPT裡面
生成一個答案 被拆解成一連串的文字接龍的問題
本來你問機器臺灣最高的山是哪座
你今天的目標是要機器答出玉山這個答案
但實際上ChatGPT做的事情
並不是直接把完整的答案生出來
他做的事情是去做了一系列的文字接龍
先把臺灣最高的山是哪座
問號這個句子當做一個未完成的句子
他去預測說這個句子後面應該接哪一個字是合理的
比如說可能接玉是合理的
那產生一個合理的可以接在輸入後面的字以後
再把這個字貼到前面去
再做一次文字接龍
臺灣最高的山是哪座問號玉後面接哪個字是合理的呢
也許接山是合理的
那再把山貼到輸入去
現在的問題變成臺灣最高的山是哪座問號玉山
然後要機器輸出什麼呢
也許機器覺得已經沒有什麼好輸出了
這個就是句子的結束了
他就輸出結束這個符號
那整個生成的過程就結束了
機器也得到了玉山這個答案
這個能夠做文字接龍的模型有一個名字
就叫做語言模型
那我相信大家在報章雜誌上
最近一定常常聽到語言模型這個詞彙
其實他指的就是一個在做文字接攏的模型
那把本來要生成一個完整答案這件事情
改成一系列的文字接攏
有什麼樣的好處呢
本來我說生成式AI的難點就是可能的答案
是無窮無盡的
但我們再來想想文字接龍這個問題
文字接龍的答案是有限的
現在機器要解的問題
是一系列同樣的文字接龍的問題
而文字在做文字接龍的時候機器要做的
就是猜出下一個字可以接什麼
那如果中文的常用字可能就是三四千個
是有限的
所以這個時候本來生成是A的問題
把它變成文字接容以後
它就變成了一系列的分類的問題
機器回到從有限的選項中選出答案的問題了
而從有限的選項選出答案
是我們人類一直都知道怎麼做的事情
所以本來很困難的生成一整段文章的這些問題
就變成文字接龍的問題
一系列分類的問題
而變得可以解了
但至於實際上到底是怎麼解的
才變成像今天這麼厲害的Chativity
那這個就是往後課程的內容了
好 但是語言模型
並不是生成是人工智慧的全部
他只是生成是人工智慧的其中一個技術而已
事實上生成並不一定要用文字接龍的方式
生成可以有不同的策略
在我們剛才的敘述裡面
我們說怎麼生一篇文章
因為文章是用文字構成的
所以生一篇文章這個任務
可以看作是生成一個序列的文字
那其實同樣的概念
好像也可以拿來生成其他東西
例如說生成圖片
我們知道圖片是由像素所構成的
所以既然文字接龍可以解生成文章的問題
像素接龍也有機會可以解生成圖片的問題
這種把複雜的物件拆解成較小的單位
再按照某種固定的順序
把這些較小的單位生成出來的這種策略
今天有一個名字叫做autoregressive generation
那像ChatGPT就是採用了Auto Regressive的Generation
至於還有什麼其他的策略
我們日後都會再講到
那從這個投影片上看起來生成圖片
也可以跟ChatGPT一樣
用像素接龍的方式來生圖片
有沒有人這樣嘗試過呢
有 其實OpenAI在很多年前
就打造了影像版的GPT
用像素接龍的方式來產生圖片
但這個方法後來並沒有紅起來
為什麼沒有紅起來
這個是往後我們在講到生成策略的時候
再會跟大家說明的
那生成式人工智慧不是今天才有的
它一直都有人在研究
其實在2015年
我剛開的第一堂機器學習的課程
並不叫機器學習
它叫機器學習及其深層與結構化
那我打算要強調兩個重要的技術
一個是深層學習
你可能問深層學習是什麼
跟深度學習有什麼關係
它就是深度學習
那個時候呢
Deep Learning還沒有統一的中文翻譯
所以我是翻成深層學習
我覺得深層學習比較符合
Deep Learning實際上做的事情
不過後來大家都翻成深度學習就是了
那什麼是結構化呢
結構化學習就是今天的深層式AI
因為深層式AI就是要深層有結構的東西
所以過去我們叫做結構化學習
不過今天我們叫做深層式學習
好 那過去2015年講的結構化學習
跟今天的生成式AI它背後的技術
有什麼一樣的地方呢
你可以看看過去的課程
結論就是沒什麼一樣的地方
這個技術變化真的非常的快
短短不到十年的時間
技術已有了翻天覆地的變化
但是生成式AI這個概念
其實不是今天才有的
因為生成式AI的概念其實不是今天才有
生成式AI相關的應用
早就充斥在你的日常生活中
舉例來說
Google翻譯
大家知道Google翻譯是什麼時候上線的嗎
是2006年就上線了
非常早就已經有Google翻譯了
而翻譯這件事情本來就是生成式AI的其中一個應用
因為機器需要產生一段文字
這本來就是一種生成式AI
而且翻譯的時候
人可能會的可能的輸入
你可能要翻譯的文句是千變萬化的
不管輸入什麼樣的文句
都要得出一個合理的對應的翻譯
而這個正確的對應的翻譯
可能在訓練資料裡面一次都沒有出現過
所以翻譯本來就是一個生成式AI的問題
所以生成式AI不是只有今天才有
但是為什麼今天
今日生成式AI突然爆紅起來了呢
到底是發生了什麼事
這個是我們下一個階段的課程
會再幫大家剖析的
好那我知道說
我看一下我們的時間
也許已經不太夠我講完下一段課程
我準備等一下時間就來回答
slido上面的問題
然後因為今天沒講到什麼
有技術含量的東西,你一定覺得
哎呀,今天就聽那個故事
沒聽到什麼技術含量的東西
好吧,如果你要聽有技術含量的東西
不然你先來找一下我那個
課程的,我個人的那個
Youtube頻道,你在那個Youtube上
搜尋我的名字,就可以找到
我的Youtube頻道,那裡面的第一部影片
80分鐘講大型人模型
你可以先看一下那一部
瞭解GPT是
怎麼被打造出來的
等於是一個預期,未來我們還會
講更多這方面的知識
