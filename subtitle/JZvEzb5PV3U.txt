好 那我們接下來啊
除了 Aauto-Encoder
可以用來做當 strime 的任務以外
我還想跟大家分享一下
Aauto-Encoder 其他有意思的應用
那我跟大家講這個 Feature 的 Disentanglement
好 Feature 的 Disentanglement 是什麼意思呢
什麼是 Disentangle 呢
Disentangle 的意思就是
把一堆本來糾纏在一起的東西把它解開
這個東西呢
就叫做 Disentangle
那為什麼會有 Disentangle 這個議題呢
我們來想想看
Aauto-Encoder 它在做的事情是什麼
Aauto-Encoder 在做的事情是
如果是圖片的話
就是把一張圖片變成一個 Code
再把 Code 呢 變回圖片
既然這個 Code 可以變回圖片
代表說這個 Code 裡面啊
有很多的資訊
包含圖片裡面所有的資訊
舉例來說
圖片裡面有什麼樣的東西啊
圖片的色澤紋理啊等等
Aauto-Encoder 這個概念也不是只能用在影像上
如果用在語音上
你可以把一段聲音丟到 Encoder 裡面
變成向量 再丟回 Decoder
變回原來的聲音
代表這個向量包含了
語音裡面所有重要的資訊
包括這句話的內容是什麼
就是 Encoder 的資訊
還有這句話是誰說的
就是 Speaker 語者的資訊
那如果今天是一篇文章
丟到 Encoder 裡面變成向量
這個向量通過 Decoder 會變回原來的文章
那這個向量裡面有什麼
它可能包含文章裡面
文句的句法的資訊
也包含了語意的資訊
但是這些資訊是全部糾纏在一個向量裡面
我們並不知道一個向量的哪些維
代表了哪些資訊
舉例來說
如果我們今天把一段聲音訊號丟進 Encoder
它會給我們一個向量
但是這個向量裡面
哪些維度代表了這句話的內容
哪些維度代表這句話的語者
也就是誰說的
我們沒有這樣的資訊
而 Feature Disentangle 想要做到的事情就是
我們有沒有可能想辦法
在 Train 一個 Aauto-Encoder 的時候
同時有辦法知道
這個 Representation
或又叫做 Embedding
或又叫做 Code
它們是一樣的東西
我們這個 Embedding 的哪些維度
代表了哪些資訊呢
我們有沒有可能做到說 Encoder 輸出一個
舉例來說 100 維的向量
我們知道說前 50 維就代表了這句話的內容
後 50 維就代表了這句話
說話人的特徵呢
那這樣子的技術就叫做 Feature Disentangle
那 Feature Disentangle 呢
其實有很多各式各樣的技術啦
那實際上是怎麼做的
我本來想要講
但是後來猶豫一下
想說我們先不要講這件事情好了
我們就是主要就想告訴大家說
Feature Disentangle 是有辦法做的
那至於實際上怎麼做
我在這邊就列幾篇論文
給有興趣的同學參考
如果你沒有興趣的話
就知道說這件事情是可行的
我們有可能知道 Aauto-Encoder 裡面
每一個 Dimension 代表了什麼樣的資訊
好 那製作 Feature Disentangle
有什麼樣的應用呢
當然你可以想想看有什麼樣的應用啦
這邊舉一個語音上的應用
這個應用叫做 Voice Conversion
那什麼是 Voice Conversion 呢
Voice Conversion 的中文叫做語者轉換
所以也許你沒有聽過語者轉換這個詞彙
但是你一定看過它的應用
它就是柯南的領結變身器
這個在二十年前
阿笠博士就已經做得很成功了啦
那只是過去
阿笠博士在做這個 Voice Conversion 的時候啊
我們需要成對的聲音訊號
也就是假設你要把 A 的聲音轉成 B 的聲音
你必須把 A 跟 B 都找來
叫他唸一模一樣的句子
就 A 說好 How are you
B 也說好 How are you
A 說 Good morning
B 也說 Good morning
他們兩個各說一樣的句子
說個 1000 句
接下來呢
就結束了
就是 Supervised Learnin 的問題啊
你有成對的資料
Train 一個 Supervised 的 Model
把 A 的聲音丟進去
輸出就變成 B 的聲音
就結束了
但是如果 A 跟 B 都需要唸一模一樣的句子
念個 500 1000 句
顯然是不切實際的
舉例來說
假設我想要把我的聲音轉成新垣結衣的聲音
我得把新垣結衣找來
更退一萬步說
假設我真的把新垣結衣找來
她也不會說中文啊
所以她沒有辦法跟我唸一模一樣的句子
而今天有了 Feature Disentangle 的技術以後
也許我們期待機器可以做到
就給它 A 的聲音 給它 B 的聲音
A 跟 B 不需要唸同樣的句子
甚至不需要講同樣的語言
機器也有可能學會把 A 的聲音轉成 B 的聲音
那實際上是怎麼做的呢
假設我們蒐集到一大堆人類的聲音訊號
然後拿這堆聲音訊號呢
去 Train 一個 Aauto-Encoder
同時我們又做了 Feature Disentangle 的技術
所以我們知道在 Encoder 的輸出裡面
哪些維度代表了語音的內容
哪些維度代表了語者的特徵
接下來
我們就可以做語音的轉換
怎麼說呢
因為在 Encoder 裡面
我們已經知道哪些部分代表內容
哪些部分代表語者
接下來
我們就可以把兩句話
聲音跟內容的部分互換
舉例來說
這邊是我的聲音
我說 How are you
丟進 Encoder 以後
那你就可以抽出
你就知道說這個 Encoder 裡面
某些維度代表 How are you 的內容
某些維度代表我的聲音
今天你把這個你老婆的聲音丟進 Encoder
它就知道某一些維度
代表你老婆說的話的內容
某一些維度
代表你老婆聲音的特徵
接下來我們只要把我說話的內容的部分取出來
把你老婆說話的聲音的部分
聲音特徵的部分取出來
把它拼起來
丟到 Decoder 裡面
就可以用你老婆的聲音
講我說的話的內容
這件事情真的有可能辦到嗎
以下是真正的例子
聽起來像是這個樣子
Do you want to study a PhD
這個是我的聲音啦
就是問你要不要念博班啦
在這門課裡面
我就是要冷不防開始業配念博班這件事情
好 那把我的聲音呢
丟到 Encoder 裡面以後呢
你可以想像說在 Encoder 裡面
我們知道哪些維度代表了念博班這件事
哪些維度代表了我的聲音
那為了簡化起見
你就想像說
它輸出 100 維的向量
前 50 維代表內容
後 50 維代表說話人的特徵
好 接下來這句話是你老婆說的
仕事忙しいのがな（00：07：06）
不知道 不太確定在說什麼
就是日文啊
不太確定在說什麼
好 把這句話呢
丟到 Encoder 裡面
一樣這個 Encoder 的輸出前 50 維是日文
後 50 維代表你老婆說話的特徵
好 接下來呢
就把我的聲音的前 50 維
代表內容的部分取出來
把你老婆的
把你老婆的聲音丟進 Encoder 以後
後 50 維的部分抽出來
拼起來
一樣是一個 100 維的向量
丟到 Decoder 裡面
看看輸出來的聲音
是不是就是你老婆叫你念博班的聲音
聽起來像是這個樣子
Do you want to study a PhD
你老婆叫你念博班啦 知道嗎
還不趕快乖乖簽下去
那其實反過來也可以啦
就是換成把日文的部分拿出來
把我的聲音的特徵拿出來
一樣串成一個 100 維的向量
丟到 Decoder 裡面
它聽起來就會變成這樣
仕事忙しいのがな（00：08：07）
我也不知道自己在說什麼就是了
好 所以確實用 Feature Disentangle
你有機會做到 Voice Conversion
那其實在影像上
在 NLP 上
也都可以有類似的應用
所以可以想想看
Feature Disentangle 可以做什麼樣的事情
好 那下一個要跟大家講的應用
叫做 Discrete Latent Representation
到目前為止我們都假設這個 Embedding
它就是一個向量
這樣就是一串數字
它是 Real Numbers
那它可不可以是別的東西呢
舉例來說
它可不可以是 Binary
那 Binary 有什麼好處呢
Binary 的好處也許是說
每一個維度
它就代表了某種特徵的有或者是沒有
舉例來說
輸入的這張圖片
如果是女生
可能第一維就是 1
男生第一維就是 0
如果有戴眼鏡
就是第三維 1
沒有戴眼鏡 就是第三維是 0
也許我們把這個向量
這個 Embedding 變成 Binary
變成只有 0 跟 1 的數字
可以讓我們再解釋 Encoder 輸出的時候
更為容易
甚至有沒有可能這個向量
強迫它一定要是 One-Hot 呢
也就只有一維是 1
其他就是 0
如果我們強迫它是 One-Hot
也就是每一個東西圖片丟進去
你只可以有
你的 Embedding 裡面只可以有一維是 1
其他都是 0 的話
那可以做到什麼樣的效果呢
也許可以做到 unSupervised 的分類
舉例來說
假設你有一大堆的
假設你想要做那個手寫數字辨識
你有 0 到 9 的圖片
你把 0 到 9 的圖片統統蒐集起來
Train 一個這樣子的 Aauto-Encoder
然後強迫中間的 Latent Representation
強迫中間的這個 Code 啊
一定要是 One-Hot Vector
那你這個 Code 正好設個 10 維
也許每一個 One-Hot 的 Code
所以這 10 維
就有 10 種可能的 One-Hot 的 Code
也許每一種 One-Hot 的 Code
正好就對應到一個數字也說不定
所以今天如果用 One-Hot 的 Vector
來當做你的 Embedding 的話
也許就可以做到完全在沒有
完全沒有Llabel Data 的情況下
讓機器自動學會分類
其實還有其他
在這種啊 Discrete 的 Representation 的這個
技術裡面啊
其中最知名的就是 VQVAE
Vector Quantized Variational Aauto-Encoder
那 VQVAE 啊
是這樣子運作的
就是你輸入一張圖片
Encoder 呢 輸出一個向量
這個向量它是一般的向量
它是 Continuous 的
但接下來你有一個 Codebook
所謂 Codebook 的意思就是
你有一排向量
這排向量也是 Learn 出來的
你把 Encoder 的輸出
去跟這排向量呢
都去算個相似度
你可以想
就是都去算個相似度
那你發現這件事情啊
其實跟 Self-attention 有點像 對不對
這個 Vector 就是 Query
這些 Vector 就是 Key
對不對
就是跟那個 Attention 是很像的
我們在講 Self-attention 的時候
花很多力氣講 Query
Key 跟 Value
所以這個東西就是 Query
這個東西就是 Key
那接下來呢就看這些 Vector 裡面
誰的相似度最大
那你把相似度最大的那個 Vector 拿出來
這邊就是那個
這個 Key 跟那個 Value
是等於是共用同一個 Vector
如果你把這整個 Process
用 Self-attention 來比喻的話
那就等於是 Key 跟 Value 是共同的 Vector
然後把這個 Vector 呢
丟到 Decoder 裡面
然後要它輸出一張圖片
然後接下來 Training 的時候
就是要讓輸入跟輸出越接近越好
這一個 Decoder
這個 Encoder
這一個 Codebook
都是一起從資料裡面被學出來的
這樣做的好處就是你就可以
你就有 Discrete 的這個 Latent Representation
也就是說這邊 Decoder 的輸入
一定是這邊這個 Codebook
裡面的向量的其中一個
假設你 Codebook 裡面有 32 個向量
那你 Decoder 的輸入
就只有 32 種可能
你等於就是讓你的這個 Embedding
它是離散的
它沒有無窮無盡的可能
它只有 32 種可能而已
那其實像這樣子的技術啊
如果你拿它 把它用在語音上
你就是一段聲音訊號輸進來
通過 Encoder 以後產生一個向量
接下來呢
你去計算這個相似度
把最像的那個向量拿出來丟給 Decoder
再輸出一樣的聲音訊號
這個時候你會發現說你的 Codebook 啊
可能可以學到最基本的發音部位
舉例來說 你的
這個最基本的發音單位啊
又叫做 Phonetic
那如果你不知道 Phonetic 是什麼的話
你就把它想成是 KK 音標
那你就會發現說
這個 Codebook 裡面每一個 Vector
它就對應到某一個發音
就對應到 KK 音標裡面的某一個符號
這個是 VQVAE
那其實還有更多瘋狂的想法
Representation 一定要是向量嗎
能不能是別的東西
舉例來說
它能不能是一段文字
是可以的
舉例來說
假設我們現在要做文字的 Aauto-Encoder
那文字的 Aauto-Encoder 的概念
跟語音的影像的沒有什麼不同
就是你有一個 Encoder
一篇文章丟進去
也許產生一個什麼東西 一個向量
把這個向量丟到 Decoder
再讓它還原原來的文章
但我們現在可不可以不要用向量
來當做 Embedding
我們可不可以說我們的 Embedding
就是一串文字呢
如果把 Embedding 變成一串文字
有什麼好處呢
也許這串文字就是文章的摘要
因為你想想看
把一篇文章丟到 Encoder 的裡面
它輸出一串文字
而這串文字
可以通過 Decoder 還原回原來的文章
那代表說這段文字
是這篇文章的精華
也就是這篇文章最關鍵的內容
也就是這篇文章的摘要
不過啊 這邊的 Encoder
顯然需要是一個 Seq2seq 的 Model
比如說 Transformer
因為我們這邊輸入是文章嘛
這邊輸出是一串文字嘛
這個 Decoder 輸入是一串文字
輸出是文章嘛
所以都是輸入一串東西
輸出一串東西
輸入一串文字 輸出一串文字
所以 Encoder 跟 Decoder
顯然都必須要是一個 Seq2seq 的 Model
所以可以想像說
這邊是一個你作業五在訓練的 Transformer
這個也是另外一個 Transformer
它們都是讀一段文字
輸出另外一段文字
所以這整個 Aauto-Encoder 合起來啊
它不是一個普通的 Aauto-Encoder
它是一個 seq2seq2seq 的 Aauto-Encoder
它把長的 Sequence 轉成短的 Sequence
再把短的 Sequence 還原回長的 Sequence
而這個 Aauto-Encoder 大家訓練的時候
不需要標註的資料
因為訓練 Aauto-Encoder
只需要蒐集大量的文章
蒐集大量沒有標註的資料
在這邊就是大量的文章就可以了
如果你真的可以訓練出這個模型
如果這串文字真的可以代表摘要的話
你就是讓機器自動學會做摘要這件事
讓機器自動學會做
unSupervised 的 Summarization
但是真的有這麼容易嗎
實際上這樣 Train 起來以後發現
嗯 是行不通的
為什麼
因為這兩個 Encoder 跟 Decoder 之間
會發明自己的暗號啊
所以它會產生一段文字
那這段文字是你看不懂的
你看不懂的文字
這 Decoder 可以看得懂
它還原得了原來的文章
但是人看不懂
所以它根本就不是一段摘要
所以怎麼辦呢
再用 GAN 的概念
加上一個 Discriminator
Discriminator 看過人寫的句子
所以它知道人寫的句子長什麼樣子
但這些句子
不需要是這些文章的摘要性
另外一堆句子
所以它知道人寫的句子長什麼樣子
然後呢
這個 Encoder 要想辦法去騙過 Discriminator
Encoder 要想辦法產生一段句子
這段句子不只可以透過 Decoder
還原回原來的文章
還要是 Discriminator 覺得像是人寫的句子
期待通過這個方法
就可以強迫 Encoder
不只產生一段密碼可以給 Decoder 去破解
而是產生一段人看得懂的摘要
那你可能會問說
這個 Network 要怎麼 Train 啊
這個 Output 是一串文字哦
那這個文字要怎麼接給 Discriminator
跟這個 Decoder 呢
告訴你
看到你沒辦法 Train 的問題
就用 RL 硬做
這樣這邊就是 RL 硬做就結束了這樣子
好 所以這個
Network 後來硬 Train 起來以後呢
因為你可能會覺得這個概念有點像 CycleGAN
沒錯 你可以想這根本就是 CycleGAN
就是這是一個 Generator
這是另外一個 Generator
這是 Discriminator
你要輸入跟輸出越接近越好
其實這根本就是 CycleGAN
我們只是從 Aauto-Encoder 的角度
來看待 CycleGAN 這個想法而已
好 那實際上做的結果是怎麼樣呢
以下是真正 Network 輸出的結果啦
你給它讀一篇文章
然後它就用 Aauto-Encoder 的方法
拿 300 萬篇文章做訓練以後
然後看看給它一篇新的文章
它可不可以是
那個 Encoder 的輸出的句子
是不是就是人可以看得懂的摘要
舉例來說
給 Encoder 看這篇文章
它的輸出是
澳大利亞加強體育競賽之外的藥品檢查
看起來還可以
那這邊有一個特別強的啦
就是這篇文章是
中華民國奧林匹克委員會
今天接到一九九二年冬季奧運會邀請函
丟給 Encoder 之後
它的輸出是奧委會接獲冬季奧運會邀請函
它知道把奧林匹克委員會
自己就縮寫成奧委會
這個不知道怎麼回事
它自己就學到了這件事情
當然很多時候
它也是會犯錯的
我特別喜歡舉這種極其犯錯的例子
舉例來說
你給它讀這篇文章
印度尼西亞蘇門答臘島近日來連降暴雨
機器產生的摘要是什麼呢
Encoder 的輸出是
印尼門洪水泛濫
印尼門是什麼東西呢
大概就是印度尼西亞蘇門的縮寫啦
可能人類寫的句子裡面
常常出現羅生門 (風二門)
等等什麼門
所以機器覺得
Encoder 覺得印度尼西亞蘇門
應該可以縮寫成印尼門
那有時候它也會產生莫名其妙的句子啊
比如說把這篇文章給機器讀了以後
Encoder 的輸出是
合肥領導幹部下基層做搞迎來送往規定一律簡
不知道在說些什麼
總之是個句子 不知道在說些什麼
好 所以這個例子只是想要告訴你說
我們確實有可能
拿一段文字來當做 Embedding
其實還有更狂的
我還看過有拿 Tree Structure
當做 Embedding
就一段文字把它變成 Tree Structure
再用 Tree Structure 還原一段文字
好 我把 Reference 列在這邊給大家參考
好 接下來啊
還有 Aauto-Encoder 更多的應用
Aauto-Encoder 還可以拿來做些什麼事情呢
舉例來說
我們剛才用的都是 Encoder
那其實 Decoder 也有作用
你把 Decoder 拿出來
這不就是一個 Generator 嗎
我們說 Generator
不是就是要吃一個向量
產生一個東西
比如說一張圖片嗎
而 Decoder 不正好是吃一個向量
產生一張圖片嗎
所以 Decoder
你可以把它當做一個 Generator 來使用
你可以從一個已知的 Distribution
比如說 Gaussian Distribution
Sample 一個向量
丟給 Decoder
看看它能不能夠輸出一張圖
事實上在我們之前
在講這個 Generative Model 的時候
其實有提到說除了 GAN 以外
還有另外兩種 Generative 的 Model
其中一個就叫做 VAE
Variarional 的 Aauto-Encoder
你看它名字裡面的 Aauto-Encoder
顯然是跟 Aauto-Encoder 非常有關係的
它其實就是把 Aauto-Encoder 的 Decoder 拿出來
當做 Generator 來用
那實際上它還有做一些其他的事情啊
至於它實際上做了什麼其他的事情
就留給大家自己研究
所以 Aauto-Encoder Train 完以後
也順便得到了一個 Decoder
Aauto-Encoder 可以拿來做壓縮
我們今天知道說你在做圖片
我們圖片如果太大的話
也會有一些壓縮的方法
比如說 JPEG 的壓縮
而 Aauto-Encoder 也可以拿來做壓縮
你完全可以把 Encoder 的輸出
當做是一個壓縮的結果
因為一張圖片
是一個非常高維的向量
而一般我們 Encoder 的輸出
是一個非常低維的向量
你完全可以把那個向量
看作是一個壓縮的結果
所以你的 Encoder 做的事情
就是壓縮
你的 Decoder 做的事情
就是解壓縮
那只是這個壓縮啊
它是那種 lossy 的壓縮
所謂 lossy 的壓縮就是它會失真
因為在 Train Aauto-Encoder 的時候
你沒有辦法 Train 到說
輸入的圖片跟輸出的圖片
100% 完全一模一樣啦
它還是會有一些差距的
所以這樣子的 Aauto-Encoder 的壓縮技術
你拿這樣子的技術來做壓縮
那你的圖片是會失真的
就跟 JPEG 圖片會失真一樣
用這個 Aauto-Encoder 來做壓縮
你的圖片也是會失真的
好 那接下來
就是我們在作業裡面要使用的技術
在作業裡面我們會拿 Aauto-Encoder
來做 Anomaly 的 Detection
那我在規劃作業的時候
其實就是想要 Aauto-Encoder 出一個作業
那 Aauto-Encoder 的技術很多
那最後我決定做 Anomaly 的 Detection
因為這個是你在非常多的場合
都有機會應用到的一個技術
好 Anomaly 的 Detection 要做的是什麼呢
它要做的事情就是
假設你有一堆的訓練資料
這邊用 X1 到 XN 來表示我們的訓練資料
而 Anomaly Detection
它的中文通常翻譯成異常檢測
異常檢測要做的事情就是
來了一筆新的資料
它到底跟我們之前在訓練資料裡面看過的資料
相不相似呢
也就是說你需要找出
你需要有一個異常檢測的系統
這個異常檢測的系統
是透過大量你已經看過的資料訓練出來的
給它一筆新的資料
如果這筆新的資料
看起來像是訓練資料裡面的 Data
就說它是正常的
如果看起來不像是訓練資料裡面的 Data
就說它是異常的
那其實 Anomaly
Anomaly 這個詞啊
有很多不同的其他的稱呼
比如說有時候你會叫它 Outlier
有時候你會叫它 Novelty
有時候你會叫它 Exceptions
但其實指的都是同樣的事情
你就是要看某一筆新的資料
它跟之前看過的資料到底相不相似
但是所謂的相似這件事啊
其實並沒有非常明確的定義
它是見仁見智的
會根據你的應用情境而有所不同
舉例來說
假設現在你的訓練資料這個都是雷丘
那這個皮卡丘就算是異常的東西
但是假設你的訓練資料裡面
你所有的動物都是皮卡丘
那雷丘就是異常的東西
所以我們並不會說
某一個東西它一定就是 Normal
一定就是 Anomaly
我們不會說某個東西它一定是正常或異常
它是正常或異常
取決於你的訓練資料長什麼樣子
或者是說假設你的訓練資料裡面
通通都是寶可夢
那雷丘跟皮卡丘通通都算是正常的
而可能數碼寶貝
亞古獸知道嗎
這應該是亞古獸 對不對
亞古獸算是異常的
好 那怎麼
那個這個異常檢測有什麼樣的應用呢
舉例來說
它可以來做詐欺偵測
假設你的訓練資料裡面
有一大堆信用卡的交易紀錄
那我們可以想像說
多數信用卡的交易都是正常的
那你拿這些正常的信用卡訓練的交易紀錄
來訓練一個異常檢測的模型
那有一筆新的交易紀錄進來
你就可以讓機器幫你判斷說
這筆紀錄算是正常的 還是異常的
所以這種異常檢測的技術
可以拿來做詐欺偵測
或者是它可以拿來做網路的這個侵入偵測
舉例來說
你有很多連線的紀錄資料
那你相信多數人連到你的網站的時候
他的行為都是正常的
多數人都是好人
你蒐集到一大堆正常的連線的紀錄
那接下來有一筆新的連線進來
你可以根據過去正常的連線
訓練出一個異常檢測的模型
看看新的連線
它是正常的連線 還是異常的連線
它是有攻擊性的 還是正常的連線
或者是它在醫學上也可能有應用
你蒐集到一大堆正常細胞的資料
拿來訓練一個異常檢測的模型
那也許看到一個新的細胞
它可以知道這個細胞有沒有突變
也許有突變
它就是一個癌細胞等等
那講到這邊有人可能會想說
Anomaly Detection 異常檢測的問題
我們能不能夠把它當做二元分類的問題來看啊
你說你要做詐欺偵測
你就蒐集一大堆正常的信用卡紀錄
一堆詐欺的信用卡紀錄
訓練一個 Binary 的 Classifier
就結束啦
就這樣子不是嗎
比較難點就是你要蒐資料
但是這種異常檢測的問題它的難點
正在就在蒐資料上面
通常你比較有辦法蒐集到正常的資料
你比較不容易蒐集到異常的資料
你可能有一大堆信用卡交易的紀錄
但是多數信用卡交易的紀錄可能都是正常的
異常的資料相較於正常的資料
可能非常地少
甚至有一些異常的資料混在正常的裡面
你也不太可
你可能也完全沒有辦法偵測出來
所以在這一種異常檢測的問題裡面
我們往往假設
我們有一大堆正常的資料
但我們幾乎沒有異常的資料
所以它不是一個一般的分類的問題
這種分類的問題又叫做 One Class 的分類問題
就是我們只有一個類別的資料
那你怎麼訓練一個模型
因為你想你要訓練一個分類器
你得有兩個類別的資料
你才能訓練分類器啊
如果只有一個類別的資料
那我們可以訓練什麼東西
這個時候就是 Aauto-Encoder
可以派得上用場的時候了
舉例來說
假設我們現在想要做一個系統
這個系統是要偵測說一張圖片
舉例來說
它是不是真人的人臉
那你可以找到一大堆圖片
它都是真正的人臉
那我們就拿這些真人的人臉
來訓練一個 Aauto-Encoder
舉例來說
這個是你老婆的照片
你可以在聊天室推我老婆請測照
這是你老婆的照片
那你可以拿它來訓練一個 Aauto-Encoder
那你訓練完這個 Aauto-Encoder 以後
在測試的時候
如果進來的也是你老婆的照片
那因為在訓練的時候有看過這樣的照片
所以它可以順利地被還原回來
你可以計算這一張照片通過 Encoder
再通過 Decoder 以後
它的變化有多大
你可以去計算這個輸入的照片
跟這個輸出的照片
它們的差異有多大
如果差異很小
你的 Decoder 可以順利地還原原來的照片
代表這樣類型的照片
是在訓練的時候有看過的
不過反過來說
假設有一張照片是訓練的時候沒有看過的
舉例來說這根本不是人的照
她是人嘛 她是團長
團長 她是那個涼宮春日
但是她不是真人
她是一個動畫的人物
她是二次元的人物
一個二次元人物的照片
輸入 Encoder 再輸出 Decoder 以後
因為這是沒有看過的東西
這是訓練的時候沒有看過的照片
那你的 Decoder
就很難把它還原回來
如果你計算輸入跟輸出的差異
發現差異非常地大
那就代表說
現在輸入給 Encoder 的這張照片
可能是一個異常的狀況
可能是訓練的時候沒有看過的狀況
所以你就可以看 reconstruction 的 loss
這個 reconstruction 的好壞
來決定說你現在在測試的時候
看到這張照片
是不是訓練的時候有看過同類型的照片
這個就是我們
好 那這個就是我們在作業裡面
要大家做的事情啦
好 那這個異常檢測啊
其實也是另外一門學問
那我們課堂上就沒有時間講了
異常檢測不是只能用 Aauto-Encoder 這個技術
Aauto-Encoder 這個技術
只是眾多可能方法裡面的其中一個
我們拿它來當做 Aauto-Encoder 的作業
因為我相信
你未來有很多的機會用得上異常檢測這個技術
那實際上有關異常檢測更完整的介紹
我們把過去上課的錄影放在這邊
給大家參考
好 那以上就是有關 Aauto-Encoder 的部分
在我們請助教來講作業之前
我們看一下大家有沒有問題想要問的
欸 大家有問題想要問嗎
沒有嗎
好 如果暫時沒有問題的話
那我們就請助教來講下一個作業
