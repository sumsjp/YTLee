臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://ai.ntu.edu.tw/
我們要 train 一個
輸入文字
然後要產生對應的二次元人物的頭像
那這個技術呢，你就要用到 conditional GAN
所謂 conditional GAN 的意思就是說
我們之前的 GAN，是隨機輸入一個
vector，然後產生一張給你
那你其實根本不能控制說你要 output 什麼樣的東西
那我們這邊要講 conditional GAN 的意思是說
你可以輸入一個，比如說是文字
然後產生對應那個文字的圖片
也就是你可以操控你要輸出的結果
好那我們今天要舉的例子呢
在作業2裡面要做的東西呢
就是 Text-to-Image
那這個東西就是輸入文字產生對應的圖片
當然要做到這件事情
要輸入文字產生對的圖片，它其實可以被當作是一個
單純的 supervised learning problem 來看
那怎麼用一個supervised learning 的方式來 learn 一個
Text-to-Image 的 model 呢？
你需要的就是一大堆的圖片
每一張圖片都需要對應的文字描述
然後套用一個傳統的supervised learning的方法
你可以說我就 learn 一個network， 它的輸入就是一段文字
輸出就是對應的圖片
那你希望輸出的圖片
跟你的目標，越接近越好
比如說你會 minimize 你的 network output 的
你的 network output
跟這個文字所對應的 image 的 L1 或 L2 的 loss
但是光是這麼做，會有什麼樣的問題呢？
你可以想像說，在你的 training data 裡面
火車它的對應圖片其實是有很多張的
這些是正面的火車，它們都是火車
這些是側面的火車，它們也通通都是火車
哪你現在如果要讓你 network 的 output
如果你用傳統方法 learn 一個 network 的話
它會覺得說輸入 train 的時候，輸入火車的時候
它要長得像這 3 張，同時也要長得像這 3 張
所以到時候你 network 的 output 就會變成是
這些一大堆 image 的平均
如果你產生這種正面的火車是好的結果
你產生這個側面的火車是好的結果
但是同時產生正面的火車跟側面的火車合起來
這是錯誤的結果
今天假設你用 traditional 的方法
來 learn 一個 conditional 的 generation
你用一般的方法來 learn 一個 text to image 的 generator
你會發現說你產生出來的 image 都是特別模糊的
為什麼？
因為你產生出來的 image 會是多張 image 的平均
你的 model 在學習的時候
它想要產生的結果，是多張 image 的平均
所以這邊就需要用到 GAN 的技術
那我們說在原來的 GAN 裡面
你的 generator 就是吃一個從 normal distribution sample 出來的 z
根據這個 z ，產生一張 image x
那在 conditional generation 裡面呢
你的 generator 不是只有吃 z，同時也吃了另外一個東西
吃了另外一個 conditional 的 text c
所以你的 conditional GAN 呢
它就是同時吃一個 normal distribution 的 sample 出來的 vector
跟一段文字，然後根據這段文字
還有這個 sample 出來的 vector
它產生 generated 的結果
那接下來呢，你要 train 一個 discriminator
在我們原來的 GAN 裡面呢，discriminator 只吃一張 image x
然後它告訴你說這個 x，它的 quality 好不好
這個 discriminator 它吃一個 x，它 output 一個 scalar
這個 scalar 代表說呢，input 的 x
它到底有多好，或者是多不好
那你在 train 這個 discriminator 的時候， 你就會告訴這個 discriminator 說
如果是 real image，就給它 1 分
如果是 generated image，就給它 0 分
但光是這麼做，是不夠的
假設你是用我們之前看到的那種方式來 train discriminator 的話
會發生什麼問題呢？
你會發現說，今天 generator 在產生 image 的時候
它會完全無視 input 的 condition
因為 discriminator 它只檢查說你現在 input 的 image 是不是一張 high quality 的 image
所以今天對 generator 來說，它要騙過 discriminator
它只要產生high quality 的 image 就好了， 它只要產生清晰的圖就好了
它可完全無視你 input condition
不管你輸入是貓，狗，火車，它可能都輸出貓
反正只要這個 discriminator 覺得它產生出來的貓是一支高品質的貓
看起來很像是真的貓，就結束了
這個顯然不是我們要的
我們希望機器是按照我們輸入的 condition
產生不同的圖片
所以今天你要注意，當你在做 conditional GAN 的時候
你的 discriminator 不可以只看 generator 的輸出
它要同時看 generator 的輸入跟輸出
這時候你的 discriminator 有兩個任務
我們說discriminator 它吃一個 condition 跟吃一個 object
然後產生一個 scalar
這個 scalar 它對應到兩件事情
第一件事情是 x 是不是真實的？
第二件事情是，你的 x 跟它的 condition c
他們合起來，是不是應該湊成一對
也就是 x 是真的還不是真的，x 跟 c 是不是應該湊成一對
這兩個東西加起來就是 discriminator 的 output
所以今天在 train 這種 discriminator 的時候
這個就是我們在作業 3-2 要做的事情啦
我們今天在 train 這種 discriminator 的時候
對這種 discriminator 來說
就是現在 discriminator 它不是只吃 image， 它是吃一個 pair
它是吃一個 image 跟一段文字
什麼樣的文字跟 image 的組合要給它高分呢？
當然是一段文字，它對應的 image，他們合起來
要給它 1 分
但是什麼樣的狀況，應該給它 0 分呢？
如果今天是正確的文字，一段文字
跟 generator 的輸出，正確的文字
跟 generated 的 image，當然要給它低分
但是還有另外一個 case 應該要給它低分
因為這個 discriminator 它不是只要看你產生出來的 image 好不好
它還要看你產生出來的 image 跟它 input 的 text
他們有沒有被 match 在一起
所以今天不是只有一個 case 給它第低分
還有另外一個 case 要給它低分
什麼樣的 case 應該要給它低分呢？
你拿一張真實的 image
但是隨便給它配個，隨便給它加上
隨機的文字
比如說這個是火車，你就說它一隻貓
這個 case 要給 discriminator 低分
你要告訴 discriminator 說，就算是產生好的圖
但是給它一個隨機的文字
他們沒有辦法 match 在一起，他們是不匹配的
這個時候，也應該要給它低分
所以跟一般的 generator 不一樣，跟一般的 GAN 不一樣
當你做 conditional GAN 的時候， 你的 discriminator 它是吃一個 pair 當作 input
那你在 train 這個 discriminator 的時候
它有兩種 negative 的 examples， 有兩種 cases 是應該給它低分的
一個 case 是，輸入一段文字給 generator
generator 產生一張模糊的圖，所以就要給低分
給一張清晰的圖，但是隨便給它加上一個隨機的文字
這個應該也要給它低分
如果你比較喜歡看演算法的話，這邊我就把演算法列一下
你就照著這個 call 這樣，知不知道
就是照著這個 call，怎麼 call 呢？
我們就一行一行講給你聽，這怎麼 call
我們從 database 裡面 sample 出 m 個 example
那注意一下，因為今天是 conditional 的 generation
所以你的每一個 example 都是
假設是 text to image，都是 image 跟文字的 pair
文字是 c，image 是 x
所以你的每一個 sample data 都是 文字跟 image 的 pair...
這個是要給高分的
是 positive examples
對 discriminator 來說，要給高分的
前半段是在訓練 discriminator
那你接下來 sample 出 m 個 vector
然後把這 m 個 vectors
每一個都去加上一個 condition
你這邊有 m 個 condition c1 到 cm 對不對？
把這 m 個 vector，每一個都去加上 condition
產生 x tilde，產生 m 張generated 的 image
接下來，你再去你的 database 裡面
sample 出 m 個 objects
我們這邊寫作 x1 hat 到 xm hat
這 m 張 image，這個 x hat 它也是好的 image
可是 x tilde 是 generated 的 image
這個 x hat
它也是 real 的 image
也是 database sample 出來的 image
接下來在 train 你的 discriminator 的時候
如果是正確的 c 跟 x 的 pair，就給它高分
如果今天是 c 配上 x tilde
一段文字敘述，配上 generated 出來的模糊的結果
那應該要給它低分
如果今天是一段文字敘述
配上 x hat
從 training date 裡面 sample 出來的 real image
從 training data 裡面 sample 出來的清楚的 image
但是跟這個 c 它是沒有辦法配在一起的， 這個也要給它低分
所以今天是這個 case 給它高分
這兩個 case 也要給它低分
那這個實作跟之前講的 GAN，其實沒有太大差別
唯一差別地方就是，你要多加這一項就是了
之前只有一種 negative example
現在變成有兩種 negative example
那接下來 train generator
train generator 怎麼做，sample 出 m 個 vectors
然後再 sample 出 m 個 conditions
然後把每一個 vector z，跟每一個 condition 加起來
一起丟到 generator 裡面
再通過 discriminator，那你希望這個分數，越大越好
這個就是大家作業 3-2 要實做的東西
那在 discriminator 的 network 的架構上
應該要怎麼設計呢？
我發現我最常看到的設計是這樣
input 一個 object，就一張 image
然後通過一個 network 把它變成一個 embedding
然後你的 condition 現在是一串文字
文字你可能也通過一個 network， 把它也變成 embedding
那你把這兩種 embedding 組合起來丟到 network 裡面
然後最後 network output 一個 scalar
這個 scalar 代表了兩件事，一件事是 input 的 x 有多好
同時又代表了 x 跟 c 合起來， 它們湊成一個 pair 有多合適
但是我發現有另外一種 discriminator 的架構
而這種 discriminator 的架構，在文獻上看起來它的 performance 是不錯的
然後我發現有 3 篇 paper 都是做這樣的事情
那我個人認為這個架構，其實好像是比較有道理的
這個架構是這樣，這個架構是說
我們有一個 object 進來
object 先通過一個 network
然後就 output 一個分數
接下來這個綠色的 network
它也吐出一個 embedding
這個 invalid 也跟你的 condition 結合起來， 丟到另外一個藍色 network 裡面
藍色 network 也吐出一個分數
所以現在你吐出兩個分數，一個是綠色的 network 吐出來的分數
綠色的 network 只看你的 object，它不管這個 condition
它只看你的 object
然後它去看這個 object 決定說
現在 output 的結果是 realistic 還是不是 realistic
那這個藍色的 network 呢？
藍色的 network 它同時看了 x，也看了 c
兩個湊起來以後
它會告訴你說，它應該是被 match 在一起的
還是不應該被 match 在一起的
所以今天這個藍色的 network 它同時看了 x，同時看了 c
它決定說這兩個東西它到底應該是 match 的，還是不是 match 的
但我覺得把這兩種 evaluation 的結果把它拆開
其實可能是比較合理的
因為今天在上面這個 case
如果你給 network 一筆 data
一組 data，告訴它說這是一個壞的 example， 你應該給它低分
但是你沒有告訴它說為什麼是低分
我們都講說我們有兩種 native example
一種 native example 是 其實你的 image 跟文字還是 match 的
只是 image 的 quality 不好，因為它是 generator 產生的
另外一個 case 是， 你的 image 的 quality 是好的，但是它是不 match 的
這兩種 case 都要給它低分
但是對這個 network 來說，它就會 confused 這樣
它就不知道為什麼這個東西是給它低分
舉例來說你可能是說給它一個很清晰的圖片
給它一個很清晰的火車，但是搭配狗
告訴它說這個要給低分，也許它會覺得說
會不會是因為這個火車不夠清晰
應該要產生的更清晰一點
所以今天對這種 network 來說
兩種不同的錯誤就是你的 x 不夠 realistic
還有 x 跟 c 不夠 match
對它來說它不知道到底是哪一種錯誤
你就把兩種 data 都倒給它，希望它自己可以分辨
可是我覺得就下面這個 case 而言，你就可以
把這兩個 case 分開
你就會告訴它說
假設你今天的 case 是你的 x 產生出來不夠清晰
那只需要這個值變小就好
如果你今天是 x 很清晰
只是跟 c 不 match
那你只需要讓這個值變小，那這個值就不用變小
我覺得這可能是一個比較合理的設計
不過就是給大家參考就是了
不過我現在看到比較多的 network 是用上面這個方式設計的
不過也有些 paper 用下面這個方式來設計它的 discriminator
我覺得下面其實是比較合理的
也許你可以在作業裡面試試看
然後告訴我說你覺得哪一個結果 performance 比較好
那還有一個技術你可以用在作業裡面的叫做，stack GAN
你不用 stack GAN 你就可以過 base line， 那如果你想要登峰造極
你就可以用一下 stack GAN
stack GAN 是怎麼樣呢？
stack GAN 的概念是說
先產生小張的圖，根據小張的圖，再產生大張的圖
在原始的 stack GAN 的 paper 裡面， 它想要產生的圖大小是 256x256
不過太大張了
你直接產生 256x256 的圖會壞掉
所以 stack GAN 在 train 的時候
它把整個 training process
拆成兩階，先拆成兩階，有一個第一階的 generator
第一階的 generator 它的工作是說，吃一段文字進來
這 network 有點複雜，詳情你再去看一下 paper
吃一個文字敘述進來
再吃一個 noise 進來， 把它們通通都 concatenate 在一起
然後產生一張 image
然後這個 image 比較小，只有64x64
那另一個 discriminator check 說
這個 image 搭配這段文字的敘述
是不是 match 的
那接下來你有第二個 generator
第二個 generator 是什麼呢
第二個 generator 就是吃一段文字的敘述
配一張64x64 的 image
然後產生一張 256x256 的圖
然後第二個 discriminator 看說
這個 256xx256 的圖是不是 realistic 的
總之你在做的時候，你就是分成兩階
先產生小的，再產生大的，那你直覺就會知道說
這樣 performance 應該會比較好的
像之前不是 Nvidia 有 report 說
他們的選片可以產生 1024x1024 的超級大圖
它產生出來的人臉是連毛細孔都看得到的那一種
它們做的就是類似 stack GAN 的概念
你就產生小張的圖，先產生4x4
再根據 4x4 產生 8x8，再產生 16x16
最後一直到產生1024x1024
不過它們實際上在 train 的時候， 這些所有疊在一起的 generator
都是 jointly 合在一起 train 的
它是先 train 第一個小的
再疊第二個比較大的，然後大的跟小的一起 train
再疊更大的，然後再一起 train 這樣子
那剛才講的那個 conditional GAN 是產生文字
再產生對應的圖片
那我們現在也可以產生圖片
然後產生另外一張對應的圖片
那這個東西是怎麼做的呢？
這邊你看文獻上可以看到很多的例子
比如把黑白的圖轉成彩色的圖
把白天轉成夜晚，這怎麼做的？
你要 train 這種 network
首先當然你要有 training data
假設你今天是要把簡單的幾何圖形
變成真實的房屋的樣子
但你需要收集很多簡單的幾何圖形
跟真實房屋的 pair
這種 data 收集個好幾萬張
然後去 train 一個 network
當然你可以用 supervised 的方法來解這個問題
但是用 supervised 的方法，問題就是
你產生出來的圖片，會是比較模糊的
如果用 supervised 的方法， 你的做法是說，你有一個 network
然後你 input 一張圖片
它 output 一張對應的圖片
然後你希望這張對應的圖片
它的目標越接近越好
你通常會算個比如說 L1 loss 或 L2 loss
當你發現如果你只有這麼做的話，你會遇到的問題是
你產生出來的 output 會是特別模糊的
這跟我們之前講 text to image 一樣
你同一張 image 它可能可以對應到很多不同的房子
今天network 在學的時候
它就是產生一個平均的結果
所以它產生的圖片會是比較模糊的
這個時候，你就可以引入 GAN 的概念
在 GAN 裡面，你的 generator
它吃一個簡單的圖，它吃這個 condition，跟一個 noise z
產生一張對應的圖片
那你的 discriminator 做的事情是什麼呢？
你的 discriminator 會檢查這個 generator 的 input 跟output 湊起來
是不是一個 pair
那我們之前有講過說
你今天在 conditional GAN 裡面， 在 train discriminator 的時候
你應該給它吃一個 pair
而不是只是 generator 的 output
你應該給它 generator 的input 跟output 的 pair
然後它會給它一個分數
如果你用 GAN 來做的話
你會發現說，你產生的圖，就清晰很多
但它的問題是
GAN 它會產生一些奇奇怪怪的東西
舉例來說這邊有一個又像是煙囪，又像是窗戶的東西
這本來 input 裡面沒有的
對這個 discriminator 來說
產生這個東西，好像也沒有特別不對
但如果你今天要給它下額外的 constrain 的話
你可以下另外一個 constrain 說
你希望 generator 的 output 跟 training data 裡面
目標的那個 image，同時也要越靠越近越好
也就是對你的 generator 來說
它有兩個目標，一個目標是
要產生夠清晰的圖去騙過 discriminator
另外一方面，你又希望 generator 產生出來的 output
不要跟原來的目標相差太多
如果你把這兩個東西，同時一起考慮的話
那你產生出來的結果，就會比較好
不只是產生清晰的圖， 這個圖上面，也不會產生奇怪的東西
這個是 image to image
那這 image to image 那篇paper 裡面呢
它的 discriminator 有稍微經過設計
因為如果你今天要產生出來的 image 非常大張
那你的 discriminator 如果是吃整張image 當作 input 的話
你結果很容易壞掉，為什麼？
因為你的 discriminator，因為 image 很大嘛
所以你 discriminator 參數也要很多
那你很容易 train 一train 就很容易 over fitting
或你 train 的時間就非常的長
所以其實在前面那個 image to image 的那個 paper 裡面
它做的事情是
它的 discriminator 每次只檢查圖片裡面的一小塊而已
它不是讓 discriminator 去檢查整張圖片
因為這樣你的 discriminator 的參數量，會太多
它只讓 discriminator 檢查一小塊圖片
然後再說這一小塊圖片它到底是好的，還是不好的
當然一個 discriminator 要檢查多大的區域
就變成一個你需要去調整的參數
在 paper 裡面它當然有調說， 如果看整張 image 會怎麼樣
如果小到只看一個 pixel 會怎麼樣
這個如果只看一小塊，叫做 patch GAN
如果只看一個 pixel 就叫做 pixel GAN
那你可以想像說只看一個 pixel，當然是一點用都沒有
如果只看一個 pixel，它不就只考慮那一個點的事情嗎？
所以它產生出來的 image，就會整個都糊掉
就會看不出來在產生什麼東西
所以當然只用一個 pixel 是不行的
但是只看整張 image，performance 也不是最好的
你要調一下這個 patch 的 size
看看說怎樣的 patch size 可以給你最好的結果
這個東西叫做 patch GAN
其實同樣的技術，不是只能用在影像上
到目前為止，我們講 GAN 的時候，都是 apply 在影像上
其實它的技術，也可以用在語音上
舉例來說，你可以用 GAN 這個技術來做 speech enhancement
什麼是 speech enhancement 呢？
speech enhancement 的意思是說
你有一段聲音訊號
它被雜訊干擾，它加了很多背景的噪音
你希望機器可以自動把背景噪音去掉
那通常有兩個作用，一個是把背景噪音去掉以後
再丟到語音辨識系統裡面，也許正確率會比較高
另外一方面，把背景噪音去掉以後，再播給人聽
也許人聽得比較清楚
那如果今天是一般的 speech enhancement，怎麼 train 的呢？
你要找很多聲音
然後把這些聲音，也都加上一些雜訊
接下來，你就 train 一個 generator
input 一段有雜訊的聲音
希望 output 就是沒有雜訊的聲音
input 一段有雜訊的聲音
把沒有雜訊的聲音，當作你的目標
去訓練你的 generator
這是一段聲音訊號，但它是用 spectrum 來表示它
它看起來就像是一個 image 一樣
所以這個 generator 常常也就會直接套用你在產生 image
我們剛才說 conditional generation，它會做在 image 上嘛
那其實那些 image 上常用的架構
其實也可以直接套用到 speech enhancement 上面
也是沒有什麼問題的
但是我們剛才有講過說，直接 train generator
你產生出來的結果就會比較模糊
所以你要再加上 GAN 的概念
不只要直接 train generator
你還要 train 一個 discriminator
discriminator 的工作呢
就是看 generator 的 input 加output
這個我們今天強調很多次了，在 conditional GAN 裡面
你不可以只看 generator 的 output
discriminator 要同時看generator 的 input 跟output
然後給它一個分數
這個分數決定說
現在 output 的這一段聲音訊號是不是 clean 的
同時 output 跟input 是不是 match 的
你並不希望你本來說 I love you
然後通過 generator 以後就變成 I hate you 這樣子
那就不行，所以你希望 output 跟 input
他們是 match 在一起的
那同樣的技術，也可以做 video 的 generation
那怎麼做 video 的 generation 呢？
就是給 generator 看一段影片
然後讓它預測，接下來會發生什麼樣的事情
讓它產生影片接下來發生的事情
那要怎麼做到這件事情呢？
你就需要一個 discriminator
那我們說 discriminator 不能夠只看 generator 的 output
它要同時看，generator 的 input 跟 output
你把 generator 的 input 跟output 接在一起
變成一段完整的影片
然後讓 discriminator 去檢查說，這一段影片
到底是不是一個合理的影片
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
