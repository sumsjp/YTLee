好 我們就開始來上課吧
那上週講到哪裡呢
上週講到 WGAN
我們還說實際上呢
如果你要實做 WGAN 的話
其實有很多不同的做法
那今天看起來呢
效果最好的
其實是 Spectral Normalization
很多人會縮寫成這個 SNGAN
SN 就是 Spectral Normalization 的意思
好 但是雖然說已經有 WGAN
但其實並不代表說
GAN 就一定特別好 Train
GAN 仍然是以
很難把它 Train 起來而聞名的
那為什麼 GAN 很難被 Train 起來呢
它有一個本質上困難的地方
我們來想想看 Discriminator 跟 Generator
它們各自在做的事情是什麼
Discriminator 做的事情
是要分辨真的圖片跟產生出來的
也就是假的圖片的差異
這是 Discriminator 在做的事情
而 Generator 在做的事情
它是要去產生假的圖片
騙過 Discriminator
而事實上這兩個 Network
這個 Generator 跟 Discriminator
它們是互相砥礪
才能互相成長的
只要其中一者
發生什麼問題停止訓練
另外一個人就會跟著停下訓練
就會跟著變差
跟著慘掉
所以今天
假設你在 Train Discriminator 的時候
一下子沒有 Train 好
你的 Discriminator 沒有辦法分辨
真的跟產生出來的圖片的差異
那 Generator
它就失去了可以進步的目標
Generator 就沒有辦法再進步了
Generator 沒有辦法再進步了
Discriminator 也會跟著停下來的
如果 Generator 沒有辦法再進步
它沒有辦法再產生更真實的圖片
那 Discriminator 就沒有辦法再跟著進步了
所以 Discriminator 跟 Generator
它們在訓練的時候
只要其中一者不再進步
另外一個人就會跟著停下來
但是到目前為止
大家已經 Train 過了很多次的 Network
你有辦法保證說你 Train 下去
它的 Loss 就一定會下降嗎
不一定對不對
你要讓 Network Train 起來
往往你需要調一下 Hyperparameter
才有可能把它 Train 起來
那今天這個 Discriminator 跟 Generator
它們互動的過程是自動的
一旦在某一個步驟
你 Discrimi
因為我們不會在中間
每一次 Train Discriminator 的時候
你都換 Hyperparameter
所以只能祈禱
說每次 Train Discriminator 的時候
它的 Loss 都是有下降的
那如果有一次沒有下降
那整個 Training
很有可能就會變就會慘掉
整個 Discriminator 跟 Generator
彼此砥礪的這個過程
就可能會停下來
所以今天 Generator 跟 Discriminator
在 Train 的時候
它們必須要棋逢敵手
就任何一個人放棄了這一場比賽
另外一個人也就玩不下去了
所以 GAN 本質上它的 Training
仍然不是一件容易的事情
當然它是一個非常重要的技術
所以雖然它是一個前瞻的技術
有人可能會覺得說
你不要把這種
你自己都不見得 Train 的起來的 Network
放到那個作業裡面
但是我覺得說
這是一個重要的前瞻的技術
所以我們還是
應該要讓大家有機會
接觸這種最前瞻的技術
你至少可以知道說
Train GAN 不是一件那麼容易的事情
當然其實從另外一個角度而言
因為很多人都在做類似的研究
所以在網路上
你可以找到滿坑滿谷相關的程式
所以其實從這個角度而言
它其實也沒有你想像的那麼困難
不過 Train GAN
仍然不是一件容易的事就是了
好 你可以在網路上找到滿坑滿谷的
GAN 的 Tips
那這些有沒有用呢
不好說 不好說
就是把一些相關的
跟 Train GAN 的訣竅有關的文獻
還有連結列在這邊
其實就給大家自己參考
好 那 Train GAN 最難的
其實是要拿 GAN 來生成文字
就如果你要拿 GAN 生成一段文字
這個會是最困難的
為什麼用 GAN 生成一段文字
會是最困難的呢
我們知道說
如果你要生成一段文字
那你可能會有一個
Sequence To Sequence 的 Model
你有一個 Decoder
那這個 Decoder 會產生一段文字
那我們現在這個
Sequence To Sequence 的 Model
就是我們的 Generator
這個在過去
在講 Transformer 的時候
這是一個 Decoder
那它現在
在 GAN 裡面
它就扮演了 Generator 的角色
負責產生我們要它產生的東西
比如說一 段文字
那你說這個會跟原來的 GAN
在影像上的 GAN 有什麼不同呢
就最 High Level 來看
就演算法來看
可能沒有太大的不同
因為接下來
你就是訓練一個 Discriminator
Discriminator 把這段文字讀進去
去判斷說這段文字是真正的文字
還是機器產生出來的文字
而 Decoder 就是想辦法去騙過 Discriminator
Generator 就是想辦法去騙過 Discriminator
你去調整你的這個 Generator 的參數
想辦法讓 Discriminator 覺得
Generator產生出來的東西是真正的
但是真正的
但是這邊的難點在哪裡呢
這邊的難點在於
你如果要用 Gradient Descent
去 Train 你的 Decoder
去讓 Discriminator Output 分數越大越好
你會發現你做不到
為什麼你做不到呢
大家知道說
在計算這個微分的時候
所謂的 Gradient
所謂的微分
其實就是某一個參數
它有變化的時候
對你的目標造成了多大的影響
我們現在來想想看
假設我們改變了 Decoder 的參數
我們 De 這個 Generator
也就是 Decoder 的參數
有一點小小的變化的時候
到底對 Discriminator 的輸出
有什麼樣的影響
好 Decoder 的參數
如果有一點小小的變化
那它現在輸出的這個 Distribution
也會有小小的變化
那因為這個變化很小
所以它不會影響最大的
那一個 Token 是什麼東西
我知道說 Token
可能對於各位同學來說
你可能會覺得有點抽象
那如果你要想得更具體一點
Token 就是你現在在處理這個問題
處理產生這個 Sequence 的單位
那 Token 呢
是人訂的了
所以假設我們今天
在產生一個中文的句子的時候
我們是每次產生一個 Character
一個方塊字
那方塊字就是我們的 Token
那假設你在處理英文的時候
你每次產生一個英文的字母
那字母就是你的 Token
假設你一次
是產生一個英文的詞
英文的詞和詞之間
是以空白分開的
那就是詞就是你的 Token
好 所以 Token 的定義
是你自己決定的
看你要拿什麼樣的東西
當做你產生一個句子的單位
好 那今天呢
這個 Distribution 只有小小的變化
在取 Max 的時候
在找分數最大那個 Token 的時候
你會發現
分數最大的那個 Token
是沒有改變的
你 Distribution 只有小小的變化
所以分數最大的那個 Token 是同一個
那對 Discriminator 來說
它輸出的分數
它輸出是一模一樣的
這樣輸出的分數就沒有改變
所以你會發現說
當 Decoder 的參數有一點變化的時候
Discriminator 輸出是沒有改變的
所以你根本就沒有辦法算微分
你根本就沒有辦法做 Gradient Descent
有同學可能會說
欸 這個 這邊不是 Max
是因為 Max 造成不能做 Gradient Descent 嗎
那那個 CNN 裡面不是有那個 Max Pooling 嗎
那怎麼還可以做 Gradient Descent
這個問題就留給你自己深思一下
為什麼在這個地方
有 Max 不能做 Gradient Descent
而在CNN有 Max Pooling
卻可以做 Gradient Descent
好 但是就算是不能做 Gradient Descent
你也不用害怕
記不記得我們上週有講說
遇到不能用 Gradient Descent Train 的問題
就當做 Reinforcement Learning 的問題
硬做一下就結束了
所以你確實可以用 Reinforcement Learning
來 Train 你的 Generator
在你要產生一個 Sequence 的時候
你可以用 Reinforcement Learning
來 Train 你的 Generator
但這會發生什麼問題呢
Reinforcement Learning 是以難 Train 而聞名
GAN 也是以難 Train 而聞名
這樣的東西加在一起
就大炸裂這樣 Train 不起來
非常非常地難訓練
所以要用 GAN 產生一段文字
過去一直被認為
是一個非常大的難題
所以有很長一段時間
沒有人可以成功地把 Generator 訓練起來
沒有人成功的可以訓練一個 Generator
用 GAN 的方式
訓練一個 Generator 產生文字
通常你需要先做 Pretrain
那 Pretrain 這件事情
其實我們等一下馬上就會提到
如果你現在還不知道 Pretrain 是什麼的話
也沒有關係
總之過去你沒有辦法用正常的方法
讓 GAN 產生一段文字
直到有一篇 Paper 叫做 ScrachGAN
它的 Title 就開宗明義跟你炫耀說
它可以 Train Language GANs Form Scrach
Form Scrach 就是不用 Pretrain 的意思
好 所以它可以用
它可以直接從隨機的初始化參數開始
Train 它的 Generator
然後讓 Generator 可以產生文字
那它怎麼做到的呢
最關鍵的就是
爆調 Hyperparameter
跟一大堆的 Tips
那你可以想像
這就是 Google 的 Paper
它爆收了參數以後
然後再加上了
這邊就講了很多的 Tips
比如說呢
這個橫軸是它們的 Major
這個叫做 FED
那這個是用在文字上的
我們今天就不講
這不重要
總之這個值越低越好
一開始要有一個叫做 SeqGAN-Step 的技術
沒這個完全 Train 不起來
然後接下來有一個很大的 Batch Size
多大呢
通常就是上千
沒有那個
你自己在家沒辦法這麼做的
Discriminator 加 Regularization
Embedding 要 Pretrain
改一下 Reinforcement Learning 的 Argument
最後就有 ScratchGAN
就可以從真的把 GAN Train起來
然後讓它來產生 Sequence
好 那今天有關 GAN 的部分
我們只是講了一個大概
那如果你想要學最完整的內容
我在這邊留下一個連結給大家參考
那其實有關 Generative 的 Model
不是只有 GAN 而已
還有其他的
比如說 VAE
比如說 FLOW-Based Model
那我在這邊也列了兩個影片的連結
給大家參考
那我想強調一下就是
這邊的影片連結並不是說
我要趕快去把
我一定要看過這些影片連結
才能夠學習接下來的內容
因為機器學習可以講的東西實在太多了
所以如果
假設你沒有太多的時間
那你唯一真正需要聽的
只有我上課講的內容
上課講的內容是 Self Content
它本身是 Consistent 的
你只要每一堂課都有聽
你接下來的內容
你應該都可以依序聽下去
應該都可以聽懂
然後在上課中
會放一些影片的連結
這個就等於是額外分出去的分支
如果你真的很有興趣的話
可以進行深入的研究
那為什麼我們不再講更多東西呢
因為在上課的設計呢
這個課程的內容
是以真正能夠對你有幫助
以實務為導向的
就假設你想要 Train 一個 Generator
你想讓機器可以產生東西
你有很多方法
你可以用 GAN
你可以 VAE
可以用 FLOW-Bases Model
我們這邊就選擇告訴你 GAN
所以以後
你如果有人叫你
Train 一個 Generative Model
你有辦法去 Train 它
那你如果想要深入研究
你可以在研究 VAE 跟 FLOW-Bases Model
那有人可能會問說
為什麼選擇 GAN
為什麼不是選擇其他的 Model 呢
一個最直覺
一個是
一個最直接的理由是
GAN 的 Performance 是比較好的
如果你要產生非常好的圖片的話
你還是今天要用 GAN
通常 VAE 或 FLOW-Bases Model
它們產生的結果
都是跟 GAN 有非常大的一段差距
它們通常都是 Plan 說
我經過了一番努力
暴調了一堆參
爆弄了一堆 Tips
最後可以跟 GAN 差不多而已
所以 GAN 通常
它產生出來的結果還是比較好的
那你可能會說
GAN 比較難 Train
這個比較 Train 吧
VAE 或 FLOW 會不會比較好 Train
這個是
如果你真的有實做 VAE 或 FLOW 的話
它們沒有比較好 Train 老實說
你可能會覺得說
從它的式子上看起來
GAN 很神祕
有一個 Discriminator Generator
它們要互動
然後像 FLOW-Bases Model VAE
它們都比較像是
直接 Train 一個一般的模型
它們有一個很明確的 Objective
但你實際上 Train 起來發現說
它們也沒有那麼容易成功地被訓練起來
它們的 Objective 裡面有很多項
它們的 Loss 裡面有很多項
然後把每一項都平衡
才能夠有好的結果
但要達成平衡也非常地困難
跟 GAN
我覺得 Train 的難度是不遑多讓
所以我們這邊就選擇 GAN 呢
作為我們課堂上介紹的
生成式的 Generative 的 Model
那至於其他 Model
你可以再多多
如果你有興趣
你可以再自己涉獵
好 那有講到這邊
也許有同學會想說
為什麼我們要特別用一些
提出一些新的做法
來做 Generative 這件事
如果我們今天的目標就是
輸入一個 Gaussian 的 Random 的 Variable
輸入一個 Gaussian
從 Gaussian 的這個 Random Variable
Sample 出來的 Vector
把它變成一張圖片
那我們能不能夠用
Supervised Learning 的方法來做呢
怎麼做
也就說我有一堆圖片
我把這些圖片拿出來
每一個圖片都去配一個 Vector
都去配一個
從 Gaussian Distribution
Sample 出來的 Vector
那接下來呢
接下來就當做 Supervised Learning 的方法
硬做就結束了
這樣子大家懂嗎
就是 Train 一個 Nerwork
這個 Network
你已經說這張圖片
就是對到這個 Vector
這張圖片就是對到這個 Vector
Train 一個 Network
輸入一個 Vector
輸出就是它對應的圖片
把對應的圖片當做你訓練的目標
訓練下去就結束了
能不能這麼做呢
能這麼做
真的有這樣子的生成式的模型
那難的點是說
如果這邊
純粹放隨機的向量
Train 起來結果會很差
你可能根本連 Train 都 Train 不起來
所以怎麼辦
你需要有一些特殊的方法
至於什麼樣特殊的方法
你要有一些特殊的方法
去安排這些 Vector
那至於有什麼特殊的方法
我在這邊一樣放兩篇論文的連結
大家發現說這都不是很舊的論文
像這個什麼 Gradient Original Network
這個是去年
去年 20 年 7 月的文章
這都是比較新的論文和比較新的方法
那我把連結放在這邊給大家參考
好 那接下來我們要講的
就是 GAN 的評量
怎麼說
怎麼看說
我們現在產生出來的 Generator
它好或者是不好呢
那要評估一個 Generator 的好壞
並沒有那麼容易
那最直覺的做法
也許是找人來看
你要知道
今天這個 Generator 產生出來的圖片
到底像不像動畫的人物
那就找人直接來看
也許就結束了
所以其實很長一段時間
尤其是人們剛開始研究
Generative 這樣的技術的時候
很長一段時間沒有好的 Major
那時候要評估 Generator 的好壞
都是人眼看
然後直接用吹的這樣
就說在 Paper 最後就放幾張圖說
你看這個
我覺得應該是比文獻上
目前結果都還要好
太棒了
這應該是 （00：16：08）
然後就結束了這樣子
所以發現比較早年的 GAN 的 Paper
它沒有數字
整篇 Paper 裡面沒有這個 In Major
沒有 Accuracy
它就是放幾張圖片告訴你說
這個應該是比過去的文章都好
然後就結束了
但是你知道這樣顯然是不行的嘛
就是完全用人來看
顯然有很多的問題
比如說不客觀
不穩定等等諸多的問題
所以有沒有比較客觀
而且自動的方法
來想辦法量一個 Generator 的好壞呢
如果針對特定的一些任務
是有辦法設計一些方法的
舉例來說
在作業 6 裡面
我們就是要叫大家生成二次元人物的頭像
那在作業裡面一個評估的標準
就是我們跑一個動畫人物人臉偵測的系統
然後看說你提供的那些圖片裡面
抓到幾個動畫人物的人臉
那如果你提供 1000 張圖片裡面
抓到 900 個人臉
跟提供 1000 張圖片
抓到 300 個人臉
那顯然 900 個人臉的
那一個 Generator
它做出來的結果是比較好的
但是這是針對作業 6 的設計
那如果是跟一般的 Case 呢
如果我們不侷限在我們的作業
跟一般的 Case
我隨便訓練了一個 Generator
它不一定是產生動畫人物的
因為它產生別的
它專門產生貓
專門產生狗
專門產生斑馬等等
那我們怎麼知道
它做得好不好呢
那有一個方法呢
是一樣跑一個影像的分類系統
把你的 GAN 產生出來的圖片
丟到一個的影像的分類系統裡面
看它產生什麼樣的結果
影像分類系統輸入是一張圖片
我們這邊叫做 y
輸出呢
是一個機率分布
我們這邊叫它 P ( c│y )
P ( c│y ) 是一個機率的分布
然後接下來我們就看說
這個機率的分布如果越集中
就代表說現在產生的圖片可能越好
雖然我們不知道這邊產生的圖片
裡面有什麼東西
不知道它是貓還是狗還是斑馬
我們不知道它是什麼
但是如果丟到了一個影像分類系統以後
它輸出來的結果
它輸出來的這個分布非常集中
代表影像分類系統
它非常肯定
它現在看到什麼樣的東西
它非常肯定它看到了狗
它非常肯定它看到了斑馬
然後代表說
你產生出來的圖片
也許是比較接近真實的圖片
所以影像辨識系統才辨識得出來
如果你產生出來的圖片是一個四不像
根本看不出是什麼動物
那影像辨識系統就會非常地困惑
它產生出來的這個機率分布
就會非常地平坦
非常地平均分布
那如果是平均分布的話
那就代表說你的 GAN
產生出來的圖片
可能是比較奇怪的
所以影像辨識系統才會辨識不出來
好 所以這個是靠影像辨識系統
來判斷你產生出來的圖片好壞
這是一個可能的做法
但是光用這個做法是不夠的
光用這個做法會有什麼問題呢
光用這個做法你會被一個叫做
這個 Evaluation 的方法
評估的方法會被一個
叫做 Mode Collapse 的問題騙過去
什麼叫 Mode Collapse 呢
Mode Collapse 是說
你在 Train GAN 的時候
你有時候 Train 著 Train 著
就會遇到一個狀況是
假設這些藍色的星星
是真正的資料的分布
紅色的星星是你的 GAN
你的 Generative 的 Model
它的分布
你會發現說 Generative Model
它輸出來的圖片來來去去
就是那幾張
來來去去就是那幾張
可能單一張拿出來
你覺得好像還做得不錯
但讓它多產生幾張就露出馬腳
發現說
原來它就是程咬金只有三斧頭
原來產生出來就只有那幾張圖片而已
那以下是一個 Mode Collapse 的例子啦
就是我們在這個上週有看到說
我就 Train 了一個 Generator
讓它產生二次元的人物
那 Train 著 Train 著 Train 到最後
我就發現變成這樣的一個狀況
這一張臉越來越多
越來越多
而且它還有不同的髮色
這個髮色比較偏紅
這個髮色比較偏黃
越來越多
最後就通通都是這張臉
那這就是一種 Mode Collapse 的現象
那為什麼會有 Mode Collapse
這種現象發生呢
就直覺上你還是比較容易理解
你可以想成說
這個地方就是 Discriminator 的一個盲點
當 Generator 學會產生這種圖片以後
它 Discr
它就永遠都可以騙過 Discriminator
Discriminator 沒辦法看出說
這樣子的圖片是假的
那這是一個 Discriminator 的盲點
Generator 抓到這個盲點就硬打一發
就發生 Mode Collapse 的狀況
那可是到底要怎麼避免
Mode Collapse 的狀況呢
我認為今天其實還沒有一個非常好的解答
舉例來說
我們在上週給大家看到了
BGAN 的結果
就是會產生網球狗那個結果
那是 Google 做的
它也爆收了參數
但就算是它爆收了參數
它發現最終
它仍然沒有辦法真的避免
Mode Collapse 的狀況
就 BGAN Train 到最後
還是 Mode Collapse
那 BGAN 那邊 Paper 怎麼解決這個問題呢
其實很簡單
Model 在 Generator 在訓練的時候
一路上都會把那個 Train Point 存下來
在 Mode Collapse 之前
把 Training 停下來
就 Train 到 Mode Collapse
然後就把之前的 Model 拿出來用
就結束了這樣
所以就算是強如 Google 爆收參數
現在還是沒有辦法徹底解決
Mode Collapse 的問題
好 不過 Mode Collapse 這種問題
你至少你知道有這個問題
你可以看得出有這個問題
你的 Generator 總是產生這張臉的時候
你不會說你的 Generator
是個好的 Generator
你知道說發生了一些狀況
你的 Generator 不是特別地好
但是有另外一種
跟 Mode Collapse 還是有點像
但是更難被偵測到的問題
叫做 Mode Dropping
Mode Dropping 的意思是說
你的真實的資料分布可能是這個樣子
但是你的產生出來的資料
只有真實資料的一部分
單純看產生出來的資料
你可能會覺得還不錯
而且分布
它的這個多樣性也夠
但你不知道說真實的資料
它的多樣性的分布
其實是更大的
我這邊舉一個例子
好 那這邊呢
是一個真實的例子
就有個同學
他 Train 了這個人臉生成的 GAN
那它在某一個 Iteration 的時候
它的 Generator 產生出這些人臉
你會覺得說
沒有問題
而且人臉的多樣性也夠
有男有女
有向左看
有向右看
各式各樣的人臉都有
好 這個是第 T 個 Iteration 的時候 Generator
你也不覺得
它的多樣性有問題
但如果你再看下一個 Iteration
Generator 產生出來的圖片是這樣子的
你有沒有發現問題
它的膚色有問題啊
所以它之前
你看有男有女沒有問題
但是它膚色偏白啊
這邊膚色偏黃啊
你沒弄好人家都覺得
你的 Generator 有種族歧視
所以在這種 Mode Dropping 的問題是
不太容易被偵測出來的
事實上今天到底
今天這些非常好的 GAN
BGAN
Progress GAN BGAN
Progress GAN
可以產生非常真實人臉這些 GAN
到底有沒有 Mode Dropping 的問題
可能還是有的
如果你看多了
GAN 產生出來的人臉
你會發現說
雖然非常真實
但好像來來去去
就是那麼幾張臉而已
它有一個非常獨特的特徵是
你看多了以後就覺得
這個臉好像是被生成出來的
所以今天也許 Mode Dropping 的問題
都還沒有獲得本質上的解決
好 但是我們會需要去量說
現在我們的 Generator
它產生出來的圖片
到底多樣性夠不夠
所以怎麼做呢
過去有一個做法呢
一樣是藉助我們的 Image Classify
你就把一堆圖片
就很像你的 Generator 產生 1000 張圖片
把這 1000 張圖片裡
都丟到 Image Classify 裡面
看它被判斷成哪一個 Class
每張圖片
都會給我們一個 Distribution
給我們一個 Distribution
你把所有的 Distribution 平均起來
接下來看看平均的 Distribution 長什麼樣子
如果平均的 Distribution 非常集中
就代表現在多樣性不夠
如果什麼圖片丟進去
你的影像分類系統都說
是看到 Class 2
看到裡面有 Class 2 這樣的東西
那代表說
每一張圖片也許都蠻像的
你的多樣性是不夠的
那如果另外一個 Case
不同張圖片丟進去
不同張
你的 Generator 產生出來的圖片
丟到 Image Classifier 的時候
它產生出來的輸出的分布
都非常地不同
你平均完以後發現
平均完後的結果是非常平坦的
那這個時候代表什麼
這個時候代表說
也許你的多樣性是足夠的
那你會發現說在評估的標準上
當我們用這個 Image 的 Classifier
來做評估的時候
Diversity 跟 Quality 好像是有點互斥的
因為我們剛才在講 Quality 的時候
我們說
越集中代表 Quality 越高
但是 Diversity 是越平坦
越分布 越平均
代表 Diversity 越大
不過我要強調一下這個 Quality 跟 Diversity
它們評估的範圍不一樣
Quality 是只看一張圖片
一張圖片丟到 Classifier 的時候
分布有沒有非常地集中
而 Diversity 看的是一堆圖片
它分布的平均
一堆圖片你的 Image Classifier 輸出的平均
如果輸出越平均
那就代表
如果輸出的這個平均
越平均的話
這邊有兩個平均啦
那我想大家應該知道我的意思
如果輸出的平均越平均的話
就代表說現在的 Diversity 越大
那過去有一個非常常被使用的分數
叫做 Inception Score
那它的縮寫呢 是 IS
所謂 Inception Score
顧名思義就是這邊用的這個 CNN
是用一個叫做 Trip 來做的
所以叫 Inception Score
那這個 Inception Score 呢
是怎麼訂出來的呢
你就量一下
用 Inception Network 量一下 Quality
如果 Quality 高
那個 Diversity 又大
那 Inception Score 就會比較大
不過在作業裡面
我們並不會用 Inception Score
為什麼我們不用 Inception Score 呢
你想想看
假設把你產生出來的二次元人物
丟到 Inception Net 裡面
它的輸出可能就是都看到人臉嘛
你可能 Diversity 很大
產生不同的髮色
產生不同的眼睛的顏色的人物
但是對 Inception Network 來說
它都是人臉啊
所以你可能算出來 Diversity 其實是小的
所以 Inception Score 在我們這個作業中
可能是不適用的
那在我們的作業中
會採取另外一個 Evaluation 的 Measure
叫 Fréchet 的 Inception Distance
這個東西是什麼呢
它的縮寫叫做 FID
這個東西是什麼呢
你先把你產生出來的二次元的人物啊
丟到 Inception Net 裡面
那如果你把這個二次元人物一路丟丟丟
丟到最後
讓那個 Inception Network 輸出它的類別
那你得到的可能就是人臉
那每一張二次元的人物看起來都是人臉
那我們不要拿那個類別
我們拿進入 Softmax 之前的 Hidden Layer 的輸出
進入 Softmax 之前
你的 Network 不是會產生一個向量嗎
那可能是上千維
長度是上千維的一個向量
把那個向量拿出來
代表這張圖片
那如果我們拿出來的是一個向量
而不是最後的類別
那雖然最後分類的類別可能是一樣的
但是在決定最後的類別之前
這個向量就算都是人臉
可能還是不一樣的
可能會隨著膚色 髮型
這個向量還是會有所改變的
所以我們就不取最後的類別
只取這個 Inception Network 中間的
其實是最後一層的這個 Hidden Layer 的輸出
來代表一張圖片
那在這個投影片上啊
所有紅色的點
代表你把真正的圖片
丟到 Inception Network 以後
拿出來的向量
那這個向量其實非常高維度
是上千維的
那我們就把它假設
我們可以把它畫在二維的平面上
好 那這個藍色的點呢
藍色的點是你自己的 GAN
你自己的 Generator
產生出來的圖片
它丟到 Inception Network 以後
進入 Softmax 之前的向量
把它畫出來
假設是長這個樣子
接下來呢
你就假設這兩組資料
假設真實的圖片跟產生出來的圖片
它們都是 Gaussians 的 Distribution
然後去計算這兩個 Gaussians Distribution 之間的
Fréchet 的 Distance
就結束了
那至於 Fréchet 的 Distance 是什麼
你有興趣再自己看一下文獻
反正在作業裡面
我們的 Judge Systerm 會幫大家算好
好 但是這邊
因為它是一個 Distance
所以這個值就是越小越好嘛
距離就是越小越好
距離越小
代表這兩組圖片越接近
那當然就是產生出來的品質越高
但這邊你一定心裡還是有很多問號
第一個問號就是
當做 Gaussians Distribution 沒問題嗎
這個應該不是 Gaussians Distribution吧
嗯 會有問題 就這樣子
然後另外一個問題就是
如果你要準確的得到你的 Network 它的分布
那你可能需要產生大量的 Sample 才能做到
那這需要一點運算量
那這個也是要做 FID 不可避免的問題
所以其實我們在作業裡面
我們不會只看
我們也不會只看 FID
只看 FID
其實結果會怪怪的
怪怪的 因為你
你假設你的這個輸出的分布一定是 Gaussians 嘛
那它實際上不是 Gaussians
硬假設它是 Gaussians
沒有怪怪的嗎
會怪怪的
所以我們是同時看 FID
跟動畫人物人臉的這個
偵測出來的人臉的數目
這兩個指標
我會同時看這兩個指標
那這樣可以得到比較合理而精確的結果
好 那 FID 算是今天比較常用的一種 Measure
那有一篇 Paper 叫做
Are GANs Created Equal
A Large Scale Study
那你可以想見說這個也是 Google 做的啦
那就是爆做了各式各樣不同的 GAN
有
那個時候它就列舉了好多不同的
各式各樣的 GAN
那每一個 GAN
當然它的這個訓練的這個 Objective
訓練的那個 Loss 有點不太一樣
我這邊就不細講
各式各樣的 GAN
每一種 GAN
它都用不同的 Random Seed
去跑過很多次以後
看看結果怎麼樣
那以下呢
下面這個圖呢
就是在四個不同的資料庫上面得到的結果
那橫軸這邊代表的是不同的 GAN
那這邊的值啊
是越小越好
它是 F
它是 FI
欸 我這邊怎麼寫成 FIT 呢
不好意思 這我寫錯了
不好意思 不好意思
我記得改一下
這個不是 FIT
這個是 FID
這個是 FID 的分數
那這個 FID 的分數就是越小越好啦
那你會發現說
這邊每一個方法呢
它都不是只得到一個數值
它都得到一個分布
為什麼它得到是一個分布呢
因為你要用那個不同的 Random Seed 去跑啊
用不同 Random Seed 去跑
每次跑出來的結果都不太一樣
那這邊混了一個不是 GAN 的做法
混了一個 VAE 在這裡
那你會發現說
如果比較這些 GAN 的方法跟 VAE 的方法
VAE 的方法顯然是比較穩定的
不同的 Random Seed
看起來差距還是比較小的
那 GAN 的方法
不同 Random Seed 差距是很大的
那你又可以很明顯地看出
VAE 跟 GAN
它的這個好的程度啊
不在同一個量級上
GAN 呢
可以產生遠比 VAE 更好的結果
不過你會發現說不同的 GAN
好像結果差不多
所以這邊就
那抬頭就是 Are GANs Created Equal
然後看起來所有的 GAN 都差不多
然後農場文最喜歡這種文章啊
它就會說
啊 所有的 GAN 都差不多啦
所以那跟 GAN 有關的研究都是白忙一場
但是其實事實上也未必是如此
如果你仔細看那篇文章的話
在做實驗的時候
所有這些不同的 GAN 用的 Network 架構
都是同一個
它只是爆收了那個
Random Seed 跟 Learning Rate 而已
所以 Network 架構還是同一個
那所以我們不知道說
是不是有某些 Network 架構
特別 Favor 某些
某些種類的 GAN
或者是某些種類的 GAN
會不會在不同的 Network 架構上
表現得比較比較穩定
比如說如果你看 WGAN 的話
WGAN 最原始的 Paper
它標榜的其實是它 Network 架構胡亂設計
它胡亂兜個什麼 100 層的 Generator
就很沒有必要弄一個 100 層的 Generator
它也 Train 得起來
所以也許 WGAN 是在不同的 Generator
不同的 Network 架構的時候比較穩定
那你試不同的 Random Seed
可能沒有特別穩定等等之類的
不知道
這篇 Paper 並沒有給我們這方面的答案
好 那其實剛才那些 Measure 也完全
也並沒有完全解決 GAN 的問題
Evaluation 的問題
因為還有什麼 Evaluation 的問題呢
你想想看以下的狀況
假設這是你的真實資料
你不知道怎麼回事
訓練了一個 Generator
它產生出來的 Data
跟你的真實資料一模一樣
所以如果你不知道真實資料長什麼樣子
你光看這個 Generator 的輸出
你會覺得太棒了
它做得很棒
那 FID 算出來
一定是非常小的
但問題是這個是你要的嗎
如果它產生出來的圖片都跟資料庫裡面的
訓練資料的一模一樣
訓練資料就在你手上
直接從訓練資料裡面
Sample 一些 Image 出來不是更好
幹嘛要 Train Generator
我們 Train Generator 其實是希望它產生
新的圖片啊
資料集裡面
訓練資料裡面沒有的人臉啊
如果訓練資料裡面有一模一樣的人臉
直接用訓練資料裡面的人臉就好了
何必用 GAN 呢
所以有時候你的 GAN 產生出來的結果很好
也許你在作業裡面
FID 算出來也很低
然後人臉辨識系統也給你很高的分數
但是它不一定是一個好的 GAN
那像這種問題
就不是我們作業的 Measure 可以偵測的
但是它是一個問題
那怎麼解呢
你可能會說
那我們就把
我們 Generator 產生出來的圖片
跟真實資料比個相似度吧
看看是不是一樣嘛
如果很多張都一樣就代表說
Generator 只是把那個訓練資料背起來而已
它沒有很厲害
但是那如果我問另外一個問題
假設你的 Generator 學到的是
把所有訓練資料裡面的圖片都左右反轉呢
那它也是什麼事都沒有做啊
假設它學到就是
把訓練資料裡面所有的圖片都左右翻轉
那你會覺得
嗯 它看起來很棒
它實際上也是什麼事都沒有做
但問題是你比相似度的時候
又比不出來
所以 GAN 的 Evaluation
是非常地困難的
還甚至 光要如何評估
一個 Generator 做得好不好這件事情
都是一個可以研究的題目
如果你真的很有興趣的話
這邊放了一篇相關的文章啦
裡面就列舉了二十幾種
GAN Generator 的評估的方式
給大家參考
好 那接下來呢
我們要講 Conditional 的 Generation
那也許我們講了conditional 的 Generation 以後
再下課
然後接下來就是讓助教來講一下 GAN 的作業
好 那什麼是 Conditional 的 Generation 呢
剛才我們講的那個 Generator
到目前為止我們講的 Generator
它輸入都是一個隨機的分布而已
那這個不見得非常有用
我們現在想要更進一步的是
我們可以操控 Generator 的輸出
我們給它一個 Condition x
讓它根據 x 跟 z 來產生 y
那這樣的 Conditional Generation
有什麼樣的應用呢
比如說你可以做文字對圖片的生成
那如果你要做文字對圖片的生成
它其實是一個 Supervised Learning 的問題
你需要一些 Label 的 Data
你需要去蒐集一些圖片
蒐集一些人臉
然後這些人臉都要有文字的描述
告訴我們說
這個是紅眼睛
這個是黑頭髮
這個是黃頭髮
這個是有黑眼圈等等
告訴我們這樣子
我們要這樣的 Label 的資料
才能夠訓練這種 Conditional 的 Generation
所以在 Text To Image 這樣的任務裡面
我們的 x 就是一段文字
那你可能問說
一段文字怎麼輸入給 Generator 呢
那就要問你自己了
你要怎麼做都可以
以前會用 RNN 把它讀過去
然後得到一個向量
再丟到 Generator
今天也許你可以把它丟到一個
這個 Transformer 的 Encoder 裡面去
把 Encoder Output 這些向量通通平均起來
丟到 Generator 裡面去
怎麼樣都可以 反正
你用什麼方法都可以
只要能夠讓 Generator 讀一段文字就行
好 那你期待說你輸入 Red Eyes
然後呢
機器就可以畫一個紅眼睛的角色
但每次畫出來的角色都不一樣
那這個畫出來什麼樣的角色
取決於什麼呢
取決於你 Sample 到什麼樣的 z
Sample 到不一樣的 z
畫出來的角色就不同
但是通通都是紅眼睛的
這個就是 Text To Image 想要做的事情
真的可以做到這樣子的事情嗎
可以
這個過去有這個作業啦
這學期雖然沒有
但過去有這個作業
就是輸入紅頭髮
這個是之前助教做的結果
輸入紅頭髮
輸入綠眼睛
那產生的結果就是這個樣子
產生各式各樣紅頭髮 綠眼睛的角色
輸入藍頭髮 紅眼睛
就產生各式各樣藍頭髮 紅眼睛的角色
你發現
那個有時候機器也是會犯錯的啦
比如說這邊有一個異色瞳
雖然說要畫紅眼睛
但它覺得畫一隻紅色的眼睛就可以矇混過去
另外一隻眼睛仍然是藍色的
那要怎麼做 Conditional 的 GAN 呢
我們現在的 Generator 有兩個輸入
一個是從 Normal Distribution
Sample 出來的 z
另外一個是 x
也就是一段文字
那我們的 Generator 會產生一張圖片 y
那我們需要一個 Discriminator
那如果按照我們過去所學過的東西
Discriminator
它就是吃一張圖片 y 當作輸入
輸出一個數值
這個數值代表輸入的圖片
多像真實的圖片
是真實的
還是生成的
那怎麼訓練這個 Discriminator 呢
你就說如果看到真實的圖片
你就輸出 1
如果看到生成的圖片
就輸出 0
你就可以訓練 Discriminator
然後 Discriminator 跟 Generator 反覆訓練
也許你就可以去把 Generator 訓練出來
但這樣的方法
沒辦法真的解 Conditional GAN 的問題
為什麼呢
因為如果我們只有 Train 這個 Discriminator
這個 Discriminator 只會看 y 當做輸入的話
那 Generator 會學到的是
它會產生可以騙過 Discriminator 的
非常清晰的圖片
它會產生清晰的圖片
但是跟輸入完全沒有任何關係
因為對 Generator 來說
它只要產生清晰的圖片
就可以騙過 Discriminator 了
它何必要去管 Input 文字敘述是什麼呢
你的 Discriminator 又不看文字的敘述
所以它根本就不需要管文字的敘述
你不管輸入什麼文字
就無視這個 x
反正就是產生一個圖片
可以騙過 Discriminator 就結束了
但這顯然不是我們要的
所以在 Conditional GAN 裡面
你要做有點不一樣的設計
你的 Discriminator 不是只吃圖片 y
它還要吃 Condition x
所以你的 Discriminator
它有 y 作為輸入
有 x 作為輸入
然後產生一個數值
那這個數值不只是看 y 好不好
光圖片好
沒有用
光圖片好
Discriminator 還是不會給高分
什麼樣的情況下 Discriminator 才會給高分呢
一方面圖片要好
另外一方面圖片跟 x
就是文字的敘述
它們必須要配得上
這個圖片跟文字的敘述必須要是相配的
Discriminator 才會給高分
那怎麼樣訓練這樣的 Discriminator 呢
那你需要文字跟影像成對的資料
所以 Conditional GAN
一般的訓練
是需要這個 Pair 的 Data 的
是需要有標註的資料的
是需要成對資料的
有這些成對資料
那你就告訴你的 Discriminator 說
看到這些真正的成對的資料
就給它一分
看到 Red Eyes
但是搭配
欸 這邊我也不知道為什麼會是這個樣子
不過沒有關係
反正我這邊本來就是沒有要放什麼特別的東西
就放個亂七八糟的圖而已
好 可能 Red Eyes 跟機器產生出來的圖片
那就是給 0 分
然後訓練下去
就可以產生
就可以做到 Conditional GAN
那其實在實作上啊
光是這樣子
拿這樣子的 Positive Sample
還有 Negative Sample
來訓練這樣的 Discriminator
其實你得到的結果往往不夠好
光是告訴 Discriminator 說
這樣子的狀況是好的
這樣子的狀況是不好的
這樣是不夠的
你還需要加上一種不好的狀況是
已經產生好的圖片
但是文字敘述配不上的狀況
所以你通常會把你的訓練資料拿出來
然後故意把文字跟圖片亂配
故意配一些錯的
然後告訴你的 Discriminator 說
看到這種狀況
你也要說是不好的
用這樣子的資料
你才有辦法把 Discriminator 訓練好
然後 Generator 跟 Discriminator
反覆的訓練
你最後才會得到好的結果
這個就是 Conditional GAN
好 在目前的例子裡面都是
看一段文字產生圖片
那 Conditional GAN 的應用
不只看一段文字產生圖片啦
也可以看一張圖片
產生圖片
那看一張圖片產生圖片
也有很多的應用
比如說
給它房屋的設計圖
然後讓你的 Generator 直接把房屋產生出來
給它黑白的圖片
然後讓它把顏色著上
給它這個素描的圖
讓它把它變成實景 實物
那給它這個白天的圖片
讓它變成晚上的圖片
有時候你會給它
比如說起霧的圖片
讓它變成沒有霧的圖片
把霧去掉
好 所以 Conditional GAN
除了輸入文字 產生影像以外
也可以輸入影像 產生影像
那像這樣子的應用啊
叫做 Image 的 Translation
那有人又叫做 Pix2pix
這個 Pix 就是 Pixel
就是像素的縮寫啦
所以叫做 Pix2pix
好 那怎麼做呢
跟剛才講的從文字產生影像
沒有什麼不同
現在只是從影像產生影像
把文字的部分用影像取代掉而已
那當然同樣的做法
同樣要產生這樣的 Generator
產生一張圖片
輸入一張圖片 產生一張圖片
你當然可以用 Supervised Learning的方法
那在文獻上你會發現說
如果你用 Supervised Learning 的方法
你得不到非常好的結果
通常你用 Supervised Learning 的方法
訓練一個圖片生圖片的 Generator
你產生出來的結果可能是這個樣子
就是這是你的 Generator 的輸入
那這個是你 Generator 的輸出
那你會發現說它非常地模糊
為什麼它非常地模糊呢
你可以直覺想成說
因為同樣的輸入
可能對應到不一樣的輸出
就好像我們在講 GAN 剛開始的
開場的時候講的那個例子
今天在同一個轉角
那個小精靈可能左轉
也可能右轉
最後學到的
就是同時左轉跟右轉
那對於 Image To Image 的 Case
也是一樣的
輸入一張圖片
輸出有不同的可能
機器學到的
Generator 學到的
就是把不同的可能平均起來
結果變成一個模糊的結果
所以這個時候我們需要用 GAN 來 Train
你需要加一個 Discriminator
Discriminator 它是輸入一張圖片
還有輸入 Condition
然後它會同時看這個圖片跟這個 Condition
有沒有匹配
來決定它的輸出
那這個是文獻上用 GAN 的輸出
從右上角這篇 Paper 截取出來的
那你會發現說
如果單純用 GAN 的話
它有一個小問題
所以它產生出來的圖片呢
比較真實
但是它的問題是它的創造力呢
想像力過度豐富
它會產生一些輸入沒有的東西
沒有叫它輸入的東西
舉例來說
這是一個房子
左上角明明沒有其他東西
這邊它卻在屋頂上
加了一個不知道是煙囪還是窗戶的東西
那文獻上如果你要做到最好啊
往往就是 GAN 跟 Supervised Learning
同時使用啦
那同時使用
往往可以給你最好的結果
那所謂同時使用的意思就是
Generator 在訓練的時候
一方面它要去騙過 Discriminator
這是它的一個目標
但同時它又想要產生一張圖片
跟標準答案越像越好
它同時去做這兩件事
那往往產生出來的結果是最好的
那 Conditional GAN 還有很多應用啦
這邊給大家看一個莫名其妙的應用
就是給 GAN 呢
聽一段聲音啦
然後呢
它產生一個對應的圖片啦
什麼意思呢
比如說給它聽一段狗叫聲
看它能不能夠畫出一隻狗啦
好 那我剛才講說 Conditional GAN 需要這個
Label 的資料
需要成對的資料
那這個聲音跟影像成對的資料
其實並沒有那麼難蒐集
因為你可以爬到大量的影片
那影片裡面有影像 有畫面
也有聲音訊號
那你就知道說
這一個畫面 這一幀
這一幀的圖片
這一幀的畫面
對應到這一小段聲音
這一幀的畫面對應到這一小段聲音
把這些資料蒐集起來
你就可以 Train 一個 Conditional GAN
聽一段聲音
讓它想像它聽到的場景
是什麼樣子的
好 那這個是我們實驗室有個同學做的
然後這個是一個真正的 Demo
這個是一個那個真正的 Demo 啦
那機器聽這樣的聲音
好 這聽起來有點像是這個電視機壞掉的聲音
那機器覺得它聽到什麼呢
剛才那一段聲音機器覺得
它聽到一個小溪
聽到一個小瀑布
或者是我們再聽另外一段聲音
機器覺得它聽到一艘快艇在海上奔馳
當然我有點擔心說
欸 這個會不會機器並沒有真的學到
聲音跟圖片之間的關係
會不會它只是把
它在訓練資料裡面有看過的圖片存起來而已
所以我決定把聲音調大
你聽看看結果會怎樣
所以我們把聲音調大
接下來真的很大聲哦
好 然後聲音越來越大
你就發現說
這個溪流裡面的水花就越來越多
從一條小溪
變成尼加拉瓜瀑布
然後剛才的這個快艇的例子也是一樣
就把快艇的聲音變大
你聽看看會怎樣
當聲音越來越大的時候
你發現快艇旁邊的水花就越來越多
好像快艇開得越來越快
不過我要承認
這個其實是稍微 Cherry Pick 的結果
就稍微挑過的結果
很多時候覺得 Generator 產生出來的東西
就是這個樣子啦
不知所云這樣
這就給它一個鋼琴聲
然後它好像想畫一個鋼琴
但又沒有很清楚
這個是給它聽狗叫聲啦
好像想畫一個動物
但又不知道要畫些什麼
這個是聲音到影像的產生
好 那我看到最近最驚人的
Conditional GAN 的應用啊
是有人用 Conditional GAN 產生會動的圖片
我們知道在哈利波特裡面
那些人物的畫像是會動的
是會說話的
那 Samsung 呢
就做了一個類似的應用
用 GAN 做的
給它一張圖片
比如說蒙娜麗莎的畫像
然後就可以讓蒙娜麗莎開始講話
這個是 Conditional GAN 的其中一個應用
我把論文放在這邊給大家參考
好 那講到這邊呢
正好告一個段落
也許我們先休息一下
我們十分鐘後再回來
那等一下呢
助教會講作業 6
