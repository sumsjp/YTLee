好 那個講完 Domain Adaptation 以後
我們就稍微休息一下
然後下一堂課就會播放助教的錄影
其實助教在講 Domain Adaptation 這一段
講得非常地清楚
所以我們這邊就會比較快地帶過
那等一下如果你有聽不清楚的地方
其實等一下助教的錄影
你還有機會再聽一次
如果等一下講的東西
雖然我講得有點快
但你已經聽得非常懂了
那等一下播助教錄影的時候
你就休息一下 去做其它事情
好 那我們呢
就開始來講 Domain Adaptation 的部分吧
好 到目前為止
我們已經訓練了很多
Machine Learning 的 Model
所以對大家來說
訓練一個 Classifier 完全不是一個問題
所以假設要你訓練一個數字的 Classifier
你只要有給你訓練資料
你訓練好一個模型
然後 Apply 在 用在測試資料上就結束了
那像數字辨識這麼簡單的問題
你在 Benchmark Corpus
在（00：01：04）Benchmark Corpus 上
隨便做一做
可能都會做到 99.5% 的正確率
但是假設今天測試資料
跟訓練資料的分布不一樣
怎麼辦呢
我們舉一個簡單的例子
假設訓練的時候
你的數字是黑白的
但測試的時候
你的數字是彩色的
會發生什麼樣的事情呢
你可能會覺得說
一邊是黑白的 一邊是
雖然一邊是黑白的 一邊是彩色的
但是對 Model 來說
數字的形狀是一樣的
它能夠在黑白的圖片上認出數字來
在彩色的圖片上
會不會應該也可以認出數字來呢
但實際上不是
如果你今天在這樣子黑白的數字上面
訓練一個模型
直接用到彩色的數字上
你得到的正確率會非常地低
會低到只有 57%
不能算是一個及格的分數
所以我們今天知道說
一旦訓練資料跟測試資料
它中間有一些差異
它們中間的分布是不一樣的
你在訓練資料上訓練出來的模型
在測試資料上面可能就會壞掉
那這種問題 叫做 Domain Shift
也就是當你的訓練資料跟測試資料
它的分布有些不同的時候
這種狀況叫做 Domain Shift
在多數的這種作業裡面
或者是 Benchmark Corpus 裡面
我們都假設無視 Domain Shift 這個問題
我們的訓練資料跟測試資料
往往有著一樣的分布
那這樣都會給大家一個錯誤的印象就是
哇 這個今天的什麼人工智慧
真的是很厲害
都超越人類啦
在很多任務上面都有極高的正確率
但是實際上用在真實的應用上
當你的訓練資料跟測試資料的中間
有一點差異的時候
機器能不能夠做得好
就是一個未知數了
那我們今天就是要來講說
假設訓練資料跟測試資料
有一點差異的時候
有沒有什麼方法可以讓我們
能夠做得比什麼都不做結果還要好
好 那今天就是要講 Domain Adaptation 的技術
那 Domain Adaptation 的技術
也可以看做是 Transfer Learning 的一種
怎麼說呢
Transfer Learning 就是
你在 A 任務上學到的技能
可以被用在 B 任務上
那對於 Domain Adaptation 來說
你的訓練資料是一個 Domain
你的測試資料是另外一個 Domain
你在訓練資料上面
某一個 Domain 上學到的資訊
你要把它用到另外一個 Domain
用到測試資料上面
所以你是把一個 Domain 學到的知識
用在另外一個 Domain 上
所以它可以看做是
Transfer Learning 的其中一個環節
那在過去上課的錄影裡面
有完整的講了 Transfer Learning 相關的技術
那因為今天時間有限
我們就只 Focus 在
Domain Adaptation 的部分就好
如果你有興趣的話
你可以再看一下過去上課的錄影
好 那 Domain Shift
其實有很多種不同的類型
我們剛才看到的
只是 Domain Shift 的其中一種可能
是模型輸入的資料的分布有變化的狀況
那輸入分布有變化是一種可能性
其實還有另外一種可能性是
輸出的分布也可能有變化
舉例來說 在你的訓練資料上面
可能每一個數字它出現的機率都是一樣的
但是在測試資料上面
可能每一個輸出的機率是不一樣的
有可能某一個數字它輸出的機率特別大
有沒有可能有這種事情發生呢
這也是有可能的
那這也是一種 Domain Shift
還有一種更罕 比較罕見
但也不是完全不可能發生的狀況是
輸入跟輸出雖然分布可能是一樣的
但它們之間的關係變了
也許在你的訓練資料裡面
這種東西叫做 0
但是在你的測試資料裡面
這種東西叫做 1
這也不是不可能的
也是有可能發生這種狀況嘛
也是有可能發生說
輸入跟輸出它們的關係不一樣
在訓練跟測試資料不一樣的狀況
那這又是另外一種 Domain Shift
那我們今天呢 只專注在
輸入資料不同的 Domain Shift 的上面
好 那在等一下的課程裡面
這個測試的資料
我們說它來自 Target Domain 訓練的資料
我們說它來自 Source Domain
所以 Source Domain 是我們的訓練資料
Target Domain 是我們的測試資料
好 那在 Domain Adaptation 裡面
我們的這個情境是這個樣子的
我們有一堆訓練資料
那這邊我們就直接拿手寫數字辨識
來當作我們的例子啦
我們有一堆訓練資料
那這些資料來自 Source Domain
而且這些訓練資料是有標註的
我們知道每張圖片對應的數字是什麼
但是我們希望再用這些資料
訓練出一個模型
這個模型可以用在不一樣的 Domain 上
那要把這個模型用在不一樣的 Domain 上
在訓練的時候
我們就必須要對另外一個 Domain
也就是現在測試資料所在的 Target Domain
有一些了解
那隨著了解的程度不同
我們就有不同的 Domain Adaptation 的方法
那了解最多的是
假設我們在 Target Domain 上
我們有一點資料
而且這些資料居然還有 Label
那這是一種情況
但還有另外一種更好的狀況是
也許你根本在 Target Domain 上
就有一大堆的資料
那些資料也都有 Label
那你其實就不需要做 Domain Adaptation
你直接拿 Target Domain 的資料來訓練就好了
所以如果你在 Target Domain 上
已經有一大堆的資料
而且它們還有標註
那你不需要做 Domain Adaptation
那要做 Domain Adaptation 的情境可能是
你有 Target Domain 的資料 也有標註
但是量非常地少
那在這種狀況下怎麼辦呢
那這種狀況還算是在 Domain Adaptation 裡面
比較容易處理的狀況
如果你今天遇到的是
有標註資料 只是資料量很少的情況下
你可以用這些有標註的資料
來微調你在 Source Domain 上訓練出來的模型
那這邊所謂的微調
就跟你在做 BERT 的時候的行為很像
就是你已經有一個在 Source Domain 上
訓練好的 Model
那你拿 Target Domain 的 Data
只稍微跑個兩 三個（Edpa）就足夠了
好 那在這一種情境下
你需要注意的問題就是
因為你的 Target Domain 的資料量非常少
所以你要小心 不要 Overfit
也就是說 你不要在 Target Domain 上的資料上
跑太多的 Iteration
那如果你跑太多的 Iteration
可能會 Overfit 到 Target 的這些少量的資料上
然後呢 你在你真正的 Testing Set 上就做不好
這是有可能的
那為了避免 Overfitting 的情況
過去就有很多的 Solution
比如說 把 Learning Rate 調小一點
舉例來說 你要讓（Find To）前
跟（Find To）後的模型的參數
不要差很多
或者是讓（Find To）前
跟（Find To）後的模型
它的輸入跟輸出的關係
不要差很多 等等
那有很多不同的方法
那這邊呢 我們就不細講
好 那今天主要想要跟大家分享的情境
也是我們作業要處理的情境是
我們在 Targe Domain 上有大量的資料
但是這些資料是沒有標註的
你的 Targe Domain 是有顏色的數字
你也蒐集到了一大堆有顏色的數字的圖片
但是沒有人標註說
每一張圖片裡面的數字是什麼
那我們在作業裡面要處理的就是
遇到這種狀況的時候
到底應該要怎麼解呢
好 到底應該要怎麼解呢
那像這種情境
其實是蠻符合你在真實的系統上
有可能會發生的情境
舉例來說 你在實驗室裡面訓練了一個模型
你想要把它用在真實的場域裡面
你就把你的模型上線
那確實有一些人來用
但是你發現你得到的 Feedback 很差
大家都嫌棄你的系統正確率很低
那怎麼辦
但是你這個時候
你也許就可以用 Domain Adaptation 的技術
那因為你的系統已經上線
也真的有人使用
所以你可以蒐集到一大堆的資料
只是這些資料它們是沒有標註的
那現在要問的問題是
怎麼用這些沒有標註的資料
來幫助我們在 Source Domain 上
訓練出一個模型
它可以用在 Targe Domain 上呢
那這邊最 Basic 的想法是這個樣子的
這邊基本的概念是這個樣子
我們想要找一個 Feature Extractor
這個 Feature Extractor
它其實也是一個 Network
這個 Network 呢 吃一張圖片作為輸入
它吐出一個 Factor
吐出一個 Feature
雖然 Source Domain 跟 Target Domain
它們的 Image 表面上看起來不一樣
但是 Feature Extractor
會把它們不一樣的部分拿掉
只抽取出它們共同的部分
所以雖然從圖片上看起來
這兩組圖片一個有顏色 一個沒有顏色
它本來就很不一樣
但是我們期待說
這個 Feature Extractor 可以學到
就無視顏色這件事情
把顏色的資訊濾掉
那今天不管是來自 Source Domain 的圖片
還是來自 Target Domain 的圖片
只要通過這個 Feature Extractor 以後
它得到的 Feature 看起來是沒有差異的
它們看起來有一樣的分布
那這樣你就可以用這些 Feature
訓練一個模型
在 Source Domain 上訓練一個模型
直接用在 Target Domain 上
那接下來的問題就是
怎麼找出這樣一個 Feature Extractor
好 怎麼找出這樣的一個 Feature Extractor 呢
那其實我們可以把一個一般的 Classifier
就分成 Feature Extractor
跟 Label Predictor 兩個部分
我們知道一個 Image 的 Classifier
就是輸入一張 Image Output
就是分類的結果
那假設這個 Image 的 Classifier 有 10 層
那我們就說
前 5 層算是 Feature Extractor
後 5 層算是 Label Predictor
因為前 5 層
你一個 Image 通過前 5 層
它輸出就是一個 Factor 嘛
那如果你上 CNN 的話
它輸出其實是 Feature Map 啦
但 Feature Map 拉直
也可以看做是一個 Factor 嘛
那這個 Factor
再丟到 Label Predictor 的後面 5 層
它會產生 Class
那所以我們可以把前 5 層
看做是 Feature Extractor
那你可能會問說
那為什麼是前 5 層呢
為什麼不是前 4 層 前 3 層 前 2 層 前 1 層呢
可以是前 4 前 3 前 2 前 1
這個是你自己決定的
一個 Classifier 裡面
哪些部分算 Feature Extractor
哪些部分算是 Label Predictor
這個是你自己決定的
那這個也算是一個 Hyper Parameter 啦
就跟 Network 架構要調一下一樣
要調一樣
那如果你今天呢
用 Domain Adaptation 的方法
那這邊等一下要用的方法叫
Domain Adversarial Training
用 Domain Adversarial Training
你要把 Classifier 裡面的哪個部分 哪幾層
當做 Feature Extractor
這個也要問你自己
那這個也是你自己要決定的
好 那我們現在要怎麼來訓練這個
Feature Extractor 跟 Label Predictor 呢
今天對於 Source Domain 上的資料
Source Domain 上的資料是有標註的
我們就期待把 Source Domain 的資料丟進去
那就去跟訓練一個一般的分類器一樣
它通過 Feature Extractor
再通過 Label Predictor
可以產生正確的答案
但不一樣的地方是
Target Domain 的這些資料
我們有一堆 Target Domain 的資料
但這些資料是沒有任何的標註的
這些資料是沒有任何的標註的
所以我們不能說
把這些資料丟進去以後
期待 Label Predictor 會 Output 什麼數字
因為我們根本不知道 Label Predictor
要 Output 什麼數字才是對的
但是這些資料可以怎麼被使用呢
這些資料的使用方式就是
我們把這些圖片丟到這個 Image
丟進這個 Image Classifier
然後我們把
Feature Extractor 的 Output 拿出來看
拿出來看以後
我們希望 Source Domain 的圖片
丟進去的 Feature
跟 Target Domain 的圖片丟進去的 Feature
它們看起來要分不出差異
就是這個 Source Domain 的圖片
我們用它的 Feature
我們用藍色的點來表示
Target Domain 的圖片
它的 Feature 我們用紅色的點來表示
我們要這些藍色的點跟這些紅色的點
分不出差異
那怎麼讓藍色的點跟紅色的點
分不出差異呢
那這個就要藉由
Domain Adversarial Training 的技術
那等一下如果你覺得這一段講得有點快
也沒有關係
等一下助教會再更詳細地講過一次
好 那我們現在要做的事情就是
訓練一個 Domain 的 Classifier
這個 Domain 的 Classifier
它就是一個二元的分類器
它吃這個 Factor 當作輸入
它要做的事情就是判斷說
這個 Factor 是來自於 Source Domain
還是來自於 Target Domain
它要判斷這個 Factor
是來自 Source Domain
還是來自 Target Domain
而 Feature Extractor 它學習的目標
就是要去想辦法騙過這個 Domain Classifier
那聽到騙過這件事情
欸 是不是讓你腦中就浮現了
Gan 這個東西
是不是就浮現了
Generative Adversaria Network 這個東西呢
沒錯 Domain Adversarial Training
就非常像是 Gan
你可以把 Feature Extractor
想成是 Generator
把 Domain Classifier
想成是 Discriminator
那其實 Domain Adversarial Training
最早的 Paper
我記得是發表在 2015 年的 ICML 上面
比那個 Gan 還要稍微晚一點點啦
不過它們幾乎可以說是同時期的作品
在 Domain Adversarial Training 那篇 Paper 裡面
是有引用到 Gan 那篇 Paper
但那時候 Gan 那篇 Paper
還沒有上（00：15：09）
所以它只說
欸 有一篇 有另外一篇 Paper
它提了一個叫 Gan 的想法
然後它是 Technical report 放在網路上的
還跟我的想法有點像
所以它們算是一個同時期的作品
好 但是講到這邊
這個 Domain Adversarial Training
跟 Gan 還是有一點不一樣
那在這個遊戲裡面
對 Generator 好像優勢太大了
那對 Generator 來說
它要騙過 Discriminator
完全不需要花什麼力氣
有一個非常無腦的做法
就是你的 Feature Extractor
也就是你的 Generator
不管看到什麼輸入
永遠都輸出 0 就好了
看到什麼輸入我都輸出一個 Zero Factor
那對 Domain Classifier 來說
它完全不知道 Input 的 Image 是什麼
它永遠都看到 Zero Factor
它就完全無法分辨這個 Factor
來自於哪一個 Domain
但是這顯然不是我們要的狀況
如果 Feature Extractor 只會輸出 Zero Factor
那這樣子等於根本就什麼事都沒有做是一樣的
那這件事情會發生嗎
其實這件事情是不會發生的
為什麼
因為 Label Predictor 也需要這個 Feature
Label Predictor 它也需要這個 Feature
讓它可以去判斷
輸入的圖片屬於哪一個類別
所以假設 Generator 它就直接放一個大絕說
今天不管輸入什麼樣的 Image
我輸出都是 Zero Factor
那對於 Label Predictor 來說
它就沒有辦法判斷是哪一張圖片
那在這個情況下
因為 Feature Extractor
它還是需要產生這個 Factor
讓 Label Predictor 可以產生正確的圖片
所以 Feature Extractor 它就不能放大絕
它就不能看到什麼東西
永遠都輸出 Zero Factor
好 那這邊呢
我們用符號再稍微把我們剛才講過的事情
再重新說 說得更清楚一點
假設 Label Predictor 的參數
我們就叫它 θp
Domain Classifier 的參數 叫做 θd
然後 Feature Extractor 的參數 叫做 θf
然後呢 這個 Source Domain 上的這些 Image
它的 Classification 的這個 Cross Entropy
就 Source Domain 這些 Image
它是有 Label 的
所以你可以算它們的 Cross Entropy
你根據它們的 Cross Entropy
訂出一個 Loss
而 θp 它的
喔 這邊還沒有講 θp
這邊是有一個 L
L 是這個 Domain 的這個
這個 Source Domain 上的那些 Image
它有 Label
你可以算出 Cross Entropy
然後對於這個 Domain 的 Classifier 而言
它要去想辦法分辨
Source 跟 Target Domain 的差距
它要去做一個
Binary 的 Classification 的問題
它要去做一個二元分類的問題
這個分類的問題有一個 Loss 叫做Ld
那我們現在要去找一個 θp
它可以讓這個 L 越小越好
我們要去找一個 θd
它可以讓這個 Ld 越小越好
你說 Label Predictor 它要做的事情
就是讓這個 Source Domain 的 Image
分類越正確越好
Domain Classifier 要做的事情
就是讓 Domain 的分類越正確越好
而 Feature Extractor 呢
Feature Extractor 它要做的事情是
它站在 Label Predictor 這邊
然後呢 它要去捅 Domain Classifier 一刀
它要去做 Domain Classifier 相反的事情
所以這個 Feature Extractor
它的 Loss 是 Label Predictor 的 Loss L
去減掉 Domain Classifier 的 Loss
叫做 Ld
喔 所以 Feature Extractor 它的 Loss
就是大 L 減掉 Ld
你要去找一個參數 找一組參數 θf
它可以讓大 L 減 Ld 的值越小越好
好 這個是最原始的
Domain Adversarial Training 的做法
但這真的是最好的做法嗎
你可以想想看喔
那這個詳情我們就不細講
這個留給大家自己思考 自己發覺
你想想看喔
假設 Domain Classifier 它的工作
是要把 Source Domain 跟 Target Domain 分開
是要看到這種圖片
它知道它的 Feature 來自 Source Domain
看到這種圖片
它知道它的 Feature 來自 Target Domain
它要把這兩組 Feature 分開
而 Feature Extractor 如果它的 Loss
是 Domain Classifier 直接加一個負號
那意味著什麼
意味著說 它要做的事情
就是跟 Domain Classifier 相反
本來 Domain Classifier 看到這張圖片的 Feature
它說是 Source
那現在 Feature Extractor
是要讓 Domain Classifier 看到這個圖片以後
它說是 Target
看到這個圖片 反過來要說是 Source
如果你這麼做
不是也把兩組 Feature 分開來了嗎
我們說我們現在要做的事情
是要讓 Domain 跟
這個 Source 跟 Target Domain 沒有差別
但是你今天不管是用 Ld
還是負的 Ld
其實都是要
把 Source 跟 Target Domain 分開呀
你去讓 Ld 的值
本來 Domain Classifier
是要讓 Ld 的值越小越好
你現在是負的 Ld
Feature Extractor 要讓 Ld 的值越大越好
其實也是把 Source 跟 Target Domain分開
所以這未必是最好的做法
至於怎麼做
當然這招是有用的
這招是有用的
那但是怎麼做可以做得更好
欸 這個留給大家慢慢思考
好 那我們來看一下
Domain Adversarial Training
最原始的 Paper
它做的結果怎麼樣呢
當年看到這個 Paper 的時候
真的覺得結果非常地驚人
好 那這邊呢 它做了四個任務
那上半部 是 Source Domain 的圖片
這邊其實都是數字辨識啦
那下半部呢 都是 Target Domain 的圖片
好 如果今天呢
我們是拿 Target Domain 的圖片來做 Training
Target Domain 的圖片來做 Testing
那結果像是這個樣子
每一個任務正確率都是 90% 以上
但如果說
我們今天是 Source Domain Training
Target Domain Testing
Train 在黑白的數字上
測試在彩色的數字上
結果直接慘掉
哇 這直接慘掉 沒辦法做啦
結果直接慘掉
那如果加上 Domain Adversarial Training 的話
結果怎麼樣呢
你會發現說本來如果只 Train 在黑白的圖片上
測試在彩色的圖片上
正確率 57.5
那如果今天有做 Domain Adversarial Training
正確率就飆升到 81%
在很多其他任務上進步量都挺明顯的
59 到 71
74 到 88.7
這個進步量都是挺明顯的
那這個就是 Domain Adversarial Training
好 到這邊我們停一秒鐘
看看有沒有同學有問題
哦 好
我看一下
好 有一個同學問說
Domain Classifier
這裡是類似 KMNIST 的 Class Array 嗎
欸 不是
它就是一個二元的分類器
Domain 那個 Classifier
它就是一個 Network
它也可以有很多層
那它有幾層也是你自己決定的
所以它不是一個
這個 KMNIST 的 Class Array
它就是一個 Classifier
它要去訓練說看到一個
Input 一個 Feature 的 Vector
那 Output 就是它是屬於 Source Domain
還是 Target Domain
哦 有同學幫我回答了
哦 是助教
好 助教幫我回答了
好
好 那我們就繼續講啦
好 那剛才這整套想法
還是有一個限制
有一個小小的問題
什麼樣小小的問題呢
我們來看看哦
今天 藍色的圈圈跟藍色的三角形
代表 Source Domain 上的兩個 Class
那我們當然可以找一個 Boundary
去把這兩組 Class 把它分開來
對於 Target Domain 上的 Data
我們沒有任何的 Class 的 Label
我們就只能說所有 Target Domain 的 Data
我們都用這個正方形來表示它
那我們今天訓練的目標
就是要讓這些正方形它的分布
跟這個圈圈三角形合起來的分布越接近越好
但是什麼叫做越接近越好呢
左邊這個 Case
紅色的點跟藍色的點
它們也算是蠻 Align 在一起的
也算是分布蠻接近的
右邊這個 Case
紅色的點跟藍色的點
它們也算是分布蠻接近的
但是你覺得左邊比較好
還是右邊比較好呢
好 我們試試看這邊有沒有可能進行互動
欸 左邊
覺得左邊比較好的同學
你就在聊天室輸入一個 1
欸 右邊
覺得右邊比較好的同學
你就在聊天室輸入一個 2
好 我們看看有沒有辦法做互動
好 那我順便回答一下同學的問題
Proposed Approach
後面括號的百分比是什麼意思
那個百分比
就是進步量啦
就是進步量
那個沒有什麼特別的的意思
好
然後呢 有同學問說
訓練資料只有 Source Data 的狀況
哦 他是在 @ 別人
他在回答別人的問題
好
好 大家都選 2
大家都選 2
也有同學選 -1
好
選 2 的超級多 好
好 我看選大多數的同學呢
都覺得是右邊
沒錯 很多人也覺得是右邊
所以我們是不是應該要讓右邊的狀況發生
而避免讓左邊的狀況發生呢
好 怎麼做呢
怎麼讓右邊的狀況發生
左邊的狀況不要發生呢
也許一個可能的想法是
我們既然知道藍色的圈圈跟藍色的三角形
它們的分界點在哪裡
這個分界點我們是知道的
那我們應該要讓這些方形
雖然我們不知道它是哪一個類別
但我們讓這些方形遠離這一個分界點
怎麼讓方形遠離這個分界點呢
那在文獻上就有很多不同的做法啦
你可以參考一下文獻
看看你覺得怎麼做比較好
舉例來說一個最簡單的做法是說
呃 今天我有很多 Unlabeled 的圖片
丟到 Feature Extractor
再丟到 Label Predictor 以後
我不知道它是哪一個類別
但是我希望它離 Boundary 越遠越好
那什麼叫做離 Boundary 越遠越好呢
如果今天輸出的結果非常地集中
叫做離 Boundary 遠
如果今天輸出的結果每一個類別都非常地接近
叫做離 Boundary 近
所以我希望說把 unLabled 的 Image
丟進 Feature Extractor
再丟進 Label Predictor
輸出的結果
它離 Boundary 越遠越好
也就是說這集中在某一個類別上
我們雖然不知道它應該算是哪一個類別
但至少應該集中在某一個類別上
好 那這只是一種招數
並不是全部
那你可以參考一下文獻
比如說有一個知名的方法叫做 DIRT-T
DIRT-T
這個 DIRT-T 它其實
它 Paper 裡面還特別告訴你說
這個要唸 Dirty
要唸 Dirty
這個大家都是這個模型命名大師
都會命名一些很有創意的名字
好 這個 DIRT-T 是一個招數
還有另外一個招數叫這個
Maximum Classifier Discrepancy
如果你要在這個 Domain Adaptation 座位裡面
得到最好的結果的話
那這些招數是不可或缺的
那實際上這些招數怎麼進行
還挺複雜
這個就留給大家自己研究
那這邊還有一個問題
什麼樣的問題呢
我們到目前為止
好像都假設說
Source Domain 跟 Target Domain
它的類別都要是一模一樣
Source Domain 假設是影像分類的問題
Source Domain 有老虎 獅子跟狗
Target Domain 也應該要有老虎 獅子跟狗
但是真的一定會這樣嗎
Target Domain 是沒有 Label 的
我們根本不知道 Target Domain 裡面
有什麼樣的類別
而在這個圖示裡面 這個實心的
實線的圈圈代表
Source Domain 裡面有的東西
這個虛實線的圈圈
代表 Target Domain 裡面有的東西
所以呢 有沒有可能是
這個 Source Domain 裡面的東西比較多
Target Domain 裡面的東西比較少呢
有沒有可能是
Source Domain 裡面的東西比較少
Target Domain 的東西比較多呢
有沒有可能兩者雖然有交集
但是各自都有獨特的類別呢
這都是有可能發生的
所以在這個前提之下
你說 Source Domain 跟 Target Domain
你硬要把它們完全 Align 在一起
聽起來有點問題呀
因為舉例來說在這個 Case 裡面
哦 你說你要讓 Source Domain 的 Data
跟 Target Domain 的 Data
它們的 Feature 完全 Match 在一起
那意味著說
你硬是要讓老虎去變得跟狗像
或者是老虎硬是要變得跟獅子像
到時候你就分不出老虎這個類別了
聽起來就是有問題的方法
那怎麼解決這個問題
怎麼解決 Source Domain 跟 Target Domain
它可能有不一樣的 Label 的問題
那你可以參見這個
Universal Domain Adaptation 這篇文章
好 那我們來看看有沒有同學有問題要問的
好 有同學問說
如果 Feature Extractor 是 CNN
而不是 Linear Layer
那 Domain Classifier Input
就是 Feature Map
拉直的 Latent Embedding
這樣 Latent Space 學到的東西
把兩個 Domain 分部彌平會不會有影響
因為 Feature Map 本來就有 Space 的關係
現在卻硬是被拉直
你說得非常對
真的 你說得非常對
就是 Feature Extractor
它是一個複雜的 Network
然後我們硬是要
把兩個 Domain 的東西拉在一起
會不會變成它只是為了拉在一起而拉在一起
它根本就沒有學到
我們本來希望
這個 Feature Space 學到的東西呢
簡單的回答就是 會
會
所以 Domain Adaptation
沒有大家想像得那麼容易 Train 起來
雖然好像剛才講得都非常地順利
那作業裡面可以自己體驗一下啦
這個 Domain Adaptation
算是偏難做的一個作業
所以 呃 這一個
你知道我們在 Train 的時候
我們有兩件事情
有兩件事互相結抗
一個是要去騙過 Domain Classifier
另外一個是要讓分類變正確
那我們期待說這兩件事情都可以同時做好
也就是說一方面既騙過 Domain Classifier
一方面又分類分得好
那就同時把兩個 Domain Align 在一起
同時 Latent Space
我們又希望它的分布是正確的
比如說我們覺得 1 跟 7 比較像
那他們為了要讓 Classifier 做好
那今天你的 Feature Extractor
就會讓 1 跟 7 比較像
然後 1 跟
比如說 1 跟 4 比較不像
它就讓 1 跟 4 拉得比較遠一點
我們期待說
藉由需要把 Label Predictor 的 Performance
衝高這件事情
latent representation 裡面的這個 Space
仍然是保留一個比較好的 Latent Space
但是不一定 這件事不一定總是會成功了
如果你今天你給 Domain Classifier
就是要騙過 Domain Classifier
這件事情的權重太大
你的 Model 就會學到說
它都只想騙過 Domain Classifier
它就不會產生好的 Latent Space
所以剛才同學問的問題
確實是有可能會發生的
所以大家在實做的時候
這個也是有些參數要調的
好
好 希望這樣有回答到同學的問題
好 那接下來 還有一個更嚴峻的狀況
剛才我們是假設說沒有 Labeled Data
但至少有一大堆
這個時候你還可以說
我要把兩個 Space 呢 把它拉在一起
但是有一個可能是
假設不只沒有 Label
而且 Data 還很少
比如說我就只有一張而已
這個時候你只有一張
你的這個 Target Domain 只有一張
只有一個點
你根本沒有辦法跟那個 Source Domain
把它 Align 在一起
這個時候怎麼辦呢
假設 Target Domain 的 Data 非常少的時候
怎麼辦呢
也不是沒有方法啦
有一個方法叫做 Testing Time Training
它的縮寫是 TTT
這個我們就把連結附在這邊給大家參考
Testing Time Training 就是想要處理
假設我的 Target Domain 沒有 Lable
而且還只有一張的時候
到底應該要怎麼辦
但其實還有一個更嚴峻的狀況
這個狀況是
如果我什麼都不知道怎麼辦呢
如果我們對 Target Domain 一無所知的話
怎麼辦呢
這個時候又分成兩種情形
對 Target Domain 一無所知的這種問題
這個時候我們就不叫 Domain 的 Adaptation
通常就叫 Domain Generalization
因為我們並不是要
Adapt 到某一個特定的 Domain 上
我們對那個特定的 Domain 已經一無所知了
我們是期待今天機器學到
Domain Generalization
在 Testing 的時候
不管來什麼神奇的 Domain
它都可以處理
那 Domain Generalization
又分成兩種狀況
一種狀況是我的訓練資料非常地豐富
本來就包含了各式各樣不同的 Domain
假設你要做貓狗的分類器
那你現在呢 在訓練資料裡面
有真實的貓跟狗的照片
有素描的貓跟狗的照片
然後有這個水彩畫的貓跟狗的照片
期待因為訓練資料有多個 Domain
模型可以學到如何彌平 Domain 間的差異
今天有測試資料是卡通的貓跟狗
它也可以處理
這是一種狀況
那這種狀況你還比較能夠想像要怎麼處理
那我們這邊就不細講
我們都只各放一些有代表性的論文
給大家參考
但還有另外一種
你會覺得真的不知如何下手的狀況是
假設訓練資料只有一個 Domain 呢
假設你的訓練資料只有一個 Domain
而測試資料有多種不同的 Domain 的話
怎麼處理呢
在文獻上也不是沒有人試
也是有人試著去解惑這種問題的
那他怎麼做呢
這細節我們就不講啦
在概念上就是有點像是 Data Augmentation
雖然你只有一個 Domain 的資料
想個 Data Augmentation 的方法
去產生多個 Domain 的資料
然後你就可以套上面這個 Secnario 來做做看
看能不能夠在測試的時候
新的 Domain 都可以做好
好 這個是 Domain Generalization
好 那這個部分就是很簡短的跟大家帶過
這個 Domain Adaptation 的種種技術
更多的細節
在下一堂課助教的說明裡面
都還會跟大家仔細地說明
我們在這邊呢 就先休息 5 分鐘
休息一下 然後我們等一下再回來
