我們要來講 Network 的架構
我們開始探討 Network 的架構設計
那我第一個跟大家講的
Network 架構的變形呢
是 Convolutional 的 Neural Network
它的縮寫呢 就是 CNN
那這個 CNN 啊
它是專門被用在影像上的
我希望透過 CNN 這個例子
來讓你知道說 Network 的架構
它的設計有什麼樣的想法
那為什麼設計 Network 的架構
可以讓我們的 Network 結果做得更好
好 我們接下來要講的例子是跟影像有關的
我們今天就想像說
我們要做影像的分類
也就是給機器一張圖片
它要去決定說這張圖片裡面有什麼樣的東西
好 那怎麼做呢
我們已經跟大家講過怎麼做分類這件事情
在以下的討論裡面
我們都假設我們的模型輸入的圖片大小
是固定的
舉例來說 它固定輸入的圖片大小
都是 100 × 100 的解析度
我們假設說不會突然出現大小不一的照片
即使今天一般在做影像辨識的時候
往往都有這樣子的假設
就算是今天 Deep Learning 已經這麼的 Popular
我們往往都還是需要假設說
一個模型輸入的影像大小都是一樣的
你說圖片可能有大有小啊
而且不是所有圖片都是正方形的啊
有長方形的怎麼辦
今天常見的處理方式
丟進影像辨識系統處理方式就是
把所有圖片都先 Rescale 成大小一樣
再丟到影像的辨識系統裡面
好 我們的模型的輸出應該是什麼呢
我們模型的目標是分類
所以我們會把每一個類別
表示成一個 One-Hot 的 Vector
我的目標就叫做 y^
好 在這個 One-Hot 的 Vector 裡面
假設我們現在類別是一個貓的話
那貓所對應的 Dimension
它的數值就是 1
其他的東西所對的 Dimension 的數值就是 0
那這個 Dimension 的長度就決定了
你現在的模型可以辨識出多少不同種類的東西
如果你向量的長度是 2000
就代表說你這個模型
可以辨識出 2000 種不同的東西
那今天比較強的影像辨識系統
往往可以辨識出 1000 種以上的東西
甚至到上萬種不同的 Object
那如果你今天希望你的影像辨識系統
它可以辨識上萬種 Object
那你的 Label 就會是一個上萬維
維度是上萬的 One-Hot Vector
好 我的模型的輸出通過 Softmax 以後
輸出是 y'
然後我們希望 y' 和 y^
它們的 Cross Entropy 越小越好
那有關 Cross Entropy 的部分呢
我們已經跟大家講過了
所以相信這個地方大家不是問題
接下來的問題是怎麼把一張影像
當做一個模型的輸入呢
那我們先來看一下對電腦來說
一張影像是什麼樣的東西
那其實對於一個 Machine 來說呢
一張圖片其實是一個三維的 Tensor
什麼叫做 Tensor 呢
如果不知道 Tensor 是什麼的話
你就想成它是維度大於 2 的矩陣就是 Tensor
就是矩陣是二維的嘛
那二維以上的 超過二維的矩陣
你就叫它 Tensor
一張圖片它是一個三維的 Tensor
哪三維呢
其中一維代表圖片的寬
另外一維代表圖片的高
還有一維代表圖片的 Channel 的數目
這個所謂的 Channel 是什麼意思呢
一張彩色的圖片
今天它每一個 Pixel
都是由 R G B 三個顏色所組成的
所以這三個 Channel 就代表了 R G B 三個顏色
那長跟寬就代表了今天這張圖片的解析度
代表這張圖片裡面有的 Pixel
有的像素的數目
那接下來我們就要把這一個三維的 Tensor
把它拉直
我們把它拉直以後就可以
丟到一個 Network 裡面去了
還記得嗎 到目前為止我們所講的 Network
它的輸入其實都是一個向量
所以我們只要能夠把一張圖片變成一個向量
我們就可以把它當做是 Network 的輸入
但是怎麼把這個三維的 Tensor 變成一個向量呢
那最直覺的方法就是直接拉直它
一個三維的 Tensor 裡面有幾個數字呢
有在這個例子裡面有 100 × 100×3 個數字
所以一張圖片
是由 100 × 100×3 個數字所組成的
把這些數字通通拿出來排成一排
就是一個巨大的向量
這個向量可以作為 Network 的輸入
而這個向量裡面
每一維它裡面存的數值
其實就是某一個 Pixel
某一個顏色的強度 對不對
每一個 Pixel 有 R G B 三個顏色所組成
每個顏色都有一個數值代表說這個顏色的強度
在這個向量裡面
每一維它的數值就代表了某一個位置的
某一個顏色的強度
好 那這個向量啊
我們可以把它當做是一個 Network 的輸入
那我們到目前為止
只講過了 Fully Connected Network
好 如果我們把向量當做 Network 的輸入
我們 Input 這邊 Feature Vector
它的長度就是 100 × 100×3
非常長的一個 Vector
那假設我們現在的
第一層的 Neuron 的數目有 1000 個
那你能計算一下這邊第一層
總共有多少個 Weight 嗎
我們每一個 Neuron
它跟輸入的向量的每一個數值
都會有一個 Weight
所以如果輸入的向量長度是 100 × 100×3
有 1000 個 Neuron
那我們現在第一層的 Weight
就有 1000×100 × 100×3
也就是 3×10 的 7 次方
是一個非常巨大的數目
那如果參數越多會有什麼樣的問題呢
雖然隨著參數的增加
我們可以增加模型的彈性
我們可以增加它的能力
但是我們也增加了 Overfitting 的風險
有關什麼叫模型的彈性
到底 Overfitting 怎麼產生的
下週吳培元老師會從數學上
給大家非常清楚的證明
那我們這邊就講概念上
如果模型的彈性越大
就越容易 Overfitting
那我們怎麼減少在做影像辨識的時候
怎麼避免使用這麼多的參數呢
那考慮到影像辨識這個問題本身的特性
其實我們並不一定需要 Fully Connected 這件事
考慮影像本身的特性
我們其實不需要每一個 Neuron
跟 Input的每一個 Dimension 都有一個 Weight
怎麼說呢
接下來就是對影像辨識這個問題
對影像本身的特性的一些觀察
第一個觀察是
對影像辨識這個問題而言
假設我們想要知道說
這張圖片裡面有一隻動物
這個動物是一個鳥 要怎麼做呢
也許對一個影像辨識的系統而言
對一個影像辨識的 Neuron
對一個影像辨識的類神經網路裡面的神經而言
它要做的就是偵測說現在這張圖片裡面
有沒有出現一些特別重要的 Pattern
而這些 Pattern 是代表了某種物件的
舉例來說 如果現在有某一個 Neuron 說
它看到鳥嘴這個 Pattern
有某個 Neuron 又說
它看到眼睛這個 Pattern
又有某個 Neuron 說
它看到鳥爪這個 Pattern
也許看到這些 Pattern 綜合起來就代表說
我們看到了一隻鳥
類神經網路就可以告訴你說
因為看到了這些 Pattern
所以它看到了一隻鳥
那也許你會覺得說
看 Pattern 然後決定它是什麼
這件事情好像沒有很聰明
但你仔細想想
人是不是也是用同樣的方法
來看一張圖片中有沒有一隻鳥呢
舉例來說這一個例子
不知道你有沒有看到
這裡面有什麼樣的動物啦
你看這邊有一個鳥嘴啦
這邊有一個眼睛啦
看起來牠是一個烏鴉啦
但是牠其實是一隻貓這樣子
如果你看到牠是一隻鳥的話
那你就應該放下酒杯了
因為這是一隻貓
好 所以其實就算是人
我們在判斷一個物件的時候
往往也是抓最重要的特徵
然後看到這些特徵以後
你很直覺的就會覺得說
你看到了某種物件
對機器來說
也許這也是一個有效的
判斷影像中有什麼物件的方法
但是假設我們現在用 Neuron 做的事情
其實就是判斷說現在有沒有某種 Pattern 出現
那也許我們並不需要每一個 Neuron
都去看一張完整的圖片
因為這一些重要的 Pattern
比如說鳥嘴 比如說眼睛 比如說鳥爪
並不需要看整張完整的圖片
才能夠得到這些資訊
你要知道說這邊有沒有一個鳥嘴
你其實只要看非常小的範圍就知道了
你並不需要看整張圖片
所以這些 Neuron 也許根本就不需要
把整張圖片當作輸入
它們只需要把圖片的一小部分當作輸入
就足以讓它們偵測某些特別關鍵的 Pattern
有沒有出現了
這是第一個觀察
根據這個觀察啊
我們就可以做第一個簡化 怎麼簡化呢
本來我們每一個 Neuron
它要看完整的圖片
把圖片裡面的每一個 Pixel
每個 Pixel 都還有三個數字
把一張圖片裡面所有的資訊都丟給一個 Neuron
然後讓它產生矛盾
這是 Fully Connected Network 做的事情
但是現在我們已經觀察到說
也許不需要讓一個 Neuron 看完整的圖片
只要讓它看圖片的一小部分就足夠了
那怎麼透過這個觀察
來設計我們的 Neural Network 呢
在 CNN 裡面有一個這樣的做法
我們會設定一個區域叫做 Receptive Field
每一個 Neuron 都只關心
自己的 Receptive Field 裡面發生的事情就好了
舉例來說 你會先定義說這個藍色的 Neuron
它的守備範圍就是這一個 Receptive Field
那這個 Receptive Field 裡面有 3×3×3 個數值
好 這裡小的立方體裡面有 3×3×3 個數值
那對藍色的 Neuron 來說
它只需要關心這一個小範圍就好了
不需要在意整張圖片裡面有什麼東西
只在意它自己的 Receptive Field 裡面
發生的事情就好
那這個 Neuron
怎麼考慮這個 Receptive Field 裡
有沒有發生什麼樣的事情呢
它要做的事情就是
把這 3×3×3 的數值拉直
變成一個長度是 3×3×3 也就是 27 維的向量
再把這 27 維的向量作為這個 Neuron 的輸入
這個 Neuron 會給 27 維的向量的
每一個 Dimension 一個 Weight
所以這個 Neuron 有 3×3×3 27個 Weight
再加上 Bias 得到的輸出
這個輸出再送給下一層的 Neuron 當作輸入
好 所以每一個 Neuron
它只考慮自己的 Receptive Field
那這個 Receptive Field 要怎麼決定出來呢
那這個就要問你自己了
你可以說這邊有個藍色的 Neuron
它就看左上角這個範圍
這是它的 Receptive Field
另外又有另外一個黃色的 Neuron
它是看右下角這個 3×3×3 的範圍
這個立體的部分我就畫不出來了
我這邊畫一個正方形代表 3×3×3 的範圍
這個是黃色這個 Neuron 的 Receptive Field
那 Receptive Field 彼此之間也可以是重疊的
比如說我現在畫一個 Receptive Field
那這個地方它是綠色的 Neuron 的守備範圍
它跟藍色的 跟黃色的都有一些重疊的空間
這樣也是可以的
好 所以 Receptive Field 彼此之間是可以重疊的
你可以說兩個人的守備範圍彼此是有重疊的
那你甚至可以兩個不同的 Neuron
它們守備看到的範圍
也許一個範圍使用一個 Neuron 來守備
你沒有辦法偵測所有的 Pattern
所以同個範圍可以有多個不同的 Neuron
所以同個 Receptive Field
它們可以有多個
所以多的 Neuron
它們可以去守備同一個 Receptive Field
那接下來你就會浮想聯翩有各式各樣的想法
舉例來說
那我可不可以 Receptive Field 有大有小呢
因為畢竟 Pattern 有的比較小 有的比較大
有的 Pattern 也許在 3×3 的範圍內
就可以被偵測出來
有的 Pattern 也許要 11×11 的範圍
才能被偵測出來
那我可不可以 Receptive Field 有大有
這個算是常見的招式了
我可不可以 Receptive Field
只考慮某些 Channel 呢
我們這邊看起來我們的 Receptive Field
是 R G B 三個 Channel 都考慮
但也許有些 Pattern
只在紅色的 Channel 會出現啊
也許有些 Pattern
只在藍色的 Channel 會出現啊
我可不可以有的 Neuron 只考慮一個 Channel 呢
可以
其實之後在講到 Network Corporation 的時候
會講到這種 Network 的架構
在一般 CNN 裡面你不常這樣子的考慮
但是有這樣子的做法
好 那有人會問說這邊的 Receptive Field
通通都是正方形的
你剛才舉的例子裡面
3×3 11×11 也都是正方形的
可不可以是長方形的呢
可以 可以是長方形的
這完全都是你自己設計的
Receptive Field 是你自己定義的
你完全可以根據你對這個問題的理解
決定你覺得 Receptive Field 應該要長什麼樣子
那這邊還可以有各式各樣怪怪的想法
你可能會說 Receptive Field 一定要是
Receptive Field 的範圍一定要相連嗎
我們可不可以說有一個 Neuron
它的 Receptive Field 就是影像的左上角
跟右上角
理論上可以
但是你就要想看為什麼你要這麼做嘛
會不會有什麼 Pattern 是會
也要看一個圖片的左上角
跟右下角才能夠找到的
也許沒有 如果沒有的話
這種 Receptive Field 就沒什麼用
我們之所以 Receptive Field 都是
一個相連的領地
就是我們覺得要偵測一個 Pattern
那這個 Pattern
它就出現在整個圖片裡面的某一個位置
而不是出現
而不是分成好幾部分
出現在圖片裡面的不同的位置
所以 Receptive Field 呢 它都是相
通常見到的都是相連的領地
但如果你說你要設計很奇怪的 Receptive Field
去解決很特別的問題
那完全是可以的
這都是你自己決定的
好 雖然 Receptive Field 你可以任意設計
但這邊要跟大家講一下
最經典的 Receptive Field 的安排方式
最經典的安排方式是什麼呢
第一個會看所有的 Channel
一般在做影像辨識的時候我們可能
你可能不會覺得說
有些 Pattern 只出現某一個 Channel 裡面
所以會看全部的 Channel
所以既然會看全部的 Channel
我們在描述一個 Receptive Field 的時候
只要講它的高跟寬就好了
就不用講它的深度
反正深度一定是考慮全部的 Channel
而這個高跟寬合起來叫做 Kernel Size
舉例來說在這個例子裡面
我們的 Kernel Size 就是 3×3
那一般我們 Kernel Size 其實不會設太大
你在影像辨識裡面
往往做個 3×3 的 Kernel Size 就足夠了
如果你說你設個 7×7 9×9
那這算是蠻大的 Kernel Size
一般往往都做 3×3
講到這邊你就會問說
那如果 Kernel Size 都是 3×3
意味著說我們覺得在做影像辨識的時候
重要的 Pattern 都只在 3×3 這麼小的範圍內
就可以被偵測出來了
聽起來好像怪怪的
有些 Pattern 也許很大啊
也許 3×3 的範圍沒辦法偵測出來啊
等一下我們會再回答這個問題
那我現在先告訴你說
常見的 Receptive Field 設定方式
就是 Kernel Size 3×3
然後一般同一個 Receptive Field
會有一組 Neuron 去守備這個範圍
所以你畫一個 Receptive Field 以後
不會只有一個 Neuron 去關照它
不會只有一個 Neuron 去守備它
往往會有一組 一排 Neuron 去守備它
比如說 64 個 或者是 128 個 Neuron 去守備
一個 Receptive Field 的範圍
好 到目前為止我們講的都是一個 Receptive Field
那各個不同 Receptive Field 之間的關係
是怎麼樣呢
你會把你在最左上角的這個 Receptive Field
往右移一點
然後就製造一個新的守備範圍
製造一個另外一個 Receptive Field
那這個移動的範圍啊
這個移動的量叫做 Stride
像在這個例子裡面 Stride 就等於 2
那 Stride 是一個你自己決定的參數
決定的那個 Hyperparameter 你要自己調的
但這個 Stride 你往往不會設太大
往往設 1 或 2 就可以了
因為你希望這些 Receptive Field
跟 Receptive Field 之間是有重疊的
為什麼我們希望
Receptive Field 之間是有重疊的呢
因為假設 Receptive Field 完全沒有重疊
那有一個 Pattern 就正好出現
在兩個 Receptive Field 的交界上面
那就會變成沒有任何 Neuron 去偵測它
那你也可能就會 Miss 掉這個 Pattern
所以我們希望 Receptive Field 彼此之間
有高度的重疊
那假設我們設 Stride = 2
那第一個 Receptive Field 就在這邊
那第二個就會在這邊
那第三個呢 就再往右移兩格
再往右移兩格就放在這邊
那這邊就遇到一個問題了
它超出了影像的範圍 怎麼辦呢
那有人可能會說
那就不要在這邊擺 Receptive Field
但你這樣就漏掉了影像的邊邊的地方啊
如果有個 Pattern 就在邊邊的地方
你就沒有 Neuron 去關照那些 Pattern啦
沒有 Neuron 去偵測出現在邊邊的 Pattern 了
所以一般邊邊的地方也會考慮的
但超出範圍了怎麼辦呢
超出範圍你就做 Padding
什麼叫 Padding
Padding 就是補 0
好 所以如果你今天 Receptive Field 有一部分
超出影像的範圍之外了
那就當做那個裡面的值都是 0
其實也有別的補值的方法
Padding 就是補值的意思
有別的補值的方法
比如說有人會說
我這邊不要補 0 好不好
我補整張圖片裡面所有 Value 的平均
可以 或者你說
我把邊邊的這些數字拿出來補
在這個沒有值的地方可不可以
可以 有各種不同的 Padding 的方法
好 那你除了這個橫著移動
你也會這個直著移動
你有會有這個垂直方向上的移動
在這邊呢 我們一樣垂直方向 Stride 也是設 2
所以你有一個 Receptive Field 在這邊
垂直方向移動兩格
就有一個 Receptive Field 在這個地方
你就按照這個方式
掃過整張圖片
所以整張圖片裡面
每一吋土地都是有被某一個
Receptive Field 覆蓋的
也就是圖片裡面每一個位置
都有一群 Neuron 在偵測那個地方
有沒有出現某些 Pattern
好 那這個是第一個簡化
Fully Connected Network 的方式
好 那第二個觀察是什麼呢
第二個觀察就是
同樣的 Pattern
它可能會出現在圖片的不同區域裡面
比如說鳥嘴這個 Pattern
它可能出現在圖片的左上角
也可能出現在圖片的中間
雖然它們的形狀都是一樣的 都是鳥嘴
但是它們可能出現在
圖片裡面的不同的位置
按照我們剛才的討論
你同樣的 Pattern
出現在圖片的不同的位置
似乎也不是太大的問題
因為出現在左上角的鳥嘴
它一定 它落在某一個 Receptive Field 裡面
因為 Receptive Field 是蓋滿整個圖片的
所以圖片裡面沒有任何地方
不是在某個 Neuron 的守備範圍內
所以這些 這個地方
一定是某一個 Neuron 的 Receptive Field
那假設在那個 Receptive Field 裡面
有一個 Neuron 它的工作
就是偵測鳥嘴的話
那鳥嘴就會被偵測出來
好 所以就算鳥嘴出現在中間
也沒有關係
假設有 這邊一定是在某一個
Receptive Field 的範圍裡面
那個 Receptive Field
一定有一組 Neuron 在照顧
那假設其中有一個 Neuron
它可以偵測鳥嘴的話
那鳥嘴出現在圖片的中間
也會被偵測出來
但這邊的問題是
這些偵測鳥嘴的 Neuron
它們做的事情其實是一樣的
只是它們守備的範圍是不一樣
那既然它們做的事情是一樣的
守備範圍是不一樣的
我們真的需要每一個守備範圍
都去放一個偵測鳥嘴的 Neuron 嗎
它們做的事情根本就是重複的啊
只是它們的守備範圍不一樣啊
如果不同的守備範圍
都要有一個偵測鳥嘴的 Neuron
那你的參數量不會太多了嗎
而這個概念就好像是
好 為什麼教務處希望
可以推大型的課程一樣
假設說每一個科系
其實都需要程式相關的課程
或每一個科系都需要
機器學習相關的課程
那到底需不需要在每一個系所
都開機器學習的課程
還是說開一個比較大班的課程
讓所有系所的人都可以修課
這個就是教務處推動大型課程的想法
好 那如果放在影像處理上的話
是怎麼樣呢
好 如果放在影像處理上的話
我們能不能夠讓
不同 Receptive Field 的 Neuron
它們共享參數
也就是做 Parameter Sharing
就是共享參數
那共享參數是什麼意思呢
這邊舉得更具體一點
所謂共享參數就是
這兩個 Neuron 它們的 weights
完全是一樣的
我這邊特別用顏色來告訴你說
它們的 weights 完全是一樣的
上面這個 Neuron 的第一個 weight
叫做 w1
下面這個 Neuron 的第一個 weight 也是 w1
它們是同一個 weight
我用黃色來表示
上面這個 Neuron 的第二個 weight 是 w2
下面這個 Neuron 的第二個 weight 也是w2
它們都用黃色來表示
以此類推
上面這個 Neuron 跟下面這個 Neuron
它們守備的 Receptive Field 是不一樣的
但是它們的參數是一模一樣的
那有人可能就會問說
欸 它的參數是一模一樣
那它會不會輸出永遠都是一樣的啊
不會 為什麼
因為它們的輸入是不一樣的
這兩個 Neuron 的參數一模一樣
但是它們照顧的範圍是不一樣的
所以上面這個 Neuron
我們說它的輸入是 x1 x2
下面這個 Neuron
我們說它的輸入是 x1' x2'
那它們的輸出是什麼呢
上面這個 Neuron 的輸出就是
x1 × w1 + x2 × w2
全部加加加 再加 Bias
然後透過 Activation Function 得到輸出
下面這個 Neuron 雖然也有 w1 w2
但 w1 跟 w2 是乘以 x1' x2'
所以它的輸出
不會跟上面這個 Neuron 一樣
因為輸入不一樣的關係
所以就算是兩個 Neuron 共用參數
它們的輸出也不會是一樣的
那你可以想見說
你不會讓兩個守備一模一樣
Receptive Field 的 Neuron 共享參數
因為如果今天兩個守備一樣的
區域的 Neuron 共享參數的話
它們的輸出就一定都固定會是一樣的
那如果兩個 Neuron 守備的範圍不一樣
就算它們的參數一樣
它們的輸出也不會是一樣的
所以這是第二個簡化
我們讓一些 Neuron 可以共享參數
那至於要怎麼共享
你完全可以自己決定
而這個是你可以自己決定的事情
但是接下來還是要告訴大家
常見的 在影像辨識上面的共享的方法
是怎麼設定的
那我們剛才已經講說
每一個 Receptive Field
它都有一組 Neuron 在負責守備
比如說 64 個 Neuron
所以這個 Receptive Field
有 64 個 Neuron
這個 Receptive Field 也有 64 個 Neuron
那它們彼此之間會怎麼共享參數呢
我們這邊用一樣的顏色
就代表說這兩個 Neuron
共享一樣的參數
所以其實每一個 Receptive Field
都只有一組參數而已
就是這個 Receptive Field 的
第一個 Neuron
會跟這個 Receptive Field 的
第一個 Neuron 共用參數
它的第二個 Neuron
跟它的第二個 Neuron 共用參數
它的第三個Neuron
跟它的第三個 Neuron 共用參數
所以每一個 Receptive Field
都只有一組參數而已
那這些參數有一個名字 叫做 Filter
所以這兩個 Neuron
它們共用同一組參數
這組參數就叫 Filter1
這兩個 Neuron 它們共同一組參數
這組參數就叫 Filter2 叫 Filter3 叫 Filter4
以此類推
好 這是第二個簡化的方法
好 我們目前已經講了兩個簡化的方法
那我們來整理一下我們學到了什麼
好 這是 Fully Connected 的 Network
它是彈性最大的
那我們說 因為不需要看整張圖片
也許只要看圖片的一小部分
就可以偵測出重要的 Pattern
所以我們有了 Receptive Field 的概念
當我們強制一個 Neuron
只能看一張圖片裡面的一個範圍的時候
它的彈性是變小的
如果是 Fully Connected 的 Network
它可以決定
它看整張圖片 還是只看一個範圍
就如果它只想看一個範圍
就把很多 Weight 設成 0
就只看一個範圍嘛
所以 Fully Connected Layer 它自己決定
它要看整張圖片 還是一個小範圍
但加上 Receptive Field 的概念以後
意思就是說
沒得選了 就只能夠看一個小範圍
反正我們覺得看一個小範圍就夠了
所以只能看一個小範圍
所以加入 Receptive Field 以後
你的 Network 的彈性是變小的
好 那接下來呢
接下來我們還有參數共享這件事
參數共享這件事
又更進一步限制了 Network 的彈性
本來在 Learning 的時候
它可以決定說
這兩個 Network 的參數要是什麼
每一個 Neuron 可以各自有不同的參數
它們可以正好學出一模一樣的參數
也可以有不一樣的參數
但是加入參數共享以後
就意味著說 某一些 Neuron
無論如何 參數就算一模一樣的
也沒得選了
參數要一模一樣
所以這又更增加了對 Neuron 的限制
而 Receptive Field 加上 Parameter Sharing
就是 Convolutional Layer
就是大家常常聽到的 Convolutional Layer
那有用 Convolutional Layer 的 Network
就叫 Convolutional Neural Network
就是 CNN
所以從這個圖上啊
你可以很明顯地知道說
其實 CNN 它的 Bias 比較大
它的 Model 的 Bias 比較大
那你可能會想說
有 Model Bias 比較大 不是一件壞事嗎
Model Bias 大 不一定是壞事
因為當 Model Bias 小
Model 的 Flexibility 很高的時候
它比較容易 Overfitting
Fully Connected Layer
它可以做各式各樣的事情
它可以有各式各樣的變化
但是它可能沒有辦法在
任何特定的任務上做好
而 Convolutional Layer
它是專門為影像設計的
剛才講的 Receptive Field 參數共享
這些觀察 都是為影像設計的
那因為 Convolutional Layer
是特別為影像設計的
所以它在影像上仍然可以做得好
雖然它的 Model Bias 很大
但這個在影像上不是問題
但是如果它用在影像之外的任務
那你就要很小心了
你就要仔細想想
那些任務有沒有我們剛才講的
影像用的特性
好 那其實剛才是 CNN 的某一種介紹方式啦
那現在我們要講另外一種介紹方式
第二種介紹方式
跟剛才講的介紹方式是一模一樣的
只是同一個故事
用不同的版本來說明
那你看看你比較喜歡哪一個版本
那這個第二個版本是
你比較常見的 說明 CNN 的方式
那第二個版本的故事
跟第一個版本的故事
是一模一樣的
所以假設第一個版本
你聽得有點迷迷糊糊的話
那我們來聽第二個版本
第二個版本是這樣的
什麼叫做 Convolutional Layer 啊
Convolutional 的 Layer 就是
裡面呢 有很多的 Filter
這些 Filter 啊 它們的大小是
3 × 3 × Channel 的 Size
那所謂 Channel 就是
如果今天是彩色圖片的話
那就是 RGB 三個 Channel
如果是黑白的圖片的話
它的 Channel 就等於 1
那一個 Convolutional 的 Layer 裡面呢
裡面就是有一排的 Filter
每一個 Filter 呢
它都是一個 3 × 3 × Channel
這麼大的 Tensor
那每一個 Filter 的作用啊
就是要去圖片裡面
抓取某一個 Pattern
當然這些 Pattern
要在 3 × 3 × Channel
那麼小的範圍內啦
它才能夠被這些 Filter 抓出來
那這些 Filter
怎麼去圖片裡面抓 Pattern 的呢
我們現在舉一個實際的例子
那在等一下的例子裡面
我們假設 Channel 是 1
也就是說我們圖片是黑白的圖片
那我們假設這些 Filter 的參數是已知的
Filter 就是一個一個的 Tensor
這個 Tensor 裡面的數值
我們都已經知道了
那實際上這些 Tensor 裡面的數值
其實就是 Model 裡面的 Parameter
這些 Filter 裡面的數值
其實是未知的
它是要透過（00：31：04）去找出來的
那我們現在已經假設說
這些 Filter 裡面的數值已經找出來了
我們來看看說這些 Filter
是怎麼跟一張圖片進行運作
怎麼去圖片上面把 Pattern 偵測出來的
好 這是我們的圖片
它是一個 6 × 6 的大小的圖片
好 那這些 Filter
怎麼在這個圖片上面
去偵測 Pattern 呢
它的做法就是這樣
先把 Filter 放在圖片的左上角
然後把 Filter 裡面所有的值
在這邊有 9 個值
把這 9 個值
跟左上角這個範圍內的 9 個值做相乘
也就是把這個 Filter 裡面的 9 個值
跟這個範圍裡面的 9 個值呢
做 Inner Product
做完是多少呢 心算是 3
好 接下來這個 Filter 呢
本來放在左上角
接下來就往右移一點
那這個移動的距離啊 叫做 Stride
那在剛才講前一個版本的故事的時候
我們的 Stride 是設 2
那在這個版本的故事裡面呢
我們 Stride 就設為 1
好 那往右移一點
然後再把這個 Filter
跟這個範圍裡面的數值
算 Inner Product 算出來是多少呢
心算算出來是 -1 嗎
好對 那這個太簡單了
這是太簡單的數學
那又把它再往右移一點
這邊有 1 這邊有 1 有 1
好 這邊 -1 -1 -1
算出來多少 -3
然後就以此類推
再往右移一點 再算一下
然後這邊全部掃完以後
就往下移一點 再算一下
以此類推
一直到把這個 Filter 放在右下角
算出一個數值 它是多少
這邊 1 1 1 這邊 -1 1 -1
答案就是 -1 就這樣
反正這個 Filter 怎麼說它在偵測 Pattern 呢
好 你看這個 Filter 裡面
它對角線的地方都是
所以它看到 Image 裡面
出現什麼東西的時候
它的值會最大
看到 Image 裡面也出現連三個 1 的時候
它的數值會最大
所以你會發現說呢
在這邊的輸出裡面
左上角的地方的值最大
左下角的地方的值最大
就告訴我們說
這個圖片裡面左上角有出現 3
左上角有出現這個 Pattern
左下角有出現這個
三個 1 連在一起的 Pattern
這個是第一個 Filter
好 那接下來呢
我們把每一個 Filter
都做重複的 Process
比如說這邊有第二個 Filter
一個 Filter 很明顯
它就在偵測 1 排成一直線的時候的狀況
我們就把第二個 Filter
先從左上角開始掃起
得到一個數值
往右移一點 再得到一個數值
再往右移一點 再得到一個數值
反覆同樣的 Process
反覆同樣的操作
直到把整張圖片都掃完
我們又得到另外一群數值
所以每一個 Filter
都會給我們一群數字
紅色的 Filter 給我們一群數字
藍色的 Filter 給我們一群數字
如果我們有 64 個 Filter
我們就得到 64 群的數字了
那這一群數字啊
它又有一個名字
它叫做 Feature Map
所以當我們把一張圖片
通過一個 Convolutional Layer
裡面有一堆 Filter 的時候
我們產生出來了一個 Feature Map
那假設這個 Convolutional Layer裡面
它有 64 個 Filter
那我們產生出來的這個 Feature Map 啊
就有 64 組數字
每一組在這個例子裡面是 4 × 4
就第一個 Filter 產生4 × 4個數字
第二個 Filter 也產生 4 × 4個數字
第三個也產生 4 × 4個數字
乃至到 64 個 Filter
都產生 4 × 4 個數字
那這個 Feature Map 可以看成是什麼呢
這個 Feature Map你可以看成是
另外一張新的圖片
只是這個圖片的 Channel 啊
不是 RGB 這個圖片的 Channel
有 64 個
每一個 Channel 就對應到一個 Filter
本來一張圖片它三個 Channel
通過一個 Convolution
它變成一張新的圖片
有 64 個 Channel
好 那這個 Convolutional Layer 啊
當然是可以疊很多層的
剛才是疊了第一層
那如果疊第二層會發生什麼事呢
第二層的 Convolution 裡面
也有一堆的 Filter
那每一個 Filter 呢
它的大小我們這邊也設 3 × 3
那它的高度呢
它的高度必須設為 64
為什麼 我們知道說
Filter 的這個高度啊
就是它要處理的影像的 Channel
所以跟剛才第一層的 Convolution
假設輸入的影像是黑白的 Channel是 1
那我們的 Filter 的高度就是 1
輸入的影像如果是彩色的 Channel 是 3
那 Filter 的高度就是 3
那在第二層裡面
我們也會得到一張影像
對第二個 Convolutional Layer 來說
它的輸入也是一張圖片
那這個圖片的 Channel 是多少
這個圖片的 Channel 是 64
這 64 怎來
這個 64 是前一個 Convolutional Layer 的
Filter 數目
前一個 Convolutional Layer
它 Filter 數目 64
那輸出以後就是 64 個 Channel
所以第二層
假設你想要把這個圖片當做輸入
那你的 Filter 的高度也等於是 64
好 所以第二層也有一把 Filter
只是這把 Filter 它們的高度是 64
好 那接下來要回答一個問題就是
如果我們的 Filter 的大小一直設 3 × 3
會不會讓我們的 Network
沒有辦法看比較大範圍的 Pattern 呢
其實不會的
因為你想想看
如果我們在第二層 Convolutional Layer
我們的 Filter 的大小一樣設 3 × 3 的話
會發生什麼事情呢
如果我們一樣設 3 × 3 的話
當我們看最左上角這個數值的時候
最左上角這個數值在影像上
其實是對應到這個範圍
右下角的數值在影像上
其實是對應到這個範圍
所以當我們看這 3 × 3 的範圍的時候
和第一個 Convolutional Layer 的輸出的
這個 Feature Map 的
3 × 3 的範圍的時候
我們在原來的影像上
其實是考慮了一個 5 × 5 的範圍
所以雖然我們的 Filter 只有 3 × 3
但它在影像上考慮的範圍
是比較大的 是 5 × 5
所以今天你的 Network 疊得越深
同樣是 3 × 3 的大小的 Filter
它看的範圍就會越來越大
所以 Network 夠深
你不用怕你偵測不到比較大的 Pattern
它還是可以偵測到比較大的 Pattern
好 剛才我們講了兩個版本的故事了
那這兩個版本的故事
是一模一樣的
我們在第一個版本的故事裡面
說到了有一些 Neuron
這些 Neuron 會共用參數
這些共用的參數
就是第二個版本的故事裡面的 Filter
我們這邊這組參數有 3 × 3 × 3個
這個 Filter 裡面有 3 × 3 × 3個數字
我這邊特別還用顏色
把這些數字圈起來
告訴你說 這個 Weight 就是這個數字
這個 Weight 就是這個數字
這個 Weight 可能就是這個數字
以此類推
那這邊呢 我把 Bias 去掉了
那 Neuron 這個是有 Bias 的
這個 Filter 有沒有 Bias 呢
其實是有的
只是在剛才的故事裡面沒有提到
在一般的這個實作上
你的 CNN 的這些 Filter
其實都還是有那個 Bias 的數值的
然後呢 在剛才第一個版本的故事裡面
我們說不同的 Neuron
它們可以 Share Weight
然後去守備不同的範圍
而 Share Weight 這件事
其實就是我們把 Filter 掃過一張圖片
那把 Filter 掃過一張圖片這件事啊
叫做 其實就是 Convolution
這就是為什麼 Convolutional Layer
要叫 Convolutional Layer 的關係
因為把 Filter 掃過一張圖片這件事情
其實就是 Convolution
那所謂的把 Filter 掃過圖片這件事情
其實就是不同的 Receptive Field
Neuron 可以共用參數
而這組共用的參數
就叫做一個 Filter
好 我們今天特別從兩個不同的面向
跟你講 CNN 這個東西
希望可以幫助你對 CNN 有更深地了解
好 所以我們說這個
為什麼用 CNN 是基於兩個觀察
第一個觀察是 我們不需要看整張圖片
那對 Neuron 的故事版本
對於第一個故事而言就是
Neuron 只看圖片的一小部分
對 Filter 的故事而言就是
我們有一組 Filter
每個 Filter 只看一個小範圍
它只偵測小的 Pattern
然後我們說 同樣的 Pattern
可能出現在圖片的不同的地方
所以 Neuron 間可以共用參數
對 Filter 的故事而言就是
一個 Filter 要掃過整張圖片
這個就是 Convolutional Layer
那 Convolutional Layer
在做影像辨識的時候呢
其實還有第三個常用的東西
這個東西呢 叫做 Pooling
那 Pooling 是怎麼來的呢
Pooling 來自於另外一個觀察
這個觀察是
我們把一張比較大的圖片做 Subsampling
舉例來說你把偶數的 Column 都拿掉
奇數的 Row 都拿掉
圖片變成為原來的1/4
但是不會影響裡面是什麼東西
把一張大的圖片縮小
這是一隻鳥
這張小的圖片看起來還是一隻鳥
那所以呢 有了Pooling 這樣的設計
那 Pooling 是怎麼運作的呢
Pooling 這個東西啊
它本身沒有參數
所以它不是一個 Layer
它裡面沒有 Weight
它沒有要 Learn 的東西
所以有人會告訴你說 Pooling 呢
比較像是一個 Activation Function
比較像是 Sigmoid 呀 ReLU 那些
因為它裡面是沒有要 Learn 的東西的
它就是一個 Operator
它的行為都是固定好的
沒有要根據 Data 學任何東西
那 Pooling 其實也有很多不同的版本啦
我們這邊講的是 Max Pooling
好 Max Pooling是怎麼運作的呢
我們剛才說每一個 Filter 都產生一把數字
每一個 Filter 都產生一把數字
要做 Pooling 的時候
我們就把這些數字幾個幾個一組
比如說在這個例子裡面就是 2×2 個一組
2×2 個一組 2×2 個一組
每一組裡面選一個代表
在 Max Pooling 裡面
我們選的代表就是最大的那一個
那你可能會問說為什麼是選最大的那一個呢
你不一定要選最大的那一個
這個是你自己可以決定的
Max Pooling 這一個方法是選最大的那一個
但是也有 Min Pooling 啊
Min Pooling 就是選平均嘛
我還看過選幾何平均的
所以有各式各樣的 Pooling 的方法
那你說這邊一定要 2×2 個一組嗎
也不一定
這個也是你自己決定的
你要 3×3 4×4 也可以
這個是你自己決定
好 所以我們做完 Convolution 以後
往往後面呢 還會搭配 Pooling
那 Pooling 做的事情就是把圖片變小
做完 Convolution 以後我們會得到一張圖片
這一張圖片裡面有很多的 Channel
那做完 Pooling 以後
我們就是把這張圖片的 Channel 不變
本來 64 個 Channel 還是 64 個 Channel
但是我們會把圖片變得比較狹長一點
在剛才的例子裡面
本來 4×4 的圖片
如果我們把這個 Output 的數值啊
2×2 個一組的話
那 4×4 的圖片就會變成 2×2 的圖片
這個就是 Pooling 所做的事情
那一般在實作上啊
往往就是 Convolution 跟 Pooling 交替使用
就是你可能做幾次 Convolution
做一次 Pooling
比如兩次 Convolution 一次 Pooling
兩次 Convolution 一次 Pooling
不過你可以想見說 Pooling
對於你的 Performance
還是可能會帶來一點傷害的
因為假設你今天要偵測的是非常微細的東西
那你隨便做 Subsampling
Performance 可能會稍微差一點
所以近年來你會發現
很多影像電視的 Network 的設計
往往也開始把 Pooling 丟掉
他會做這種
Full Convolution 的 Neural Network
就整個 Network 裡面統統都是 Convolution
完全都不用 Pooling
那是因為近年來運算能力越來越強
Pooling 最主要的理由是為了減少運算量
做 Subsampling
把影像變少 減少運算量
那如果你今天你的運算資源
足夠支撐你不做 Pooling 的話
很多 Network 的架構的設計
往往今天就不做 Pooling
全 Convolution
Convolution 從頭到尾
然後看看做不做得起來
看看能不能做得更好
好 那一般以後
你的架構就是 Convolution 加 Pooling
那我剛才講過說 Pooling 是可有可無啦
今天很多人可能會選擇不用 Pooling
好 那如果你做完幾次 Convolution 以後
接下來呢
最終怎麼得到最後的結果呢
你會把 Pooling 的 Output 做一件事情
叫做 Flatten
Flatten 這個字眼剛才在作業二裡面
助教其實也有提到所謂 Flatten 的意思就是
把這個影像裡面啊
本來排成矩陣的樣子的東西拉直
把所有的數值拉直變成一個向量
再把這個向量
丟進 Fully Connected 的 Layer 裡面
最終你可能還要過個 Softmax
然後最終得到影像辨識的結果
這就是一個經典的影像辨識的Network
它可能有的樣子就是長這樣
裡面有 Convolution
有 Pooling 有 Flatten
最後再通過幾個
Fully Connected 的 Layer 或 Softmax
最終得到影像辨識的結果
那我們在作業三就是會做一個影像辨識的題目
好 那除了影像辨識以外啊
你可能聽過 CNN 另外一個最常見的
最耳熟能詳的應用
就是用來下圍棋
那今天呢 如果講個機器學習的課
沒有提到 AlphaGo
大家就覺得你什麼都沒有講對不對
所以我們來提一下 AlphaGo
好 怎麼用這個 CNN 來下圍棋呢
我們說下圍棋其實就是一個分類的問題
你的 Network 的輸入
是棋盤上黑子跟白子的位置
你的輸出就是下一步應該要落子的位置
可是我們今天已經知道說
Network 的輸入就是一個向量啊
那怎麼把棋盤表示成一個向量呢
完全沒有問題
棋盤上就是有 19 × 19 個位置嘛
那我們就把一個棋盤
表示成一個 19 × 19 維的向量
在這個向量裡面
如果某一個位置有一個黑子
那那個位置我們就填 1
如果白子我們就填 -1
如果沒有子我們就填 0
那我們就可以告訴 Network 說
我們就可以告訴 Network 說
現在棋盤上的盤勢長什麼樣
我們可以用一個 19 × 19 維的向量
來描述一個棋盤
當然這不一定是要這麼做啦
不一定要黑子是 1 白子是 -1
然後沒有子就是 0
這只是一個可能的表示方式而已
你們可以想出其他更神奇的表示方式
總之我們有辦法把棋盤上的盤勢
用一個向量來描述
把這個向量輸到一個 Network 裡面
然後呢
你就可以把下圍棋當作一個分類的問題
叫這個 Network 去預測
下一步應該落子的位置落在哪裡最好
所以下圍棋
就是一個有 19 × 19 個類別的分類的問題
Network 會 Output 說
在這 19 × 19 個類別裡面
哪一個類別是最好的
應該要選擇下一步落子的位置應該在哪裡
那這個問題完全可以用一個
Fully Connected 的 Network 來解決
但是用 CNN 的效果更好
為什麼用 CNN 的效果更好呢
首先你完全可以把一個棋盤
看作是一張圖片
一個棋盤
可以看作是一個解析度 19 × 19 的圖片
一般圖片很大
一般圖片可能都 100 × 100 的解析度
都是很小的圖片了啊
但是棋盤是一個更小的圖片
這個圖片它的解析度只有 19 × 19
這個圖片裡面每一個像素 每一個 Pixel
就代表棋盤上一個可以落子的位置
那 Channel 呢
一般圖片的 Channel 就是 RGB 嘛
RGB 代表一個顏色
那棋盤上每一個 Pixel 的 Channel
應該是什麼呢
在 AlphaGo 的原始論文裡面它告訴你說
每一個棋盤的位置
每一個棋盤上的 Pixel
它是用 48 個 Channel 來描述
也就是說棋盤上的每一個位置
它都用 48 個數字
來描述那個位置發生了什麼事
那至於為什麼是這 48 個
那這個顯然是圍棋高手設計出來的
那 48 個位置包括
比如說 啊 這個位置是不是要被叫吃了
這個位置旁邊有沒有顏色不一樣的等等
就是這樣子描述每一個位置
所以你會用 48 個數字
來描述棋盤上的一個位置
這一個棋盤它就是 19 × 19 的解析度的圖片
它的 Channel 就是 48
好 但是為什麼 CNN 可以用在下圍棋上呢
我們剛才就有強調說 CNN 啊
其實並不是你隨便用都會好的
它是為影像設計的
所以如果一個問題
它跟影像沒有什麼共通的特性的話
你其實不該用 CNN
所以今天既然在下圍棋可以用 CNN
那意味著什麼
那意味著圍棋跟影像有共同的特性
什麼樣共同的特性呢
我們剛才講說在影像上的第一個觀察是
很多重要的 Pattern
你只需要看小範圍就知道
下圍棋是不是也是一樣呢
舉例來說這一個 Pattern
你就算不用看整個棋盤的盤勢
你都知道說這邊發生了什麼事
這個就是白子被黑子圍住了嘛
那接下來黑子如果放在這邊
就可以把白子提走
那白子要放在這邊才不會
才可以接這個白子 才不會被提走
那其實在 AlphaGo 裡面啊
它的第一層的 Layer
它的 Filter 的大小就是 5 × 5
所以顯然在設計這個 Network 的人覺得說
棋盤上很多重要的 Pattern
也許看 5 × 5 的範圍就可以知道了
再來是我們說影像上的第二個觀察是
同樣的 Pattern 可能會出現在不同的位置
在下圍棋裡面是不是也是一樣呢
這個叫吃的 Pattern
它可以出現在棋盤上的任何位置
它可以出現在左上角
也可以出現在右下角
所以從這個觀點來看
影像跟下圍棋有很多共同之處
但是讓人想不透的地方是
在做影像的時候我們說我們都會做 Pooling
也就是一張影像做 Subsampling 以後
並不會影響我們對影像中物件的判讀
但是棋盤是這個樣子嗎
你可以把棋盤上的奇數行跟偶數列拿掉
還是同一個棋局嗎
聽起來好像不是對不對
下圍棋這麼精細的任務
你隨便拿掉一個 Column 拿掉一個 Row
整個棋整個局勢就不一樣啦
怎麼可能拿掉一個 Row 拿掉一個 Column
還會沒有問題呢
所以有人就會說
啊 CNN 裡面就是要有 Pooling
然後影像辨識都是用 Pooling
所以 AlphaGo 也一定有用 Pooling
所以代表 AlphaGo 很爛啊
針對 Pooling 這個弱點去攻擊它
一定就可以把它打爆
真的是這樣嗎
可是 AlphaGo 又這麼強
顯然它沒有這麼顯而易見的弱點
所以這個問題就讓我有點困擾
好 但後來我就去仔細讀了一下
AlphaGo 那篇 Paper
其實 AlphaGo 在 Nature 上的 Paper
其實沒有多長
大概就
我記得就五 六頁而已
所以其實你一下子就可以看完了
而且在這個文章的正文裡面
甚至沒有提它用的網路架構是什麼樣子
它沒有講 Network 架構的細節
這個細節在哪裡呢
這個細節在附件裡面
所以我就仔細讀了一下附件
看看說 AlphaGo 的網路結構長什麼樣子
好 我們就來看一下
這個附件裡面是怎麼描述
AlphaGo 的類神經網路結構的
它先說呢
我們把一個棋盤
看作 19 × 19 × 48 那麼大小的 Image
這我們剛才講過了
把棋盤看作是一個圖片
好 接下來它說它有做 Zero Padding
Padding 這件事我們有講嘛
就是你的 Filter 如果超出影像的範圍就補 0
Zero Padding 就是超出範圍就補 0 的意思
好 它說它的 Filter 的大小啊
Kernel Size 就是 Filter 的大小是 5 × 5
然後有 k 個 Filter
k 是多少
k 是 192
這當然是試出來的啦
它也試了 128 跟 256 發現 192 最好了
好 這是第一層
然後 Stride=1
Stride 是什麼 我們剛才也解釋過了
然後這邊有用了 Rectifier Nonlinearity
這是什麼
這個就是 ReLU 啦
這個就是 ReLU
然後在第二層呢
到第 12 層都有做 Zero Padding
然後呢 這個 Kernel Size 都是 3 × 3
一樣是 k 個 Filter
也就是每一層都是 192 個 Filter
Stride 呢 一樣設 1
就這樣疊了很多層以後呢
因為是一個分類的問題
最後加上了一個 Softmax
讀完以後你有發現什麼玄機嗎
發現它沒有用 Pooling 啊
就是這個樣子
所以這給我們一個很好的例子就是
類神經網路的設計這個應用之道
存乎一心啊
你不要看影像上面都有用 Pooling
就覺得 Pooling 一定是好的
在下圍棋的時候就是不適合用 Pooling
所以你要想清楚說
你今天用一個 Network 架構的時候
我這個 Network 的架構到底代表什麼意思
它適不適合用在我現在這個任務上
而那 CNN 呢
除了下圍棋還有影像以外
欸 近年來也用在語音上
也用在文字處理上
這邊我們就不再細講
但是呢 你如果你真的想把 CNN 用在語音上
用在這個文字處理上
你要仔細看一下文獻上的方法
這個在影像 在語音上
在文字上
那個 Receptive Field 的設計啊
這個參數共享的設計啊
跟影像上不是一樣的
所以你要想清楚
那些 Receptive Field 用在語音
用在文字上的設計跟影像上不是一樣
是考慮了語音跟文字的特性以後所設計的
所以你不要以為在影像上的 CNN
直接套到語音上它也 Work
可能是不 Work 的
你要想清楚說影像
語音有什麼樣的特性
那你要怎麼設計合適的 Receptive Field
好 那有人會說 CNN
其實 CNN
它沒有辦法處理影像放大縮小
或者是旋轉的問題
怎麼說呢
假設今天你給 CNN 看的狗都是這個大小
它可以辨識說這是一隻夠
當你把這個圖片放大的時候
它可以辨識說牠還是一隻狗嗎
可能是不行的
你可能會想說 欸怎麼會不能夠辨識呢
這兩個形狀不是一模一樣啊
怎麼放大就不能辨識呢
CNN 這麼笨嗎
它就是這麼笨
對它來說這兩張圖片
雖然這個形狀是一模一樣的
但是如果你把它拉長成向量的話
它裡面的數值就是不一樣的啊
所以對 CNN 來說
雖然你人眼一看覺得它形狀很像
但對 CNN 的 Network 來說它是非常不一樣
所以事實上
CNN 並不能夠處理影像放大縮小
或者是旋轉的問題
當它今天在某種大小的影像上
假設你裡面的物件都是比較小的
它在上面學會做影像辨識
你把物件放大它就會整個慘掉
所以 CNN 並沒有你想像的那麼強
那就是為什麼在做影像辨識的時候
往往都要做 Data Augmentation
所謂 Data Augmentation 的意思就是說
你把你的訓練資料
每張圖片都裡面截一小塊出來放大
讓 CNN 有看過不同大小的 Pattern
然後把圖片旋轉
讓它有看過說
某一個物件旋轉以後長什麼樣子
CNN 才會做到好的結果
那你說 欸 CNN 這個不能夠處理 Scaling
跟 Rotation 的問題啊
那有沒有什麼 Network 架構
是可以處理這個問題呢
其實有的
有一個架構叫 Special Transformer Layer
我們不會講它
就把它的這個錄影的連結放在這邊
給大家參考
