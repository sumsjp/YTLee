臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://ai.ntu.edu.tw/
那我們剛剛講的那些東西都是 attack 在影像上面的應用
那我們現在要講 attack 在音訊上面能夠做到哪些事情
我們等下會跟大家介紹三個東西
第一個是 attack 應用在 ASR 上面
第二個是 attack 應用在 ASV 上面
那這兩個我們大概都會簡單講一下說他是在幹嘛
不過他跟前面 image 的攻擊其實還蠻像的
所以說我們並不會到非常非常詳細的去講解他
那後面的 hidden voice attack 也不是我們等下要講的重點
我們會告訴大家說他跟前面兩個 attack 不太一樣的是
他攻擊的並不是那個用 deep learning train 的那個 model
而是攻擊我們在把資料餵進 deep learning model 之前
我們需要做的 preprocess 這個階段
我們從這個階段來著手這個攻擊
我們現在要來跟大家講一下
attack 在 ASR 上面的應用
什麼是 ASR 呢
ASR 就是 auto speech recognition 的縮寫
那他做的事情就是一個自動化的語音辨識
也就是說你今天如果講了一段文字
這個 model 他會自動幫你把你剛剛講的話
用文字轉出來
舉例來說如果我說 it was the best of times.
it was the worst of times
那你的 model 正常來講
他應該舊會吐出一句類似我剛剛講的一段文字
好那今天要怎麼攻擊這個 model 呢
你其實可以把他想像成
一段音訊其實就是一個一維的圖片
那你就是一樣對這一維做 FGSM attack
然後去算出一個 perturbation，然後再將這個噪音
加回你原本要去做 transcript 的音訊
這個音訊加入噪音之後，我們一樣餵入原本的 model 裡面
這個 model 可能原本應該會預設出這個句子
可是因為你加上雜訊之後
他可能造成他文字上面的一些錯誤
比如說原本應該是要
讓他辨識出 it was the best of times, it was the worst of times
可是因為加入這段雜訊之後
那個 model 就把原本的句子辨認成 it is a truth universally acknowledged that a single
聽起來很沒有意義這樣
那這個就是 attack 在 ASR 上面的做法
我們現在講一下 attacks on ASV
ASV 是什麼呢
ASV 就是 automatics speaker verification
也就是說你今天講一段文字
這個 model 可以辨識說這段文字是你講的
那如果有另外一個人講，他也可能可以成功辨識說
那是另外一個人講的
總之他就是會根據這段 input 的音訊
然後去辨認說這段音訊是屬於哪個 speaker 所講出來的話
那今天一樣
我們也是用 FGSM 來產生一段雜訊
將這個雜訊再加回原本的音訊
這個加上雜訊的音訊
餵入我們的 model 之後
原本這段音訊可能是 A 這個 speaker 所講的 可是因為你有這個雜訊讓 model 可能不小心判斷成 b 這個人講的
那這個就是 attack 在 ASV 上面的應用
我們這邊要來跟大家講下
一個很厲害很厲害的東西
他叫做 wake up words
我們先來看一下這段影片
你看完這支影片你可能會想說，蛤？
這到底是什麼東西？這也算攻擊嗎
你可以再注意聽一下他最後講的那段
他問說 google 什麼是華堡
好那這到底在幹嘛呢
那個時候有個東西叫做 google home
這個 google home 如果牽涉到剛剛講的指令
像他剛剛就以為說，使用者問了
誒什麼是華堡
華堡是漢堡王的一種漢堡
那這個 google home 他就會去維基百科
把華堡裡面的介紹一字不漏地唸給你聽
那我們也知道維基百科其實是可以被很多人改的
那有些人就會開始亂改說華堡裡面有加了什麼奇怪的東西
一個最誇張的就是之前還被人家改說華堡裡面其實加的是人肉
那 google home 他也就真的乖乖的一字不漏地把這些東西唸出來
這個其實當時還蠻轟動的因為
如果你家電視機旁邊就有一個 google home
那每次只要播到這個廣告
這 google home 就會被啟動
那也在那個時間點下，同時很多人
都去 query 維基百科華堡的這個頁面
導致流量瞬間大增
我們現在來跟大家介紹一下 hidden voice attack
這個 attack 其實剛剛的 wake up words 其實有點像
剛剛那個 wake up words 是藉由廣告裡的一段指令去啟動你的 google home
那這個 hidden voice attack 他一樣會講一個指令
只不過這個指令會被做一些修改
讓你聽不出來他是一段指令
這段指令等下我們播出來讓大家聽一下
你會發現它就跟一段雜訊沒什麼兩樣
我舉個例來說
假如說今天原本是講 hey siri
那這個 attack 會去把 hey siri 這段文字做一些
我的 iphone 被啟動了
那他做的事情就是
會把 hey siri 你剛剛講的這段音訊
做一些修改，修改到讓你聽不出來
你其實可以想像說那這是一個多恐怖的事情
今天你拿著這段音訊去一個公共場合把它播出來
大家只會聽到一段噪音，但大家不會知道那個就是 hey siri
然後接著你附近所有人他只要是 iphone，他可能一不小心就被啟動了
好那我們等下要播一下這段音訊這樣子
那可能你要稍微把聲音調小聲一點，不然我是怕會傷到你的耳朵這樣子
好那我現在要播了
不知道你有沒有聽出來，如果沒有聽出來沒關係，我可以再播一次
有聽出來了嗎
好那如果沒有聽出來沒有關係
我現在把答案告訴你，他剛剛講的那段文字
是叫做 turn on the computer
那你知道這個答案後你再去聽一次，看你聽不聽得出來
好那我想你應該也有聽出來了吧
你一開始會聽不出來其實原因還蠻簡單的因為
一段雜訊你說真的要聽懂那個文字是還蠻困難的
但是我一旦跟你講了答案之後你的大腦就會去預設一個立場說我等下應該要聽到什麼
然後你就會針對你腦袋中預設的那個答案去更仔細的聽說
你剛剛聽到的那個雜訊有沒有我剛剛跟你講的那段文字這樣子
我們在實際講 hidden voice attack 是什麼東西之前
我們要先給大家一個概念叫做 psychoacoustics
psychoacoustics 是什麼意思呢
他翻成中文就叫做心理聲學
也就是說我們會去研究說
人對聲音包括我們現在講的這種話
一般的話跟 speech 以及音樂
我們生理跟心理反應是什麼樣子的
這就是 psychoacoustics
他就是研究我們人對聲音的感知程度和反應
舉最簡單的例子
我們都知道感知的極限
我們人大部分的人都只能聽到 20 Hz ~ 20000 Hz 之間
這個範圍之內的頻段
那如果超出這個範圍的話，大概是聽不到
那當然會隨著人的年齡，這個範圍也會愈來愈小
特別是我們在高頻段上面，很多人可能已經聽不到 16000 以上赫茲的聲音
再來也是一個很重要的東西就是
聲音的定位
同樣是來自四面八方的聲音
但我們就是能分辨出來說，這段聲音是從可能右前方來的，那另外一段聲音可能是從左後方來的這樣
人藉由雙耳所聽到的聲音的時間或是響度差
來藉由這個響度差或是時間差來辨識出聲音是從哪個方位而來的
其實我想如果你有玩過那種 3D 遊戲的那種槍戰什麼的
之類的遊戲你其實都可以知道
你戴上耳機之後
你其實可以聽出那個槍聲是從哪裡來的
你可以聽出那個腳步聲可能是從你
樓梯上面的那層樓的上面傳出來的還是從你後面、還是從你做後方、還是那個甚至在你的正前方
你都可以藉由那個聲音來聽出來
這個就是我們人耳對聲音定位的反應
這邊這張圖是在做 hidden voice attack 的時候
他原本的音訊跟經過攻擊的音訊
他們前後之間的差別
其實我們剛剛講的，像我們剛剛講的 hey siri 這段音訊
他其實也就是應用 psychoacoustics 裡面的一些概念
也就是我剛剛講說，我讓你聽說
好我的 hey siri 又被啟動了
來那他這個概念就是說
我今天直接播一段雜訊給你聽
那這段雜訊
我如果沒有跟你講答案
你其實是不知道這段雜訊當中其實是有一些有意義的文字
就像那個 turn o n the computer，我一開始播給你聽的時候你其實是聽不太出來裡面有什麼字的
那這個也是 psychoacoustics 的一環
那這個 hidden voice attack 其實就是利用了這個性質
反正我播的音訊，你聽了幾次大概也是聽不出來裡面是在講什麼這樣子
那你可以發現經過我們攻擊的這段音訊
他跟原本的音訊其實已經長得非常非常非常的不一樣了
這也是為什麼你其實聽不太出來他在講什麼的原因之一
那你也可以看到說不管是振幅或者是音訊的長度
都有一些很明顯的變動
那我們等下會跟大家講說這些變動是如何做成的，然後
要如何改用原本的音訊，好讓這個原本的音訊
能夠讓你人耳聽不出來是什麼
但是這邊又有一個很重要的前提就是
你這個音訊即使做了更動之後
還是要讓你的 model 能夠正確的辨識
這樣才有辦法啟動那個你蘋果的裝置，或是啟用 google home
或是啟用一些其他 speech 的 API
來讓他正確辨識出你講的文字
然而他最重要的就是
他其實 attack 的就是我們人的耳朵、我們人的大腦
他就是要讓你聽不出來剛剛那段雜訊裡面到底講了什麼東西
我們現在要開始跟大家講說
這個 hidden voice attack 他是如何實作的？他的原理到底是什麼
那在講這個之前我們要讓大家知道
我們一般音訊在做語音辨識之前
我們在餵進 model 的時候
是不能直接餵進去的，我們必須對他做一些 preprocess
對他做一些些微的更動
來讓 model 可以將我們剛剛講的音訊吃進去
那你可以把 signal processing 這個工作
你就想像說，他是這樣一段音訊當中重要的資訊抽取出來
那其實我們這個 hidden voice attack
他攻擊的就是這個 signal preprocessing 的這個階段
跟我們平常看到的 image
或者是我們剛剛看到的 ASR attack, ASV attack
非常非常的不一樣
我們剛剛講的那些 attack 他攻擊的都是這個 model 在 inference 的這個階段
也就是說 model 其實是已經被 train 好的
但是我藉由我更動 input 加上一些噪音之後
我又讓你這個原本 train 好的 model 去做一些預測錯誤的行為
去讓 model 沒有辦法正確的辨識說這個話是哪個人講的
或者說這段話是什麼樣的文字
又或者是你給他一張圖片，那個 model 會把他辨識成可能另外一個錯誤的類別這樣子
但這個 hidden voice attack 他做的不是這個事情
hidden voice attack 反而要讓你這個 model 在 inference 的時候
能夠被正確的辨識
也就是說
像我們剛剛講的 auto speak recognition
我們剛剛講的那個 hey siri ，但是那個 hey siri 他不是
我說他會被加入一些奇怪的東西
然後去改一改、動一動，讓人聽不出來他講的是 hey siri
但是你聽不出來沒有關係
好我的 hey siri 又被啟動了
好不管他
我們剛才講到說
那個我們剛才講的一段文字
反正你人聽不懂
對就是要讓你人聽不懂
但是 model 仍然能夠正確地辨識出
你剛剛講的那段文字
好那現在講到這裡大概要跟大家講一下說
這個 signal preprocessing 他到底是在做什麼用的
不過我們這邊大概就是大略講過去，如果你非得要知道這每個 block 裡面的細節是在講什麼的話
你可能要去上一下數位語音處理概論的課這樣子
那我們這邊就是大概講過去這樣
首先前面有一個不用 processing 的階段
他裡面有 low-Pass Filter 跟 Noise Removal
那這個 low-pass filter 他就是容許低頻的訊號可以通過
但是他會減弱或者是減少頻率高於截止頻率的訊號
也就是說我們會把頻率太高的部分把他濾掉
那再來 noise removal 就是字面上的意思，他會去除一些雜訊
那在做完 noise removal 之後
接下來要做的就是 signal preprocessing
signal preprocessing 他第一個做的就是 FFT
FFT 就是 Fast Fourier transform
那這個 Fast Fourier transform 裡面實際的數學在做什麼
同學其實不太需要知道
同學只需要知道 FFT 會把時域轉成頻域
那我們目的就是需要知道這個訊號包含的成分是什麼
也就是說某某頻域他的成分有多大
舉例來說我們人所發出的聲音頻率一般最高就是到 4k Hz
所以我們可以用這種方法來分析說人的聲音大部分是落在哪個頻域
我們用 FFT 會得到一個 spectrogram
那得到這個 spectrogram 之後
我們為了得到合適大小的聲音特徵
我們接著會通過一串 mel filter bank
那這個 mel filter bank
在講這個之前
要讓大家知道說我們人耳對那種特別高的頻段其實是滿遲鈍的
那反而是對我們平常講話的這個頻段
的頻率反而是比較靈敏的這樣
那這個 mel filter bank 其實就是蠻符合我們的人耳的設計這樣
他在低頻數的濾波器比較密集
那高頻段的濾波器就會比較少這樣子
那經過這個 mel filter bank 之後
還會再做一些數學運算
那一樣這些數學運算大家一樣知道就好
他是 log of powers 跟 discrete cosine transform
經過這些數學運算以後我們最後可以得一些數字，這些數字
就是叫做 acoustic feature
那這個 acoustic feature 也就是我們最後要餵進 model
的那些 input
好那我們現在來實際跟大家講說
我們這個一段音訊他是要如何被做攻擊
那他加入 perturbation 的方法主要有四種
第一個是 Time Domain Inversion
第二個是 Random Phase Generation
第三個是 High Frequency Addition
第四個是叫 Time Scaling
那我們給大家看一下
上面這段藍色的線是原本的音訊這樣
那下面是總共有四種 perturbation
也就是說原本的這段波形在經過 time domain inversion 的話
他的圖片就會變成這樣子
那原本的音訊經過 Random Phase Generation
他的波形就會變這樣子
那經過 High Frequency Addition 波形就會變這樣子
那經過 Time Scaling 波形就會變這樣子
那我們等下就會一一介紹這兩個 perturbation 分別是在做什麼
然後是用什麼原理來達成的
我們現在來介紹一下 Time Domain Inversion
這個 time domain inversion 他利用的就是
magnitude 的 fft
他多對一的性質
意思就是說我今天有可能
input 是兩個不一樣的波
但是這兩個不一樣的波
最後做出來的 magnitude fft
居然會是相同的
那你說這樣子可以幹嘛呢
這不就代表說我們今天原本一段音訊
我有可能經過修改
但是仍然讓他的 magnitude fft
算出來的結果是一樣的
那我下面就有舉一個例子就是說
像散波跟副散波他的 magnitude fft 結果都是右邊那個圖的樣子
好那這樣可以幹嘛呢
你可以想像說好像讓他加個負號
是不是就可以讓我們的音訊不太一樣
但是卻讓 magnitude fft 的結果卻是一樣的
所以我們才會叫做 time domain inversion
我們其實就是把這段波
一直作翻轉
這樣子有什麼好處
因為正向波一直這樣做 inversion 之後，你其實已經
聽不出來他原本是講什麼的
因為他的聲音已經變得斷斷續續的
聽起來其實就算一段很奇怪的斷斷續續的噪音
所以說你才會看到我們最後面的那張圖
原本的音訊已經變得像鋸齒狀了
因為我們不斷地對他做 inversion
那這樣其實就可以達到一個
我改變原本的音訊，去讓最後 preprocess 的結果一樣的效果
那剛剛講完 time domain inversion
那現在我們要講第二種 perturbation 的方法
他叫做 random phase generation
這個 random phase generation 是在做什麼呢
我們先來給大家一個觀念
我們在做完 frequency spectrogram之後
fft 回傳的東西是一個複數形式
a + bi
那這個 a + bi 到底是什麼東西呢
這個 a + bi 其實就是我們這段 signal 的 phase
那有這個 a,b 可以幹嘛
有這個 a,b 我們就可以算
這個 signal 他的 magnitude
那 magnitude 怎麼算呢
我們就是利用 a 平 + b 平再開根號
那同學看到這邊有沒有想到一件事情
如果我們要維持我們這個 magnitude 是一樣的話
是不是可以調整這個 a,b
去讓這個 magnitude 仍然是一樣的數值
這代表什麼
代表了我們調整一個 signal 的 phase
去讓他的 magnitude 跟原本一模一樣
那這樣可以做什麼呢
如果 phase 跟原本的不同
我們這個音訊聽起來就會跟原本不一樣
但是仍然是一個很重要的一點
那就是 magnitude spectrum 仍然會相同
為什麼呢
因為我們控制 a,b 讓他在做平方和開根號之後
magnitude 仍然會是一樣的
這個就是叫 random phase generation
那右下角的圖就是我們在經過 random phase generation 之後
他原本的波形會變成像現在這樣子
你一樣也是可以看到說他是比較高低起伏然後會有一點點感覺不連續然後上下亂跳這樣子
我們剛剛講完 random phase generation 之後
我們來跟大家介紹第三種 perturbation 的方式
他叫做 high frequency addition
那這個 high frequency addition 是在做什麼呢
在 preprocessing 的過程當中
你還記得有個 low-pass filter
他會把相較於人聲高很多的頻段濾掉
那這樣子做的好處他可以增加 VPS 的正確率
那我們既然知道 low-pass filter 會把相較人聲高很多的頻段濾掉
我們是不是就可以在裡面加入一些高頻段的音訊
反正我加了這些音訊之後
等一下都會被 low-pass filter 濾掉
那這樣勢必 preprocess 後的結果
應該是不會差太多的
可能甚至會是一樣的
我們就是利用這點，我們在原本的音訊裡面
加入很多高頻率的 sine 波
那這些音訊加入了很多高頻率的 sine 波會發生什麼事呢
你這個音訊勢必就會感覺加入了一些奇怪的噪音
而且這些噪音如果加了很多的話
甚至他的強度可能會很強
這也是為什麼我們剛剛 demo 的時候跟同學說必須要把聲音關小聲的原因之一
因為你可以看到說像右下角的這張圖
那個原本好好的音訊在使用 high frequency addition 之後
他音訊會變成右下圖這樣子
你可以看到說他其實上下起伏很大的變化
然後他振幅也非常非常大這樣子
那如果加入一堆 sine 波之後
勢必會讓原本的音訊聽起來很不舒服
那這個也就達到了我們 hidden voice attack 他的目標之一
就是讓你聽得不太舒服然後又聽不出你的內容是在講什麼
但是因為我們剛剛加的都是 high frequency sine 波
所以 low-pass filter 都會把這些東西濾掉
濾掉之後會造成 preprocess 後的結果
仍然是相同的
好那我們剛剛講完 high frequency addition之後
我們要來介紹第四種加入 perturbation 的方法
那就是 time scaling
這個 time scaling 顧名思義你可以聽得出來
他是在時間軸上做一些更動
那你可以想像他在做的事情就是
我們將音訊快轉到讓 model 能夠正確辨識
但是我們人又聽不太懂他是在說什麼
然而要知道一件事情
就是說我們即使將這段音訊快轉了
但是我們仍然要確保這段音訊的 sample rate 是一樣的
我們原本假如說一段音訊有十萬個點
那這十萬個點如果我們把他快轉到時間剩下一半的話
那勢必在這一半的時間之內
我們必須要再丟掉五萬個點
才有辦法讓他的 sample rate 仍然是相同的
我們在這邊先解釋一下什麼是 sample rate
那 sample rate 就是說我們一個波是不是由好幾個點所組成
那這個 sample rate 就是每秒有幾個點這樣子
所以才會說如果我們把時間減半的話
我們必須要丟掉一半的資料，我們才有辦法維持一定的 sample rate 這樣
那我們就是藉由這個方法
讓我們 audio 變短
但是那個我們出來的 spectrum 還是會跟原本的一樣
好那我們剛剛把四種 perturbation 的方法都介紹完了
那就讓大家回顧一下說，左邊這個是我們原本的 audio
那經過我們的 time domain inversion
然後 random phase generation
跟 high frequency generation 以及 time scaling 之後
我們原本一段好好的音訊
就會被變成右邊這個紅色的波形
那勢必說你可以看到這兩個波型差非常多
那我們人耳聽到可能就沒有辦法聽出來原本的音訊是在講什麼東西
但然而一個非常重要的點就是說
這段藍色跟紅色的音訊在經過 preprocess 之後
他們的結果都會是一樣的
那這樣 model 就有辦法正確的辨識
那現在其實是講完了我們今天要上課的所有內容
我們幫同學複習一下我們今天大概講了什麼樣的東西
我們今天講的主要是分為 attack 在影像上面的 task 以及
attack 在音訊上面的 task
我們在影像上面我們講了 one pixel attack
以及我們在實作 one pixel attack 的時候我們需要的 differential evolution
我們利用 differential evolution 找出我們要攻擊的那個 pixel
以及那個 pixel 對應的 r,g,b 值
再來是講說 attack 在音訊上面的攻擊
我們稍微介紹了一下 attack 在 ASR 以及 ASV 上面
他的應用
以及我們花最久時間講的 hidden voice attack
我們可以看到我們不管是在音訊
還是在圖像上面的 attack
他們要做的事情不盡相同
然後意義也不盡相同
甚至他們攻擊的對象也不全然一樣
那希望同學在看過這些 attack 之後
能夠受益良多然後學習到一些新的演算法
那這個是我在講投影片當中用到的一些參考資料
歡迎同學點擊然後去做進一步的學習
那我們今天的課程就到此結束，謝謝各位同學，謝謝大家
