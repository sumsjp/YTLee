[Music]
hello everyone my topic is one shot
voice convergent by vector connotation
my name is da who and my supervisor is
Tommy Lee we account for our nation tell
you diversity and to my knowledge did
the first attempt using vector
connotation technique to achieve while
sharp voice converging so this is our
outline we were first introduced about
what it's voice converging and focus our
intentional feature distinct of based
NASA and introduced about better
connotation and we will talk about our
proposed approach and our experiment so
let's introduce about voice coverage
voice converging is a task transform the
audio speaker a speaker be purpose of is
linguistic content it has many
application like consultation of
text-to-speech system personalized HCI
and privacy protection in general we
divided tasks into two categories para
data and improve data parody tom is that
the speakers in the data set with the
same corpus a such kind of data sets how
to collect um parody I don't have this
question there are two main method in
Arabic data didn't respond and CJ didn't
angle ten base model likes psycho
against our gain slope based model I
blow and ward belongs to period
transform in this talk we will focus on
feature disentanglement method so from
now we will focus on the future
disentangle based method cause of the
absence of the pair data feature is in
tango bass voice conversion can be seen
as a random of collect order the loss
function here minimizes - grant distance
between input and output
our main target here is not to
reconstruct the origin signal was speedy
embedding space
our goal is speed embedding space into
content and speaker information
if the counter encoded experiment called
a well-trimmed
we just replaced the input before
speaker encoder as our target then the
voice convergence fulfilled when the
main question here is how can we make
one encoded for content and one for
speaker here we'll leave some common
method for content encoder we have
internalization but the bursa LOS vector
connotation and is at which a model for
speaker encoder we have one huckleberry
printed model like adapter architecture
and D vector and a die in this talk we
will focus on the model that no need of
pretend like internalization a reversal
loss and other in a reversal money is a
typical voice coverage of Messer
he learned the future disentangle by
reversal on a general speed classifier
on company Betty and a job of containing
coded to learn to for discrimination but
at the same time is fulfilled auto
encoder in speaker Kasper cannot craft
by N's betrayal campaign Betty maybe it
means that the content color cannot
encode any speaker information here we
introduce a network architecture
designed in sedimentation in
sedimentation subject the in bed space
from its mean and divide a standard
deviation is improved at this kind of
design can remove del information and in
the audio to man tell information maybe
the speaker information and it is also
very success in voice conversion so
there's two major contribution in our
paper first we add vector condensation
after Intel normalization which Allah
made more speaker information second we
derive a new method to distress be the
information on the adapter connotation
scheme
so let's first introduce what is vector
commutation and we start from the
typical auto encoder for auto encoder we
put the audio signal to the an encoder
and get encoder output and we put the
encoder output direct into the decoder
which means that encoder output is equal
to the decoder input intercalation is a
small modification first we denote our
encoder
as context before vector and we have a
set of the novel vectors we denote them
as our codebook we compute a similarity
between the content before vector and
each vector in our corpora and select
the one which is most similar to our
contacts before vector and then project
it as our decoder input because of the
connotation there may be some
information loss between the contact
before detector but some kind of design
can missing information puzzling because
only few of factors can be the decoder
input and information button is very
important in for his conversion here is
some table related to the tactical
integer and formal citation please click
on funder to ask his paper it is but
that there may be a set of contacts in
desk image for meditation and these
people also show that vector
quantization valuation auto encoder is
got a speaker Commissioner post and this
is another paper the left hand side is
quite the batting that better
commentator learned and the rest is the
international phonetic alphabet shot and
this is human venture they are very
similar so according to this paper when
we can learned for rehabilitation by
detecting validation so from now we will
talk about our proposed model so let's
get in our subject
first we will look at our encoder output
that it is also context before that we
did not ask our contest before doctor as
a yellow circle and its data under
invented space here different color
mister different speakers second we look
at the content vectoring on Kobol from
the slide that we mentioned above this
contest better may represent sound
forming information so on this earth
then we contact our content before
factor to the contact space and we put
the two slide above together the yellow
that points means the content before dr.
and the group is the contact Thatcher
the contest before that to find the most
similar content actors and project on it
as we mentioned above contest actual
naming some form arrogant Asia Sanfelice
big spawn different speakers put it to
the same contest vector and here is our
question what is the difference between
them before contest like this vector
this vector and respective here we have
some assumption we can view the
difference between contest before and
content vector as a speaker embedding so
this is our model architecture overview
first we fit our audio signal into
encoder get encoded output and then we
contact our encoder over together
contain daddy so here are encoded
operate the contacts before vector in
the meantime we subtract the contain
burning from the encoder output to get a
speaking body and we take the edge on
the authoress because the speaking body
is a global information and then we put
the contain bagging and speaking banding
together due to gain to the decoder in a
training phase we minimize the space
quality improve output so let's talk
about experiment we do the experiment
VCC
of us which is comprised of four hundred
uh speakers following resilience for his
speaker and about forty four hours we
random select 20 speakers as our
testings and so on the first step which
had an autoencoder and it's a general
test for future disentangle based model
and he can perform well on the second
step we test feature disentangle
bleeding we test both on content and
speaking code for coming colder we
transfigured eternity uncontained daddy
to make sure that there's no speaking
information in the content bedding for
speaking caller to the Disney on
speakers if our master is right
difference between bedding may separate
very well and in the final we listen to
our convert and audio the solids are
Kumgang dizzy
tango experiment with takes our model
and channels bigger different down or
contained any our result on right hand
side as edges win the contest number in
our code book and what assessment does
become accuracy no accuracy means a
stronger disentangled lately when our
contest amber is small we have felt very
strong vision for ability but when in
larger context under the disentangle
Brady job when our number is 256 gives
almost 50% accuracy and this cannot
achieve oil converging in the nest depth
we put in turn normalization before
vector quantization the random is that
the internalization with all
quantization and the green lines meet
the condition path is analyzation and
the recession that the performance list
very much in love we compare our result
is go to easy energy voice conversion by
retreat the diamond and hit the content
space he means that in the diminutive of
k√∂nigsberg small enough then there may
be no speaker information can be encoded
in it's all homie sees will change you
have a very strong is entangled lady on
this gravity
yellow lies but if we're in love the
dimension of the content base it is Auto
busy word eternal phone voice coverage
em and visually single operated job so
also easily sensitive to the divinity of
the dotted space but our model is not so
sensitively contact number even if we in
not our continent to 256 the accuracy
only 20% and then we do the experiment
on speaking pairing we extra 20 on sink
speakers bedding in our testing set and
do disney of them s means female and all
miss Belle there's a boundary between
female in there and you can see that the
difference between bedding can be
separate very well it means that our
speaking very little success
so in the final we human evaluate our
converted audios and the realization
resulted in our paper so this is our
conclusion speaker embedding can be
directly exchanged by difference between
context before a competitor vector
colonization past internalization
performs better
so this is all demo all source and
target audios is in our testing set and
there are on things because the
converted audio is not generated by the
model we mentioned above we use a more
powerful model the ASCII Keynesian model
between our encoder and decoder so
because of the strong is tango ability
of vector connotation even we add skin
collation module they can also for your
voice conversion so let's just listen
the audio this is female to male voice
converging Washington is consumed by the
crisis we are really impressed
Washington is consumed by the crisis
male to female voice converging not part
of the attempt empathy for back to whole
thing was just unreal
what
portable feel some sympathy for budget
three mental female writers closed for
several hours he has given a new deputy
minister to transform plant there a nice
place for settle on Malcolm L Lockerbie
has been a terrible disaster for
everyone they keep the atmosphere in boy
Lockerbie has been a terrible disaster
for every well thank you very much
