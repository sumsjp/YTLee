我們已經看了作業一了
其實之後好幾個作業
它看起來的樣子
基本上都是大同小異
就是你會有一堆訓練的資料
這些訓練資料裡面
會包含了x跟y的hat
會有x¹ 和跟它對應的ŷ¹
x² 跟它對應的ŷ²
一直到xⁿ 還有它對應的ŷⁿ
測試資料
測試資料就是你只有x沒有y
剛才大家已經看了作業一了
其實在之後每一個作業
看起來都是非常類似的格式
比如說作業二
其實是做語音辨識
我們的x就是非常小的一段聲音訊號
其實這個不是真正的
完整的語音辨識系統
它是語音辨識系統的一個閹割版
x是一小段訊號
ŷ是要去預測 是要去判斷說
這一小段聲音訊號
它對應到哪一個phoneme
你不知道phoneme是什麼沒有關係
你就把它想成是kk音標就可以了
作業三叫做影象辨識
這個時候我們的x是一張圖片
ŷ是機器要判斷說這張圖片裡面
有什麼樣的東西
作業四是語者辨識
語者辨識是要做什麼事情呢
語者辨識要做的事情是
這個x也是一段聲音訊號
ŷ現在不是phoneme
ŷ是現在是哪一個人在說話
你可以想像說這樣的系統
現在其實非常的有用
如果你打電話去銀行的客服
現在都有自動的語者辨認系統
它會聽說現在打電話進來的人
是不是客戶本人
就少了客服人員問你身份驗證的時間
作業五是做那個Machine Tanslation
是做機器翻譯
x就是某一個語言
比如說
這是我唯一會的一句日文
痛みを知れ
它的ŷ就是另外一句話這樣
好 再來
現在你在留言區裡面
就可以洗一些???(02:13)之類的
訓練資料拿來做什麼呢
訓練資料就要拿來訓練我們的Model
訓練Model的過程上週已經講過了
訓練的過程就是三個步驟
第一個步驟
你要先寫出一個有未知數的function
這個未知數
以後我們都用θ來代表
一個Model裡面所有的未知函數
所以fθ(x)的意思就是說
我現在有一個function叫f(x)
它裡面有一些未知的參數
這些未知的參數表示成θ
它的input叫做x
這個input叫做feature
而接下來你要定一個東西叫做loss
loss是一個function
這個loss的輸入就是一組參數
去判斷說這一組參數是好還是不好
接下來你要解一個
Optimization的problem
你要去找一個θ
這個θ 可以讓loss的值越小越好
可以讓loss的值 最小的那個θ
我們叫做θ*
有了θ*以後
那你就把它拿來用在測試資料上
也就是你把θ* 帶入這些未知的參數
本來fθ(x)裡面有一些未知的參數
現在這個θ 用θ*來取代
用θ*來取代
它的輸入就是你現在的測試資料
輸出的結果 你就把它存起來
然後上傳到Kaggle就結束了
接下來你就會遇到一個問題
直接執行助教的sample code
往往只能夠給你???simple baseline的結果而已
如果你想要做得更好
那應該要怎麼辦
以下就是如何讓你做得更好的攻略
它適用於前期所有的作業
這個就跟魔關羽一樣你知道嗎
開局就送
可以幫助你打贏前期所有的副本
這個攻略是怎麼走的呢
從最上面開始走起
第一個是你今天如果你覺得
你在Kaggle上的結果不滿意的話
第一件事情你要做的事情是什麼
檢查你的training data的loss
有人說 我在意的不是應該是
testing data的loss嗎
因為Kaggle上面的結果
呈現的是testing data的結果
但是你要先檢查你的training data
看看你的model在training data上面
有沒有學起來
再去看testing的結果
所以你要先檢查一下
training data的loss
如果你發現
你的training data的loss很大
顯然它在訓練資料上面也沒有學好
接下來你要分析一下
在訓練資料上面沒有學好
是什麼樣的原因
這邊有兩個可能
第一個可能是model的bias
model的bias這件事情
我們在上週已經跟大家講過了
所謂model bias的意思是說
假設你的model太過簡單
舉例來說
我們現在寫了一個有未知
parameter的function
這個未知的parameter
我們可以代各種不同的數字
你代θ¹ 得到一個function
我們把那個function用這個
一個點來表示
θ² 得到另一個function
你把所有的function集合起來
得到一個function的set
但是這個function的set它太小了
這個function的set裡面
沒有包含任何一個function
可以讓我們的loss變低
可以讓loss變低的function
不在你的model可以描述的範圍內
你的model裡面有未知的參數
未知參數可以代任何的數值
把這些數值代進去以後
你得到了一個function的set
代入不同的數值得到不同的function
把所有function集合起來
你得到一個function的set
在這個set裡面
沒有任何一個function
可以讓你的loss變低
在這個情況下
就算你找出了一個θ*
它是這些藍色的function裡面
最好的那一個
它是那個藍色的function裡面
可以讓loss最低的那一個
也無濟於事了
這些都是魯蛇
它只是魯蛇裡面的霸主
就還是一個魯蛇
那個loss還是不夠低
這個狀況就是你想要在大海裡面撈針
這個針指的是一個loss低的function
結果針根本就不在海裡
白忙一場
你怎麼撈都撈不出針
因為針根本就不在你的
這個function set裡面
不在你的這個大海裡面
所以怎麼辦
這個時候重新設計一個model
怎麼重新設計
給你的model更大的彈性
我們上週已經示範過
舉例來說
你可以增加你輸入的features
我們上週說
本來我們輸入的features
只有前一天的資訊
假設我們要預測接下來的這個
觀看人數的話
我們用前一天的資訊
不夠多
那用56天前的資訊
那model的彈性就比較大了
你也可以用Deep Learning
增加更多的彈性
所以如果你覺得
你的model的彈性不夠大
那你可以增加更多features
可以設一個更大的model
可以用deep learning
來增加model的彈性
這是第一個可以的解法
但是並不是training的時候
loss大就代表一定是model bias
你可能會遇到另外一個問題
這個問題是什麼
這個問題是optimization做得不好
什麼意思呢
我們知道說
我們今天用的optimization
在這門課裡面
我們其實都只會用到gradient descent
這種optimization的方法
這種optimization的方法很多的問題
舉例來說 我們上週也講過說
你可能會卡在local minima的地方
你沒有辦法找到一個
真的可以讓loss很低的參數
如果用圖具象化的方式來表示
就像這個樣子
這個是你的model
它可以表示的函式所形成的集合
你可以把θ 代入不同的數值
形成不同的function
把所有的function通通集合在一起
得到這個藍色的set
這個藍色的set裡面
確實包含了一些function
這些function它的loss是低的
但問題是gradient descent這一個演算法
沒辦法幫我們找出
這個loss低的function
gradient descent說你要我幫你解
optimization的problem
我給你這個θ* 然後就結束了
但是這個θ^* 它給我的loss不夠低
這一個model裡面
存在著某一個function
它的loss是夠低的
gradient descent
沒有給我們這一個function
這就好像是說 我們想大海撈針
針確實在海裡
但是我們卻沒有辦法把針撈起來
這邊問題就來了
我們今天看到
training data的loss不夠低的時候
到底是model bias
還是optimization的問題呢
今天我們發現說
我們找不到一個loss低的function
到底是因為我們的model的彈性不夠
我們的海裡面沒有針
還是說
我們的model的彈性已經夠了
只是optimization gradient descent不給力
它沒辦法把針撈出來
到底是哪一個呢
到底我們的model已經夠大了
還是它不夠大
怎麼判斷這件事呢
這邊一個建議判斷的方法
就是你可以透過比較不同的模型
來得知說
你的model現在到底夠不夠大
怎麼說呢
我們這邊舉一個例子
這一個實驗是從residual network
那篇paper裡面節錄出來的
我們把paper連結放在右上角
這篇paper一開頭就跟你講一個故事
它說 我想測2個networks
一個network有20層
一個network有56層
我們把它們測試在測試資料上
這個橫軸指的是training的過程
就是你參數update的過程
隨著參數的update
當然你的loss會越來越低
但是結果20層的loss比較低
56層的loss還比較高
這個residual network是比較早期的paper
2015年的paper
如果你現在大學生的話
那個時候你都還是高中生而已
所以那個時候大家對Deep Learning
了解還沒有那麼的透徹
大家對deep learning
有各種奇怪的誤解
很多人看到這張圖都會說
這個代表什麼
這個代表overfitting
告訴你deep learning不work 知道嗎
56層太深了 不work
根本就不需要那麼深
那個時候大家也不是每個人都覺得
deep learning是好的
那時候還有很多
對deep learning的質疑
所以看到這個實驗有人就會說
最深沒有比較好
所以這個叫做overfitting
但是這個是overfitting嗎
這個不是overfitting
等一下會告訴你overfitting是什麼
並不是所有的結果不好
都叫做overfitting
你要檢查一下訓練資料上面的解釋
你檢查訓練資料的結果發現說
現在20層的network
跟56層的network比起來
在訓練資料上
20層的network loss其實是比較低的
56層的network loss是比較高的
這代表什麼
這代表56層的network
它的optimization沒有做好
它的optimization不給力
你可能問說
你怎麼知道是
56層的optimization不給力
搞不好是model bias
搞不好是56層的network
它的model彈性還不夠大
它要156層才好
56層也許彈性還不夠大
但是你比較56層跟20層
20層的loss都已經可以做到這樣了
56層的彈性一定比20層更大對不對
如果今天56層的network要做到
20層的network可以做到的事情
對它來說是輕而易舉的
它只要前20層的參數
跟這個20層的network一樣
剩下36層就什麼事都不做
identity copy前一層的輸出就好了
56層的network一定可以做到
20層的network可以做到的事情
所以20層的network
已經都可以走到這麼底的loss了
56層的network
它比20層的network彈性還要更大
所以沒有道理
20層的network可以做到的事情
56層的network做不到
所以56層的network
如果你optimization成功的話
它應該要比20層的network
可以得到更低的loss
但結果在訓練資料上面沒有
這個不是overfitting
這個也不是model bias
因為56層network彈性是夠的
這個問題是你的optimization不給力
optimization做得不夠好
所以剛才那個例子就告訴我們說
你怎麼知道你的optimization
有沒有做好呢
這邊給大家的建議是
看到一個你從來沒有做過的問題
也許你可以先跑一些比較小的
比較淺的network
或甚至用一些
不是deep learning的方法
比如說 linear model
比如說support vector machine
有一些方法比如說support vector machine
不知道是什麼也沒有關係
它們可能是比較容易做Optimize的
它們比較不會有
optimization失敗的問題
也就是這些model它會竭盡全力的
在它們的能力範圍之內
找出一組最好的參數
它們比較不會有失敗的問題
所以你可以先train一些
比較淺的model
或者是一些比較簡單的model
先知道 先有個概念說
這些簡單的model
到底可以得到什麼樣的loss
接下來還缺一個深的model
如果你發現你深的model
跟淺的model比起來
深的model明明彈性比較大
但loss卻沒有辦法
比淺的model壓得更低
那就代表說你的optimization有問題
你的gradient descent不給力
那你要有一些其它的方法
來把optimization這件事情做得更好
舉例來說
我們上次看到的這個
觀看人數預測的例子
我們說在訓練資料上面
2017年到2020年的資料是訓練資料
一層的network
它的loss是0.28k
2層就降到0.18k
3層就降到0.14k
4層就降到0.10k
但是 我測5層的時候結果變成0.34k
這是什麼問題
我們現在loss很大
這是什麼問題
這是model bias的問題嗎
顯然不是
因為4層都可以做到0.10k了
5層應該可以做得更低
這個是optimization的problem
這個是optimization的時候做得不好
才造成這樣子的問題
好 那如果optimization做得不好的話
怎麼辦呢
這個我們下一節課
就會告訴大家要怎麼辦
你現在就知道說有這個問題
知道怎麼判斷說
現在如果你的training的loss大
到底是model bias還是optimization
如果model bias 那就把model變大
如果是optimization失敗了
那就看等一下的課程怎麼解這個問題
好 假設你現在經過一番的努力
你已經可以讓你的
training data的loss變小了
那接下來你就可以來看
testing data loss
看testing data loss做得怎麼樣
如果testing data loss也小
有比這個strong baseline還要小就結束了
沒什麼好做的就結束了好嗎 結束了
好 那但是如果你覺得還不夠小呢
如果training data上面的loss小
testing data上的loss大
那你可能就是真的遇到
overfitting的問題
你要注意 是training的loss小
testing的loss大 才叫做overfitting
很多同學每次一看到結果不好
在testing上的結果不好
就說這個是overfitting
不一定是overfitting
你拿一個結果來問我說
老師這個結果要怎麼做得更好的時候
我第一個問題就會問你說
你在training data上的loss
到底做得怎麼樣
我發現十個同學有八個同學都說
要看training data的loss嗎
我沒有把training data loss記下來
你要把training data loss記下來
先確定說你的optimization沒有問題
你的model夠大了
然後接下來
才看看是不是testing的問題
好 如果是training的loss小
testing的loss大
這個有可能是overfitting
為什麼會有overfitting這樣的狀況呢
為什麼有可能training的loss小
testing的loss大呢
這邊就舉一個極端的例子來告訴你說
為什麼會發生這樣子的狀況
這是我們的訓練資料
假設根據這些訓練資料
某一個很廢的
machine learning的方法
它找出了一個一無是處的function
這個一無是處的function
是什麼樣的function呢
這個一無是處的function說
如果今天x當做輸入的時候
我們就去比對這個x
有沒有出現在訓練資料裡面
如果x有出現在訓練資料裡面
就把它對應的ŷ當做輸出
如果x沒有出現在訓練資料裡面
那怎麼辦
就輸出一個隨機的值
那你可以想像說
這個function啥事也沒有幹
它是一個一無是處的function
但雖然它是一個一無是處的function
它在training的data上
它的loss可是0呢
你把training的data
通通丟進這個function裡面
它的輸出跟你的訓練資料的level
是一模一樣的
所以在training data上面
這個一無是處的function
它的loss可是0呢
可是在testing data上面
它的loss會變得很大
因為它其實什麼都沒有選
這是一個比較極端的例子
在一般的狀況下
也有可能發生類似的事情
舉例來說
假設我們輸入的feature叫做x
我們輸出的level叫做y
那x跟y都是一維的
x跟y之間的關係
是這個二次的曲線
這個曲線我們刻意用虛線來表示
因為我們通常沒有辦法
直接觀察到這條曲線
我們真正可以觀察到的是什麼
我們真正可以觀察到的
是我們的訓練資料
訓練資料 你可以想像成
就是從這條曲線上面
隨機sample出來的幾個點
今天的模型 它的能力非常的強
它的flexibility很大
它的彈性很大的話
你只給它這三個點
它會知道說
在這三個點上面我們要讓loss低
所以今天你的model
它的這個曲線會通過這三個點
但是其它
沒有訓練資料做為限制的地方
它就會有freestyle
因為它的這個flexibility很大
它彈性很大
所以你的model
可以變成各式各樣的function
你沒有給它資料做為訓練
它就會有freestyle
可以產生各式各樣奇怪的結果
這個時候
如果你再丟進你的testing data
你的testing data 和training的data
當然不會一模一樣
它們可能是從同一個
distribution sample出來的
testing data是橙色的這些點
訓練data是藍色的這些點
用藍色的這些點
找出一個function以後
你測試在橘色的這些點上
不一定會好
如果你的model它的自由度很大的話
它可以產生非常奇怪的曲線
導致訓練資料上的結果好
但是測試資料上的loss很大
好 那至於更詳細的背後的數學原理
為什麼這個比較有彈性的model
它就比較會
overfitting背後的數學原理
我們留待下下週
吳佩源老師會跟大家更詳細的說明
我們今天就是講一下它的概念就好
好 那怎麼解決剛才那個
overfitting的問題呢
有兩個可能的方向
第一個方向是
也許這個方向往往是最有效的方向
是增加你的訓練資料
所以今天假設你自己
想要做一個application
你發現有overfitting的問題
其實我覺得
最簡單解決overfitting的方法
就是增加你的訓練資料
所以今天如果訓練資料
藍色的點變多了
那雖然你的model它的彈性可能很大
但是因為你這邊的點非常非常的多
它就可以限制住
它看起來的形狀還是會很像
產生這些資料背後的二次曲線
但是你在作業裡面
你是不能夠使用這一招的
因為我們並不希望大家浪費時間
來蒐集資料啊等等
這個不是機器學習技術最核心的部分
我們希望大家多focus在
機器學習核心的技術上
而不是花太多力氣去網路上蒐集資料
看看怎麼把作業做好
這個不是我們要大家做的
在作業裡面不能夠自己蒐集資料
那你可以做什麼呢
你可以做data augmentation
這個方法並不算是使用了額外的資料
Data augmentation是什麼意思呢
Data augmentation就是
你用一些你對於這個問題的理解
自己創造出新的資料
舉例來說在做影像辨識的時候
非常常做的一個招式是
假設你的訓練資料裡面有某一張圖片
把它左右翻轉
或者是把它其中一塊截出來放大等等
你做左右翻轉 你的資料就變成兩倍
那這個就是data augmentation
但是你要注意一下data augmentation
不能夠隨便亂做
這個data augmentation
這個augment 要augment得有道理
舉例來說在影像辨識裡面
你就很少看到有人把影像上下顛倒
當作augmentation
為什麼
因為這些圖片都是合理的圖片
你把一張照片左右翻轉
並不會影響到裡面是什麼樣的東西
但你把它顛倒 那就很奇怪了
這可能不是一個訓練資料裡面
可能不是真實世界會出現的影像
那如果你給機器看這種
奇怪的影像的話
它可能就會學到奇怪的東西
所以data augmentation
要根據你對資料的特性
對你現在要處理的問題的理解
來選擇合適的
data augmentation的方式
好 那這邊是增加資料的部分
那還有什麼解法呢
另外一個解法就是不要讓你的模型
有那麼大的彈性
給它一些限制
舉例來說 假設我們直接限制說
現在我們的model
一定是一條二次曲線
我們somehow通靈出 知道說
x跟y背後的關係
其實就是一條二次曲線
只是我們不明確的知道這二次曲線
裡面的每一個參數長什麼樣
那你說你怎麼會通靈出這樣子的結果
你怎麼會知道說
要用多constrain的model才會好呢
那這就取決於你對這個問題的理解
因為這種model是你自己設計的
到底model要多constrain多flexible
結果才會好
那這個要問你自己
那要看這個設計出不同的模型
你就會得出不同的結果
好 那現在假設我們已經知道說
模型就是二次曲線
那你就會給你
你就會在選擇function的時候
有很大的限制
因為二次曲線要嘛就是這樣子
要嘛就是這樣子的
來來去去就是那幾個形狀而已
所以當我們的訓練資料有限的時候
因為我們來來去去
只能夠選那幾個function
所以你可能
雖然說只給了三個點
但是因為我們能選擇的function有限
你可能就會正好選到
跟真正的distribution
比較接近的function
然後在測試資料上得到比較好的結果
所以這是第二個方法
解決overfitting的問題
你要給你的model一些限制
最好你的model正好
跟背後產生資料的過程
你的process是一樣的
那你可能就會
你就有機會得到好的結果
但是如果你給你的
有哪些方法可以給model製造限制呢
舉例來說
給它比較少的參數
如果是deep learning的話
就給它比較少的神經元的數目
本來每層一千個神經元
改成一百個神經元之類的
或者是你可以讓model共用參數
你可以讓一些參數有一樣的數值
那這個部分如果你沒有很清楚的話
也沒有關係
我們之後在講CNN的時候
會講到這個部分
所以這邊先前情 先預告一下
就是我們之前講的network的架構
叫做fully-connected network
那fully-connected network
其實是一個比較有彈性的架構
而CNN是一個比較有限制的架構
就說你可能會說
CNN不是比較厲害嗎
大家都說做影像就是要CNN
比較厲害的model
難道它比較沒有彈性嗎
沒錯
它是一種比較沒有彈性的model
它厲害的地方就是
它是針對影像的特性
來限制模型的彈性
所以你今天fully-connected的network
可以找出來的function所形成的集合
其實是比較大的
CNN這個model所找出來的function
它形成的集合其實是比較小的
其實包含在fully-connected的
network裡面的
但是就是因為CNN給了
比較大的限制
所以CNN在影像上
反而會做得比較好
那這個之後都還會再提到
還有哪些其它的方法呢
一個就是用比較少的features
那剛才助教已經示範過
本來給三天的資料
改成用給兩天的資料
其實結果就好了一些
那這個是一個招數
還有一個招數叫做Early stopping
Early stopping
Regularization跟Dropout
都是之後課程還會講到的東西
那這三件事情在作業一的程式裡面
這個Early stopping其實是有的
助教有寫在它的code裡面
所以不知道這是什麼也沒有關係
反正你直接執行sample code
裡面就有了
Regularization
助教留下了一個空格給大家填
那你不知道什麼是regularization
沒有關係
反正你可以過得了middle的baseline
那如果你想做得更好
也許你可以先自己survey一下
regularization是什麼
看有沒有辦法自己寫
那Dropout
這是另外一個在Deep Learning裡面
常用來限制模型的方法
那這個之後還會再提到
但是我們也不要給太多的限制
為什麼不能給模型太多的限制呢
假設我們現在給模型更大的限制說
我們假設我們的模型
一定是Linear的Model
一定是寫成y=a+bx
那你的model它能夠產生的function
就一定是一條直線
今天給三個點
沒有任何一條直線
可以同時通過這三個點
但是你只能找到一條直線
這條直線跟這些點比起來
它們的距離是比較近的
但是你沒有辦法找到任何一條直線
同時通過這三個點
這個時候你的模型的限制就太大了
你在測試資料上就不會得到好的結果
但是 這個是overfitting嗎
這個不是overfitting
因為你又回到了model bias的問題
所以你現在這樣在這個情況下
這個投影片的case上面你結果不好
並不是因為overfitting了
而是因為你給你模型太大的限制
大到你有了model bias的問題
所以你就會發現說
這邊產生了一個有點矛盾
這邊產生了一個矛盾的狀況
今天你讓你的模型的複雜的程度
或這樣讓你的模型的彈性越來越大
但是什麼叫做複雜的程度
什麼叫做彈性
在今天這堂課裡面
我們其實都沒有給明確的定義
只給你一個概念上的敘述
那在下下週的課程裡面
你會真的認識到
什麼叫做一個模型很複雜
什麼叫做一個模型有彈性
怎麼真的衡量一個模型的彈性
複雜的程度有多大
那今天我們先用直觀的來了解
所謂比較複雜就是
它可以包含的function比較多
它的參數比較多
這個就是一個比較複雜的model
好 那一個比較複雜的model
如果你看它的training的loss
你會發現說 隨著model越來越複雜
Training的loss可以越來越低
但是testing的時候呢
當model複雜 越來越複雜的時候
剛開始
你的testing的loss會跟著下降
但是當複雜的程度
超過某一個程度以後
Testing的loss就會突然暴增了
那這就是因為說
當你的model越來越複雜的時候
複雜到某一個程度
overfitting的狀況就會出現
所以你在training的loss上面
可以得到比較好的結果
那在Testing的loss上面
你會得到比較大的loss
那我們當然期待說
我們可以選一個中庸的模型
不是太複雜的 也不是太簡單的
剛剛好可以在訓練資料上
給我們最好的結果
給我們最低的loss
給我們最低的testing loss
怎麼選出這樣的model呢
一個很直覺的 你很有可能
沒有人告訴你要怎麼做的話
你可能很直覺就會這麼做的
做法就是說
這個kaggle不是立刻上傳
就可以知道答案了嗎
所以假設我們有三個模型
它們的複雜的程度不太一樣
我不知道要選哪一個模型才會剛剛好
在測試資料上得到最好的結果
因為你選太複雜的就overfitting
選太簡單的有model bias的問題
那怎麼選一個不偏不倚的
不知道 那怎麼辦
把這三個模型的結果都跑出來
然後上傳到kaggle上面
你及時的知道了你的分數
看看哪個分數最低
那個模型顯然就是最好的模型
但是並不建議你這麼做
為什麼不建議你這麼做呢
我們再舉一個極端的例子
好 我們再把剛才那個
極端的例子拿出來
假設現在有一群model
這一群model不知道為什麼都非常廢
它們每一個model產生出來的
都是一無是處的function
我們有一到這個零有多少個
我不知道 我隨便打 當作一兆好了
我們有一到一兆個model
這一到一兆個model不知道為什麼
learn出來的function
都是一無是處的function
它們會做的事情就是
訓練資料裡面有的資料就把它記下來
訓練資料沒看過的
就直接output隨機的結果
好 那你現在有一兆個模型
那你再把這一兆個模型的結果
通通上傳到kaggle上面
你就得到一兆個分數
然後看這一兆的分數裡面
哪一個結果最好
你就覺得那個模型是最好的
那雖然說每一個模型
它們在這個Testing data上面
這個testing data它都沒有看過啊
所以它輸出的結果都是隨機的
但雖然在testing data上面
輸出的結果都是隨機的
但是你不斷的隨機
你總是會找到一個好的結果對不對
所以也許編號五六七八九的那個模型
它找出來的function
正好在testing data上面
就給你一個好的結果
那你就會很高興覺得說
這個model編號五六七八九
是個好model
這個好model得到一個好function
雖然它其實是隨機的 但你不知道
但這個好function
在這個testing data上面
給我們好的結果
所以你就覺得說 這個結果不錯
就這樣 我就選這一個model
這個function
當作我們最後上傳的結果
當作我最後要用在
private testing set上的結果
但是如果你這樣做
往往就會得到非常糟的結果
因為這個model畢竟是隨機的
它恰好在public的testing set data上面
它public的testing set上
得到一個好結果
但是它在private的testing set上
可能仍然是隨機的
所以假設你今天在選model的時候
你都用public的
就我們這個testing set
分成public的set跟private的set
你在看分數的時候 你只看得到
public的分數 private的分數
要deadline以後才知道
但假設你在挑模型的時候
你完全看你在public set上面的
也就leaderboard上的分數
來選擇你的模型的話
你可能就會這個樣子
你在public的leaderboard上面排前十
但是deadline一結束
你就心態就崩了這樣
你就掉到三百名之外
而且我們這修課的人這麼多
你搞不好會掉到一千名之外
也說不定
好 而且這件事情並不是傳說
並沒有誇飾
每年都會有這樣子的狀況發生
那因為今年我們會看public
就是說我們在算分數的時候
你在public上面的結果好
還是會給你一點分數
我們不是只看private的分數而已
是public跟private的分數都看
那過去有些學期
是只看private的分數的時候
發生這種狀況
你心態就會整個崩掉這樣子
你就會非常非常的鬱悶
好 那這個時候有同學就會說
那為什麼我們要把testing的set
分成public跟private呢
為什麼我們不能
就通通都分public就好呢
為什麼要為難大家呢
為什麼要讓大家疑神疑鬼
不知道自己private上的結果是什麼
你自己想想看
假設所有的data都是public
那我剛才說
就算是一個一無是處的Model
得到了一無是處的function
它也有可能在public的data上面
得到好的結果
如果我們今天只有public的testing set
沒有private的testing set
那你就回去寫一個程式
不斷random產生輸出就好
然後不斷把random的輸出
上傳到kaggle
然後看你什麼時候
可以random出一個好的結果
那這個作業就結束了
這個顯然沒有意義
顯然不是我們要的
而且因為如果今天 你想想看
然後這邊有另外一個有趣的事情就是
你知道因為今天如果
public的testing data是公開的
你可以知道public的
testing data的結果
那你就算是一個很廢的模型
產生了很廢的function
也可能得到非常好的結果
那這就應證了說
為什麼在機器學習的領域
在那些benchmark的corpora上面
往往機器可以得到異於
異乎尋常的好的結果
往往都超越人類
所謂benchmark corpora的意思就是
有一些data set是公開的
好 舉例來說
這個???(36:15) speech是一個公開的
用來訓練語音辨識的資料集
那如果你想要測試
自己的語音辨識的模型好不好的話
那你就訓練在???(36:25) speech上面
那???(36:27) speech也有testing set
所有人都共用一模一樣的testing set
那我們就可以比較不同模型的好壞
但是問題是這些testing set的結果
都是public的
所以就算是一個很廢的模型
它只能產生很廢的function
你只要做得夠多
你還是可以在public的set上
得到結果 得到好的結果
那這就解釋為什麼說
這些benchmark corpora最終
往往機器可以得到超乎人類的結果
那這個最有名的例子就是這個
大家記得16年的時候
Microsoft跟那個IBM
都不約而同的說
它們的machine在語音辨識上面
得到超越人類的結果
專業的聽打員
做的這個語音辨識的錯誤率還要低
那這個是怎麼來的
那個其實就是做在
benchmark的corpora上面
那個其實是做在一個叫做
switchboard benchmark corpora上面
那你說要在benchmark corpora上面
得到一個非常好的超越人類的結果
在現實生活中 它真的有超越人類嗎
我想你不會相信對不對
就算你不是做語音辨識的研究人員
你光是有用過
其實今天語音辨識系統無所不在
每個手機拿出來都有語音辨識
你其實不會相信說
機器在語音辨識的能力
已經超越人類
所以這個就是在那些
benchmark corpora上
Benchmark corpora的testing set
就是public的testing set
但是你真的訓練出一個語音辨識系統
上線給人用的時候
那這個是private的testing set
你有可能在public的testing set上面
得到什麼超越人類的結果
但並不代表它在
private的testing set上
一定是好的
在那些benchmark corpora上面
今天機器都說
超越人類的語音辨識的正確率了
並不代表在日常生活中
它的語音辨識的正確率超越了人類
所以你知道說
那些說在benchmark corpora得到
什麼超越人類的結果
那個都比較像是
騙騙麻瓜的商業的辭令
不過我覺得說
有benchmark corpora所做出結果來
還算是 已經是很有品了
我聽過更沒有品的是怎樣呢
就是有一個不知道哪來的新創
去接了一個政府的計劃
然後說要做語音辨識
然後就拿那個data set
KPI就訂說
我們這個要做到90%以上的正確率
然後做完 沒有得到90%
怎麼做都做不到90%
人家要來驗收了怎麼辦呢
它們就說 跟驗收的人說
你這個testing set不好
你這個testing set裡面雜訊很多
我幫你把它清乾淨這樣
我把有雜訊的那個句子拿掉這樣
然後KPI就達到了正確率就90%以上
就起飛了 就過了那個KPI了
其實還有更更沒品的啦
就是有人會
有怪怪的新創會拿出
拿出它自己的app給你看
我自己做了一個語音辨識系統
你知道嗎
跟google辨識出來的結果都一樣好喔
為什麼呢
就是因為它偷copy了
google的API這樣子
好 所以有各種各樣奇奇怪怪的東西
所以網路上奇奇怪怪的吹捧
大家有時候看看就好
好 所以講了這麼多
只是想要告訴大家說
我們為什麼要切public的testing set
我為什麼要切private的testing set
然後你其實不要花
不要用你public的testing set
去調你的模型
因為你可能會在
private的testing set上面
得到很差的結果
那不過因為今年
你在public set上面的
好的結果也有算分數
所以怎麼辦呢
為了避免你 就你可能會說
好 那我放棄private set的結果
就只拿public set的結果
然後不斷地產生隨機的結果
去上傳到Kaggle來
然後看看說能不能夠
正好隨機出一個好的結果
為了避免你浪費時間做這件事情
所以有每日上傳的限制
讓你不會說
我拿很廢的模型只產生隨機的結果
不斷的測試public的testing的score
好 那到底要怎麼做才選擇model
才是比較合理的呢
那界定的方法是這個樣子的
那助教程式裡面也都幫大家做好了
你要把Training的資料分成兩半
一部分叫作Training Set
一部分是Validation Set
剛才助教程式裡面已經看到說
有90%的資料放在Training Set裡面
有10%的資料
會被拿來做Validation Set
你在Training Set上訓練出來的模型
你在Validation Set上面
去衡量它們的分數
你根據Validation Set上面的分數
去挑選結果
再把這個結果上傳到Kaggle上面
去看看你得到的public的分數
那因為你在挑分數的時候
是用Validation Set來挑你的model
所以你的public的Testing Set的分數
就可以反應你的
private Testing Set的分數
就比較不會得到說
在public上面結果很好
但是在private上面結果很差
這樣子的狀況
當我知道說
其實你看到public的結果以後
你就會去想要調它
你看到你現在弄了一堆模型
然後用Validation Set檢查一下
找了一個模型放到public set上以後
發現結果不好
你其實不太可能不根據這一個結果
去調整你的模型
但是假設這一個route做太多次
你根據你的
public Testing Set上的結果
去調整你的model太多次
你就又有可能fit在
你的public Testing Set上面
然後在private Testing Set上面
得到差的結果
不過還好反正我們有限制上傳的次數
所以這個route
你也沒有辦法走太多次
可以避免你太過fit在
public的Testing Set上面的結果
好 那我知道說今天因為
public的Testing Set上面的結果
是大家都可以看到的
然後很多人都會
然後名字你又可以隨便亂取
所以假設有一個人洗到第一名的話
他就會非常的得意
他就把自己的名字改成一些什麼
我第一次試就第一名了
或是 我其實只是個旁聽
那其實他不是旁聽的
那他改成說
我其實只是個旁聽的
隨便做就第一名了
那這個時候你就會覺得很緊張
尤其他如果是你認識的
隔壁小毛得到第一名
到處耀武揚威的時候
你就會開始有點緊張
你就會說
等一下 你不要得意
我等一下就去把你刷下來這樣
那這個時候你要不要理他呢
你不要理他
根據過去的經驗
就在public leaderboard上排前幾名的
往往private很容易就慘掉這樣子
所以在public的Testing上面
得到太好的結果
也不用高興得太早
其實 最好的做法
就是用Validation loss
最小的直接挑就好了
就是你不要去管
你的public Testing Set的結果 這樣
那我知道說在實作上
你不太可能這麼做
因為public set的結果你有看到
所以它對你的模型的選擇
可能還是會有些影響的
但是你要越少去看那個
public Testing Set的結果越好
這樣有回答到你的問題嗎
好 如果有其他問題
我等一下再回答
好 那這個是
剛才忘了複述那個同學的問題
線上直播的同學
我複述一下剛才那個同學的問題
他的問題是說
所以我們不能去看
public Testing Set的結果嗎
理想上是
理想上你就用Validation Set挑就好
然後上傳以後 怎樣就是怎樣
有過那個strong basseline以後
就不要再去動它了
那這樣子就可以避免
你overfit在Testing Set上面
好 那但是這邊會有一個問題
就是怎麼分Training Set
跟Validation Set呢
那如果在助教程式裡面
就是隨機分的
但是你可能會說
搞不好我這個分 分得不好啊
搞不好我分到很奇怪的Validation Set
會導致我的結果很差
如果你有這個擔心的話
那你可以用N-fold Cross Validation
N-fold Cross Validation是怎麼做的
就你先把你的訓練資料切成N等份
在這個例子裡面我們切成三等份
切完以後
你拿其中一份當作Validation Set
另外兩份當Training Set
然後這件事情你要重複三次
也就是說
你先第一份第二份當Train
第三份當Validation
然後第一份第三份當Train
第二份當Validation
第一份當Validation
第二份第三份當Train
然後接下來 你有三個模型
你不知道哪一個是好的
你就把這三個模型
在這三個setting下
在這三個Training跟Validation的
data set上面
通通跑過一次
然後把這三個模型
在這三種狀況的結果都平均起來
把每一個模型在這三種狀況的結果
都平均起來
再看看誰的結果最好
那假設現在model 1的結果最好
你用這三個fold得出來的結果是
這個model 1最好
然後你再把model 1
用在全部的Training Set上
然後訓練出來的模型
再用在Testing Set上面
好 那這個是N-fold Cross Validation
好 那這個就是這門課前期的攻略
它可以帶你打贏前期所有的副本
那接下來也許你要問的一個問題是
上週結束的時候
不是講到預測2/26
也就是上週五的觀看人數嗎
到底結果做得怎麼樣
好 那這個就是我們要做的結果
上週比較多人選了三層的network
所以我們就把三層的network
拿來測試一下
以下是測試的結果
我們就沒有再調參數了
大家決定用三層的就是下好離手了
就直接用上去了
好 得到的結果是這個樣子了
這個圖上 這個橫軸就是從
2021年的1月1號開始 一直往下
然後紅色的線是真實的數字
藍色的線是預測的結果
2/26在這邊 這個是今年2021年
觀看人數最高的一天了
那機器的預測怎樣呢
哇 非常的慘 差距非常的大
差距有2.58k這麼多
感謝大家 為了讓這個模型不準
上週五花了很多力氣
去點了這個video
所以這一天是
今年觀看人數最多的一天
那你可能開始想說
那別的模型怎麼樣呢
其實我也跑了一層二層跟四層的看看
所有的模型 都會慘掉
兩層跟三層的錯誤率都是2點多k
其實四層跟一層比較好
都是1.8k左右
但是這四個模型不約而同的
覺得2/26應該是個低點
但實際上2/26是一個公值
那模型其實會覺得它是一個低點
也不能怪它
因為根據過去的資料
禮拜五就是沒有人要學機器學習
禮拜五晚上大家都出去玩了對不對
禮拜五的觀看人數是最少了
但是2/26出現了反常的狀況
好 那這個就不能怪模型了
那我覺得出現這種狀況
應該算是另外一種錯誤的形式
這種錯誤的形式
我們這邊叫作mismatch
那也有人會說
mismatch也算是一種Overfitting
這樣也可以
這都只是名詞定義的問題
那我這邊想要表達的事情是
mismatch它的原因跟overfitting
其實不一樣
一般的overfitting
你可以用搜集更多的資料來克服
但是mismatch意思是說
你今天的訓練資料跟測試資料
它們的分佈是不一樣的
在訓練資料跟測試資料
分佈是不一樣的時候
你訓練資料再增加
其實也沒有幫助了
那其實在多數的作業裡面
我們不會遇到這種mismatch的問題
我們都有把題目設計好了
所以資料跟測試資料它的分佈差不多
舉例來說 以剛才作業一的
Covid19為例的話
假設我們今天資料在
分訓練資料跟測試資料的時候
我們說2020年的資料是訓練資料
2021年的資料是測試資料
那mismatch的問題可能就很嚴重了
這個我們其實有試過了 試了一下
如果今天用2020年當訓練資料
2021年當測試資料
你就怎麼做都是慘了 就做不起來
訓練什麼模型都會慘掉
因為2020年的資料跟2021年的資料
它們的背後的分佈其實都是不一樣
所以你拿2020年的資料來訓練
在2021年的作業一的資料上
你根本就預測不準
所以後來助教是用了別的方式
來分割訓練資料跟測試資料
好 所以我們多數的作業
都不會有這種mismatch的問題
那除了作業十一
因為作業十一就是
針對mismatch的問題來設計的
作業十一也是一個影像分類的問題
這是它的訓練資料
看起來蠻正常的
但它測試資料就是長這樣子了
所以你知道這個時候
這個時候增加資料哪有什麼用呢
增加資料
你也沒有辦法讓你的模型做得更好
所以這種問題要怎麼解決
那猶待作業十一的時候再講
好 那你可能會問說 我怎麼知道
現在到底是不是mismatch呢
那我覺得知不知道是mismatch
那就要看你對這個資料本身的理解了
你可能要對你的訓練資料跟測試資料
的產生方式有一些理解
你才能判斷說
它是不是遇到了mismatch的狀況
好 那這個就是我們作業的攻略
