臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心
告訴我們說，network 越 deep
從 1 層到 7 層，我的 error rate 不斷地下降
那問題是
如果你仔細地思考一下這個問題
你的 network 越深
如果你 imply 的是你的參數越多的話
那這個有甚麼好說的
你的 model 比較複雜
你的 data 如果比較多的話
本來你的 performance 就會比較好
所以你真正要比較一個
你真正要比較 Deep 和 Shallow 的 model 的時候
你應該做的事情是，你要調整 Deep 和 Shallow 的 model
讓他們的參數是一樣多的
那很多人在比較 Deep 和 Shallow 的 model 的時候
是沒有注意到這一件事情的
所以那一個評比是不公平的
如果你要給 Deep 和 Shallow 的 model 公平的評比
你要故意調整他的參數
讓他們的參數是一樣多的，在這個情況下
Shallow 的 model 就會是一個
矮胖的 model，Deep 的 model就會是一個瘦高的 model
接下的問題就是
在這個公平的評比之下
是 Shallow 比較強還是 Deep 比較強 ?
所以剛才那一個實驗結果裡面呢
是有後半段
後半段的實驗結果是這樣說的
它說我們用 5 層
每層兩千個 neuron， 得到 error rate 是17.2
error rate 是越小越好 ，那這一邊用一層
3772 的 neuron，得到 error rate 是 22.5
為什麼是 37722 個 neuron 呢？
這並不是什麼 lucky number
這是為了讓一個 hidden layer 的 network 跟
有 5 層的 hidden layer 的 network，它們的參數是接近的
那如果我們只有一層的 network
這個時候它的 error rate 是 22.5
這個 error rate 遠比它大
如果我們看另外一個 case，7 層
每層 2000 個 neuron 跟一層 4634 個 neuron
它們的參數數目是接近的
這個時候你會發現說
只有一層它的 performance 是比較差的
甚至如果你今天再增加 network 的參數變成一層
但是有 16k 個 neuron，有好多好多的 neuron
有原來這個 case 的4倍
那你的 error rate 也只有從 22.6 降到 22.1 而已
當你用一個只有一層，但非常非常寬的 network
跟也是只有一層，但是沒有那麼寬的 network 來比
因為他的參數比較多
所以它的 performance 還比它強
它的 performance 還是比它強
但如果你比較
這個有兩層的 network 跟這個只有一層的 network
這個有兩層的 network 的參數遠比它少
這個參數是少的
這個參數是多的
但是結果，這個 case 只有兩層
它的 performance 還是比
只有一層的 network 的 performance 還要好
現在，接下來的問題就是
為什麼會這樣
因為在很多人的的想像裡面
deep learning 會 work 就是因為
這是一個，有人覺得說 deep learning 就是一個暴力輾壓的方法
我弄一個大很大的 model
然後我 collect 一大堆的 data
所以就得到比較好的 performance
它就是一個暴力的方法
你有沒有發現實際不是這個樣子
如果你今天只是單純的增加 parameter
但是你是讓 network 長寬
而不是長高的話
其實你對 performance 的幫助，是比較小的
把 network 長高，對 performance 的影響很有幫助
把 network 長寬 ，幫助沒有那麼好
為什麼會這樣呢？
我們可以想像說，當我們在做 deep learning 的時後
其實我們就是在做這個模組化的這件事情
甚麼意思呢 ?
大家都應該會寫程式
所以你就知道說，當你在寫程式的時候
你不能把所有的程式都寫在 main function 裡面
你不能把 5000 行的程式都寫在 main function 裡面
你會寫一些 subfunction
對不對，你會在你的 main function 裡面
去 call subfunction 1、function 2 和 function 3
然後 function 2 裡面可能還會去 call
subsub 1、subsub 2 和 subsub 3
然後 subsub 2 還會再 call subsubsub2 這個樣子
它是一層一層
它是有這個結構化的結構
但是這個層次，你要有結構化的架構
這樣做的好處是
有一些 function 是可以共用的
比如說，搞不好這個 function 是 sorting
然後，你只要在其他的
更 high level 的 function 裡面 call sorting
就會 call 到這個 function
你就不用每一次在每一個 subfunction 裡面
需要做 sorting 的時候
都 implement 一個完整的 sorting function
你可以把它變成模組
需要的時候再去 call 它
這樣你就可以減少你程式的複雜度
可以讓你的程式比較簡潔
那如果用在 machine learning 上面呢
你可以想像我們現在有架一個 task
假設我們要做影像分類
那我們要把 image 分成，比如說 4 類
比如說，長頭髮女生、長頭髮男生
和短頭髮女生、短頭髮男生
那你可能說，我們對這四類我們要分類的影像
通通去 collect data
比如說，長頭髮女生可以 collect 到一堆 data
長頭髮男生也有一些 data
短頭髮女生，短頭髮男生都有一些 data
你就去 train 4 個 classifier
你就可以 solve 這個 problem
但是問題就是，長頭髮的男生
你的 data 可能是比較少的
比如說，在立法院裡面
只有林昶佐是長頭髮
那他現在也不是長頭髮，所以這個 data 是比較少的
就是你沒有太多的 training data
所以，你 train 出來的
detect 長頭髮男生的 classifier
就比較 weak
所以，你 detect 長頭髮男生的 performance 就比較差
那怎麼辦呢？
你可以用模組化的概念
假設我們現在不是先直接去解那一個問題
而是把原來的問題切成比較小的問題
比如說，我們 learn 一些 classifier
這一些 classifier 它的工作
是去 detect 有沒有某一種 attribute 出現
比如說，它不是直接去 detect 說
是長頭髮男生，還是長頭髮女生
它是把這個問題切成比較小的問題
它把這個問題切成
我們先決定說，input 一張 image，它是男生還是女生
input 一張 image，它是長頭髮還是短頭髮
雖然說，長頭髮的男生 data 很少
但女生的 data 和男生的 data 都可以
分別 collect 到足夠的 data
雖然，長頭髮男生的 data 很少
但是長髮的人跟短髮的人的 data
你都可以 collect 到夠多
所以你 train 這些 basic 的 classifier 的時候
你就不會 train 的太差
你這些 basic 的 classifier 都是有足夠 data
把它 train 好
所以，接下來
如果你要解，最後我們要真正處理的問題的時候
你的每一個 classifier 就去參考這一些
basic 的 attribute 的 output
你就最後要下決定的那一個 classifier
它是把前面的 basic 的 classifier 當中的 module
去 call 它的 output
而每一個 classifier 都共用同樣的 module
都共用同樣的 module
只是可能用不同的方式來使用它而已
對 classifier 來說
它看到前面的 basic 的 classifier 告訴它說
是女生、是長頭髮
那這個 classifier output 就是 yes，反之就是 no
所以，對後面這些 classifier 來說
它可以利用前面這些 classifier
所以它只要用比較少的 training data
就可以把結果 train 好
雖然說 classifier 2 的 data 很少
但是，現在要做的事情是比較簡單的
真正複雜的事都被 basic classifier 做掉了
所以，classifier 需要做的事情比較簡單
所以，比較少的 data，就可以把它 train 好
那 deep learning 怎麼跟模組化的概念，扯上關係呢？
你想想看
每一個 neuron 其實就是一個 basic 的 classifier
第一層 neuron，它是一個最 basic 的 classifier
第二層 neuron 是比較複雜的 classifier
它用第一層 basic 的 classifier 的 output
當作它的 input
它把第一層的 classifier 當作 module
而第三層的 neuron 又把第二層的 neuron
當作它 module，以此類推
當然這邊要強調的是說
在做 deep learning 的時候
怎麼做模組化這件事情是 machine
自動學到的
那我覺得呢，這件事情還頗神奇
那 machine 就自動學到說
比如說，在 image 裡面
第一層 classifier 就是 detect 最單純的 attribute 等等
那我們剛才說
做 modularization 的好處是甚麼
做 modularization 的好處是
讓我們的模型變簡單了，對不對
我們是把本來的比較複雜的問題，變得比較簡單
所以，當我們把問題變簡單的時候
就算 training data 沒有那麼多
我們也可以把這個 task 做好
這個是 modularization、這是模組化的精神
如果 deep learning 做得是做模組化的話
其實，神奇的事就是
deep learning 需要的 training data 是比較少的
這個，有沒有跟你的認知是相反的呢
我知道現在因為 deep learning 很紅
新聞上都有各種各式樣的說法
常常聽有人說
AI 就等於 big data 加 deep learning
那很多人就會覺得說
所以，這個 deep learning 會 work
是因為 big data 的關係
沒有 big data，deep learning 就不會 work
其實，我認為並不是這個樣子
你知道嗎 ， 如果你仔細想想看
假設我有真正很大的 big data
假設我們今天要做 image 的 classification
然後，我們的 data base 實在是太大了
大到我可以把全世界的 image 通通收集進來
testing 的每一張 image
都在我的 data base 裡面有一張
那我何必做 machine learning
我直接 table lookup 就好了
所以其實 machine learning 跟 big data
在某種程度上它們其實是相反的
你有真正的 big data 的時候
你就不用 learn 它，你就 table lookup
我們之所以不能 table lookup
就是因為沒有足夠 data
所以，我們才需要 machine 去做舉一反三這件事情
我們才需要 machine 去做學習這一件事情
所以這一邊有沒有跟你的認知是不太一樣的呢
其實當我們做 deep learning 的時候
就是因為我們沒有足夠的 training data
所以，我們需要 deep learning
那剩下的我們就留待下一次再說，謝謝
好，各位同學大家好
我們開始上課吧
上周我我們講到說
為什麼我們需要用到 deep learning
然後 ，這是我們已經講過的
如果你們在用 deep learning 的話
其實你們是在做模組化這一件事情
所以，如果從模組化的觀點來看的話
deep learning 所給我們帶來的優勢並不是
就像有人說的，我就用一個比較大的 model
然後有比較多的參數，collect 比較多的 training data
然後，硬 train 下去，所以
performance 比 Shallow 的 model 好
可能不是這樣
因為我們說 deep learning 的好處是來自於模組化
那模組化的好處是，我現在是用
比較 efficient 的方式來使用我的參數
在影像上面
你可以觀察到類似模組化的現象
我今天要講的是，接下來我要講的是
語音的部分
那我們知道 deep learning 在影像和語音上表現的特別好
我們在來一下在語音上
為什麼我們會需要用到模組化的概念
那我們先非常非常簡短的介紹一下
語音的、人類語言的架構
當你說一句話的時候
比如說 ，你說 what do you think
那這句話其實是由一串 phoneme 所組成的
所謂的 phoneme，它的中文翻成音素
它是語言學家訂出來的，人類發音的基本單位
如果你不知道 phoneme 是甚麼的話
就把它想成是音標
所以，what 由 4 個 phoneme 組成
do 由兩個 phoneme 組成，you 由兩個 phoneme 組成
等等，然後接下來，同樣的 phoneme
它可能會有不太一樣的發音
為甚麼呢？當你發 d uw 的時候
和你發 y uw 的時候
你心裡想的是同一個 phoneme
你心裡想要發的都是 uw
但是，因為人類口腔器官的限制
所以，你沒辦法每一次發的 uw 都是一樣的
為甚麼呢？因為這個 uw 前面跟後面
有接了其他的 phoneme
因為人類發音器官的限制
所以，你的 phoneme 的發音會受到前後的 phone 所影響
所以，為了表達這一件事情
我們會給同樣的 phoneme
不同的 model
這個東西叫做 tri-phone
那 tri-phone 表達的方式是這樣
你把這個 uw
加上前面的 phoneme d 跟後面的 phoneme y
跟這個 uw 加上前面的 phoneme y 跟後面的 phoneme th
就是 tri-phone
那有人看到這種表示方式就覺得說
tri-phone 就是 3 個 phone
看起來像是
本來只考慮一個 phone，現在考慮 3 個
不是這個意思，不是考慮 3 個 phone 的意思
這個意思是說，現在一個 phone
我們用不同的 model 來表示它
如果一個 phoneme ，它的 contest 不一樣
這兩個 uw 的 contest 不一樣
我們就用不同的 model
來模擬、來描述這樣子的 phoneme
那一個 phoneme，它可以拆成幾個 state
state 有幾個，其實是你要自己訂的
是 engineer 自己訂的，比如說，我們通常就訂成
3 個 state
那這個是人類語言的基本架構
怎麼做語音辨識呢？
語音辨識其實非常的複雜
我們現在只是講語音辨識的第一步
第一步這是你要做的事情是把
acoustic feature 轉成 state
這是一個單純的 classification 的 problem
這個 classification 的 problem 就跟
比如說，你在作業三
把 input 一張 image 分成 10 類是一樣的
現在只是要 input 一個 acoustic feature
然後，把它分說它是哪一個 state
所以，acoustic feature 是甚麼呢？
這邊我們不會細談，所謂的 acoustic feature
簡單講起來就是
input 聲音訊號，它是一串 wave form
那你把這個，在這個 weight phone 上面取一個 window
這個通常不會取太大
比如說，250 個 mini second
你把一個 window 當作
你把一個 window
裡面就把它用一個 feature
來描述這個 window 裡面的特性
那這個東西，就是一個 acoustic feature
那你在這個聲音訊號上面呢
你會每隔一個時間點，每隔一小段
時間，就取一個 window
所以，一段聲音訊號就會變成一串
vector sequence，這個叫做 acoustic feature sequence
那在做語音辨識的第一階段
你需要做的事情就是
決定每一個 acoustic feature
它屬於哪一個 state
你要建一個 classifier，這個 classifier 告訴我們說
第一個 acoustic feature 它屬於 state a, state a
第三個也屬於 state a
接下來屬於 state b，接下來屬於 state c 等等
光只有做這樣子，是沒有辦法做一個語音辨識系統的
這個東西只是 state 而已
你要把 state 轉成 phoneme
然後再把 phoneme 轉成文字
接下來，你還要考慮同音異字的問題
用 language model 考慮同音異字的問題，等等
這個就不是我們今天所要講的
我想要比較一下
過去在用 deep learning 之前
和用 deep learning 之後，在語音辨識上的模型
有什麼不同
這個時候，你就更能夠體會說為甚麼 deep learning
在語音上，會有非常顯著的成果
那我們說
我們要繼續做的事情
在語音辨識的第一個階段，就是要做分類這個問題
也就是決定一個 acoustic feature
它屬於哪一個 state
那傳統的方法呢
叫做這個 HMM-GMM
這個 GMM 的方法是怎麼做的呢
這個方法是說
我們假設每一個 state
它就是一個 stationary 的
它裡面訊號的分佈
每一個屬於某一個 state 的 acoustic feature 的分佈呢
是 stationary 的，所以你可以用一個model 來描述他
比如說，這一個 state
這個第一當作中心的這個 tri-phone 的第一個 state
它可以用一個 GMM 來描述它
那另外一個 state
可以用另外一個 GMM 來描述它
這時候給你一個 feature
你就可以算說，這一個 acoustic feature
從每一個 state 產生出來的機率
這個東西叫做 Gaussian Mixture Model，叫做 GMM
但是如果說你仔細想一想，發現這一招其實
根本不太 work，為甚麼呢？
因為 tri-phone 的數目太多了
一般語言，中文英文
都有 30 幾、將近 40 個 phoneme
我們就算 30 個好了
那在 tri-phone 裡面
每一個 phoneme，隨著它 contest 的不同
也要用不同的 model
所以，到底有多少個 tri-phone
你有 30 的 3 次方個 tri-phone
你有 9000 個，不是 9000，是
是 27000 個 tri-phone
每一個 tri-phone 又有三個 state
所以，你有數萬個 state
你每一個 state 都要很用一個 GMM 來描述
那參數太多了
你的 training data 根本不夠
所以傳統上，在有 deep learning 之前怎麼處理這件事呢
我們說有一些 state
其實它們會共用同樣的 model distribution
這件事情叫做 Tied-state
那你可能會覺得有點抽象
甚麼叫做不同的 state 共用同樣的 distribution 呢
意思就是說
假如你在寫程式的時候
不同的 state 的名稱，就好像是 pointer 一樣
所以，實際上你真的在寫程式的時候，你就這麼寫
state 的名稱是 pointer
那不同的 pointer
它們可能會指向同樣的
它們可能會指向同樣的 distribution
所以，有一些 state
它的 distribution 是共用的
有一些沒有共用
到底哪一些要共有，哪一些不要共用
就變成說，你要憑著經驗
還有一些語言學的知識阿
來決定說哪些 state 它們的聲音是需要共用的
可是，這樣是不夠的
如果只分 state 的 distribution
要共用或不共用，這樣太粗了
所以，有的人就會開始提出一些想法說
如何讓它部分共用，等等
那在 deep learning 火紅之前
再前一個提出來比較有創新的方法，叫做 subspace GMM
那其實它裡面有這個 modularization、有模組化的影子
在這個 subspace GMM 裡面呢
這個方法是說，我們原來是每一個
state 它就有一個 distribution
在 subspace GMM 裡面，它說
我們先把很多很多的 Gaussian
先找出來，我們先找一個 Gaussian pool
那每一個 state，它的 information 就是一個 key
那一個 key 告訴我們說，這個 state
要從這個 Gaussian 的 pool 裡面
挑那些 Gaussian 出來，比如說
可能有某一個 state 1
它挑第一、第三、第五個 Gaussian
某一個 state 2，它挑第一、第四、第六個 Gaussian
如果你這樣做的話
這些 state 有些時候就可以 share 部分的 Gaussian
那有些時候就可以完全不 share Gaussian
那至於要 share 多少的 Gaussian
這個東西，是可以從 training data 去把它學出來的
這個是在 DNN 火紅之前的做法
但是，如果你仔細想想
剛才講的這個，HMM-GMM 的方式
所有的 phone 或者是 state
是 independent model 的
這件事情是不 efficient 的
對 model 人類的聲音來說
那如果你想想看人類的聲音
不同的 phoneme
雖然說我們把它歸類為不同的音素
我們在分類的時候把他歸類為不同的 class
但這些 phoneme 之間並不是
完全無關的
它們都是由人類的發音器官所 generate 出來的
它們中間是有根據人類發音器官發音的方式
它們是有某些關係的
舉例來說，在這個圖上
這個圖呢，在這個圖上呢
人類語言裡面所有的母音
這個母音的發音呢
其實，就只受到三件事情的影響而已
一個是你舌頭的前後的位置
一個是你舌頭上下的位置
還有一個，就是你的嘴型
所以，一個母音的發音
其實就只受到這三件事的影響而已
比如說，在這個圖上呢
你可以找到英文的五個
常見的、英文的 5 個母音 a, e, i, o, u
這個 a, e, i, o, u 啊
它們之間的差別就是
當你發 a 到 e 到 i 的時候
你的舌頭是由下往上
那個 i 跟 o 的差別呢
是你的舌頭放在前面或放在後面的差別
所以，如果你發 a, e, i, o, u 的話
你的舌頭變化方式呢
就會這張圖一樣
相信這個時候，你心理一定是在想
一定是在默念 a, e, i, o, u 這樣
然後，你會想說
怎麼感覺不太出來
我發現你自己唸，不太會感覺你的舌頭位置在哪裡
你要知道說，你的舌頭位置是不是真的跟這個圖上一樣
你就回去張大嘴巴，對著鏡子唸 a, e, i, o, u
你會發現說，你舌頭的位置呢
就跟這個圖上是一模一樣的
在這個圖上，同一個位置
的母音呢
代表說，舌頭的位置是一樣的，但是
嘴型是不一樣的
比如說，我們看左上角
在最左上角的位置有兩個母音
一個是 i，一個是 u 這樣
那 i 跟 u 的差別
它們舌頭位置是一樣的，只是嘴型是不一樣的
如果是 i 的話，嘴是比較扁的
u 的話，嘴是比較圓的
所以，你只要改變嘴型的位置，就可以從 i 變成 u
你本來發 i~~~u~~~ 這樣子
你改變一下嘴型，它的發音就不一樣
所以說，因為不同的 phoneme 之間是有關係的
所以，你說每一個 phoneme 都搞一個自己的 model
這件事情其實是沒有效率的
那如果今天是用
deep learning 是怎麼做的呢
如果是 deep learning 的話
你就是去 learn 一個 deep neural network
這個 deep neural network 的 input 呢
就是一個 acoustic feature
它的 output 就是每一個 feature 屬於哪一個 state 的機率
這是一個很單純的 classification 的 problem
跟你作業三做在影像上是沒有甚麼差別的
learn 一個 DNN，input 是一個 acoustic feature
output 就是告訴你說，這個 acoustic feature
屬於每一個 state
它屬於 state a, state b, state c 的機率
那這邊最關鍵的一點是
所有的 state
都共用同一個 DNN
在整個辨識裡面，你就只有一個 DNN 而已
你沒有每一個 state 都有一個 DNN
所以，有人覺得說
所以，有些人他沒有想清楚
這個 deep learning 到底 powerful 在哪裡，他會說
從 GMM 變到 deep learning 厲害的地方就是
本來 GMM 通常你最多也就做 64 個 Gaussian mixture 而已
那 DNN 有 10 層，每層 1000 個 neuron
果然參數很多，參數變多了，所以 performance 變好了
這是一個暴力輾壓的方法，其實也沒什麼
其實 DNN 不是一個暴力輾壓的方法
你仔細想想看，在做 HMM-GMM 的時候
你說 GMM 只有 64 個 mixture
好像覺得很簡單，但是其實你是
每一個 state 都有一個 Gaussian mixture
所以真正合起來，它的參數是多得不得了的
如果你仔細去算一下
GMM 用的參數跟 DNN 用的參數
我曾經在不同的 task 上估測過這一件事情
它們用的參數，你會發現其實是差不多多的
所以，DNN 它只是用一個很大的 model
GMM 是用很多很小的 model
但是，當我們把這兩個東西拿來比較的時候
其實它們用的參數量，是差不多多的
但是，DNN 把所有的
它把所有的 state
通通用同一個 model 來做分類
會是比較有效率的做法
為甚麼這樣是比較有效率的做法呢
舉例來說，如果你今天把
一個 DNN
它的某一個 hidden layer 拿出來
然後，因為一個 hidden layer
比如說，它其實有 1000 個 neuron
你沒有辦法分析它
但是，你可以把那 1000 個 layer 的 output 降維
降到 2 維
所以，在這個圖上
每一個點代表了一個 acoustic feature
它通過 DNN 以後
它把它這個 output layer 的 output 降到二維
可以發現說它的分布是長這個樣子的
在這個圖上的顏色代表甚麼意思呢
這邊的顏色，其實就是
a, e, i
a, e, i, o, u 這樣，特別把這 5 個母音
用跟這邊圖的顏色一樣的框框
把它框起來
那你會發現神奇的事就是
這邊，這 5 個母音的分布
跟這一個圖的分布，其實幾乎是一樣的
這邊是 a, e, i, o, u
所以，你可以發現說
DNN 在做的事情
它的比較 lower 的 layer 做的事情
它其實是在
它並不是真的要要馬上去偵測說
現在 input 這個發音，它是屬於
哪一個 phone 或哪一個 state，它做的事情是
它先觀察說，當你聽到這個發音的時候
人是用甚麼樣的方式
在發這個聲音的
它的舌頭的位置在哪裡
它的舌頭位置是高還是低呢
它的舌頭位置是在前還是後呢，等等
然後，lower 的 layer，比較靠近 input 的 layer
我們今天知道了發音的方式以後
接下來的 layer，再根據
這個結果，去決定說
現在的發音是屬於哪一個 state 或哪一個 phone
所以，所有的 phone 呢
會用同一組 detector
也就是這些 lower 的 layer
是一個人類發音方式的 detector
而所有的 phone 的偵測都是用
同一組 detector 完成的
所有 phone 的偵測，都 share 同一組的參數
所以，它這邊就有做到模組化這件事情
當你做模組化的時候
你是用比較少的參數
你是用比較有效率的方式
來使用你的參數
所以，我們回到
我們很久以前就提過的
Universality 的 Theorem
過去有一個理論告訴我們說
任何的 continuous 的 function
它都可以用一層 neural network 來完成
只要那層 neural network 夠寬的話
在 90 年代
這是很多人放棄做 deep learning 的一個原因
你想想看，只要一層 hidden layer
就可以完成所有的 function
一層 hidden layer 就可以表示所有的 function
那做 deep learning 的意義何在呢
所以很多人覺得說，deep 是沒有必要的
我們就只要一個 hidden layer 就好
但是，這個理論有一件事情沒有告訴我們的是
它只告訴我們可能性
但是它沒有告訴我們說，要做到這件事情
有多有效率
就是，沒錯，你只要有夠多的
參數，你只要這個 hidden layer 夠寬
你就可以描述任何的 function
但是，這個理論沒有告訴我們的事情是
當我們用這一件事情
我們只用一個 hidden layer
來描述 function 的時候
它其實是沒有效率的
當你有 multi-layer，當你有 hierarchy 的 structure
你用這個方式來描述你的 function 的時候
它是比較有效率的
如果剛才模組化的概念，你沒有聽得很明白的話呢
我們這邊舉另外一個例子
如果，你是 EE 的 background
然後，你修過交換電路的話
我相信你聽過這個例子以後，就會對
deep 為甚麼 powerful 沒有太多的懷疑
我想 EE background 的人，都修過
邏輯電路
其實邏輯電路可以跟 neural network 類比
我們知道在邏輯電路裡面
我們的電路是由一堆邏輯閘
AND gate, NOR gate 所構成的
對不對，在 neural network 裡面
整個 network 是由一堆 neuron、神經元所構成的
如果你有修過邏輯電路的話，你會知道說
其實只要兩層邏輯閘
你就可以表示任何的 boolean function
如果你修過邏輯電路的話，你應該知道這件事
這件事情應該不會讓你特別的驚訝
所以，既然兩層邏輯閘可以表示任何的 boolean function
那有一個 hidden layer 的 neural network
有一個 hidden layer 的 neural network，其實也是兩層
它一個 input layer、一個 output layer，所以它也是兩層
有一個 hidden layer 的 neural network
它可以表示任何的 continuous function
其實，也不會讓人特別的驚訝
但是，雖然我們可以用兩層邏輯閘
就描述任何的 boolean function
但是，實際上你在做電路設計的時候，你根本
不可能會這樣做，對不對
你可以用兩層邏輯閘就做一台電腦，但是
沒有人會這麼做
為甚麼呢？因為當你用 hierarchy 的架構的時候
當你不是用兩層邏輯閘，而是用
很多層的時候
這個時候，你拿來設計一個電路是
比較有效率的
雖然，兩層邏輯閘可以做到同樣的事情
但是，這麼做是沒有效率的
如果類比到 neural network 的話
其實，意思是一樣的
你用一層 hidden layer 可以做到任何事情
但是，用比較多的 hidden layer 是比較有效率的
所以，從邏輯閘這邊來看，你用多個邏輯閘
你用多層的架構，可以用比較少的邏輯閘就完成一個電路
那你用比較多層的
你用比較多層的 neural network
你就可以用比較少的 neuron 就完成同樣的 function
所以，你會需要比較少的參數
比較少的參數意謂著甚麼
比較少的參數意謂著，你比較不容易 overfitting
或者是，你其實只需要比較少的 data
你就可以完成你現在要 train 的任務
所以，這件事情有沒有跟你平常的認知是相反的呢
很多人的認知是
deep learning 就是很多 data 硬輾壓過去
其實不是，當我們用 deep learning 的時候
我們可以用比較少的 data
就達到同樣的任務
我們從邏輯閘這邊，再舉一個實際的例子
假設我們現在要做 parity check
假設你要設計一個電路做 parity check
那甚麼是 parity check，就是
你希望 input 一串數字
input 一串 binary 的數字
如果裡面出現的 1 的數目是偶數的話
它的 output 就是 1，如果出現的是奇數的話呢
它的 output 就是 0
假設你 input 的 sequence 的長度
總共有 1 個 bit 的話
那用兩層邏輯閘，理論上可以保證你
你要 2^d 個 gate
你要 2^d 個 gate，才能夠描述
才能描述這樣子的一個電路
但是，如果你用多層次的架構的話
你就可以用比較少的邏輯閘
就做到 parity check 這件事情
舉例來說，你可以把
好幾個 XNOR gate 接在一起
如果你把邏輯閘用這種方式接的話
現在 input 1 跟 0
我把 XNOR gate 的真值表放在右上角
input 1 跟 0，它的 output 就是 0
i然後，input 0 跟 1，它的 output 就是 0
input 0 跟 0，它的 output 是 1
你就做完 parity check 這件事情了
這邊用的就是一個 hierarchical 的架構
當你用這樣子的架構的時候
當你用這種比較多層次的架構的時候
你其實只需要 O(d) gates
你就可以完成你現在要做的任務了
所以，當你用比較多層次的架構來設計電路的時候
你可以用比較少的邏輯閘，就達到同樣的事情
這對 neural network 來說也是一樣的
用比較少的 neuron，去描述同樣的 function
如果剛才舉的例子，你沒有聽懂的話
如果你沒有修過邏輯電路，你沒有聽懂的話
以下是一個日常生活中就會碰到的例子
這個例子是剪窗花的
剪窗花大家知道嗎？
剪窗花就是說
這個應該不用解釋啦
就是一個色紙，然後把它摺起來
然後再剪一剪，就可以變成這個樣子
你並不是真的去把這個形狀的花樣剪出來
這樣太麻煩了，你先把紙摺起來
然後才剪這樣子
這個跟 deep learning 有什麼關係呢
你想想看我們用之前講的
我們用之前講的這個例子來做比喻
假設我們現在 input 的點有四個
有四個，那這個紅色的點是一類
藍色的點是一類
我們之前講說如果你沒有 hidden layer 的話
如果你是一個 linear 的 model，你要怎麼做
都沒有辦法把藍色分在一邊
把紅色分在一邊
但是，當你加了 hidden layer 的時候會發生什麼事呢
當你加了 hidden layer 的時候
就做了一個 feature 的 transformation
你把原來的 x1, x2
ship 到另外一個平面，轉換到另外一個平面
變成 x1'、x2'
所以，原來的紅色這個點跑到這裡
原來的紅色這個點跑到這裡
原來這兩個藍色的點都跑到這裡
所以，你發現這兩個藍色的點呢
是重合在一起
所以，當你從這裡
通過一個 hidden layer 變到這裡的時候
其實你就好像是把原來的這個平面
對折了一樣
你把這個平面對折，所以這個藍色的點
跟這個藍色的點，這兩個藍色的點重和在一起
這就好像是說我們在做
剪窗花的時候，先把色紙對折一樣
你把這兩個平面對折，就好像是把色紙對折一樣
當你把這個色紙對折的時候
如果你在這個地方戳一個洞
到時候，你把色紙打開的時候
它只要看你摺幾折，它在這些地方
都會有一個洞
所以，如果你把剪窗花這件事情
想成是 training
你把剪色紙這件事情
想成是根據我們的 training data
training data 告訴我們說
有畫斜線的部分是 positive
沒畫斜線的部分是屬於 negative example
假設我們已經把這個平面
像色紙一樣折起來的時候
這個時候 training data 只要告訴我們說
在這個範圍之內、在這個範圍之內、在這個範圍之內
是屬於 positive 的
它只要告訴我們這個小的區間裡面的 data
展開以後我們就可以做出複雜的圖樣
那本來 training data 只告訴我們比較簡單的事情
但是因為，現在有把空間對折的關係
你現在要把空間做各種各樣對折的關係
所以展開以後，你就可以有非常複雜的圖案
或者是說，你只要在這個地方戳一個洞
在其他地方，也就都等於戳一個洞
所以，一筆 data，如果只用這個例子來看的話
一筆 data 它就可以發揮五筆 data 的效用
所以，當你做 deep learning 的時候
你其實是用比較有效率的方式
來使用你的 data
你可能會想說，真的是這個樣子嗎
我在文獻上沒有看到太好的例子
這個比較像是我臆測
但是我做了一個 toy example
來展示這件事情
這個 toy example 是這樣子的
我們有一個 function
它的 input 是
二維 R^2，它的 output 是 0 跟 1
那這個 function 是一個地毯形狀的 function
地毯形狀的 function
在這個紅色的、菱形的範圍內
它的 input 這個 R^2，就是座標
那紅色的、這個菱形的範圍內
它的 output 就要是 1
藍色的、菱形的範圍內，它的 output 就要是 0
那現在，我們來考慮
如果我們用了不同的 training example
不同量的 training example
在一個 hidden layer 跟三個 hidden layer 的時候
我們看到甚麼樣的情境
這邊要注意一下就是，我們有特別調整一個 hidden layer
和三個 hidden layer 的參數
所以並不是說，當有三個 hidden layer 的時候
它的參數是比一個 hidden layer 多的
所以，一個 hidden layer 的 neural network
是一個很胖的 neural network
三個 hidden layer 的 neural network
它是一個很瘦的 neural network
所以，它們的參數
是調整到接近
所以你要注意一下，當你在比
一個 shallow 的 network 跟
一個比較 deep 的 network 的時候
一個公平的評比，應該要讓它們有一樣的參數
應該要讓它們有一樣的參數量
那如果你現在給它看這個
這邊是十萬筆 data 的話
那這兩個 network
都可以 learn 出這樣子的 training data
你從這個 function 裡面 sample 十萬筆 data
然後，給它去學，給它去學
然後，它學出來就是長這樣
長的就是這樣
那對一個 hidden layer 來說
反正，它可以模擬任何 function
只要它夠寬，它就可以模擬任何 function
這種菱形的 function
這種地毯的 function 應該也不是甚麼問題
現在，如果我們減少參數的量
減少到只用兩萬筆
我們只從這裡 sample 出兩萬筆來做 training
這個時候你會發現說
如果只有 1 個 hidden layer 的時候
你的結果就崩掉了
但是，如果是 3 個 hidden layer 的時候
你結果也是變得比較差
比 training data 多的時候還要差
但是你會發現說，你用 3 個 hidden layer 的時候
它的崩壞是有次序的崩壞
你看這個結果
它這個結果就像是
你今天要剪窗花的時候
你把色紙折起來，但是最後剪壞了
然後，展開以後長成這個樣子
所以說
而且你會發現說
在比較少的 training data 的時候
你有比較多的 hidden layer 最後得到的結果呢
其實是比較好的
當我們用 deep learning 的時候呢
另外一個好處是我們可以做 End-to-end learning
所謂的 End-to-end learning 的意思是這樣
比如說我們要處理的問題呢
非常的複雜
比如說，語音辨識就是一個非常複雜的問題
那我們說，我們要解一個 machine learning 的 problem 的時候
我們要做的事情就是
先找一個 hypothesis 的 function set
也就是找一個 model
當你要處理的問題是很複雜的時候
你這個 model 裡面，它會變成一個
它會需要是一個生產線
那你這個 model 裡面，它表示一個很複雜的 function
一個很複雜的 function 是由很多比較簡單的 function
串接在一起
比如說，你要做語音辨識的話
你先把聲音訊號送進來
再透過很多層 function，一層一層的轉換
最後，變成文字
當你做 End-to-end learning 的時候
意思就是說，你只給你的 model
input 跟 output
不告訴它說，中間每一個 function
要怎麼分工
你就只給它 input 跟 output
然後，讓它自己去學
讓它去學會說
中間每一個 function，生產線的每一個點
每一站，它應該要做什麼事情
那這件事情，如果 你在 deep learning 裡面要做這件事情的時候
你就是疊一個很深的 neural network
每一層就是生產線上的一個點
每一層都是一個 simple 的 function
每一層會自己學到說
它應該要做什麼樣的事情
比如說，在語音辨識裡面
在還沒有用 deep learning 的時候
在還是 shallow learning 的時代
我們怎麼做語音辨識呢，們可能是這樣做的
你先有一段聲音訊號
然後，要怎麼把聲音訊號對應成文字呢
你要先做 DFT，你不知道這是甚麼也沒有關係
反正就是一個 function
生產線上的某一個站
然後，它變成 spectrogram
然後，這個 spectrogram 通過 filter bank
不知道 filter bank 是甚麼東西沒有關係 反正就生產線上另外一站
再得到 output，再取 log
取 log 我想大家應該都知道吧，但是
它的原理其實是，這個取 log 其實是非常有道理的
不過，我們這邊不講就是了
然後再做 DCT，最後得到 MFCC
然後再把 MFCC 丟到 GMM 裡面
最後，你可以得到語音辨識的結果
這個 GMM 其實你把它換成 DNN
也是會有非常顯著的 improvement
那在這整個生產線上面呢
只有最後一個 block
只有最後這個 GMM 這個部分
藍色這個 block，是由 training data 學出來的
前面這個綠色的部分，這個都是人手訂的
就是過去有五聖先賢
他們研究了各種人類生理的知識以後
訂出了這些 function，那它非常非常的強
增一分則太肥，減一分則太瘦這樣
你就不要想在這上面再去改什麼東西
你改了之後會比較差
就這樣子大概卡了 20 年
五聖先賢實在太厲害了
但是，後來有了 deep learning 以後
我們可以把這些東西
用 neural network 把它取代掉
就是說，你可以把
你就把你的 deep neural network 多加幾層
然後，你就把 DCT 拿掉
這件事情現在已經是
typical 的做法了
過去 MFCC 這種 feature，如果你上語音課的話呢
你上李琳山老師的語音課
你很有可能知道 MFCC 是甚麼
過去，可能 20 年，這個 feature
是 dominate 語音辨識這件事情
但是現在已經不再是這樣子了
你可以直接從 log 的 output 開始做
甚至，比較多人從 log 的 output 開始做
你把你的 neural network 疊深一點， 直接從 log 的 output 開始做
你會得到比較好的結果
所以我記得在14年的、在語音的會議上的時候
MSR 的 research team (MSR = Microsoft Research)
語音 research team 的 head, Deng Li 進來說，掰掰 MFCC
大家也沒有甚麼特別的意見這樣
現在，甚至你可以從 spectrogram 開始做
你把這些都拿掉
通通都拿 deep neural network 來取代掉
也可以得到更好的結果
那 deep neural network 學到的，它要做的事情
你會發現，如果你分析 那個 deep neural network 的 weight 的話
它可以自動學到要做 filter bank 這件事情
filter bank 是模擬人類的聽覺器官
所製定出來的 filter
但是 deep learning 可以自動學到這件事情
接下來，有人就會想要挑戰說
我們能不能夠疊一個很深很深的 neural network
直接 input 就是 time domain 上的聲音訊號
然後，output 直接就是
文字，中間完全不要做 feature transform 之類的
如果連 feature transform 都不用做的話
那你就不需要學訊號與系統
但是還好這件事情，後來結局是這個樣子
這件事情的結局是這個樣子
有好多好多人前仆後繼的
在做這一件事情
這個甚至曾經一度
在 conference 裡面有兩個 session 都在做這件事情
最後，Google 有一篇 paper 是這樣
它最後的結果是
它拼死去 learn 了一個很大的 neural network
input 就是聲音訊號
完全不做其他任何的事情
input 就是 row 的 wave phone
最後可以做到跟有做 feature transform 的結果打平
但也僅止於打平而已
我目前還沒有看到有一個結果是，可以 input
聲音訊號
input time domain 的聲音，不做 Fourier transform
結果比 Fourier transform 好
可見 Fourier transform 很強，或許它已經是
訊號處理的極限了
就跟 machine learning learn 出來的結果
其實也就是 Fourier transform
如果你觀察
你看 Google 那篇 paper 的話，它其實會分析一下
它的這個 machine 做的事情
它做的事情就很像是在做Fourier transform
但是，做出來也就跟 Fourier transform 一樣好
也沒也辦法比 Fourier transform 做的更好
所以，修訊號與系統還是必要的
剛才講的都是語音的例子
那影像的話，其實也是差不多啦
這個我想大家應該都知道，所以
我們就稍微跳過去，過去影像也是
疊很多很多的 block
有很多很多人訂的、handcrafted 的 feature
那你只是在用很多很多的 block
很多很多 handcrafted 的 feature 去處理你 input 的影像
然後，只又在最後一層，用一個 shallow 的 classifier
現在，你就直接兜一個
很深的 network
input 就直接是 pixel
output 就直接是裡面影像是甚麼
就不需要抽 feature 了
那 deep learning 還有什麼好處呢
有時候我們會做
通常我們真正在意的 task
它是非常的複雜的
那在這種非常的複雜的 task 裡面
有時候非常像的 input，它會有很不一樣的output
舉例來說，你在做影像辨識的時候
這個白色的狗
跟北極熊其實看起來是很像的
它們其實是很像的
但是你的 machine 要知道說
看到這個要 output 狗，看到這個要 output 北極熊
有時候看起來很不一樣的東西
其實是一樣的，比如說，這個是火車
側面看是這個樣子，橫看成嶺側成峰
橫著看就變這個樣子
所以它們是不一樣的，但 output 都要是火車
如果你今天的 network
只有一層的話
你只能夠簡單的 transform
你沒有辦法把一樣的東西變得很不一樣
把不一樣的東西變得很像
你要讓原來 input 很像的東西
結果看起來很不像
你需要做很多層次的轉換
舉例來說，如果我們看下面這個例子
這個是語音的例子
在這個圖上，我們是吧
這個不是我做的
這個是來自於 ICASSP 2012 的一篇 paper
在這個圖上
這邊做的事情是
把 MFCC 投影到二維的平面上
那同樣的顏色
代表的是這個
不同的顏色
代表的是不同的人說的話
紅色代表是某個人說的句子
綠色代表是某個人說的句子
藍色代表是某個人說的句子
注意一下，這些人說的句子是不一樣的
在語音上，你會發現說同樣的句子
不同的人說
它的聲音訊號看起來是非常不一樣的
你會發現說，這個紅色看起來跟藍色間沒有什麼關係
藍色看起來跟綠色間沒有什麼關係
所以，有人看到這個圖就覺得
語音辨識不能做啊
不能做，不同的人說話的聲音太不一樣了
就算說同樣的句子，感覺也太不一樣不能做
如果你今天 learn 一個 neural network
如果你只看第一層的 hidden layer 的 output
你會發現說不同的人
講的話、講的同一個句子
還是看起來很不一樣
但是如果你今天看的八個 hidden layer 的 output 時候
你會發現說
不同的人說的同樣的句子
它自動的被 align 在一起
也就是說，這個 DNN 在很多的 layer 的轉換的時候
它把本來看起來很不像的東西
它知道說它們應該是一樣的
經過很多的 layer 的轉換以後
就把它們兜在一起
就把它們 map 在一起了
比如說，你看這個圖上面
這邊你會看到一條一條的線
那在這條線裡面，你會看到不同顏色的聲音訊號
也就是說，不同的人說同樣的話
經過 8 個 hidden layer 的轉換以後
對 neural network 來說，它就變得很像
本來的 input 完全不像，再通過很多個 layer 的轉換以後
它就變得像
或者是，今天這個是語音的例子
如果我們看 MNIST 手寫數字辨識的例子
其實也可以輕易地做到這些實驗
input 的 vector 是長這個樣子
input 就是 28*28 個 pixel
如果你把 28*28 個 pixel
28*28 的 vector project 到
二維的平面的話，那它看起來像是這個樣子
你會發現說，在這個圖上
它這邊這個 4 跟 9 幾乎是疊在一起的
因為 4 跟 9 很像，我們仔細想想看
4 跟 9 都是一個圈圈再加一條線
4 跟 9 很像，所以如果你光看 input 的 pixel 的話
4 跟 9 幾乎是疊在一起的，你幾乎沒有辦法把它分開
但是，如果我們看的一個 hidden layer 的 output
這個時候你會發現說， 4 跟 9 還是很像
它們還是離得很近
7 也跟 4 很像
4、7、9，它們是很像的
這是第一個 hidden layer 的 output
但是，如果我們看第二個 hidden layer 的 output，你就會發現說
4、7、9，是逐漸被分開的
到第三個 hidden layer 的 output，它們又被分得更開
所以，如果你今天要讓不一樣的 input
被 merge 在一起，相當在語音舉的例子
或者是讓
你要讓原來看起來很像的 input
最後被分得很開
那你就需要好多 hidden layer 才能辦到這件事情
那其實還有更多用 deep learning 的理由啦
那這個有人寫了一篇 paper
Microsoft 的 researcher
Rich Caruana，他寫了一篇 paper，它的 title 是
Do Deep Nets Really Need to be Deep？
如果翻譯成中文就可以翻譯成這個
深度學習是不是過譽了
在這篇 paper 裡面呢
他做了一個很神奇
這篇 paper 有點舊，它大概是兩年前 publish 的
這篇 paper 看起來，那時候覺得很神奇
但現在已經是 common sense 了
他的做法是這樣，他說
我們今天來比較一下一層的 hidden layer
跟三層的 hidden layer
它們在 MNIST 還有 TIMIT 這些
benchmark corpus 上的差別
當然結果並不意外
當你把一個 hidden layer 跟
三個 hidden layer 調一樣參數的時候
當然是三個 hidden layer performance 是比較好的
其實，你也可以自己 verify 這件事情
如果你有真的在做 deep learning 的話
其實，這是 common sense，然後
接下來，他發現說
一個 hidden layer
參數怎麼增加
performance 都不好
它很快就 saturate 了
他就想說，怎麼會這樣呢
他就做了一件當時看起來很匪夷所思的事
他說，一個 hidden layer 的 neural network
你 learning 的 target 不要用真正的 label
懂嗎？就是我們 本來learning 的時候
你要用真正的 label 阿
你就看說，這個 image 有人告訴你說這個是 1
有人告訴你說是 0
你的 network 就是用這個 train 的嘛
這是很合理的想法，他說
你現在的 shallow network 不要用這個 label
你用三層 hidden layer 的 output 當作你的 feature
三層 hidden layer，你把所有的 image
都丟到一個 learn 好的三層 hidden layer
然後，得到那些 output
那有一些 output 是錯的，就不管它是錯的這樣
然後，一層的 hidden layer 就去學三層的 hidden layer
幫你 label 的結果，那一個錯的 ，它就學一個錯的
結果，它的 performance 會比較好
會逼近三層的 hidden layer， 幾乎跟三層的 hidden layer 一樣好
因為，他就是想說
照理說，你只要一個 hidden layer 就能做到任何事
所以，沒有理由三層可以得到這個 performance
一層得不到這個 performance
但是，你直接 learn 一個一層的 network
你就是 learn 不出這個結果
你要去讓一層 network 模擬三層 network 的行為
它才能夠 learn 出這個結果
那有人讀了這篇 paper，他覺得說
Rich 的結論是 deep learning 不 work
其實他的結論不是 deep learning 不 work
我在 conference 遇過他本人
我問過他說
你的意思是 deep learning 不 work，他說不是
我的意思是 deep learning 是 work 的
就是你直接在一層 network 是 learn 不起來的
你要先 learn 三層的 network
再用一層的 network 去模擬三層 network 的行為
你才 learn 的起來
然後，這個是我在 ASRU
2015 的時候，聽過他的 keynote speech
這個時他的第一頁投影片
Do Deep Nets Really Need to be Deep？
然後，第二頁 Yes！
然後，我們留下很多時間給大家問問題，結束！
如果你想要學更多的話，你可以看一下這個
Bengio 的 deep learning 的 Theoretical 的 Motivations
他講了很多非常發人深省的想法
或者是，現在 deep learning 很紅了，所以有各種
來自其他領域的解讀，比如說從
物理的角度來解釋，為什麼要做 deep learning
從化學的角度來解釋，為什麼要做 deep learning
我把連結留在這邊給大家參考
講到這邊剛好告一個段落
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
