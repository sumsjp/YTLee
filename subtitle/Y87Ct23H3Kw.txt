Okay, let's start class.
The first lesson is to briefly introduce
machine learning
and the basic concept of deep learning.
I will talk about a story
totally unrelated to Pokémon.
I'll tell you the basic concepts of
machine learning and deep learning.
So what is machine learning?
I think that everyone must have heard
the phrase "machine learning" in newspapers or magazines.
Then you must also know that
machine learning is somewhat related to AI,
which is very popular today.
What is machine learning?
As the name implies, it seems to say that the machine has
the ability to learn. Those articles often describe
machine learning as a mysterious technique.
Such that we will get artificial intelligence
after machines have learned,
then machines will rule all mankind.
So what exactly is machine learning?
In fact, machine learning
can be generally described in one sentence.
What is machine learning? Machine learning is to
make the machine have the ability to find a function.
After the machine has the ability to find functions,
what can it do?
It can do a lot of things. For example,
suppose you ask the machine to do speech recognition;
the machine listens to a clip of audio
then generates the corresponding text.
Then all you need is a function,
the input of this function is an audio signal,
and the output is the content of this audio signal.
Then you can imagine that the function
that can turn the sound signal into text
is obviously very complicated. It is impossible
that humans can write down the function by hand.
This function is really complicated;
humans have absolutely no ability to write it down.
So we expect to rely on the power of the machine to
find the function automatically.
This is machine learning.
The example I just gave
is a speech recognition task, and there are many other tasks.
The thing in common is to find a complicated function.
For example, suppose now
we have an image recognition task.
What kind of function do we need?
The input of this function is an image.
What is the output?
The output is the content in the image.
Take the well-known AlphaGo as an example.
In fact, it can also be view as a function.
In order to make the machine play Go,
all we need is a function. The input of the function
is the position of black and white on the Go board.
The output is the next position the machine should play.
Assume that you can find a function.
The input of the function
is the position of black and white on the Go board.
The output is where the next step should be placed.
Then we can make the machine play Go automatically.
Then we made an AlphaGo.
As the output of the function differs,
machine learning has different categories.
Here we introduce some technical terms.
The first term
is regression.
Regression means
the function we are looking for
outputs a number.
This kind of machine learning task
with scalar output
is called regression.
Here is an example of regression
Suppose what we want the machine to do
is to predict the value of PM2.5
at a certain time in the future.
What the machine needs to do is to find a function
denoted as f.
The output of this function
is the value of PM2.5 at noon tomorrow.
The input may be various values related to predicting PM2.5.
It might include the value of PM2.5 today,
average temperature today,
and average ozone concentration today, etc.
This function can take these values ​​as input
and output the PM2.5 value at noon tomorrow.
The task of finding this function
is called regression.
Are there any other tasks?
There are other tasks besides regression.
Another task that everyone is familiar with
is called classification.
The classification task
is we would like the machine to do multiple-choice questions.
Some options are created by humans in advanced,
also called categories.
The output of the function we are looking for
is among the options we created.
Choose one as the output of the question.
This task is called classification.
For example,
everyone has a Gmail account
There is a function in a Gmail account.
that can help the user to detect whether an email
is spam or not.
The input of this function is an email.
What is the output?
You must first prepare the options you want the machine to choose.
In the problem of detecting spam,
there are two possible options, which are
spam or not spam.
Yes or no.
The machine must choose an answer,
either "Yes" or "No".
This is the classification problem.
Classification problems aren't limited to having only two options.
There can also be multiple choices.
For example, what AlphaGo does is also a classification task.
But its task is different in the sense that
AlphaGo has more options to choose from.
If you want to train a machine to play Go,
or if you want to train an AlphaGo yourself,
how many options should you give it?
Just think about how many positions there are on the board.
We know there are 19x19 available positions on the board.
So, the task of training a Go-playing machine
is actually a multiple choice question with 19x19 options.
What you want the machine to do is to find a function.
The function takes all black and white stones' positions
as its input
and outputs the correct choice
within the 19x19 choices.
That is, within the 19x19 choices,
it outputs the most winning next step.
So this problem is also a classification problem!
Actually, in many textbooks about machine learning,
when they talk about all kinds of tasks Machine Learning does,
they say Machine Learning's tasks
can be separated into two categories:
Regression
and Classification,
only those two.
But if you thought that Machine Learning
is simply two different kinds of tasks:
Regression and Classification,
it's just like you think
there are only five continents in this world.
You know that the world is not only the five continents, right?
There is still a LAND OF DARKNESS.
Before Demon Slayer was serialized,
we had already set off to the land of darkness.
And until now,
we still haven't arrived yet.
From this, we can see that how far away the land of darkness is.
So, in the field of machine learning,
what is the so-called land of darkness?
Outside of Regression and Classification,
there is a problem that people are often afraid of:
Structured Learning.
That is, the machine not only needs to do
multiple choice questions or output a number,
but also needs to produce a structured object.
For example, draw a picture or write an essay.
This kind of problem, where the machine needs to output structured objects,
is called Structured Learning.
Speaking more anthropomorphically,
in a fashioned way,
you can say that
the machine learns how to create.
So far,
we have talked about the three tasks of machine learning,
Regression, Classification, and Structured Learning.
Next, we'll talk about how machines find the function.
After all, machine learning is finding a function.
So how do they do that?
I’m going to use an example here to explain
how the machine finds a function.
What is the example here?
Before telling you the example, I would like to share with you that
this course has a YouTube channel!
I upload recordings of classes
onto this youtube channel.
Thanks to the students who took this course in the past,
actually quite an amount of people have subscribed.
So I am actually a third-rate YouTuber.
My videos don't have that many views, though,
but I have more than 70,000 subscribers.
So why did I suddenly mention
my YouTube channel?
Because our example
has something to do with YouTube.
Do you know what
a YouTuber cares about most?
A YouTuber cares about
the traffic of his channel, right?
Suppose a YouTuber
makes a living by YouTube.
He will care about his channel's traffic,
which earns him profit.
So I want to ask
if it is possible for us to find a function.
The input of this function
is youtube's background information,
and the output is
the total amount of clicks in the next day.
If you have a youtube channel yourself,
you may know that in the background of youtube,
you can find a lot of related information;
for example, how many people pressed like on each day,
how many people subscribed each day,
or how many views each day.
Can we utilize
all the past information to predict
how many times it is likely to be viewed tomorrow?
Is it possible that we find a function,
the input of this function is
YouTube's background information of my channel,
and the output is the total number of views that
this channel will have on the next day?
Some of you may ask why I want to do this.
If I earn money on YouTube,
I can predict how much I will make in the future.
But I don't earn money on YouTube.
So I actually don't know
why I need to do this.
It is not even useful for me.
I just wanted to give an example.
Okay, now we want to know
how we can find this function.
This function F that we're trying to find
takes the data from Youtube's management interface as the input
and outputs the total view
this channel will get on the next day.
The process of finding this function using machine learning
can be divided into three steps.
We will take the task of
predicting the number of views on this channel as an example to
explain how these three steps
actually work.
The first step is to write out
a function with unknown parameters.
In short, we start by guessing
what function F looks like.
What does its formula look like?
For example,
let's make a very rough guess of
what F might look like.
What kind of relationship would the input and the output have?
We assume it looks something like this:
y = b+w*x1.
What does each variable represent, respectively?
The y variable represents the total views we will get today.
But since today isn't over yet,
we do not know
the total number of views today.
This is something that
is unknown to us.
y is the prediction we're trying to make:
the total number of views we will get today.
Then what about x1?
x1 is the number of views that
we got on this channel yesterday.
This means that both y and x1
are numerical values.
y is the prediction we're trying to make,
and x1 is the information given.
What about b and w?
b and w are unknown parameters that
we're trying to find with the help of the data.
We don't know what w and b should be;
we could only make a rough guess.
But how do we even come up with a guess?
The guess often comes from
your understanding of the nature of the problem,
which is domain knowledge.
That's why people always say:
To use machine learning,
you need some domain knowledge.
And when
is domain knowledge needed?
Domain knowledge is needed when
we have a function with unknown parameters.
So, how do we know that
this function F predicts the number of future views
by multiplying the number of views from the previous day by w,
and then adding b?
We don't know that; it's just a guess.
We're guessing that
the number of clicks we get today
is always somewhat related to the views we got on the previous day.
So, we take the number of views from the previous day
and multiply it by a value.
But the prediction is always not exactly accurate,
so we add b to correct it,
and take the result
as our prediction.
This is a guess
and it's not necessarily correct.
We will come back later to correct this prediction.
Anyway,
we now guess that
y = b+w*x1,
and both b and w are unknown.
Now we have a function that
has several unknown parameters.
These kinds of functions with unknown parameters
are called 'models' in machine learning.
That's why we often hear the word 'model'
in the field of machine learning.
When we talk about machine learning, a model
is some function that
has unknown parameters.
Okay, so the x1 here
is something we know in this function.
It is something that we already know.
In our case, it is the data from Youtube's back-end.
So, we already know
how many views we got on the previous day.
This is called a "feature."
As for w and b,
they are unknown parameters.
Here, we also give w and b
different names.
This unknown parameter, w, is multiplied by the feature;
we call it the "weight."
This unknown parameter, b, is added directly
without being multiplied by the feature;
we call it the "bias."
These are just the definitions of some nouns.
As we continue,
these technical terms
will help us clarify things in the model
and make explaining more convenient.
So, this is the first step.
What about the second step?
The second step
is to define something called the "loss."
What is a "loss"?
It is also a function.
The inputs of this function
are the parameters of our model.
I have
written out our model, right?
Our model is called
"y is equal to b plus x1 multiplied by w,"
where b and w are unknown.
That is what we are going to find out.
As for L,
also known as Loss,
it is a function.
What are the inputs of this function?
The inputs of this function
are b and w.
So, L is a function.
Its inputs are parameters.
It's the parameters of the model.
Then, of this Loss, of this function,
What do the output values stand for?
The output values from this function stand for that
if we set these unknown parameters
to certain values,
how well it performs.
It might be a little bit abstract for you to understand.
So, I am giving you a concrete example.
Suppose that we set the unknown parameters:
b, the bias, which is equal to 0.5 k,
and w, which is equal to 1.
How do we calculate this Loss?
If we set b to 0.5 k
and w to 1,
then the function we are going to use
to predict the numbers of viewers in the future becomes
"y is equal to 0.5 k plus x 1 multiplied by 1."
Then, this kind of function,
0.5k and 1,
the function they stand for,
how much is it?
This thing is so called Loss.
Then, in this problem,
how do we calculate this loss?
We have to calculate it from the training data.
In this problem,
what is our training data?
Our training data is
the number of viewers on this channel in the past.
For example,
the number of viewers from 2017 to 2020
is known on this channel every day.
Here are all fake numbers.
I made them up.
Ok! So, we know that,
from January 1st, 2017
to December 31st, 2020,
what the number of viewers is.
Next, we can calculate the loss.
How do we calculate it?
We put the number of viewers on January 1st, 2017
into this function.
We have said that we want to know,
when b is set to 0.5 k
and w is set to 1,
how well this function will perform.
When b is set to 0.5 k
and w is set to 1,
the function we used to predict is
"y is equal to 0.5 k plus x 1 multiplied by 1."
Then, we will replace the x 1 by 4.8 k
and see what the predicted result is.
So, based on this function,
b is set to 0.5 k
and w is set to 1,
if on January 1st
the number of viewers is 4.8 k,
the number of viewers the next day should be 4.8 k multiplied by 1 plus 0.5 k,
which is 5.3 k.
As for the number of viewers the next day,
Do we know it on January 2nd?
In fact, we know it from the back-end.
So, we could compare them
to know, between the predicted result
and real result of this function,
how big the difference is.
The predicted result of this function is 5.3 k.
What is the real result?
The real result is 4.9 k.
It is overestimated.
It overestimates the number of possible viewers on this channel.
Then, we can calculate the difference.
We calculate the difference between
predicted value and real value.
The predicted value here is represented by y.
The real value here is represented by ŷ.
You can calculate the difference between y and ŷ
to get an e1,
which represents the difference between the estimated value and the real value.
There is more than one way to calculate the difference, actually.
Here, we subtract y from ŷ,
and take the absolute value directly.
The calculated value is 0.4 k.
Okay, the data we have now is
not only of January 1st
and of January 2nd,
but of from January 1st, 2017
to December 31st, 2020.
Three years of data in total.
The real value is called Label.
So, I often hear people saying that
Machine learning needs labels.
Labels refer to the real value.
This is called Label.
Also, not only can we use the value of January 1st to
predict that of January 2nd,
but we can use the value of January 2nd to
predict that of January 3rd.
Suppose our current function is
y = 0.5 k + 1 x₁.
As for January 2nd...
According to the views on January 2nd,
what is the value of predicted views on January 3rd?
It's 5.4k.
Replace x₁ with 4.9k,
multiply it by 1, and add 0.5k. We get 5.4k.
Next, calculate the gap between 5.4k
and the real answer,
also known as the "label."
The label is 7.5k here.
So, it (5.4k) seems to be an underestimation.
We underestimated the views
of this channel on January 3rd.
So we calculate e₂.
This e₂ is
y minus... It's the gap between y and ŷ,
which is 2.1k.
Hence, with the same method,
you can obtain the prediction error of each day
during the past three years.
Now, suppose our function is
y = 0.5 k + 1 x₁.
The error of each day in the past three years
can be calculated entirely.
The error of each day gives us a small e.
Okay, then we will sum up all the errors
of each day,
and get the average from the summation.
This big N represents our number
of training data points.
The number of them is the number
of those training data for three years.
So, it's 365 × 3.
365 days a year, 3 years, so it's 365 × 3.
Then we get an L.
We calculate the big L.
This big L is the result of summing up these e's,
which are the errors of all training data,
making up our loss.
The bigger the big L is,
implying the worse this set of parameters is.
The smaller the big L is,
implying the better this set of parameters is.
As for this e, which is the difference
between the estimated value and the actual value,
can be calculated by different methods actually.
In our example just now,
we calculated the gap between y and ŷ
in absolute value.
With this method of calculating the gap,
this big L obtained,
the loss obtained is called "mean absolute error,"
whose abbreviation is "MAE."
In Homework 1, instead,
we calculate the square of y minus ŷ.
If your e is calculated by
the square of subtracting y's today,
it is called "mean square error,"
also known as "MSE."
In fact, there are very subtle differences
between MSE and MAE.
Usually, you have to choose
which is your method to measure distances.
That depends on your needs
and your understanding of this task.
We won't go into detail here.
Anyway, we choose MAE
as the way we calculate this error.
Adding up all the errors,
you get the loss.
It's your freedom to choose MSE.
And we will use MSE in Homework 1.
Also, there are some tasks,
in which y and ŷ are both probabilities,
both probability distributions.
At this moment,
you may choose "cross-entropy."
We'll talk about this later, too.
Anyway, we choose MAE here.
This is the second step of machine learning.
Those numbers I just mentioned
didn't come from a real example.
But, in this course,
when I give a lecture,
I am here to show you a real example.
Therefore, the following numbers
did come from a real example.
It's the calculated result from the REAL background data
of this channel.
We can adjust different w.
We can adjust different b.
Seek all different w's and all different b's.
Exhaustively. And combine them.
We can try different combinations of w and b
and calculate their losses.
Finally, you can draw the contour map below.
On this contour map,
the redder it is,
the greater the loss calculated is,
implying the worse this set of w and b is.
The bluer it is,
indicating the smaller the loss is,
implying it's a better combination of w and b.
Take this combination of w and b,
put it into our function,
into our model,
and then we will predict it more accurately.
So you know that
suppose "w" is -0.25,
and "b" is -500.
It means that this "w" is -0.25,
and "b" is -500, which means that
there are fewer and fewer people watching this channel every day.
And the loss is so big,
which doesn’t match the real situation.
If we substitute "w" with 0.75 and substitute "b" with 500,
the correct rate or
the estimation will be more accurate.
The most accurate estimation seems
to be here.
If you substitute "w" with a value very close to 1,
and substitute "b" with a small value,
such as around 100,
at this time, the estimation is the most accurate.
This may be closer to everyone's expectation that
you take the total number of clicks in the previous day to
predict the total number of clicks on the next day.
Maybe the total number of clicks on the previous day and the number on the next day
are almost the same.
So we substitute "w" with 1
and substitute "b" with a smaller value;
maybe your estimation will be quite accurate.
A contour map like this is that
you tried different parameters,
and then calculated its loss,
and then drawn the contour map,
which is called "Error Surface".
This is the second step of machine learning.
Next, we move on to the third step of machine learning.
What we do in the third step is to
solve an optimization problem.
It doesn't matter
if you don’t know the optimization problem.
What we are going to do today is to
find a "w" and "b".
Find a value of
unknown parameters to
see that which value
can make our big L,
can make our loss value be the smallest.
That is the "w" and "b" we are looking for.
The "w" and "b" which can make the loss smallest
are called w* and b*,
which means that they are the best set of "w" and "b" to
minimize the value of the loss.
So, how to do this?
The only one optimization method that
we will use in this course
is called "Gradient Descent".
How to use "Gradient Descent",
how to use this method?
It is done like the following.
To simplify,
let's assume that there is only one unknown parameter
"w".
Let's assume that there is no unknown parameter "b",
only the unknown parameter, "w".
When we substitute "w" with different values,
we will get different losses,
and this curve is the error surface.
In the previous example,
the error surface we saw
is two-dimensional; It's 2D.
There is only one parameter here.
So the error surface we see
is 1D.
Then how to find a "w" to
minimize the value of this loss.
First, you have to randomly select an initial point.
The initial point
is called w^0.
The initial point is often randomly selected.
Just pick one randomly.
Really random.
Later in this course,
we will know that there may be some methods that
can give us a better value of w^0.
Here, we don't talk about it.
We just treat it as random.
Randomly roll a dice to
decide the value of w^0.
Let's assume that the result of our random decision
is at this place.
Then, you have to calculate
the derivative of loss with respect to "w"
when "w" is equal to w^0.
I assume you know what differential is.
This is not a problem for you.
Calculate the derivative of loss with respect to w.
If you don’t know what differential is,
that’s okay. What we are doing is to
calculate the slope of this error surface
at this point,
at the point of w^0,
which is this blue dotted line.
What if
the slope of this dotted line is negative?
What does that mean?
It means that the left side is higher, and the right side is lower
around this point.
The left side is higher, and the right side is lower.
If the left side is higher and the right side is lower,
what are we going to do?
If the left is higher and the right is lower,
then we increase the value of "w" to
make the loss smaller.
If the calculated slope is positive,
it means that the left side is lower and the right side is higher.
It looks like this.
The left side is lower, and the right side is higher.
If the left is lower and the right is higher,
it means we need to make "w" smaller.
If you can reduce the loss value by moving w to the left,
you should make w smaller.
Even if you have no idea what "Slope" is,
it doesn't matter.
Just imagine that there is somebody standing at this point,
looking around;
this
means taking the derivative.
The derivative helps us know whether the function will have a lower value
at the right or the left to the point where we are.
Then we take a step towards the point with a lower function value.
How big is this step?
The size of this step depends on two things.
The first is how big the slope at this point is.
The greater the slope,
the bigger the step is.
If the slope is small, our stride will be small.
In addition to the slope,
namely, the derivative,
which we just talked about...
In addition to the derivative,
there is another thing that affects the step size.
We denote it with η.
This η is called the learning rate.
The rate at which the model learns.
Where does it come from?
It depends on you.
You can decide the value of η yourself.
If η is set larger,
the amount of parameter update will be larger.
And the model will be able to learn faster.
If η is set smaller,
the rate of the update will be slower,
and the parameters will have slight changes at each iteration.
Things that need to be set manually
when practicing machine learning
are called hyperparameters.
The first step of machine learning
is to define a function with unknown parameters.
And these parameters,
the unknowns,
will be found by the machine itself.
Oh, there's a question.
Please speak up.
Ok, this is actually a good question.
Let me repeat it.
Someone asked
why a loss function can have negative values.
The loss is a user-defined function.
So from the definition we just made,
the loss here is the absolute value
of the difference between the gound-truth value
and the prediction.
According to the definition now,
it cannot be negative.
But the loss function
is up to you.
Say,
if the loss function today
is the above-mentioned absolute value minus 100,
then it may have negative values.
I have to remind you
about the curve here.
It is not of any real loss functions.
It's a random curve from the Internet as an example.
The reason is that
I want to give a more general example.
It is not an error surface
from any real tasks.
So this loss curve,
this error surface,
can have any shapes.
There is no presumption
regarding the shape of a loss curve.
But from the...
From the definition of the loss here,
it cannot be negative
since it outputs absolute values.
But the loss,
because this function is up to you,
it may be negative.
Since someone raised a question here,
we should pause for now.
See if you have any questions.
In the future, the TAs
will help me watch the live stream on Youtube.
(To TAs) Please read out the questions during the Live stream for me
if there are any.
(To TAs) Help me read those questions.
We will first move on with the session.
Until the session comes to an end,
we will answer those questions.
I'll ask again,
does any of you have questions here?
Great.
If not, please let me continue.
Okay, where were we?
We just talked about hyperparameters.
They should be set manually.
So in machine learning,
those you have to set manually
are called hyperparameters.
We say we are gonna move w0 one step to the right
Then this new position is called w1.
The step size is η multiplied by the differential.
To express it in a mathematical formula,
it is (w0 - η) * (the derivative),
which is w1.
Then, you just repeat the operation done before.
Calculate the differential of w¹.
And then decide how far to move w¹.
Then move it to w².
Then you continue to do the same operation over and over again.
Keep moving the position of w.
In the end, you will stop.
When will it stop?
There are often two situations.
The first situation is that you lost patience.
In the beginning, you will set up a limit.
When you are adjusting your parameters,
calculating differentials,
I only calculate limited times.
You might set
the upper limit to 1 million times.
Hence, after updating the parameters 1 million times,
I won't update them anymore.
As for how many times I should update,
this is also a hyperparameter.
This is up to you.
If the deadline is tomorrow,
you may update fewer times.
You may set it up a little more if the deadline is next week.
There is another ideal
stopping situation.
When we keep adjusting the parameters,
we arrive at some places
where its differential (which is this term)
exactly equals 0.
If this term is exactly 0,
0 times the learning rate η remains 0.
So your parameters will not move their position anymore.
Suppose we are in this ideal situation;
We update w⁰ to w¹,
and then update it to w².
In the end, we update it to wᵗ with a bit stuck.
We stuck at wᵗ.
That is, the differential is 0.
The position of the parameter will not be updated anymore.
On this point,
You might find out that
Gradient Descent
has a huge problem.
This huge problem in this example is
is obvious. That is,
we do not find the real best solution.
We don't find the w
which can minimize the loss.
In this example,
by setting w to this place,
you can minimize the loss.
However, if Gradient Descent
starts from this place
as a random initial position,
the training is likely to stop
when you arrive here.
You can't move the position of w anymore.
This position.
This is really the place where loss is the smallest.
It is called global minima.
This place is called local minima.
The loss of its left and right sides
are a bit higher than itself.
But it is not
the lowest point on the entire error surface.
This thing is called local minima.
So you may often hear someone
saying that
Gradient Descent
isn't a good method.
This method has the problem of local minima.
There is no guarantee to find the real global minima.
But textbooks often say this.
Content farms often say this.
But this is actually just an illusion.
In fact,
if you have done something related to deep learning,
or you have trained your network,
or you have done Gradient Descent by yourself,
local minima is actually a non-issue.
When we were doing Gradient Descent,
the real problem we confronted is not local minima.
Then what is it?
We will talk about it later.
Temporarily, you just
believe what most people say.
Gradient Descent
has a problem with local minima.
In this example,
it is obvious that there is a local minima problem.
But later, I will tell you
what Gradient Descent's real pain points
exactly are.
The things mentioned above
is an example with only one parameter.
Actually, our model has two parameters.
W and b.
How to use Gradient Descent
under the situation of two parameters?
In fact, it is no different from the situation of a single parameter.
If you have no problem with one parameter,
you can quickly generalize to two parameters.
We have two parameters now.
Then we give it two parameters.
We give them random initial values.
w⁰ and b⁰.
Then what's next?
You have to calculate the differential of loss with respect to w.
You have to calculate the differential of loss with respect to b.
Calculate at the position where w is equal to w⁰.
where b is equal to b₀.
where w is equal to w₀.
where b is equal to b⁰.
You have to calculate the differential of L with respect to w.
Calculate the derivative of L with respect to b.
After calculating,
according to the method that we have just used
with one parameter,
we update w and b.
Subtract the learning rate from w⁰.
Multiply the result of the differentiation to get w¹.
Subtract the learning rate from b⁰.
Multiply the result of the differentiation to get b¹
Some students might want to know
how to calculate this differentiation.
If you can't calculate the differentiation,
don't be worried.
Why don't you be worried about it?
In the framework of deep learning,
or in our homework one,
with the package PyTorch that will be used,
the calculations of differentiation are automatically calculated.
You can write only a line of code,
and the results of the differentiation would be calculated automatically.
Even if you don't know what you are doing,
you can still get the results of the differentiation.
Here,
even if you don’t know what differentiation is,
don't worry;
this step can be done in one line.
When doing homework 1,
you can try it by yourself.
Repeat the same procedures,
keep updating w and b,
and expect that at the end,
you can find the best w, w*,
and the best b, b*.
Here is an example.
We would show everyone that suppose on this question,
how we do it.
Suppose that
you choose a random initial point here.
First, you calculate the partial derivative of L with respect to w,
and calculate the partial derivative of L with respect to b.
Then you update w and b.
The direction of the update is the partial derivative of L with respect to w
multiplied by η and added a negative sign,
and the partial derivative of L with respect to b
multiplied by η and added by a negative sign.
After calculating the derivatives,
you can decide the direction of the update.
You can decide how to update w.
How to update w?
Combining the update directions of w and b,
we can get a vector,
which is this red arrow.
We move from this position to this position.
Then calculating the derivatives again,
you can decide which direction to update.
After multiplying the values of partial derivatives by the learning rate,
and adding a negative sign,
You can know where the red arrow will point.
You can know how to move the positions of w and b.
Keep moving and moving.
Expect that you can find a good pair of w and b in the end.
After using gradient descent
and doing some calculations,
we get the actual result.
The best w calculated by us is 0.97.
The best b is 100.
It's very close to our guess.
Because the value of x₁ may be very close to y,
this w is set to a value close to 1,
and b is set to a relatively small value.
How big is the loss?
The calculated loss is 480.
That is, on the data from 2017 to 2020,
if you use this function,
setting b to be 100
and w to be 970,
the average error is 480.
This means that the error of the predicted number of views
is about 500 times.
Until now,
We have talked about the three steps of machine learning.
First,
write a function.
There are unknown parameters in this function.
Second,
define a function called loss.
Third,
solve an optimization problem.
Find a pair of w and b to minimize the loss.
The values ​​of w and b found just now
can make the loss as small as 480.
But,
is it a satisfying or commendable result?
Maybe not.
Why?
Because the procedure of these three steps
is called training.
We are now
using the data with known answers
to calculate the loss.
Data from 2017 to 2020
are those we have already known the answers to.
We have already known that from 2017 to 2020,
how many views per day.
So, in fact, we are just getting hyper by ourselves.
Just pretending we don’t know the number of views on the next day,
we use this function to make predictions,
finding that the error is 480.
But, is the number of views that are already known
what we really care about?
No.
What we really care about are
the things we don't know,
which is the number of views in the future.
So what are we going to do next?
We will take this function
and use it to predict the number of views in the future.
Here,
we only have data ​​from 2017 to 2020.
On the last day of 2020,
New Year's Eve,
we found this function.
Starting from the first day of 2021,
we apply this function to
predict the number of views on the next day.
We use the number of views
on December 31st, 2020, to
predict the number of views on New Year's Day in 2021.
We use the number of views on New Year's Day to
predict the views on the day after New Year's Day,
which is January 2nd.
Use the number of views on January 2nd to predict
the views on January 3rd.
We do this every day
until February 14th;
until Valentine's Day.
Then we get the value for the average error.
What is the average error?
This is the result of real-world data.
On 2021's data which has not been seen before,
this error,
we denote it as L',
is 0.58.
So on data that have been seen;
on training data,
the error is relatively small.
On data that have not been seen;
on 2021's data,
it seems that the error is larger.
So our average error per day
is about 580 people,
around 600 people.
Can we do better?
Before we do anything,
let's analyze the results first.
How do you interpret this graph?
The horizontal axis of this graph represents time.
So the leftmost point at 0
represents January 1st, 2021.
The rightmost point
represents February 14th, 2021.
The vertical axis
is the number of views
in thousands.
What does the red line represent?
The red line is the actual number of views.
The blue line is the number of views predicted by the machine
using this function.
You can see very clearly that
there is nothing magical about this blue line.
It's almost the same as
shifting the red line to the right by one day.
It didn’t really make any powerful predictions.
It simply shifted the red line to the right by one day.
This is reasonable.
Because we think the relationship between x1,
the number of views on the previous day,
and the views on the next day...
How did we use the number of views on the previous day to
predict the number of views on the next day?
We multiplied the number of views the day before by 0.97,
then plus 0.1k, plus 100, and
obtain the number of views on the next day.
So you will find out
that the machine almost just took the views from the previous day to predict the
views on the next day.
But if you look closely at this graph,
you will see
there's some special phenomenon in this real-world data.
It is periodic.
It has an interesting periodicity.
Do you know what the pattern is?
The views become very low for two days every seven days.
Two days when the views are very low.
What days are those two days?
I found out that those two days are fixed.
They're Fridays and Saturdays.
I can understand on Friday and Saturday
everyone will go out because it's the weekend.
Who needs to learn machine learning?
Who wants to learn machine learning on Saturday?
But I don't know why
everybody goes to learn machine learning on Sunday.
I haven't understood why this happened.
Maybe it's because of
YouTube's magical algorithm.
For instance, YouTube will recommend videos.
Maybe when YouTube is recommending videos on the channel,
it chooses not to recommend them on Fridays and Saturdays,
but only on Sundays through Thursdays.
But why on Sundays through Thursdays?
I haven't understood that either.
But anyway,
when we look at the results,
it's like this.
A cycle every seven days.
Every Friday and Saturday,
there are very few people watching.
Since we already know that every seven days
is a cycle,
this formula, this model,
obviously sucks
because it can only see the day before.
If the cycles occur every seven days,
we should look at seven days at once, right?
Suppose we have a model.
It refers to the data from the previous seven days.
It copies the data from the previous seven days
as the predicted result.
Maybe the prediction will be more accurate.
So we have to modify our model.
Usually, the modification of the model
often comes from your understanding of this problem,
which is domain knowledge.
So, in the beginning,
when we don't understand the problem at all,
we just write one randomly:
y is equal to b plus wx₁,
which doesn't perform very well.
Next, after observing the real data,
we conclude that
there is a cycle every seven days.
So we should take
views in the first seven days into consideration.
Thus we wrote a new model.
What does this model look like?
This model is that y is equal to b plus xⱼ.
What does xⱼ stand for?
This subscript j represents how many days ago.
This j is equal to from 1 to 7.
That is, from one day ago, two days ago,
continue to seven days ago.
For all the data in these seven days,
we multiply them by different weights.
That is, we multiply them by different wⱼ.
Then we add them up
and plus bias to
get the predicted result.
If this is our model,
what is the result we got?
Our loss on the training data is 0.38k.
That’s because here we only consider one day.
Here we consider seven days.
So on the training data,
you will get a lower loss.
Here we consider more information,
so you should get better on the training data.
That is, you have a lower loss.
Here the loss is 0.38k.
But on the unseen data,
Can the model do well?
On the unseen data,
it is better.
The loss is 0.49k.
So if only consider one day, the loss is 0.58k.
While considering seven days, the loss is 0.49.
For every w and b here,
we all use gradient descent to
calculate its optimal value.
What does its optimal value look like?
We show it here.
We show you what its best value looks like.
Of course, I can't fully understand the logic of the machine.
I thought it would select data from seven days ago,
copy the number of viewers seven days ago
directly.
I don’t think it selects like this.
Its logic is that the previous day
has a lot to do with the value of the next day you want to predict.
So w₁* is 0.79.
I don’t know why it still considered the previous three days.
The w for the previous three days is 0.12.
The w for the previous six days is 0.3.
The w for the previous seven days is 0.18.
But it knows
if it is the previous two, four, or five days,
its value will be inversely proportional to
what we have to predict in the future.
So for w₂ w₄ and w₅, their optimal values,
which let loss on the training data
be 0.38k, is negative.
While w₁ w₃ w₆ and w₇ are positive.
We consider the value of the previous seven days.
Then you might ask
whether it's possible to consider more days?
Yes, it's possible.
We can make an easy change to consider more days.
Originally, we considered the first seven days.
Then what happens when considering 28 days?
28 days are equal to a month.
We use the number of people watched each day in the previous month
to predict the number of viewers the next day.
What is the predicted result?
The loss on the training data is 0.33k.
On the 2021's data,
the loss is 0.46k on the unseen data.
The performance looks better in 28 days.
Okay, then what will happen when considering 56 days?
The performance is slightly better on the training data.
The loss is 0.32k.
The loss is still 0.46k on the unseen data.
It looks like that
there is no way to make more progress when considering more days.
It seems that considering the number of days
has reached its limit.
Okay, for these models here,
they all take the input x.
Do you remember what x is called?
It's called a feature.
We multiply the feature by weight
and add a bias to get the predicted result.
Such models have a common name
called the linear model.
Next, we will see
how to make the linear model better.
