好 那我們就繼續講吧
我們就繼續講吧
好 那我們接下來呢
就是要講三個 Lifelong Learning 的可能解法
那第一個解法
叫做 Selective Synaptic Plasticity
那從字面上
你可能一下子沒有辦法 Get 到說
這個方法到底想要做什麼
這個 Synaptic 是突觸的意思
就是我們腦神經中這個
神經跟神經之間的連結
這個叫做突觸
Plasticity 呢
是可塑性的意思
所以簡單來說
這個方法想要做的事情就是
我們只讓我們的這個類神經網路中
某一些神經元
或某一些神經元間的連結
具有可塑性
Selective 的意思就是說
只有部分的連結是有可塑性的
有一些連結必須被固化
它必須不能夠再移動
不能夠再改變它的數值
那像這樣的方法又叫做
Regularization-based 的方法
那這個面向
這個研究的面向
在 Lifelong Learning 的領域裡面
我覺得是發展得最完整的
所以等一下我們會花比較多的時間
來講 Selective Synaptic Plasticity
那另外兩個面向呢
我們都只用一 兩頁投影片很快地帶過
那你會發現作業裡面主要的問題
也都集中在
跟 Regularization-based 有關的方法上面
好 那我們先來想一下
為什麼 Catastrophic Forgetting 這件事情
會發生呢
我們假設有任務一跟任務二
這兩個任務
而這兩個任務呢
我們假設我們的模型只有兩個參數
θ1 跟 θ2
那當然一個模型通常有上
上百萬 上億個參數
不過我們假設只有兩個參數
好 那這個投影片上這兩張圖
代表的是任務一跟任務二的 Loss Function
也就是在任務一上面
如果你的 θ1 跟 θ2
設不一樣的值
你就會有不一樣的 Loss
那我們用顏色來代表 Loss 的大小
如果顏色越偏藍色
就代表 Loss 越大
顏色越偏白色
代表
說錯
不好意思 我剛才說反
顏色越偏藍色
代表 Loss 越小
顏色越偏白色
代表 Loss 越大
好 所以左右兩張圖分別就是任務一
跟任務二的 Loss Function
也就是他們的 Error Surface
好 那我們現在先讓模型訓練任務一
那模型怎麼訓練任務一呢
你要有一個隨機初始化的參數
我們這邊叫它 θ0
然後我們會用 Gradient Descent 的方法
去調整 θ0 的參數
那你就按照 Gradient 的方向呢
去 Update θ0 的參數
得到 θb
好 那假設 Update 夠多次數
你覺得 Loss 降得夠低了
那你就等於是把任務一學完了
那假設任務一學完後
我們得到的參數是 θb
接下來我們得繼續解任務二
你就把 θb
同樣的參數拷貝過來
拷貝到任務二的這個 Error Surface 上面
注意一下
雖然左右兩邊 Error Surface 是不一樣的
但是 θb 我們這邊指的是同一組參數
θb 是用任務一訓練出來的參數
我們現在把它用在任務二上
我們現在把 θb 放在任務二上
繼續去做訓練
那在任務二上
我們有另外一個不一樣的 Error Surface
根據這個任務二的 Error Surface
去再 Update 參數
那我們可能會把 θb 往右上角移
那得到 θ*
θ* 是訓練完任務一
接下來又訓練完任務二
依序訓練兩個任務以後所得到的參數
現在用 θ* 來代表
依序訓練完兩個任務以後所得到的參數
這個 θ*
它在任務二上
是在一個 Error Surface 比較低
所以是在一個這個 Loss 比較低的位置
所以它在任務二上會得到好的表現
但如果你回頭再把 θ*
拿回到任務一上去做使用
你會發現你並沒有辦法得到好的結果
因為 θ* 只是在任務二上好
它在任務一上不見得會有低的 Loss
那這個就是 Forget 這件事情產生的原因
那要怎麼解決 Forget 這個問題呢
對一個任務而言
也許有很多不同的地方
也許有很多組不同的參數
都可以給某一個任務低的 Loss
對任務二而言
也許在這個藍色橢圓形的範圍內
結果都算是夠好的
也許在這個藍色橢圓形範圍內
Loss 都算是夠低的
如果我們 θb 移動的方向
不要往右上移
而是只往左邊移
那會不會把新的參數放到任務一上
就不會有 Forget 的情形呢
那這個就是我們等一下要跟大家分享的做法
好 那怎麼做呢
所以這邊的基本的想法是說
每一個參數
對我們過去學過的任務
它的重要性是不一樣的
有一些參數
也許對我們過去看過的任務特別重要
我們就希望在學新的參數的時候
那些舊的參數
那些重要的參數
它的值盡量不要變
新的任務只去改那些
對過去的任務不重要的參數就好
好 我們現在假設 θb
是在前一個任務所學出來的參數
所以 θb 在前一個任務上是好的
那我們會讓 θb 在第二個任務上繼續做學習
那在這個 Selective Synaptic Plasticity
這樣的做法裡面
我們會給每一個參數
一個保鏢
一個守衛
我們這邊用 bi 來表示那個守衛
對每一個參數 θi
我們都有一個守衛 bi
這邊所謂的每一個參數就是
Neural 裡面的每一個 Weight 跟它的 Bias
如果你的 network 有
100 萬個參數的話
那就有 100 萬個 bi 的值
那它們每一個參數的 bi 都是不一樣
每一個參數都有一個各自的守衛
這個守衛代表什麼
這個守衛代表說這個參數
對過去的任務而言
到底重不重要
好 所以我們今天呢
在新的任務上
我們在 Update 我們的參數的時候
我們會改寫 Loss Function
原來的 Loss Function
假設寫成 L(θ)
但我們不會直接去 Minimize L(θ)
如果我們直接 Minimize L(θ)
就會發生 Catastrophic Forgetting 的情形
就會發生災難性的遺忘
所以我們要做的事情呢
是更改我們的 Loss Function
我們有一個新的 Loss Function
叫做 L'
這個 L' 才是我們真正要去 Minimize 的對象
那這個 L' 呢
是原來的 Loss L 後面再多加了一項
這一項是什麼東西
這一項是
我們先 Σ over
這邊有個 Σ
這邊有個 Σ over 所有的 i
Σ over 所有的參數
那我們把我們要 Learn 的那個參數
那個 θi 代表我們要 Optimize
我們 unknown 的那個參數
要找出來的那個參數
去減掉從過去的任務 Learn 出來的參數 θb
θbi
θ 上標 b 下標 i
是 θb 就是過去的任務 Learn 出來的那個模型
下標 i 就是第 i 個參數
好 那我們要讓 θi
跟 θ 上標 b 下標 i
越接近越好
所以我們呢
把 θi 跟 θ 上標 b 下標 i 相減
然後取它們的平方
那我們在前面呢
會乘上一個數值叫做 bi
這個 bi 就是要告訴我們說
到底我們有多強烈地希望
θi 跟 θ 上標 b 下標 i
越靠近越好
如果 bi 的值很大
就代表說我們希望 θi 跟 θbi 非常靠近
如果 bi 的值很小
代表我們覺得 θi 沒有跟 θbi 很靠近
也無所謂
好 那這個呢
就是我們要 Optimize
這個 L' 呢
就是我們真正要 Optimize 的對象
它裡面有兩項
一個是原來的新的任務的 Loss
另外一項呢
就是要讓 θi 跟 θbi 越接近越好
但是要注意一下
我們並不是
平等地去看待
所有的參數要不要接近這件事
我們其實只要求 θ 跟 θbi
在某些參數上接近就好
並不需要所有參數都接近
只要某些參數接近就好
那哪些參數要接近
就由 bi 來控制
如果某一個參數 i
第 i 個參數它的 bi 很大
就代表我們希望第 i 個參數
它跟舊的參數
之前的任務 Learn 出來的那個參數
要非常接近
反之 bi 等於 0 就代表
我們根本不 care 新的參數跟舊的參數
到底要不要接近
好 所以如果今天呢
bi 設為 0
所有的參數它的 i
所有的參數它的 bi 我們都設為 0
那意味著什麼
那意味著就是
我們沒有給我們的 θi 任何限制
我們完全沒有要求新的 Learn 出來的參數
跟過去學出來的參數有什麼樣的關係
那這個時候就是一般的 Training
就會有 Catastrophic Forgetting 的問題
但是你可能會想說既然 bi 設 0 是不好的
那我們就把 bi 給它設一個非常大的值
所有的 i
所有的參數都給它一個非常大的 bi
那這樣就不會有 Forgetting 的問題
但是你會進入另外一個極端
這個極端叫做 Intransigence
這個極 這個 Intransigence 的意思就是
這個 不肯妥協 不肯讓步
頑固的意思
所以 Intransigence 的意思是說
假設你現在 bi 非常地
非常地大
那你最後 Learn 出來的結果
θi 跟 θb 就會非常地接近
你的新的參數跟舊的參數會非常接近
那你的模型
可能在舊的任務上不會遺忘
但新的任務它學不好
它沒有能力去把新的任務學好
那這種狀況就叫做 Intransigence
好 講到這邊
我們來看一下有沒有同學有問題要問的
好 有同學說
聲音還是炸
希望現在有好很多
現在希望現在有好很多
好 有同學問說
bi 是要人為設定
還是可以作為參數的一部分給機器訓練
好 那再等一下
在文獻上
這個 bi 都是人為設定的
在 Lifelong Learning 的研究裡面
關鍵的技術就在於
我們怎麼設定這個 bi
那如果 bi 用 Learn 的到底行不行呢
你可以想見說在這個任務裡面
你恐怕不能讓 bi 用 Learn 的
如果你讓 bi 自己學
它會學出什麼
對它來說它要讓 Loss 越小越好嘛
那怎麼讓 Loss 最小
直接 bi 等於 0
Loss 就最小了
所以如果你讓 bi 直接用 Learn 的
你並沒有辦法達到 Lifelong Learning 的效果
所以 bi 是人為設的
但是接下來最關鍵的研究問題就是
bi 到底要怎麼找到呢
我們怎麼知道
哪些參數對舊的任務是重要的
哪些參數對舊的任務是不重要的呢
這個就是研究的重點
我們這邊呢 只跟大家用提示的方式
簡單地跟大家說
bi 設計的大概念是什麼
好 那怎麼知道某一個參數
對某一個任務到底重不重要呢
那你可以在訓練完一個模型之後
我們得到 θb 之後
看看 θb 裡面每一個參數
對這個任務的影響
舉例來說
你把 θb 在 θ1 這個方向做一下移動
發現說
在 θ1 這個方向上做移動
好像對 Loss 沒有什麼影響
那我們就知道說
θ1 沒有很重要
θ1 對任務一沒有很重要
可以隨便給它一個值
那既然 θ1 對任務一沒有很重要
在新的任務上
θ1 就可以任意改變
所以我們就可以給 θ1 比較小的 bi 的值
也就是 b1 的值就會比較小
反過來說
如果我們觀察 θ2 這個方向
你會發現說
當我們改變 θ2 的值的時候
對 Loss 的影響是大的
我們改變 θ2 的值的時候
對 Loss 的影響是大的
代表說 θ2 是一個很重要的參數
θ2 對 Task 1 是重要的參數
所以你就不要去動它
所以你要把 θ2 的 b 設得大一點
你要把 b2 設得大一點
好 這個就是
Selective Synaptic Plasticity 的基本概念
而如果我們今天把 b1 呢 設小一點
b2 設大一點
那如果在 Task 2 訓練的時候
會發生什麼事呢
因為 b1 比較小
代表說我們可以把模型在這個方向上
自由地移動
而 b2 比較大
代表說在這個方向上自由地移動
是沒有辦法的
所以如果我們把 b1 設小一點
b2 設大一點
那你把 θb 做 Update 的時候
它就不會往這個方向走
它就會傾向於往這個方向走
因為我們只希望模型去更新這個 θ1 就好
盡量不要動到 θ2
那你就可能把你的這個 Gradient 的方向呢
本來是這樣 Update 的
那就變成這樣子 Update
得到 θ*
然後再把 θ* 拿回來原來的任務一
那因為任務一呢 在這個方向上移動
對 Loss 的影響是小的
所以你在任務二上
假設只有在這個方向上移動
那對任務一的 Loss 的影響就小了
那所以新的 θ* 用在這個地方
它的對 Task 1 的傷害就不大
也許你就可以藉此做到
避免 Catastrophic Forgetting 的問題
好 那接下來這個呢
是一個文獻上真正的實驗結果
那這個結果呢
是來自於 EWC 這篇 Paper
EWC Paper 的連結
也有放在下一頁投影片裡面
如果你有興趣的話再自己參考
好 那這個圖怎麼看呢
你在看那個 Lifelong Learning 的文獻的時候
這種類似的圖是非常常出現的
常常 Paper 幾乎都會放類似這樣子的圖
這個橫軸是什麼
橫軸代表依序訓練的過程
在第一個虛線左邊
這個指的是訓練任務 A
就我們有 A B C 三個任務
我們先訓練任務 A
然後呢 再訓練任務 B
再訓練任務 C
這三個任務依序訓練的結果
那縱軸呢 這邊有三個縱軸
第一個縱軸代表任務 A 的正確率
第二個縱軸是任務 B 的正確率
第三個縱軸是任務 C 的正確率
那畫這樣一個圖你就可以看出說
當我們依序學 A B C 三個任務的時候
任務 A B C 這三個任務
它的正確率會怎麼樣變化
我們先看任務 A 吧
我們先看任務 A 的變化情形
好 我們先看藍色這一條線
藍色這一條線是什麼呢
藍色這一條線就是我們完全不管
Catastrophic Forgetting 的問題
就做一般的 Training
也就是 bi 永遠都設為 0
如果 bi 永遠都設為 0 會發生什麼狀況呢
你會發現說
我們看任務 A 的正確率
一開始剛學任務 A 的時候沒有問題
正確率很高
接下來開始學任務 B 了
任務 A 的正確率就掉下來
接下來開始學任務 C 了
任務 A 的正確率又再更掉下來
這個就是 Catastrophic Forgetting
那 L2 呢
L2 這個實驗是
bi 不管哪個參數通通設 1
如果 bi 不管哪個參數通通設 1
你看 Task A
確實有達到防止
Catastrophic Forgetting 的效果
舉例來說你看綠色這條線
在任務 B 的時候沒有下降很多
在任務 C 的時候
也沒有下降很多
在訓練任務 B 的時候
任務 A 的正確率
沒有掉很多
在訓練任務 C 的時候
任務 A 的正確率
也沒有掉很多
但是 bi 永遠都設 1
你得到一個新的問題
這個問題呢
就是我們剛才提過的 Intransigence
我們來看一下
任務 B 跟任務 C 學習的狀況
綠色這一條線
當 bi 永遠等於 1 的時候
我們在學任務 B 的時候
任務 B 的正確率
卻沒有升得足夠高
這邊這個第二個縱軸呢
代表是任務 B 的正確率
然後這邊代表是學任務 B 的時候
我們在學任務 B 的時候
照理說任務 B 的正確率就應該飆升
但是沒有
綠色這一條線沒有飆升
學不起來
任務 B 學不起來
任務 C 更慘
更學不起來
橫軸是這邊是訓練任務 C 的時候
縱軸是任務 C 的正確率
你發現任務 C 的正確率
沒有其他方法高
代表任務 C 學不起來
這個就是 Intransigence
所以如果你給所有的參數一樣的限制
那這個對你的模型來說限制太大了
會導致它新的任務學不起來
好 那如果我們給不同的參數
不同的 bi
就是有的參數 bi 大
有的參數 bi 小
只固定某些參數
某些參數可以任意更動
那你就得到紅色這條線
那紅色這條線
在每一個任務上表現都是最好的
看任務 A 的話
依序學三個任務
正確率沒有掉
看任務 B 的話
在學任務 B 的時候
正確率跟藍色這條線比起來只掉了一點點
然後任務 C 也不會再掉
那如果看任務 C 的話
任務 C 的正確率
其實相較藍色這條線還是有
還是比較低一點
所以你有設這個 bi 的時候
就是會有一些影響
新的任務就是比較難學
但是沒有 bi 都設 1 的時候結果那麼慘
還是學得比 bi 都設 1 的時候
結果還要更好的
好 那其實在課堂上
我們就沒有真的告訴你 bi 怎麼算了
我們只講了概念
那在助教的程式裡面呢
助教實作了各種不同的方法
實作了各種不同算 bi 的方法
那在選擇題裡面你要回答的就是
每一種方法
它的 bi 是怎麼求出來的
那你可以選擇看文獻
來知道 bi 是怎麼設的
你也可以選擇直接讀助教的程式
看看 bi 是怎麼被設出來的
那我們這邊呢
就列了一大堆方法
有 EWC
有 SI
有 MAS
有 RWalk
有 SCP
那這邊是按照那個年代設的
這邊是按照年代
這邊是按照年代放的
由最舊的方法到最新的方法
那每一個方法
都有它自己的特色
還有它想要解決的問題
它想要考量的點
那這個就是留在作業裡面
讓大家自己去發掘
那這個部分我們就不在課堂上講
因為假設你對 Lifelong Learning
沒有特別有興趣的話
那每一個方法都講一遍
你會覺得特別冗
但是假設你對 Lifelong Learning 有興趣的話
那你把作業的選擇題要好好看一下
那你其實可以學到很多東西
好 我們來看一下有沒有同學有問題
好
看來 bi 可以直接用算的
算出來
對
bi 是直接用算的 算出來的
但是 bi 怎麼算
每一個方法都不一樣
而且每一個方法用的資料不一樣
有的方法
只需要 Model 的 Input 就好
有的方法要 Input 加 Output
也就是假設是影像分類的問題的話
有的方法只要 Image
過去任務的 Image
就可以算出 bi
有的方法是需要過去任務的 Image 加 Label
才能算出 bi
那助教每一個方法都會問你說
這個方法有沒有用到 Label
你再自己看一下助教的 Code
看看有沒有用到 Label
好
有同學問說
改變訓練 Task 的順序
訓練出來的結果會不會差很多
這個問題太棒了
簡單的回答就是會
然後等一下會舉一個例子告訴你說
改變任務的順序
結果就會差很多
所以你會發現說
在這些 Paper 裡面
他們在做實驗的時候
都不是只做一種任務的順序
他們會窮舉所有任務的順序出來做實驗
然後再取它的平均值
也就是假設你有三個任務
你不能說
你只把任務 A B C 跑完
得到平均
就說你的方法
是得到的平均值是這個樣子
在這些 Paper 裡面
常見的做法就是
你會窮舉所有的順序
A B C C B A
B C A 通通都跑過一遍
得那個平均值
才能夠代表說呢
你的 Lifelong Learning 的方法
做得好不好
好
那這個是有關 Regularization Based 的方法
那其實在 Regularization Based 的方法
還有一個早年的做法呢
叫做 GEM
Gradient Episodic Memory
這個方法呢
也是一個挺有效的方法
但它不是在參數上做限制
而是在 Gradient Update 的方向上做限制
那這個 GEM 是怎麼做的呢
這個 GEM 的做法是這個樣子
在任務二上
我們會計算任務二的 Gradient
但是我們要小心一下
我們到底要不要按照
這個任務二算出來的 Gradient 的方向
去 Update 我們的參數
那在 Update 參數之前呢
我們會先回去任務一上面
算一下說
這一個參數
如果在任務一上做 Update 的時候
它的方向到底是哪一個方向
我們用藍色的箭頭
代表 θb 這個參數
在任務一上面的時候
它 Update 的方向
如果 θb 跟 g
它們的方向不一致
那這邊所謂方向不一致就是
它們的 Inner Product 小於 0
那這個時候怎麼辦呢
就修改一下你的 g
把它變成 g′
那這邊修改的條件
修改的 Criterion 是
你希望找到一個新的 g′
這個 g′ 呢
跟 gb 呢
它們做 Inner Product 以後
要大於等於 0
而且 g′ 跟 g 呢
不能夠差太多
所以本來
你往這個方向 Update
可能會產生 Catastrophic Forgetting 的情形
但是我們刻意去修改 Update 的方向
從 g 變成 g′
這樣就可以減輕
Catastrophic Forgetting 所造成的問題
但講到這邊
你有沒有發現這個方法有一點貓膩呢
有沒有一點什麼奇怪的地方呢
你仔細想想
gb 是怎麼算出來的
我們要算 gb
我們要算 Task 1 的 Gradient
意味著我們有存有 Task 1 的資料
如果我們沒有存 Task 1 的資料
那我們根本就沒有辦法把 gb 算出來
所以 GEM 這個方法的一個劣勢就是
它需要把過去方法的資料存下來
那這個跟 Lifelong Learning 想要追求的
是有點不一致的
因為我們一開始就有說
Lifelong Learning 就是不希望
把過去的資料都存下來呀
如果過去的資料都存下來的話
資料累積得越來越多
那
那你最終會沒有辦法把過去的資料都存下來
所以 GEM
有點違反 Lifelong Learning 的最初的精神
它是有偷偷存過去的資料的
但是也許這個問題並沒有特別嚴重
為什麼
因為 GEM 這個方法
只需要存非常少量的資料就好
因為這個 gb
它最重要的工作
只是去修改一下 g 的方向
所以也許算 gb 的時候
我們不需要非常大量的資料
只要存一點點的資料就好
所以 GEM 想要做的事情是
希望透過只存一點點資料
來達到避免 Catastrophic Forgetting 的效果
所以 GEM 比較於其他方法
比如說我們剛才看到的 EWC 等等
有點不公平
因為它有偷存額外的資料
但是其實你再更仔細想一下
這個 EWC 這些方法
這些 Regularization Based 的方法
它們有
它們需要佔用額外的空間
來儲存舊的模型跟儲存 bi
所以剛才講的那些 Regularization Based 的方法
它也需要佔用到額外的空間
這些額外的空間
包括一個舊的模型
還有 bi 這個所謂的數值
所以如果 GEM
它今天雖然存了一些舊的資料
只要它存的舊的資料所佔用的記憶體的量
沒有比多存 bi 還有舊的模型多的話
也許也是可以接受的
所以如果 GEM 沒有存太多資料的話
其實也是一個可以被接受的做法
好 那接下來呢
另外兩個做法
我們就是非常快地帶過去
第一個做法呢
是 Additional Neural Resource Allocation
也就是我們改變一下
使用在每一個任務裡面的 Neural 的 Resource
什麼意思呢
一個最早的做法
叫做 Progressive Neural Networks
它的想法是這個樣子的
我們訓練任務一的時候
有一個模型
那訓練任務二的時候
你就不要再去動任務一學到的那個模型了
你另外再多開一個 Network
這個 Network 呢
它會吃任務一的
Hidden Layer 的 Output 作為輸入
所以如果任務一有學到什麼有用的資訊
任務二也是可以利用它的
但是任務一這邊的參數
任務一學出來的參數
都不要再去動它了
我們只多新增一些額外的參數
我們只 Train 額外的參數
那任務三也是一樣
我們有一組專門給任務三的參數
當訓練任務三的時候
任務一 任務二訓練出來的參數
就不要再動它了
那對於解決 Catastrophic Forgetting 而言
這當然是一個有效的做法
你完全不會有 Catastrophic Forgetting 的問題
因為舊的參數
你根本完全沒有動到它嘛
但是 Progressive Neural Networks 它會
它會造成的問題是
你每一次訓練一個新的任務的時候
你會需要額外的空間
去產生額外的 Neural
你每一次加一個新的任務
你的模型就會長大一點
如果今天
你的模型長大的速率
跟新增任務是成正比的話
那你最終
你當你的任務不斷地新增下去的時候
最終你的 Memory 還是會耗盡的
你的模型終究會太大
大到你沒有辦法把它存下來
所以 Progressive Networks
看起來並沒有完全解決
Catastrophic Forgetting 的問題
但是在任務量沒有很多的時候
Progressive Networks
仍然是可以派得上用場的
然後有另外一個方法叫做 PackNet
它是 Progressive Networks 的反過來
Progressive Networks 是說
每一次有新的任務進來
我們就多加一些 Neural
那 PackNet 呢
正好是用另外一個想法
它說我們先開一個比較大的 Network
然後接下來
每一次有新的任務進來的時候
我們只用這個大 Network 的其中一部分
就任務一的資料進來
我們就這邊 在這個圖示裡面
我們就把每一個圈圈想成是
Network 裡面的一個參數
然後任務一的資料進來
只准使用這邊
有這個
黑色框框的這些圈圈的參數
然後任務二的資料再進來
只准用這邊
橙色的參數
任務三的資料再進來
只准用這邊
綠色的參數
那這樣的好處就是
你的參數量
不會隨著任務增多
而不斷增加
但是如果相較於 Progressive Networks 的方法
想這個方法其實也只是朝三暮四而已
我們只是一開始
開一個比較大的 Network
然後說
每一個任務不要把所有的參數都用盡
只用部分的參數
然後這樣子
你就不會有 Catastrophic Forgetting 的問題
但是相較於不斷增加新的參數
你只是提早把更多的記憶體用完而已
那這個有點朝三暮四的感覺
然後 PackNet
跟 Progressive Networks
是可以結合在一起的
那這個結合的方法
也是一個很知名的做法
叫做 CPG
Compactig, Picking, and Growing
CPG
它就是我們的 Model
既可以增加新的參數
那每一次呢
又都只保留部分的參數
可以拿來做訓練
那至於這些方法的細節我們就不細講
就留給大家慢慢研究
好
我看一下到目前為止
有沒有同學有問題想問的
好 我看目前大家沒有問題想問
好 那我們就繼續
我們就繼續
好 那第三個做法
叫做 Memory Replay
第三個做法非常直覺
我們之前有講說
只要把所有的資料通通倒在一起
就不會有 Catastrophic Forgetting 的問題
但我們又說
不能夠存過去的資料
那我們乾脆就訓練一個 Generative 的 Model
這個 Generative 的 Model 就是
會產生 Pseudo-data
會產生
就我們不能夠存過去的資料
但是我們訓練一個 Generative Model
把過去的資料在訓練的時候
即時地產生出來
也就是說
我們現在有第一個任務的訓練資料
我們不止訓練一個 Classifier 來解任務一
我們同時訓練一個 Generate
它會產生任務一的資料
接下來
你在訓練任務二的時候
如果你只把任務二的資料倒給 Machine
那它可能會有 Catastrophic Forgetting 的問題
但是你又不能把任務一的資料拿出來
那怎麼辦
用 Generate 產生任務一的資料
你用這個 Generate
產生任務一的資料
給第二個任務的 Classifier 做訓練
所以這個 Classifier
它在訓練的時候
不是只看到任務二的資料
它還看到 Generate 產生出來的
任務一的資料
所以用這個方法
就可以避免 Catastrophic Forgetting 的問題
然後接下來
你又有任務二的資料
那也許你就會把任務二的資料
跟任務一產生出來的
這個 Pseudo 的資料再倒在一起
再訓練一個 Generate
這個 Generate 可以同時產生任務一
跟任務二的資料
然後這個過程
就反覆繼續下去
好 那這個方法
到底合不合理呢
就是見仁見智
因為你需要另外產生一個 Generate 嘛
那這個 Generate
當然也是會佔用一些空間
但是如果這個 Generate
佔用的空間
比你儲存資料來講
還要更小的話
那也許這就是一個有效的方法
那事實上呢
我們實驗室
也有做過一些 Lifelong Learning 的 Study
在我們的經驗上
這一種 Generate Data 的方法呢
其實是非常有效的
用這種 Generate Data 的方法
往往你都可以逼近
Lifelong Learning 的 Upper Bound
往往你都可以做到跟
Multi-Task Learning 差不多的結果
好 那接下來
如果你想想看
我們剛才講的 Lifelong Learning 的 Scenarios
我們都假設說
每一個任務
需要的模型就是一樣的
我們甚至強迫限制說
每一個任務
我們要訓練的 Classifier
它們需要的 Class 量
都是一樣的
那假設不同的任務
它們的 Class 的數目不一樣
有沒有辦法解呢
第一個任務
有 10 個 Class
第二個任務
有 20 個 Class
第三個任務有 100 個 Class
你訓練新的任務的時候
你同時要增加新的 Class
有沒有辦法解呢
是有辦法解的
那這邊就列一些文獻
比如說 Learning without forgetting
還有 LwF
還有 iCaRL
Incremental Classifier and Representation Learning
給大家參考
那助教呢
在這個
在我們的這個作業
Lifelong Learning 的作業的選擇題裡面呢
我們也問大家一些
有關這些做法的問題
如果你有興趣
再自己去讀一下這些文件
那其實
我們今天講的 Lifelong Learning
也就是 Continual Learning
只是整個 Lifelong Learning 領域研究裡面的
其中一小塊
其中某一個情境而已
其實 Lifelong Learning
也就是 Continual Learning
還有很多不同的情境
你可以閱讀一下下面這邊統整的文獻
它會告訴你說
Lifelong Learning 有三個情境
我們今天講的
只是那三個情境裡面
最簡單的一種而已
最容易的一種
剩下兩個更有挑戰性的情境要怎麼解
我們留
這個剩下另外兩種更有挑戰性的情境是什麼
我們留在選擇題裡面
讓大家自己去看看
另外兩種情境是什麼樣子
好那這個呢
就是有關 Lifelong Learning 的三個研究方向
那剛才有同學問到說
如果我們調換學任務學習的順序
會不會有非常不一樣的結果呢
確實是會有的
那這邊就舉一個具體的例子來跟大家說明
在剛才我們一開頭講的
Lifelong Learning 的例子裡面
我們說
先讓機器
先學這一種有雜訊的圖片
接下來再學沒有雜訊的圖片
但是反過來
如果先學沒有雜訊的圖片
再學有雜訊的圖片
會發生什麼樣的狀況呢
如果讓機器先學沒有雜訊的圖片的話
在任務二上
正確率 97%
在任務一上
正確率 62%
看起來能夠解沒有雜訊圖片的分類
看到有雜訊的圖片
還是 Handle 不了的
但是如果說
我們更進一步讓機器學任務一的話
這個時候你發現
它任務一 任務二
都可以做好
這個時候
沒有 Catastrophic Forgetting 的問題
所以看起來任務的順序是重要的
有一些順序
會有 Forgetting 的問題
有一些順序
其實也沒有 Forgetting 的問題
而研究什麼樣的順序才是好的
什麼樣的順序
才對學習是有效的這個問題
叫做 Curriculum Learning
