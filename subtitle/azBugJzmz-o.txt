好,那今天這堂課呢,是要跟大家簡略的介紹Diffusion Model的基本概念
那其實Diffusion Model有很多不同的變形
那以下的說明主要來自最知名的Denoising Diffusion Probabilistic Model
大家常常提到的DDPM
那今天其實比較成功的那些用Diffusion Model做的影像生成的系統
比如說DALY啊,或者Google的ImageN啊,或是Stable Diffusion啊
基本上都是用差不多的方法來作為他們的Diffusion Model
好,那這個Diffusion Model是怎麼運作的呢?
它運作的方法是這樣子的
我們來看它是怎麼生成一張圖片的
在生成圖片的第一步,是你要去Sample一個都是雜訊的圖片
就是你Sample出一個,從Gaussian Distribution裡面Sample出一個Vector
這個Vector裡面有的數字,這個Vector的Dimension
跟你要生成的圖片大小是一模一樣的
假設你今天要生一張256x256的圖片
從Normal Distribution Sample出來的那個Vector
它的Dimension就要是256x256那麼多
那就把你Sample到的那個256x256的Vector排成一張圖片的樣子
然後接下來呢,你就有一個Denoise的Module
Denoise的Network,那等一下會講說這個Denoise的Network內部長什麼樣子
這個Denoise的Network從它的名字裡面就可以知道說
輸入一張都是雜訊的圖,那輸出它就會把雜訊濾掉一點
那你就可能看到有一個貓的形狀
然後呢,再做Denoise,那貓的形狀就逐漸出來
那你的Denoise越做越多,越做越多,期待最終你就看到一張清晰的圖片
那這個Denoise的次數是事先訂好的
那我們通常會給每一個Denoise的步驟給它一個編號
那產生最終圖片的那個編號比較小啦
那一開始從完全都是雜訊的輸入開始做Denoise的編號比較大
所以我們這邊就從1999一直排到2,排到1
那這個從雜訊到圖片的步驟啊,它叫做Reverse Process
那在概念上這件事情呢,其實就像是米開朗吉羅說的
這個雕像呢,其實本來就已經在大理石裡面
他只是把不要的部分拿掉
Diffusion Model做的事情就是一樣的
本來圖片就已經在雜訊裡面
他只是把製作雜訊的部分把它濾掉,就產生一張圖片
好那以下呢,我本來是想用Meet Journey把這句話的意境呈現出來啦
後來發現其實有點困難,我直接把這句話呢
丟到Meet Journey裡面,他就畫了一些雕像的半成品出來
就ChangeBT有一個專門把這個Pump改成Meet Journey可以吃的Pump的咒語
然後伸一下看起來是這個樣子,看起來是不太行
後來我決定自己手動輸入,然後我輸入的句子是類似
有一個大衛像在石頭裡面
但是看起來Meet Journey還是沒有很懂這個意境
他沒有辦法畫一個大衛像在石頭裡面的感覺
我想說他可以畫一個有點透明的石頭,然後裡面有一個大衛像
那看起來我Pump的功力非常的弱,沒有辦法讓他畫這件事情
如果看那個Meet Journey的那個Discord
裡面的人都畫出來的圖都讓我嘆為觀止
想說非常的羨慕,每個人都是詠唱大師
所以我詠唱的技巧還非常的不純熟
沒有辦法把我心中想要表達的意境畫出來
好,那接下來呢就要講這個Denoise的Model了
那從這個圖上看來啊
你可能會想說這個Denoise的Model是不是同一個呢
是不是同一個Denoise的Model反覆用很多次呢
是,我們這邊是把同一個Denoise的Model反覆進行使用
但是因為在這邊每一個狀況你輸入的圖片差異非常大
在這個狀況你輸入的東西就是一個純雜訊
在這個狀況你輸入的東西雜訊非常小,它已經非常接近完整的圖
所以如果是同一個模型,它可能不一定能夠真的做得很好
所以怎麼辦呢?你這個Denoise的Model啊
它除了吃要被Denoise的那張圖片以外
它還會多吃一個輸入
這個輸入代表現在Noise嚴重的程度
然後1000代表剛開始Denoise的時候
這個時候Noise的嚴重程度很大
然後1代表說現在Denoise的步驟快結束了
這個是最後一步Denoise的步驟
那顯然雜訊很小
那這個Denoise的Model希望它可以根據我們現在輸入在第幾個Step的資訊做出不同的回應
這個是Denoise的Model
所以我們確實只有用一個Denoise的Model
但是這個Denoise的Model會吃一個額外的數字
告訴它說現在是在Denoise的哪一個Step
好,那Denoise的Model裡面實際內部做的事情是什麼呢?
在Denoise的模組裡面呢
它實際上有一個Noise Predictor
這個Noise Predictor做的事情
就是去預測說在這張圖片裡面的雜訊長什麼樣子
這個Noise Predictor就吃這個要被Denoise的圖片
跟吃一個Noise現在嚴重的程度
也就是我們現在進行到Denoise的第幾個步驟的代號
然後呢就輸出一張雜訊的圖
它就是預測說在這張圖片裡面雜訊應該長什麼樣子
再把它輸出的雜訊去剪掉這個要被Denoise的圖片
然後呢就產生Denoise以後的結果
所以這邊Denoise的Model並不是輸入一張有Noise的圖片
輸出就直接是Denoise後的圖片
它其實是產生一個這個輸入的圖片的雜訊
再把雜訊扣掉輸入的圖片
來達到Denoise的效果
那你可能會想說那為什麼要這麼麻煩呢
為什麼不直接認一個End-to-End的Model
輸入是要被Denoise的圖片輸出就直接是Denoise的結果呢
你可以這麼做你可以這麼做
那我在文獻上也看過有人這麼做
不過現在多數的論文還是選擇認一個Noise的Predicter
因為可以想想看產生一張圖片跟產生Noise它的難度是不一樣
如果你今天你的Denoise的Model可以產生一隻帶雜訊的貓
那它幾乎就可以說它已經會畫一隻貓了
那所以要產生一個帶雜訊的貓跟產生一張圖片裡面的雜訊
這個難度是不一樣的
所以直接認一個Noise Predictor可能是比較簡單的
認一個End-to-End的Model要直接產生Denoise的結果是比較困難的
好那接下來的問題就是怎麼訓練這個Noise Predictor呢
我們已經知道我們一個Denoise的Model
是一個Noisy的Image
然後是一個現在在Denoise的Step數目的Step的ID
然後產生Denoise的結果
我們要告訴你說其實Denoise的Model裡面是一個Noise的Predictor
它是要吃這張圖片吃一個ID
然後產生一個預測出來的雜訊
但是你要產生出一個預測出來的雜訊
你得要有光Truth啊
我們在訓練Network的時候
你就是要有Pair Data才能夠訓練啊
你需要告訴Noise Predictor這張圖片裡面的雜訊長什麼樣子
它才能夠學習怎麼把雜訊輸出出來啊
那這件事情怎麼做呢
怎麼製造出這樣子的資料呢
好這個Noise Predictor啊
它的訓練資料是我們人去創造出來的
怎麼創造呢
它的創造方法是這樣
你從你的Database裡面拿一張圖片出來
你自己加噪音進去
你就Random從Gaussian Distribution裡面Sample一組雜訊出來加上去
產生有點Noise的Image
那你可能再Sample一次
再得到更Noisy的Image以此類推
最後呢整張圖片就看不出來原來是什麼東西
你把你的手上的有的照片呢都做這樣子的事情
這個加噪音的過程啊
叫做Forward Process
又叫做Diffusion Process
那做完這個Diffusion Process以後
你就有Noise Predictor的訓練資料了
怎麼說呢
對Noise Predictor來說它的訓練資料就是
這一張加完雜訊的圖片
跟現在是第幾次加雜訊
是Network的輸入
而加入的這個雜訊
就是Network應該要Predict的輸出
就是Network輸出的光學
所以你在做完這個Diffusion Process以後
你手上就有訓練資料了
你就告訴Noise Predictor說
看到這張圖
看到第二個Step
輸入2這個數字
你要輸出是什麼
你的光處就是一個長這個樣子的Noise
接下來就跟訓練一般的Network一樣
Tread下去就結束了
但是我們要的不只是生圖而已
剛才講的好像只是從一個雜訊裡面生出圖
還沒有把文字考慮進來
那要怎麼把文字考慮進來呢
那在下一頁投影片就會講怎麼把文字考慮進來
但是在講怎麼把文字考慮進來之前
需要先讓大家知道的事情是
如果你今天要訓練一個影像生成的模型
他是吃文字產生圖片
你其實還是需要成對的資料
你還是需要圖片跟文字成對的資料
需要多少成對的資料呢
在我們的作業6裡面
我們其實沒有叫大家從文字生圖片
只有直接生圖片而已
那我們的資料是7萬張圖
那7萬張圖當然非常的少
ImageNet它是每一張圖片有一個類別的標記
還不是那個圖片的描述
不是像Cat's Head in the Snow這樣圖片的描述
它只是每一張圖有一個標記
然後它有100萬張圖片
我們現在這個圓圈的大小
來代表圖片的數量
我告訴你今天這些
你在網路上看到的非常厲害的
什麼Meet Journey
Stable Diffusion
或者是Dali
他們的資料往往來自於Lion
Lion有多少Image呢
5.85Billion的圖片
有58.5億張的圖片
所以如果你把圖片的數量
換算成這個有顏色的圈圈的話
ImageNet你可能以為已經很大了
Lion有這麼大有這麼多圖片
所以難怪今天這一些模型
可以產生這麼好的結果
Lion其實有一個搜尋的Demo的平台
你可以去裡面看看它裡面有什麼樣的圖片
裡面真的是啥都有
比如說貓的圖片
它不是只有貓的圖片跟英文文字的對應
它還有跟中文的對應
還有跟日文的對應
所以就知道說
為什麼今天那些影像生成模型
不是只看得懂英文
你中文它八成都看得懂
那是因為它的訓練資料裡面
也有中文跟其他的語言
你可以試試看在裡面
你找不找得到自己的照片
我是試一下我是找不到自己的照片
蠻多名人的照片
比如說川普那個
隨便一找就一大堆
所以你也不用意外說
為什麼那個Mijohnny都畫得出川普
因為他就是知道川普長什麼樣子
所以這個是你需要準備的訓練資料
好那有了這個文字跟影像成對的資料以後
我們先來看一下Denoise的時候
你是怎麼做的
Denoise的時候你的做法非常的簡單
把文字加到Denoise的模組就結束了
所以現在Denoise的模組
不是只看輸入的圖片做Denoise
它是根據輸入的圖片
加上一段文字的敘述去把Noise拿掉
所以在每一個Step
你的Denoise的模組都會有一個額外的輸入
這個額外的輸入就是
你要它根據這段文字的敘述
生什麼樣的圖片
好那這個Denoise Module裡面的Noise Predictor
要怎麼改呢
你就是直接把這段文字
給Noise Predictor就結束了
你就要讓Noise Predictor
多一個額外的輸入也就是這段文字
就結束了
好那訓練的部分要怎麼改呢
你現在每一張圖片
都有一段文字
所以今天你先把這張圖片
做完Diffusion的Process以後
你在訓練的時候
不只要給你的Noise Predictor
加入雜訊後的圖片
還有現在Step的ID
多給一個就是文字的輸入
然後Noise Predictor會根據這三樣東西
產生適當的Noise
就這樣
產生要去消掉的Noise
產生這個Quantum
這個就是DDPM完整演算法的Algorithm
從他原始論文裡面直接截出來的
就這樣沒有更多東西了
就這樣
然後但是這兩個Algorithm裡面
其實還是暗藏一些玄機啦
這個我們就留著
下次再跟大家講
