這個有label的case
就是你可以訓練一個classifier的case
好 那這邊要舉的例子呢 是偵測說
一個人物是不是來自辛普森的家庭啦
那以下這些人物
就是來自於辛普森的家庭
那這個是霸子 這一個是麗莎
這個是他們兩個的爸爸
這個是荷馬 這個是美枝
就算是你沒有看過辛普森家庭
你也會知道說 他們顯然是來自於
辛普森家族的人物
因為辛普森家族的人物就有一個
很明顯的特色就是 他的臉是黃的
然後嘴巴像鴨子這樣
看到這種人物 你就知道說
啊 他們是辛普森家族的人物
那看到比如說涼宮春日 你就知道說
啊 這個顯然不是來自於辛普森家庭的人物
現在我們假設說呢 我們的資料
我們不只是蒐集了很多
辛普森家庭的人物
每一個辛普森家庭的人物
都還是有label的 所以呢
每一個辛普森家庭的人物都還有label說
每一個辛普森家庭的人物的圖片
都還有標註說 他是誰這樣
好 我們知道說 這個是霸子
這個是麗莎 這個是荷馬等等
每個人 每一張圖片
都有標註他是誰
你有這些訓練資料以後呢
你就可以拿來訓練一個辛普森家的
家庭成員的classifier
給它看一張照片 它就可以判斷說
照片中的人物是辛普森家庭的
哪一個人物
好 比如說你把這個圖片
給你的辛普森家庭人物的分類去看
它就會知道說 他是荷馬 這樣
好 那這邊呢
我是真的做了相關的實驗啦
但其實我也不是特別喜歡辛普森家庭
所以呢 這邊是用一個
網路上現成的資料
在kaggle上
有一個非常喜歡辛普森家庭的人
他就蒐集了非常多張 數千張
辛普森家族裏的人物
我看起來他好像是從那個卡通
動畫裡面 一張一張人工去剪出來的
然後標上說
他真的非常喜歡辛普森家庭
他就標註說 每一張圖片到底是誰
標了很多張 真的就可以訓練一個classifier
然後就直接拿它訓練好的 現成的classifier
來做一下測試 然後正確率頗高
他還有附testing set
這可以做一下測試 正確率頗高
有96%的正確率
好 那我們現在有了這個classifier以後
我們想要做的事情就是根據這個classifier
來做異常偵測
用這個classifier來幫我們判斷說
一個人物 他是來自辛普森家庭
還是不是來自於辛普森家庭
怎麼做呢
現在我們把這個問題啊 本來我們是
拿一個classifier來做分類
那我們現在希望說 一個classifier
它不只是做分類這件事
你給它一張圖片 它不只是訴你答案說
它是辛普森家庭的哪一個人物
它還會output一個數值
這個數值代表它的信心分數
這個confidence score c呢代表機器
現在在做這個分類問題的時候
它的信心分數 它看到這張圖片
它不只是寫出一個答案
它還告訴你說 它覺得它這個答案
是對的的信心分數有多高
那根據這個信心分數
我們就可以拿來做異常偵測這件事情
因為假設今天機器的信心分數很高
那我們今天要訂一個threshold
要訂一個threshold叫做λ
我們說這種λ 這種threshold啊
通常是根據00:03:18??來檢定
那等一下 我們會講說
如果在異常偵測這種test 你的00:03:23 ??
應該長什麼樣
現在假設你已經決定好了
你的thresholdλ
如果今天這個信心分數呢
大於這個thresholdλ 也就是說
它是一個正常的data
它是來自於辛普森家庭的人物
如果今天一張圖片丟給這個classifier
它說它非常沒有信心 它的信心分數
小於某一個threshold的話
那你就說這個人物不是來自於
辛普森家庭
接下來 那怎麼樣得到這一個信心分數呢
那這邊非常直覺的 你可以想像說
如果今天把一張圖片
丟到一個辛普森家族的classifier
然後他非常肯定這一個圖片
它到底是誰的話
那顯然機器人信心分數就非常地高
我們知道說 當我們把一個圖片
丟進一個classifier的時候
其實classifier的output是一個distribution
我們都已經講過deep learning 我們在今天上課前
你應該要看的錄影裡面 已經講過deep learning了
所以知道說 今天
而且你這個output的地方
你還會用一個這個softmax的layer
這支影片裏面有的東西
我們的softmax layer是你output 是一個機率分佈
你可以把output看做是一個機率分佈
這裡把一張圖片丟到你的classifier裡面
它會給每一個你事先設定好的
可能的class一個分數
那今天在這個例子裡面
它給霸子的分數可能就特別高
因為它非常肯定說 這個是霸子
但如果你給它一張很奇怪的圖片
是它訓練的時候 沒有看過的圖片
這個時候 它output的分數
就會特別的平均
譬如說你給他看一下涼宮春日
它這個時候 它output的分數
可能就特別平均
那output分數特別平均的情況下
你就可以知道說
機器現在是比較沒有信心的
這些機器認為比較沒有信心的x
比較沒有信心的圖片
他們就是異常的東西
那剛才講的是定信的分析
那我們需要把剛才這個定信分析的結果
把它化做一個confidence 的分數
那怎麼把它化做一個confidence分數呢
一個非常直覺的方法就是
和機器現在output的這個distribution裡面
最高的數值有多少
那個數值 就是信心分數
所以在上面這個例子裡面
機器的信心分數是0.97
你要看一下 所有的類別裡面
哪一類的分數最高
那個最高的分數就是信心分數
所以上面這個例子裡面
機器看到這張圖片 它有信心
它的分類是對的這個分數是0.97
在下面這個例子裡面 就只有0.26
當然這不是唯一的方法
有其他的方法 舉例來說
因為現在你的分類器的output
是一個distribution 那給你一個distribution
就可以算亂度 你就可以算它的entropy
那如果entropy越大
就是output的這個distripution就越平均
下面這個例子就是entropy比較大的例子
上面這個例子呢 是entropy比較小的case
如果entropy比較大
代表機器現在輸出的這個distribution分佈比較不平均
代表機器現在它沒有辦法肯定說
輸的圖片是屬於哪個類別
這個時候代表機器的信心分數
是比較低的
總之你有各種不同的方法可以根據classifier
來決定它的信心分數有多少
那我們這邊呢 就拿那個類別
我們等一下會採取的方法就是
看機器output所有類別裡面
哪一個類別的分數最高 那個最高分
就是我們classifier的信心分數
當然有其他的方法
但是在文獻上看來 用不同方法的差異
其實是沒有那麼大的
好 那這個方法到底work不work呢
我就真的做了實驗
因為我手上已經有個辛普森家庭的classifier
就可以真的把image就丟進去
看看它output的信心分數有多少
那我在網路上隨便抓一個圖片
這顯然是訓練資料裡面沒有的
隨便給他看一個荷馬的圖片
它給荷馬的信心分數是1
那是一個很好的classifier
它說它有100%相信說這是荷馬
其它呢 通通都是0這樣子
我如果給它看霸子的圖片
它有81%的信心呢 它覺得這是霸子
然後有12%呢 覺得他是郭董這樣子
辛普森家庭的那個人物翻譯就是這樣
它都會套用一個名人的名字這樣
這個是郭董
他是辛普森家庭的一個角色
那如果我給他看一些
不是辛普森家庭的人物呢
舉例來說給他看三玖這樣子
你們以為我要說什麼三玖天下第一
我才不會這麼說呢
我其實要說一花一世界這樣子
好才沒有 聽不懂就算了
好 那這個是 這個人是三玖啦
這個是三玖 給它看
給這個classifier看三玖的話呢
它就覺得是柯阿三的機率是34%
都有三這樣子
然後覺得是陳趾鹹是31%
然後魯肉王是10% 這樣
好 這都是給它看動畫人物
我想說給他看一個真人
給它看一個死臭酸宅會怎樣呢
然後它覺得是柯阿三的分數是0.63啦
然後它覺得是宅王是0.08
這個也還滿準的
然後其他這我就不知道是誰了
小丑阿基是0.04 孔龍金是0.03
所以你可以發現說 今天如果是
辛普森家庭的人物
Classifier確實表示出高度的信心
如果不是辛普森家族的人物
它的信心分數確實是比較低的
然後我試來試去確實還是
但是還是試出了一些例外
舉例來說 給它看這個涼宮春日
它覺得它是柯阿三的分數會0.99這樣子
然後我在用發現一個有趣的事情就是
我發現如果不是辛普森家庭的人物
機器特別容易覺得它是柯阿三
只是信心的分數高或者是低而已
就是在涼宮春日這邊是柯阿三的
信心分數特別高
剛才在其他例子
柯阿三的信心分數是比較低的
但是也是所有低的裡面最高的
所以我就想說到底為什麼會這樣呢
我後來發現說 柯阿三其實是長這樣啦
他就是少數辛普森家族裡面
不是黃臉的人 這樣子
因為他不是黃臉啦
所以它看到不是辛普森家庭的人
特別容易被歸納成柯阿三
也許是因為涼宮春日的頭髮是棕色的
跟他的臉的顏色比較像
所以機器覺得他是柯阿三
好那這邊只是舉一些例子
那這邊就只是幾個例子而已
如果是實際看大量的資料
結果會是怎麼樣呢
比如說實際看了一下大量的資料
好那個在剛才那kaggel連結裡面
就附了一個
辛普森家庭人物的testing set
裡面有數千張辛普森家族的人物
我就把那些人物通通丟到那個classifier裡面
每一個照片 我都得到一個信心分數
那它們的分佈是這個樣子
你的信心分數是從0一直到1
好 從0%一直到100%
你會發現這個peak是非常非常的尖銳
幾乎所有的辛普森家族的人物
你丟到這個classifier 就算它辨識有錯
它也會給你一個非常高的信心分數
那我這邊其實也有發現說
如果辨識有錯的話
確實得到的信心分數就比較低一點
在這個圖上 有一些紅色的點
我相信你在台下 其實是看不太清楚
那些紅色的點是辨識錯誤的那些圖片
它的分數的分佈
那你會發現說呢 紅色的點的分佈
相較於這個藍色的這個區域呢
藍色的區域分佈是非常集中在1的地方
原來正確的圖片
機器會有非常高的信心
他就是辛普森家族的人物
那如果是丟其他動畫的人物會怎麼樣呢
這邊丟了一萬五千張其他動畫的人物
那你會發現說 它的分佈是長這個樣子
是長這樣
你可能會說 唉這邊有一大堆的圖片
它的信心分數都還是很高啊
他們不是辛普森家族的人物
但是辛普森家族的classifier
還是給它很高的信心分數
那我這邊丟的
其實是一萬五千張的圖片
那這邊呢 這個bar 它的高度呢
只有1400張 所以大概只有
十分之一的圖片
它會得到很高的信心分數
你會發現說多數的圖片
它得到的信心分數都是比較低的
你會發現說辛普森家族的人物
跟不是辛普森家族的人物
確實他們在classifier的confidence score上的分佈
是有很大的差異的
那在我們剛才呢
是用一個比較直觀的方法
來給一個信心分數這樣
那你可能會覺得這種方法讓你覺得
很弱這樣子
讓你覺得好像沒有什麼特別厲害的
不過像剛才那種非常簡單的方法
其實在實作上
往往還可以有不錯的結果
所以今天假如你是要做
這個異常偵測問題
你手上又有一個現成的classifier
其實這應該是你第一個要嘗試的baseline
雖然它非常簡單
但它不見得performance很差
很多時候有同學來問我說
啊我今天有一個anomaly detection的問題
那我要怎麼來解
我通常會建議說 你先試試這個
用classifier的信心分數來做這異常偵測的方法
那很多人就不信 他覺得說這麼簡單
怎麼可能會work呢
但其實這是一個沒有很弱的方法
當然有其他更好的方法
舉例來說 你今天在訓練一個neural network的時候
你可以直接教neural network
output信心分數這個東西
那這個技術我們就不細講了
我今天呢 就只是引用一個文獻
告訴大家說 有這樣子的技術
因為這門課是我們定位
還是一個機器學習的入門課
所以我們就不會講太深入的東西
我們會概要的overview一個技術
然後提供給大家一些訓練資料
提供給大家一些參考資料
如果你有興趣的話
可以再繼續深入去研究
你會發現說 這邊引用的資料還是很新的
舉例來說 是2018年的paper
在這門課裡面 我們都盡量
引用一些新的資料 告訴你說
這個領域仍然是非常的active
那在這篇paper裡面 它的想法是這樣
我們剛才是先訓練了一個classifier以後
在不知道怎麼回事 從classifier的輸出
得到一個信心分數
那有一些技術
是我們在訓練那個classifier的時候
我們就訓練一個classifier
它不只是可以做分類這件事情
它還會直接output一個分類的信心分數
那至於這是怎麼做到的
你就參考一下文獻
總之是有這樣的技術就是了
