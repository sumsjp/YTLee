臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://ai.ntu.edu.tw/
我們今天要講的是 Regression
等一下我會舉一個例子，
來講 Regression 是怎麼做的。
順便引出一些 machine learning 裡面
常見的重要觀念。
那regression可以做甚麼?
除了我們作業裡面要大家做的
預測PM2.5這個任務以外，
還有很多其他非常有用的task。
舉例來說，
如果你可以做一個股票預測的系統，
你要做的事情就是 :
找一個function。
這個function的input可能是，
過去十年，
各種股票起伏的資料。
或者是，
A公司併購B公司，
B公司併購C公司等等的資料。
你希望這個function在input這些資料以後，
它的output是，明天的道瓊工業指數的點數。
如果你可以預測這個的話，你就發了
還有別的task，
比如說現在很熱門的
無人車，自動車。
這個自動車也可以想成是一個regression的problem，
在這個regression的problem裡面，
input就是，你的無人車所看到的各種sensor :
它的紅外線感測的sensor，
它的影像的視訊的鏡頭所看到的馬路上的東西等等。
你的input就是這些information，
output就是方向盤的角度。
比如說，
要左轉50度，
還是右轉50度，
右轉50度你就當作左轉 負50度，
所以output也是一個 scalar。
所以無人車駕駛就是一個regression problem
input一些information，
output就是方向盤的角度，
它是一個數值。
或者是，
你可以做推薦系統。
我們都知道說，YouTube要推薦影片或者Amazon要推薦商品給你，
那推薦系統它要做的事情，
也可以想成是一個regression的問題。
就是找一個 function，
它的input是，
某一個使用者A和某一個商品B，
它的output就是，
使用者A購買商品B的可能性。
如果你可以找到這樣一個function，
它可以精確的預測說，
使用者A購買商品B的可能性的話，
那Amazon就會推薦使用者A他最有可能購買的商品。
這個是regression的種種應用，
今天我要講的是，
另外一個我覺得更實用的應用 :
就是預測寶可夢的CP值。
這個大家知道是甚麼意思嗎?
我來說明一下好了:
你的CP值就是一隻寶可夢的戰鬥力。
你抓到一隻寶可夢後，
比如說，
這個是一隻妙蛙種子，
比如說這是一隻妙蛙種子，
然後你給他吃一些星辰或糖果以後，
他就會進化成妙蛙草。
而如果他進化成妙蛙草以後，
他的CP值就變了。
為甚麼我們會希望能夠預測寶可夢的CP值呢?
因為如果你可以精確的預測一隻寶可夢在進化以後的CP值的話，
你就可以評估說，
你是否要進化這隻寶可夢。
如果他是一隻CP值比較低的寶可夢的話，
你可能就把他拿去做糖果。
你就不進化他，
這樣你就可以節省一些你的糖果的資源。
你可能就會問說，
為甚麼我們要節省糖果的資源?
因為你這樣可以在比較短時間內，
就進化比較多強的神奇寶貝。
你就會想說為甚麼我們要比較強的寶可夢?
因為他可以去打道館。
你問為甚麼我們要去打道館?
其實我也不知道這樣。
我們今天要做的事情，就是找一個function。
這個function的input，
就是某一隻寶可夢。
它的output就是
這隻寶可夢如果我們把它進化以後，
它的CP值的數值是多少。
這是一個regression的problem，
我們的input就是某一隻寶可夢所有相關的information，
比如說，
我們把一隻寶可夢用X表示，
我們把一隻寶可夢用Xcp表示。
它的CP值我們就用Xcp來表示。
我們用下標來表示某一個，
完整的東西裡面的，
某一個component，
某一個部分，我們用下標來表示。
Xcp代表某一隻寶可夢X，
它在進化前的CP值。
比如說，這個妙蛙種子，
它CP值是14，
Xs代表這一隻寶可夢X，是屬於哪一個物種。
比如說這是妙蛙種子。
Xhp代表這一隻表可夢，它的hp值是多少，
它的生命值是多少。
這個妙蛙種子的生命值是10。
Xw代表它的重量，
Xh代表它的高度。
可以看看你抓的寶可夢是不是特別大隻或特別小隻。
那output是進化後的CP。
這個進化後的CP值，
就是一個數值。
就是一個scalar，
我們把它用Y來表示。
這麼解這個問題呢?
我們第一堂課就講過說，做machine learning就是三個步驟，
第一個步驟就是，
找一個model；
第二個步驟是，
model就是一個function set，
第二個步驟就是，
定義function set裡面某一個function，
我們拿一個function出來
可以要evaluate它的好壞；
第三步驟就是找一個最好的function。
首先我們就從第一個步驟開始。
我們要找一個function set，
這個function set就是所謂的model。
在這個task裡面，
我們的function set，
應該長甚麼樣子呢?
一個 input一隻寶可夢，
output進化後的CP值的function，
應該長甚麼樣子呢?
這邊就先亂寫一個簡單的。
比如說我們認為說，
進化後的CP值Y，
等於某一個常數項B加上某一個數值W，
等於某一個常數項b加上某一個數值w，
乘上現在輸入的寶可夢的X它在進化前的CP值，
這個Xcp代表進化前的CP值，
這個Y是進化後的CP值。
這個w和b是參數，
w和b可以是任何的數值。
在這個model裡面，
w和b是未知的，
你可以把任何的數字填進去，
填進不同的數值，
你就得到不同的function。
比如說你可以有一個f1，
f1是b=10，w=9
你可以有另外一個function f2，
這個f2是b=9.8，w=9.2
你有一個f3，
它是b= -0.8，w=-1.2
如果今天你的w和b可以代任何值的話，'
其實你這個function set裡面，
可以有無窮無盡的function，
有無窮多的function。
你用這個式子y=b+w × Xcp
代表這些function所成的集合。
當然在這些function裡面，
比如說f1，f2，f3裡面
你會發現有一些function顯然不太可能是正確的。
比如說f3不太可能是正確的。
因為我們知道說CP值其實是正，
乘以-1.2就變成是負的
所以進化以後CP值就變成是負的，
這樣顯然是說不通的。
這個就是我們等一下要用靠training data來告訴我們說，
在這個function set裡面，
哪一個function才是合理的function。
這樣子的model，
這個y=b+w × Xcp這樣子的model，
它是一種linear的model。
所謂的linear的model的意思是，
簡單來說，
如果我們可以把一個function，
我們把現在我們要找的function，
寫成y=b+ ∑WiXi
那它是一個linear的function。
這邊的Xi指的是你input 的X的各種attribute。
比如說你input寶可夢的各種不同的屬性，
比如說身高或體重等等。
這些東西我們叫做feature。
從input的object裡面，
抽出來的各種數值當作function的input，
這些東西叫做feature。
這個Wi和b，
這個Wi叫做weight，
這個b叫做bias。
接下來我們要收集training data，才能夠找這個function。
這是一個supervised learning 的task，
所以我們收集的是function的input，
和function的output。
因為是regression的task，
所以function的output是一個數值。
舉例來說，你就抓了一隻，
這個是傑尼龜，
它進化後這個是卡咪龜，
卡咪龜進化是水箭龜。
這個function的input在這邊就是這隻傑尼龜。
那我們用X1來表示它。
我們用上標來表示一個完整的object的編號。
剛才我們有看到用下標來表示一個 component，
一個完整object裡面的component。
我們用上標來表示一個完整object的編號，
所以這是第一個X
這是一隻傑尼龜
那它進化以後的CP是973
所以我們function的output，
應該看到X1就output數值973。
那這個973我們用Y1 hat 來代表，
這邊用Y來代表function的output，用上標來代表一個完整的個體。
因為我們今天考慮的output是scalar，
所以它其實裡面沒有component，
它就是一個簡單的數值。
但是我們未來如果在考慮structured learning的時候，
我們output的object可能是有structure的。
所以我們還是會需要上標下標來表示一個完整的output的object，還有它裡面的component。
我們用Y hat1來表示這個數值979。
只有一隻不夠要收集很多。
比如說再抓一隻伊布，
那這個伊布就是X2。
那它進化以後可以變成雷精靈，
那雷精靈的CP值是1420，
這個1420就是Y2 hat。
我們用hat來代表說這個是一個正確的值，
是我們實際觀察到function該有的output。
你可能以為說這只是個例子，
這不只是一個例子，
我是有真正的data的。
今天其實我是想要發表，
我在神奇寶貝上面的研究成果這樣。
那我們就收集10隻神奇寶貝，
這10隻寶可夢就是從編號1到編號10
每一隻寶可夢我們都讓它進化以後，
我們就知道它進化後的CP值
就是Y1 hat 到 Y10 hat
這個是真正的data，
你可能會問說怎麼只抓10隻呢?
你不知道抓這個很麻煩嗎?
其實老實說這也不是我自己抓的，
網路上有人分享他抓出來的數據。
我拿他的數據來做一下，
其實他也沒有抓太多次，
因為抓這個其實是很麻煩的。
並不是抓來就好，你要把它進化以後，
你才知道function的output是多少。
所以收集這個data並沒有那麼容易。
所以就收集了10隻 神奇寶貝，
它進化後的CP值。
那如果我們把這十隻神奇寶貝的information畫出來的話，
這個圖上每一個藍色的點，
代表一隻寶可夢。
然後他的X軸，
X軸代表的是這一隻寶可夢他的CP值，
這個我們一抓來的時候我們就知道了
然後他的Y軸代表如果你把這隻寶可夢進化以後，進化後的CP值。
這個用 ŷ 來表示。
所以10隻寶可夢
這邊我們有10個點
這個CP值其實就特別高，
這隻其實是伊布
伊布其實不是很容易抓的
這邊每一個點就是某第n隻寶可夢的CP值，
跟它進化以後的 ŷ。
那我們用X上標n和下標cp，
來代表第n筆data，他的某一個component，也就是他的CP值。
接下來，
有了這些training data以後，
我們就可以定義一個function的好壞，
我們就可以知道一個function是多好或者是多不好，
知道說這裡面每一個function是多好或者是多不好。
怎麼做呢?
我們要定義一個
另外一個function，
叫做 loss function，
這邊寫作大寫的L
我們這裡定了一個function set，
這裡面有一大堆的function。
這邊我們要再定另外一個function
另外一個function叫做loss function，
我們寫成大寫的L。
這個loss function的input，
他是一個很特別function，
這個loss function他是function的function，
大家知道今天我的意思嗎?
他的input就是一個function，
他的output 就是一個數值告訴我們說
現在input的這個function他有多不好
我們這邊是用多不好來表示。
所以這個loss function他是一個function的function，
他就是吃一個function當作input
他的output就是這個function有多不好。
所以你可以寫成這樣，
這個L他的input就是某一個function f
你知道一個function，
他又是由這個function裡面的兩個參數b和w來決定的
這個f是由b和w來決定的
所以input這個f，
就等於input這個f裡面的b和w。
所以你可以說loss function，
他是在衡量一組參數的好壞，
衡量一組b和w的好壞。
那怎麼定這個loss function呢?
loss function你其實可以隨自己的喜好，
定義一個你覺得合理的function。
不過我們這邊就用比較常見的作法 :
怎麼定呢?
你就把這個input的w和b，
實際地代入y=b+w × Xcp 這個function裡面。
實際地代入y=b+w × Xcp這個function裡面。
你把w乘上第n隻寶可夢的CP值，
再加上這個constant b，
然後你就得到說 :
如果我們使用這一組w，
這一個w和b，
來當作我們的function，
來預測寶可夢它進化以後的CP值的話，
這個預測的值Y的數值是多少。
這個裡面的括號，比較小的括號，
他輸出的數值是我們用現在的function來預測的話，
我們得到的輸出是甚麼。
那 ŷ是真正的數值。
我們把真正的數值，
減掉預測的數值，
再取平方，
這個就是估測的誤差。
我們再把我們手上的10隻寶可夢的估測誤差，
都合起來，
就得到這個loss function。
那這個定義我相信你是不太會有問題的，
因為它非常的直覺估測 :
如果我使用某一個function，
它給我們的估測誤差越大，
那當然這個function就越不好。
所以我們就用估測誤差來定義一個loss function。
當然你可以選擇其他可能性。
再來我們有了這個loss function以後，
如果你還是有一些困惑的話，
我們可以把這個loss function的形狀畫出來。
這個loss function L(w,b)
它input就是兩個參數w和b
所以我們可以把這個L(w,b)對w和b把它做圖
把它畫出來。
在這個圖上的每一個點，
就代表著一個組w跟b，
也就是代表某一個function。
比如說，紅色這個點，
紅色這個點就代表著，
這個b=-180， 這個w=-2的時候所得到的function。
這個b=-180， 這個w=-2時候所得到的function。
就y= -180−2×Xcp這個function。
這圖上每一個點都代表著一個function。
顏色代表了，
現在如果我們使用這個function，
根據我們定義的loss function，
它有多糟糕，
它有多不好。
這個顏色越偏紅色代表數值越大，
所以在這一群的function，
他們loss非常大，也就是它們是一群不好的function。
最好的function落在哪裡呢?
越偏藍色代表那一個function越好
所以最好的function其實落在這個位子
如果你選這個function的話，
它是可以讓你loss最低的一個function。
接下來，我們已經定好了我們的loss function，
可以衡量我們的model裡面每一個function的好壞。
接下來我們要做的事情就是，
從這個function set裡面，
挑選一個最好的function。
所謂挑選最好的function這一件事情，
如果你想要把它寫成formulation的話，
如果你想要把它寫成equation的話，
那寫起來是甚麼樣子呢?
它寫起來就是，你要我們定的那個loss function長這樣，
那你要找一個f，
它可以讓L(f)最小，
這個可以讓L(f)最小的function，
我們就寫成f*。
或者是，
我們知道f是由兩個參數w和b表示，
今天要做的事情就是，
窮舉所有的w和b，
看哪一個w和b代入L(w,b)，
可以讓這個loss的值最小。
那這一個w跟b就是最好的w跟b，
那麼寫成w*
跟b*。
或者是我們把L這個function列出來，
L這個function我們知道它長的就是這個樣子，
那我們就是把w和b，用各種不同的數值代到這個function裡面，
看哪一組w跟b，可以給我們最好的結果。
如果你修過線性代數的話，
其實這個對你來說應該完全不是問題，對不對?
這個是有closed-form solution的
像我相信你可能不記得它長甚麼樣子了
所謂的closed-form solution意思是說，
你只要把10隻寶可夢的CP值
跟他們進化後的ŷ
你只要把這些數值代到某一個function裡面，
它output就可以告訴你最好的w和b是甚麼。
如果你修過線代的話，
其實你理論上是應該是知道要怎麼做的。
我假設你已經忘記了，
那我們要教你另外一個做法。
這個做法叫做
gradient descent。
這邊要強調的是，gradient descent
不是只適用於解這一個function。
解這一個function是比較容易的，
你有修過線代你其實就會了。
但是gradient descent它厲害的地方是，
只要你這個L是可微分的
不管它是甚麼function，
gradient descent都可以拿來處理這個function，
都可以拿來幫你找可能是比較好的function或者是參數。
那我們來看一下gradient descent是怎麼做?
我們先假設一個比較簡單的task，
在這個比較簡單的task裡面，
我們的loss function L(w)，
它只有一個參數w。
那這個L(w)必然是不需要是我們之前定出來的那個loss function，
它可以是任何function，
只要是可微分的就行了。
那我們現在要解的問題是，
找一個w，
讓這個L(w)最小。
這件事情怎麼做呢?
那暴力的方法就是，
窮舉所有w可能的數字，
把所有w可能的數值，
從負無限大到無限大，
一個一個值都代到loss function裡面去，
試一下這個loss function的value，
你就會知道說，哪一個w的值，
可以讓loss最小。
如果你做這件事的話，你就會發現說，
比如說這裡這個w的值，
可以讓loss最小。
但是這樣做是沒有效率的，
怎麼做比較有效率呢?
這就是gradient descent要告訴我們的。
這個作法是這樣子的 :
我們首先隨機選取一個初始的點。
比如這邊隨機選取的是，
w0
其實你也不一定要隨機選取，
其實有可能有一些其他的方法，
可以讓你找的值是比較好的。
這個之後再提，
現在就想成是，
隨機選取一個初始的點w00
接下來，
在這個初始的w0這個位置，
我們去計算一下，
w這個參數
我們要計算在w=w0這個位置，
參數w對loss function的微分。
如果你對微分不熟的話，
反正我們這邊要找的就是切線斜率。
如果今天這個切線斜率是負的的話，
那顯然就是，
所以從這個圖上就可以很明顯地看到
如果切線斜率是負的的話，
顯然左邊loss是比較高的，
右邊loss是比較低的，
那我們要找loss比較低的function，
所以你應該增加你的w值，
你應該增加w0值。
反之，如果今天算出來的斜率是正的，
代表跟這條虛線反向，
也就是右邊高左邊低的話，
那我們顯然應該減少w的值。
把我們的參數往左邊移動，
把我們的參數減小。
或者是，
假如你對微分也不熟切線也不熟的話，
那你就想成是，
有一個人，
站在w0這個點。
他往前後各窺視了一下，
看一下他往左邊走一步，
loss會減少，
往左邊走一步loss會減少，
還是往右邊走一步，
loss會減少。
如果往右邊走一步loss會減少的話，
那他就會往右邊走一步。
總之在這個例子裏面，
我們的參數是增加的，
我們的參數是會增加的，
會往右邊移動。
那怎麼增加呢?
應該要增加多少呢?
這邊的增加量，
我們寫成
有關gradient descent 的theory，
我們留到下次再講，
我們今天就講一下它的操作是甚麼樣子。
如果我們往右邊踏一步的話，
應該要踏多少呢?
這個踏一步的step size，
取決於兩件事。
第一件事情是，
現在的微分值有多大。
現在的dL/dw有多大
如果微分值越大，
代表現在在一個越陡峭的地方，
那它的移動的距離就越大，
反之就越小。
那還取決於另外一件事情，
這個另外一件事情，
是一個常數項，
是一個常數項。
這個常數項這個η，
我們把它叫做learning rate。
這個learning rate決定說，
我們今天踏一步，
不只是取決於我們現在微分值算出來有多大，
還取決於我們一個
事先就定好的數值。
這個learning rate是一個事先定好的數值。
如果這個事先定好的數值你給它定大一點的話，
那今天踏出一步的時候，
參數更新的幅度就比較大，
反之參數更新的幅度就比較小。
如果參數更新的幅度比較大的話，
你learning rate大一點的話，
那學習的效率，學習的速度就比較快。
所以這個參數η，
我們就稱之為learning rate。
所以，
現在我們已經算出，
在w0這個地方，
我們應該把參數更新η乘上dL/dw
所以你就把原來的參數w0減掉η乘以dL/dw
這邊會有一項減的，
因為如果我們這個微分算出來是負的的話，
要增加這個w的值，
如果算出來是正的的話，
要減少w的值。
所以這一項微分值，跟我們的增加減少是反向的，
所以我們前面需要乘以一個負號。
那我們把w0更新以後，
變成w1，
接下來就是重複剛才看到的步驟，
重新去計算一次
在w=w1這個地方，
所算出來的微分值。
假設這個微分值算出來是這樣子的，
這個微分值仍然建議我們，
應該往右移動我們的參數，
只是現在移動的幅度，
可能是比較小的。
因為這個微分值，
相較於前面這一項，
是比較小的。
那你就把w1−ηdL/dw，
然後變成w2。
那這個步驟就反覆不斷地執行下去，
經過非常非常多的iteration後，
經過非常多次的參數更新以後，
假設經過t次的更新，
這個t是一個非常大的數字，
最後你會到一個local minimum的地方。
所謂local minimum的地方，
就是這個地方的微分是0，
所以你接下來算出的微分都是0了，
所以你的參數接下來就會卡在這邊，
就沒有辦法再更新了。
這件事情你可能會覺得不太高興，
因為這邊其實有一個local minimum，
你找出來的跟gradient descent找出來的solution，
你找出來的參數，
它其實不是最佳解。
你只能找到 local minimum，
你沒有辦法找到global minimum。
但幸運的是，這件事情在regression上面，
不是一個問題。
因為在regression上面，
在linear regression上面，
它是沒有local minimum，
等下這種事情我們會再看到。
今天我們剛才討論的是，
只有一個參數的情形，
那如果是有兩個參數呢
我們今天真正要處理的事情，
是有兩個參數的問題，
也就是w跟b。
其實有兩個參數，
從一個參數推廣到兩個參數，
其實是沒有任何不同的。
首先你就隨機選取兩個初始值，
w0和b0，
接下來，
你就計算，
在w=w0，b=b0的時候
w對loss的偏微分，
你在計算w=w0，b=b0的時候，
b對L的偏微分。
接下來，你計算出這兩個偏微分之後，
你就分別去更新w0和b0這兩個參數，
你就把w0減掉η乘上w對L的偏微分，
得到w1。
你就把b0減掉η乘上b對L的偏微分，
你就得到b1。
這個步驟你就反覆的持續下去，
接下來，
你算出b1和w1以後，
你就再計算一次w和L 的偏微分
只是現在是計算w=w1，b=b1的時候的偏微分，
所以這項偏微分跟這項偏微分的值不是一樣的，
這是在不同位置算出來的。
接下來你有了w1和b1以後，
你就計算w1和b1在w=w1,b=b1的時候，
w對L的偏微分，
還有w1和b1在w=w1,b=b1的時候，
b對L的偏微分。
接下來你就更新參數，
你就把w1減掉η乘上算出來的微分值，
你就得到w2。
你把b1減掉η乘上微分值就得到b2。
你就反覆進行這個步驟，
最後你就可以找到一個loss相對比較小的w值跟b的值，
這邊要補充說明的是，
所謂的gradient descent的gradient指的是甚麼呢?
其實gradient就是這個倒三角 ∇L
其實gradient就是這個倒三角 ∇L
我知道大家已經，
很久沒有學微積分了，
所以我猜你八成不記得∇L是甚麼。
這個∇L就是，
你把w對L的偏微分和b對L的偏微分排成一個vector，
這一項就是gradient。
因為我們在整個process裡面，
我們要計算w對L的偏微分和b對L的偏微分，
這個就是gradient。
所以這門課如果沒必要的話，我們就盡量不要把這個大家不熟悉的符號弄出來。
只是想要讓大家知道說gradient指的就是這個東西。
那我們來visualize一下剛才做的事情。
剛才做的事情像是這樣 :
有兩個參數w和b，
這兩個參數決定了一個function長甚麼樣。
那在這個圖上的顏色，
這個圖上的顏色代表loss function的數值。
越偏藍色代表loss越小，
那我們隨機選取一個初始值，
是在左下角紅色的點這個地方。
接下來，
你就去計算，
在紅色這個點，
b對loss的偏微分還有w對loss的偏微分
然後你就把參數更新，
這個η乘上b對loss的偏微分。
還有η乘上w對loss的偏微分。
如果你對偏微分比較不熟的話，
其實這個方向，
這個gradient的方向，
其實就是等高線的法線方向。
那我們就可以更新這個參數，
從這個地方，
到這個地方。
接下來你就再計算一次偏微分，
這個偏微分告訴你說現在應該往這個方向，
更新你的參數。
你就把你的參數從這個地方移到這個地方。
接下來它再告訴你說，
應該這樣子走，
然後你就把參數從這個地方
再更新到這個地方。
那gradient descent有一個讓人擔心的地方。
就是如果今天你的loss function 長的是這個樣子，
如果今天w和b對這個loss L，它看起來是這個樣子，
那你就麻煩了。
這個時候如果你的隨機取捨值是在這個地方，
那按照gradient建議你的方向，
按照今天這個偏微分建議你的方向，
你走走走走走，
就找到這個function。
如果你隨機取捨的地方是在這個地方，
那根據gradient的方向，
你走走走就走到這個地方。
所以變成說這個方法你找到的結果，
是看人品的。
這個讓人非常非常的擔心，
但是在linear regression裡面，
你不用太擔心。
為甚麼呢?
因為在linear regression裡面，
你的這個loss function L，
它是convex。
如果你定義你loss的方式跟我在前幾頁投影片講的是一樣的話，
那一個loss是convex的。
如果你不知道convex是甚麼的話，
換句話說，
它是沒有local的optimal的位置，
或者是，
如果我們把圖畫出來的話，
它長的就是這樣子。
它的等高線就是一圈一圈橢圓形的。
所以它是沒有local optimal的地方，
所以你隨便選一個起始點，
根據gradient descent所幫你找出來的最佳的參數
你最後找出來的都會是同一組參數。
我們來看一下它的formulation。
其實這個式子是非常簡單的，
假如你要實際算一下w對L的偏微分和b對L的偏微分
這個式子長的是甚麼樣子呢?
這個L我們剛才已經看到了，
它是長這個樣子。
它是估測誤差的平方和。
如果我們把它對w做偏微分，
我們得到甚麼樣的式子呢?
這個其實非常簡單，
我相信有修過微積分的人都可以秒算。
你就把這個2移到左邊，
你要對w做偏微分，
你就先把括號裡面這一項先做偏微分，
你把2移到左邊，
你得到這樣子的結果。
接下來考慮括號裡面的部分，
括號裡面的部分，
只有負的 𝑤 ∙ 𝑥上標𝑛 下標𝑐𝑝這一項是跟w有關的
只有負的 𝑤 ∙𝑥上標𝑛 下標𝑐𝑝這一項是跟w有關的
所以如果你把括號裡面的equation對w做偏微分的話，
你得到的值就是負的 𝑥上標𝑛 下標𝑐𝑝
所以partial w partial L，
w對L的偏微分它的式子就是長這樣
如果你要算d對L的偏微分的話，
也非常簡單，
你就把2移到前面，
把2移到前面，
變成這個樣子。
然後你再把這個括號裡面的值，
對b做偏微分。
括號裡面只有負b這一項，
跟我們要做偏微分的這個b有關，
所以－b對b做偏微分得到的值，
是－1
然後就結束了。
所以有了gradient descent，
你就知道說怎麼算偏微分，
那你就可以找一個最佳的function。
那結果怎麼樣呢?
我們的model長這樣，
然後費盡一番功夫以後，
你找出來的最好的b跟w，
根據training data分別是b= －188.4，w=2.7
如果你把這一個function: y=b+w×Xcp
把它的b跟w值畫到圖上的話，
它長的是這個樣子。
這一條紅色的線，
那妳可以計算一下，
你會發現說這一條紅色的線，
沒有辦法完全正確的評定，
所有的寶可夢的進化後的CP值。
如果你想要知道說他做的有多不好的話，
或者是多好的話，
你可以看一下，
你可以計算一下你的error。
你的error就是，
你計算一下每一個藍色的點跟這個紅色的點之間的距離，
第一個藍色的點跟這個紅色的線的距離，
是e1
第二個藍色的點跟紅色的線的距離是e2
以此類推，
所以有e1到e10。
那平均的training data的error，
就是summation e1到e10。
這邊算出來是31.9
但是這個並不是我們真正關心的，
因為你真正關心的是，
generalization的case。
也就是說，
假設你今天抓到一隻新的寶可夢以後，
如果使用你現在的model去預測的話，
那做出來你估測的誤差到底有多少。
所以真正關心的是，那些你沒有看過的新的data，
這邊我們叫做testing data，
它的誤差是多少。
所以這邊又抓了另外10隻寶可夢，
當作testing data。
這10隻寶可夢跟之前拿來做訓練的10隻，
不是同樣的10隻。
其實這新抓的10隻跟剛才看到的10隻的分布，
其實是還滿像的
它們就是這個圖上的10個點。
那你會發現說，
我們剛才在訓練資料上找出來這條紅色的線，
其實也可以大致上預測，
在我們沒有看過的寶可夢上，
它的進化後的CP值。
如果你想要量化它的錯誤的話，
那就計算一下它的錯誤。
它錯誤算出來是35.0。
這個值是比我們剛才在training data 上看到的error還要稍微大一點
因為可以想想看我們最好的function是在training data上找到的
所以在training data上面算出來的error，
本來就應該比testing data上面算出來的error還要稍微大一點
有沒有辦法做得更好呢?
如果你想要做得更好的話，
接下來你要做的事情就是，
重新去設計你的model。
如果你觀察一下data你會發現說，
在原進化前的CP值特別大的地方，
還有進化前的CP值特別小的地方，
預測是比較不準的。
在這個地方和這個地方，預測是比較不準的。
那你可以想想看說
任天堂在做這個遊戲的時候，
它背後一定是有某一支程式，
去根據某一些hidden 的factor。
比如說，去根據原來的CP值和其他的一些數值，
generate 進化以後的數值。
所以到底它的function長甚麼樣子?
從這個結果看來，
那個function可能不是這樣子一條直線，
它可能是稍微更複雜一點。
所以我們需要有一個更複雜的model。
舉例來說，
我們這邊可能需要引入二次式。
我們今天，
可能需要引入(Xcp)²這一項
我們重新設計了一個model，
這個model它寫成y=b+w1×Xcp+w2×(Xcp)²
我們加了後面這一項
如果我們有了這個新的function，
你可以用我們剛才講得一模一樣的方式，
去define一個function 的好壞，
然後用gradient descent，
找出一個，
在你的function set裡面最好的function。
根據training data找出來的最好的function是b=−10.3, w1=1.0, w2=2.7×10^-3
如果我們把這個最好的function畫在圖上的話，
它長的是這個樣子。
你就會發現說，
現在我們有了這條新的曲線，
我們有了這個新的model，
它的預測在training data上面看起來是更準一點。
在training data上面你得到的average error現在是15.4。
但我們真正關心的，
是testing data
那我們就把同樣的model
再apply到testing data上。
我們在testing data上apply同樣這條紅色的線，
然後去計算它的average error。
那我們現在得到的是18.4
在剛才如果我們沒有考慮(Xcp)²的時候
算出來的average error是30左右
現在有考慮平方項得到的是18.4
那有沒有可能做得更好呢?
比如說我們可以考慮一個更複雜的model。
我們引入不只是(Xcp)²，
我們引入(Xcp)³。
所以我們現在的model長的是這個樣子。
你就用一模一樣的方法，
你就可以根據你的training data，
找到在這一個 function set裡面，
在這個model 裡面最好的一個function。
那找出來是這樣 :
b=6.4，w1=0.66,
w2=4.3×10^-3 ，w3=-1.8×10^-6
所以你發現w3其實是它的值比較小
它可能是沒有太大的影響
作出來的線其實跟剛才看到的二次的線是沒有太大的差別的
那做出來看起來像是這個樣子。
那這個時候average error算出來是15.3
如果你看testing data的話，
testing data算出來的average error是18.1。
跟剛剛二次的，
有考慮(Xcp)²的結果比起來是稍微好一點點。
剛才前一頁是18.3，有考慮三次項後是18.1
是稍微好一點點。
那有沒有可能是更複雜的model呢?
或許在寶可夢的那個程式背後，
它產生進化後的CP值用的是一個更複雜的一個function
或許它不只考慮了三次，
或者它不只考慮了(Xcp)³
或許它考慮的是四次方也說不定
那你就用同樣的方法，
再把這些參數 :b、w1、w2、w3和w4都找出來，
那你得到的function長這個樣子。
你發現它在training data上它顯然可以做得更好。
在input的CP值比較小的這些寶可夢，
這些顯然是一些綠毛蟲之類的東西，
它在這邊是predict更準的。
所以現在的average error是14.9，
剛才三次的是15.3
剛才三次的是在training data上是15.3
現在四次的時候在training data上是14.9
但是我們真正關心的是testing
我們真正關心的是如果沒有看過的寶可夢，
我們能夠多精確的預測它進化後的CP值。
所以，
我們發現說，
如果我們看沒有看過的寶可夢的話，
我們得到的average error是多少呢?
我們得到的average error其實是28.8
前一頁做出來已經是18.3了
就我們用三次的時候，
在testing data上面做出來已經是18.3了
但是我們換了一個更複雜的model以後，
做出來是28.8
結果竟然變得更糟了!
我們換了一個更複雜的model，
在training data上給我們比較好的結果
但在testing data上，
看起來結果是更糟的。
那如果換再更複雜的model會怎樣呢?
有沒有可能是五次式，
有沒有可能它背後的程式是如此的複雜，
原來的CP值的一次、兩次、三次、四次到五次
那這個時候，
我們把最好的function找出來，
你會發現它最好的function在training data上長得像是這樣子。
這個是一個合理的結果嗎?
你會發現說，
在原來的CP值是500左右，
500左右可能就是伊布之類的東西。
在原來的CP值是500左右的寶可夢，
根據你現在的model預測出來，
它的CP值竟然是負的。
但是在training data上面，
我們可以算出來的error是12.8，
比我們剛才用四次式，
得到的結果又再更好一些。
那在testing的結果上是怎樣呢
如果我們把這個我們找出來的function，
apply到新的寶可夢上面，
你會發現結果怎麼爛掉了啊
至少這一隻大概是伊布吧
這隻伊布，
它預測出來進化後的CP值，
是非常的不准。
照理說有1000多，
但是你的model卻給它一個負的預測值。
所以算出來的average error非常大，
有200多。
所以當我們換了一個更複雜的model，
考慮到五次的時候，
結果又更加糟糕了。
所以到目前為止，我們試了五個不同的model。
那這五個model，
如果你把他們分別的在training data上面的average error都畫出來的話，
你會得到這樣子的一張圖。
從高到低
也就是說，如果你考慮一個最簡單的model，
這個時候error是比較高的；
model稍微複雜一點，
error稍微下降；
然後model越複雜，
在這個training data上的error就會越來越小。
那為甚麼會這樣呢?
這件事情倒是非常的直覺，
非常容易解釋。
假設黃色的這個圈圈，
我們故意用一樣的顏色
黃色這個圈圈代表這一個式子，
有考慮三次的式子，
所形成的function space。
那四次的式子所形成的function space，
就是這個綠色的圈圈。
它是包含黃色的圈圈的，
這個事情很合理，
因為你只要把w4設為0，
是四次的這個式子就可以變成三次的式子。
所以三次的式子都包含在這個四次的式子裡面，
黃色的圈圈都包含在綠色的圈圈裏面。
那如果我們今天考慮更複雜的五次的式子的話，
它又可以包含所有四次的式子。
所以今天如果你有一個越複雜的model，
它包含了越多的function的話，
那理論上你就可以找出一個function，
它可以讓你的error rate越來越低。
你的function如果越複雜，你的candidate如果越多，
你當然可以找到一個function，
讓你的error rate越來越低。
當然這邊的前提就是，
你的gradient descent要能夠真正幫你找出best function的前提下，
你的function越複雜，
可以讓你的error rate在training function上越低。
但是在testing data上面，
看起來的結果是不一樣的。
在testing data上面看起來的結果是不一樣的。
在training data上，
你會發現說
model越來越複雜你的error越來越低；
但是在testing data上，
在到第三個式子為止，
你的error是有下降的。
但是到第四個和第五個的function的時候，
error就暴增。
然後把它的圖試著畫在左邊這邊。
藍色的是training data上對不同function的error，
橙色的是testing data上對不同function的error。
你會發現說，
今天在五次的時候，
在testing上是爆炸的，
它就突破天際沒辦法畫在這張圖上。
那所以我們今天，
得到一個觀察，
雖然說越複雜的model可以在training data上面給我們越好的結果，
但這件事情也沒有甚麼，
因為越複雜的model並不一定能夠在testing data上給我們越好的結果。
這件事情就叫做overfitting。
就複雜的model在training data上有好的結果，
但在testing data上不一定有好的結果。
這件事情就叫做overfitting。
比如當我們用第四個和第五個式子的時候，
我們就發生overfitting的情形。
那為甚麼會有overfitting這個情形呢?
為甚麼更複雜的model它在training上面得到比較好的結果，
在testing上面不一定得到比較好的結果呢?
這個我們日後再解釋。
但是你其實是可以想到很多很直觀的，
在training data上面得到比較好的結果，
在訓練的時候得到比較好的結果
但在測試的時候不一定會得到比較好的結果。
比如說，
你有沒有考過駕照?
考駕照不是都要去那個駕訓班嗎?
駕訓班不是都在那個場內練習嗎
你在場內練習不是都很順?
練習非常非常多次以後，
你就會得到很奇怪的技能。
你就學到說，
比如說，
當我後照鏡裡面看到路邊小丸子的貼紙對到正中間的時候，
就把方向盤左轉半圈這樣子。
你就學到這種技能，
所以你在測試訓練的時候，
在駕訓班的時候你可以做得很好。
但在路上的時候你就做不好。
像我就不太會開車，
雖然我有駕照。
所以我都在等無人駕駛車出來。
所以overfitting是很有可能會發生的。
所以model不是越複雜越好，
我們必須選一個剛剛好，
沒有非常複雜也沒有很複雜的model，
你要選一個最適合的model。
比如說在這個case裡面，
當我們選一個三次式的時候，
在這個case裡面當我們選一個三次式的時候，
可以給我們最低的error。
所以如果今天可以選的話，
我們就應該選擇三次的式子來作為我們的model，
來作為我們的function set。
你以為這樣就結束了嗎?
其實還沒有。
剛才只收集了10隻寶可夢，其實太少了
當我們收集到60隻寶可夢的時候，
你會發現說剛才都是白忙一場。
你仔細想 : 當我們收集60隻寶可夢，
你把它的原來的CP值和進化後的CP值，
畫在這個圖上，
你會發現說他們中間有一個非常奇妙的關係。
它顯然不是甚麼一次二次三次一百次式，
顯然都不是，
中間有另外一個力量，
這個力量不是CP值它在影響著進化後的數值，
到底是甚麼呢?
其實非常的直覺，
就是寶可夢的物種。
這邊我們把不同的物種用不同的顏色來表示，
藍色是波波，
波波進化後是比比鳥，
比比鳥進化是大比鳥。
這個黃色的點是獨角蟲，
獨角蟲進化後是鐵殼蛹，
鐵殼蛹進化後是大針蜂。
然後綠色的是綠毛蟲，
綠毛蟲進化是鐵甲蛹，
鐵甲蛹進化是巴大蝴。
紅色的是伊布，
伊布可以進化成雷精靈、火精靈或水精靈等等
你可能說怎麼都只有這些路邊就可以見到的，
因為抓乘龍快龍是很麻煩的，
所以就只有這些而已。
所以剛才只考慮CP值這件事，
只考慮進化前的CP值顯然是不對的。
因為這個進化後的CP值受到物種的影響其實是很大的。
或者是比原來的CP值
產生非常關鍵性的影響。
所以我們在設計model的時候，
剛才那個model設計的是不好的。
剛才那個model就好像是，
你想要海底撈針，
從function set裡面撈出一個最好的model
那其實裡面model通通都不好，
所以針根本就不在海裡，
所以你要重新設計一下你的function set。
所以這邊就重新設計一下function set，
我們的function set， input x跟output y，
這個input寶可夢和output進化後的CP值有甚麼關係呢?
它的關係是這樣 :
如果今天輸入的寶可夢x，
它的物種是屬於波波的話，
這個Xs代表說這個input x 的物種，
那他的輸出y=b1+w1×Xcp。
那如果它是獨角蟲的話，
y=b2+w2×Xcp。
如果它是綠毛蟲的話，
就是b3+w3×Xcp。
如果它是伊布的話，
就用另外一個式子。
也就是不同的物種，我們就看它是哪一個物種，
我們就代不同的linear function，
然後得到不同的y作為最終的輸出。
你可能會問一個問題說，
你把if 放到整個function裡面，
這樣你不就不是一個linear model了嗎?
function裡面有if 你搞得定嗎?
你可以用微分來做嗎?
你可以用剛才的gradient descent來算參數對loss function微分嗎?
其實是可以的。
這個式子你可以把它改寫成一個linear function。
寫起來就是這樣 :
這個有一點複雜但沒有關係。
我們先來觀察一下δ這個function。
如果你有修過信號的處理，我想應該知道δ這個function是指甚麼。
今天這個δ這個function的意思是說，
δ of Xs等於比比鳥的意思就是說，
假如我們今天輸入的這隻寶可夢是比比鳥的話，
這個δ function它的output就是1。
反之如果是其他種類的寶可夢的話，
它δ function的output就是0。
所以我們可以把剛才那個有 if的式子，
寫成像這邊這個樣子。
你的寶可夢進化後的CP值，
等於b1×δ(比比鳥)這樣子，
然後加上w1×δ(比比鳥)×這隻寶可夢的CP值，
加上b2×δ(獨角蟲)，
加上w2×δ(獨角蟲)，
再乘上它的CP值，
然後接下來考慮綠毛蟲，
然後接下來考慮伊布。
你可能會想說這個跟剛剛那個式子哪裡一樣了呢?
你想想看，假如我們今天輸入的那一隻神奇寶貝，
假如我們今天輸入的那一隻寶可夢，
是比比鳥的話，
假如Xs等於比比鳥的話，
意味著這兩個function會是1，
這兩個δ function如果input是比比鳥的話就是1，
其他δ function就是0。
那乘上0的項，
乘上0的項就當作沒看到，
其實就變成y=b1+w1×Xcp
所以對其他種類的寶可夢來說也是一樣。
所以當我們設計這個function的時候，
我們就可以做到我們剛才在前一頁design的那一個有if的function。
那事實上這一個function，
它就是一個linear function。
這個function就是一個linear function。
怎麼說呢?
前面這個b1 w1到b4 w4就是我們的參數，
而後面這一項δ或者是δ乘以Xcp
不同的δ，
跟不同的δ乘以Xcp，
就是後面這個Xi這一項feature。
這個藍色框框裡面的這些，
其實就是feature。
所以這個東西它也是linear model。
那有了這些以後，
我們做出來的結果怎麼樣呢?
這個是在training data 上的結果，
在training data 上面，
我們知道不同種類的寶可夢，
它用的參數就不一樣。
所以不同種類的寶可夢，
它的線是不一樣的，
它的model的那條line是不一樣的。
藍色這條線是比比鳥的線，
綠色這條線是綠毛蟲的線，
黃色獨角蟲的線跟綠毛蟲的線其實是重疊的，
紅色這條線是伊布的線。
所以就發現說，
當我們分不同種類的寶可夢來考慮的時候，
我們的model在training data上面可以得到更低的error。
你發現說現在這幾條線，
是把training data fit得更好，
是把training data 解釋得更好，
如果說我們這麼做有考慮到寶可夢的種類的時候，
我們得到的average error是3.8，在training data上。
但我們真正在意的是，
它能不能夠預測新看到的寶可夢，
也就是testing data上面的結果。
那在testing data上面，
它的結果是這個樣子：
一樣是這三條線，
發現說它也把在testing data上面的那些寶可夢fit得很好。
然後它的average error是14.3
這比我們剛才可以做好的18點多還要更好。
但是如果你再觀察這個圖的話，
感覺應該是還有一些東西是沒有做好的。
我仔細想想看，我覺得伊布這邊應該就沒救了。
因為我認為伊布會有很不一樣的CP值是因為進化成不同種類的精靈。
所以如果你沒有考慮這個factor的話，應該就沒救了。
但是我覺得這邊有一些還沒有fit很好的地方，
有一些值還是略高或略低於這條直線。
所以這個地方搞不好還是有辦法解釋的。
當然有一個可能是，
這些略高略低於，我們現在找出來這個藍色綠色線的這個model的變化
這個difference其實來自於random的數值，
就是每次那個寶可夢的程式產生進化後的CP值的時候，
它其實有加一個random的參數。
但也有可能是其實不是random的參數，
它還有其他的東西在影響著寶可夢進化後的CP值。
有什麼其他可能的參數呢?
比如說，
會不會進化後的CP值是跟weight有關係的?
會不會進化後的CP值是跟它的高度有關係的?
會不會進化後的CP值是跟它的HP有關係的?
其實我們不知道，
我又不是大木博士我怎麼會知道這些事情，
所以如果你有domain knowledge的話，
你就可能可以知道說
你應該把甚麼樣的東西
加到你的model裡面去。
但是我又沒有domain knowledge，
那怎麼辦呢?
沒關係，有一招就是把你所有想到的東西，
通通塞進去，
我們來弄一個最複雜的function，然後看看會怎樣?
這個function我寫成這樣 :
如果它是比比鳥的話，
它的CP值我們就先計算一個y'，
這個y'不是最後這個y，
這個y'還要做別的處理才能夠變成y。
我們就說，如果這個是比比鳥的話，
這其實不是比比鳥，這應該是波波，
因為比比鳥是進化後的。
這隻應該是波波。
那y'=b1+w1×Xcp+W5×(Xcp)²
我們就是不只要考慮CP值，
也要考慮CP值的平方。
如果是綠毛蟲，用另外一個式子。
如果是獨角蟲，用另外一個式子。
如果是伊布，用另外一個式子。
最好我們再把y'做其他的處理，
我們把y'，再加上HP值，它的生命值乘上w9，再加上生命值的平方乘上w10
再加上高度乘上w11，
再加上高度的平方乘上w12，
再加上它的weight乘上w13，
再加上weight平方乘上w14，
這些東西合起來，
才是最後output的y。
所以這整個式子裡面，
其實也沒有很多個參數，
就是14+4=18
跟你們作業比起來，幾百個參數比起來，
其實也不是一個太複雜的model。
那我們現在有個這麼複雜的function，
在training data上我們得到的error，
期望應該就是非常的低。
我們果然得到一個非常低的error，
這個function你可以把它寫成線性的式子，
就跟剛才一樣，
這邊我就不解釋了。
那這麼一個複雜的function，
理論上我們可以得到非常低的training error。
training error算出來是1.9，
那你可以期待你在testing set上，
也算出很低的training error嗎?
倒是不見得。這麼複雜的model，
很以可能會overfitting。
你很有可能會得到，
在testing data上得到很糟的數字。
我們今天得到的數值很糟是102.3這樣子，
結果壞掉了
怎麼辦呢?
如果你是大木博士的話，
你就可以刪掉一些你覺得沒有用的input，
然後就得到一個簡單的model，
避免overfitting的情形。
但是我不是大木博士，
所以我有用別的方法來處理這個問題。
這招叫做regularization。
regularization要做的事情是，
我們重新定義了step 2的時候，
我們對一個function是好還是壞的定義。
我們重新redefine我們的loss function。
然後，我們重新redefine我們的loss function，
把一些knowledge放進去，
讓我們可以找到比較好的function。
什麼意思呢?
假設我們的model in general寫成這樣 :
y=b+∑WiXi
我們原來的loss function，
它只考慮了error這件事。
原來的loss function只考慮了prediction的結果減掉正確答案的平方，
只考慮了prediction的error。
那regularization它就是加上一項額外的term，
這一項額外的term是λ∑(Wi)²，
λ是一個常數，
這個是等一下我們要手調一下看要設多少。
那∑(Wi)²就是把這個model裡面所有的Wi，
都算一下平方以後加起來。
那這個合起來才是我們的loss function。
前面這一項我們剛才解釋過，
所以我相信你是可以理解的。
error越小就代表當然是越好的function，
但是，
為甚麼我們期待一個參數的值越小，
參數的值越接近0的function呢?
這件事情你就比較難想像。
為甚麼我們期待一個參數值接近0的function呢?
當我們加上這一項的時候，
我們就是預期說我們要找到的那個function，
它的那個參數越小越好。
當我們加上這一項的時候，
你知道參數值比較接近0的function，
它是比較平滑的。
所謂的比較平滑的意思是，
當今天的輸入有變化的時候，
output對輸入的變化是比較不敏感的。
為甚麼參數小就可以達到這個效果呢?
你可以想想看，
假設這個是我們的model，
現在input有一個變化，
比如說我們對某一個Xi加上ΔXi
這時候對輸出會有什麼變化呢?
這時候輸出的變化，
就是ΔXi乘上Wi
你的輸入變化ΔXi
輸出就是Wi乘上ΔXi
你會發現說如果今天你的Wi越小越接近0的話，
如果你的Wi越接近0的話，
它的變化就越小。
如果Wi越接近0的話，
輸出對輸入就越不sensitive。
所以今天Wi越接近0，
我們的function就是一個越平滑的function。
現在的問題就是，
為甚麼我們喜歡比較平滑的function?
這可以有不同的解釋，你可以這樣想，
如果我們今天有一個比較平滑的function的話，
那平滑的function對輸入是比較不敏感的。
所以今天如果我們的輸入，
被一些雜訊所干擾的話，
如果今天雜訊干擾的我們的輸入，
在我們測試的時候，
那一個比較平滑的function，
它會受到比較少的影響，
而給我們一個比較好的結果。
接下來我們就要來看看說，
如果我們加入了regularization的項，
對我們最終的結果會有甚麼樣的影響?
這個是實驗的結果。
我們就把λ從0、1、10一直調到100000
所以λ值越大，
代表說今天我們的
我們現在loss有兩項，
一項是考慮error，一項是考慮多smooth
λ值越大代表考慮smooth的那個regularization那一項它的影響力越大
所以當λ值越大的時候，
我們找到的function就越平滑。
如果我們看看在training data上的error的話，
我們看看在training data上的error的話，
我們會發現說，
如果function越平滑，
我們在training data上得到的error其實是越大的。
但是這件事情是非常合理的，
因為當λ越大的時候，
我們就越傾向於考慮W本來的值，
我們就傾向考慮W的值而減少考慮我們的error。
所以今天如果λ越大的時候，
我們考慮error就愈少，
所以我們本來在training data上得到的error就越大。
但是有趣的是，
雖然在training data上得到的error就越大，
但是在testing data上面得到的error可能是會比較小。
比如說我們看這邊的例子，
原來λ=0，
就是沒有regularization的時候error是102
λ=1就變成68，
到10就變成25
到100就變成11.1
但是λ太大的時候，
到1000的時候，
error又變大變成12.8一直到26.8。
那這個結果是合理，
我們比較喜歡比較平滑的function，
比較平滑的function它對noise比較不sensitive，
所以當我們增加λ的時候，
你的performance是越來越好，
但是我們又不喜歡太平滑的function，
因為最平滑的function是甚麼?
最平滑的function就是一條水平線啊，
一條水平線是最平滑的function。
如果你的function是一條水平線的話，
那它啥事都幹不成，
所以如果今天function太平滑的話，
你反而會在testing set上又得到糟糕的結果。
所以現在的問題就是，
我們希望我們的model多smooth呢?
我們希望我們今天找到的function有多平滑呢?
這件事情就變成是你們要調λ來解決這件事情，
你必須要調整λ來決定你的function的平滑程度。
比如說你可能調整一下參數以後發現說，
今天training都隨著λ增加而增加，
testing隨著λ先減少後增加。
在這個地方有一個轉折點，
是可以讓我們的testing error最小，
你就選λ=100來得到你的model。
這邊還有一個有趣的事實，
很多同學其實都知道regularization，
你有沒有發現，
這邊我沒有把b加進去，
我剛剛突然想到一件事情，
我其實在前面那個gradient descent的投影片裡面，
有一個地方寫錯了，
然後有同學提醒我，
以後你如果有發現我投影片有寫錯的話，
以後告訴我就把你的投影片寫在投影片這樣。
這邊你發現我沒有加上b，
為甚麼呢?
你覺得是我寫錯了的同學，
你覺得是我忘了加上去的同學舉手一下，
你覺得本來就不需要加上b的同學舉手一下
這邊我覺得我沒有寫錯。
事實上很多人可能不知道這件事，
在做regularization的時候，
其實是不需要考慮bias這一項的。
首先，如果你自己做實驗的話你會發現，
不考慮bias， performance會比較好。
再來為甚麼不考慮bias呢?
因為我們今天預期的是，
我們要找一個比較平滑的function。
你調整bias的這個b的大小，
跟一個function的平滑的程度是沒有關係的。
調整bias值的大小時你只是把function上下移動而已，
對function的平滑程度是沒有關係的。
所以有趣的是，這很多人都不知道，
在做regularization的時候，
你是不用考慮bias的。
總之，
搞了半天以後，
我最後可以做到，
我們的testing error是11.1。
那在我們請助教公告作業之前，
我們就說一下今天的conclusion :
首先感謝大家來參加我對寶可夢研究的發表會，
那我今天得到的結論就是，
寶可夢進化後的CP值，
跟他進化前的CP值，
還有它是哪個物種，是非常有關係的。
知道這兩件事情幾乎可以決定進化後的CP值。
但是我認為，
可能應該還有其他的factors。
我們剛剛看到說我們加上其他甚麼高度啊體重啊HP以後，
是有比較好的，如果我們加入regularization的話。
不過我data有點少，
所以我沒有那麼confident就是了。
然後再來呢就是，
我們今天講了gradient descent的作法，
就是告訴大家怎麼做
那我們以後會講它的原理還有技巧。
我們今天講了overfitting和regularization，
介紹一下表象上的現象，
未來會講更多它背後的理論。
再來最後我們有一個很重要的問題，
首先我覺得我這個結果應該還滿正確的，
因為你知道網路上有很多的CP的預測器，
那些CP的預測器你在輸入的時候，
你只要輸入你的寶可夢的物種和它現在的CP值，
它就可以告訴你進化以後的CP值。
所以我認為你要預測進化以後的CP值，
應該是要知道原來的CP值和它的物種，
就可以知道大部分。
不過我看那些預測器預測出來的誤差，
都是給你一個range，
它都沒有辦法給你一個更準確的預測。
如果考慮更多的factor更多的input，
比如說HP甚麼啊，
或許可以預測的更準就是了。
但最後的問題就是，
我們在testing data上面，
在我們testing的10隻寶可夢上，
我們得到的average error最後是11.1。
如果我把它做成一個系統，
放到網路上給大家使用的話，
你覺得如果我們看過沒有看到的data，
那我們得到的error會預期高過11.1還是低於11.1
還是理論上期望值應該是一樣的。
你知道我的training data是裡面只有四種，裡面都沒有甚麼乘龍卡比之類的，
我們就假設使用者只能夠輸入那四種，
它不會輸入乘龍卡比這樣。
在這個情況下，
你覺得如果我們今天把這個系統放到線上，
給大家使用的話，
我們今天得到的CP值，
會比我今天在testing set上看到的高還是低還是一樣?
你覺得一樣的同學舉手一下
你覺得會比現在看到的低，舉手一下
你覺得會比我們今天看到的11.1還要高的舉手一下
我們之後會解釋，
我們今天其實用了testing set來選model
就我們今天得到的結果其實是
如果我們真的把系統放在線上的話
預期應該會得到比我們今天看到的11.1還要更高的error rate
這個時候我們需要validation觀念來解決這個問題
這個我們就下一堂課再講。
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://ai.ntu.edu.tw
