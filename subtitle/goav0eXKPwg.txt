hi my name is J I'm from tower niversity
I'm going to present our paper mail
learning for end-to-end low resource
based reflection I'll start with
introduction and motivation of mail
learning then talk about how we apply my
learning in speech recognition and
finally demonstrates an initial
experimental results so let's start mail
learning or learning to learn is a
general learning ability to make the
model can learn fast and well with such
ability the model can use less data but
get a better results and here is a
comparison with my learning and
supervised learning in supervised
learning we have added a CD contains a
bunch of pairs of x and y then we turn a
model and parameters by theta that can
receive X as input and output the
prediction of Y in contrast in mayhaw
learning we have a data set of data sets
now we have D 1 to D K HDI means one
data sets then we can chain a mega model
Capital m that can receive data T as
input then output the needed parameters
in general HT is not so large it will be
in fuchsia or low resource case let's go
back to the gold mail learning we want
to utilize set of tasks do you want to
decay to achieve fast adaptation among
syntactic DT which we are interested in
and the assumption is that we assume
that tasks are inherently related so it
will be beneficial if we can transfer
some knowledge between tasks and just
like surface learning have two stages
which is trend and test may not only
also have two stages and I call it as
math
Jen and minitest let's look at Matt
trend first in matron we want to use
that I said d12 DK together Mohammed or
capital F and inside the match ad for
each data set DK we still have two
stages which is trend and test and
called the trend stage in matron as you
look learn and the test stage imagine as
inner loop test and when it comes to my
test is corresponding to a process of
inputs the data DT that I'm single
assets to get the parameters theta and
actually it's just like the supervised
learning we knew before but the
difference is that during the trend
stage in math test we will use some
knowledge from
metamodel to learn the data and call
this process as adaptation then after
detention we can use the adapted we can
use the adapted parameters theta to
evaluate the final performance now you
might have some questions so what we may
have learn for we can formalize the
application of my own research as may
learn acts to improve learn why and X is
knowledge which is beneficial for
adaptation during a test or more
intuitively is something people need to
decide the supervised learning algorithm
but now we use male learning methods to
automatically to decide that and here I
just list some possible candidates a
wise application for example completion
and reinforcement learning and in recent
years since 2000 18 people started to
apply male learning in speech and
language processing for example machine
translation dialect generation and even
speaker attended training
so the next question is helping us with
the original data sets in two different
sub data sets or say different tasks and
it's depends on your application for
example in speaker desert training we
can view different speakers copra as
different data sets and the most simple
machine translation we can view
different language parallel data as
different tasks so I mean so forth and
in this word we may have learn initial
parameters to improve learn and to learn
speech recognition and we view different
languages as different tasks so now we
have two questions first held similar
initial parameters we adopt the
gradient-based mail and algorithm called
model agnostic Mahalo Mahalo early also
know as Mamo
to address this issue second why we
choose end-to-end speech recognition as
application and the answer is of the
entry model is easier for deployments
it's for ratios for training data and
for most languages in the world
is costly to build large enough corpus
for each state for for each of them
Venice
we only have low resource version so
it's aligned with the with the Gulf
Mallard fast adaptation on unseen tasks
and in this case is unseen language the
next few slides I'll briefly explain
honest Mamo
and some tuition behind us then
demonstrate how to apply memo with
speech recognition the Gulf memo is
almost the same as previously mentioned
Mahalo
but more specifically with limiting
adaptation process as stochastic
gradient descent so in brief we want to
learn a good initial parameter theta
star such that performing few gradient
step strategist are 10 sheep lost
minimum during MassHealth and here's how
inclined memos idea into speech
recognition let's look at the objective
first we want to find this theta that is
good for in visual language
after a yellow blur saw used in a crime
here and for simplicity I use one
gradient step as in yellow blur so theta
prime can be obtained through this
equation and LT is a loss calculation of
D and it will be used in inner loop test
so let's go back to see the objective
again that means we want to find the
parameters that is good after interval
third in the loop test then after the
whole management process we then use the
theta star to a depth of DT you might
wonder hey doesn't sell like most of
importance from earning rights in most
importance for learning we also have two
stages the first stage is be training it
will use most lingual corpora to find
good in translation for adaptation and
the second stage is set attention will
use the obtained in translation to
function on target language and yes
actually we can view the pre-training
stage as measured in Nano and finally
stage as male test but there are still a
little difference let's look at the
objective in multi text training first
of coitus multi Arizona and this
objective is a summation of the losses
of individual languages and unlike many
tires are here we just directly evaluate
the loss of theta rather than to the
prime so it doesn't consider the
interval learned process and after the
whole process after the whole project
process we will use the theta star to
adapt delta T and in X T in next two
slides I'll show the difference between
these two objectives let's look at meta
s at first again Omega SR we don't
directly evaluate people's performance
for each language instead we look at
this but
therefore we allow it to perform in
Europe learn for each language then use
the corresponding theta prime to decide
this performance so in this example
maybe the loss of theta here is not good
for t1 and t2 but synthesis can achieve
to the valley of each loss curves we
will view this as good deal in contrast
in multi ASR which will just evaluate
the performance of theta are all loss
curves and is equivalent to find the
minimum is equivalent to find the
minimum of the superposition of the Lost
curves without considering is further
potential therefore based on the
illustration would think that since
mahalia start consider adaptation
process in this objective and our final
goal is going to adapt on the party
language so meta s are somehow make the
training and testing scenario more alive
then might get better result than
previous multicast training methods and
we use the following two matrixes to
evaluate its benefit the first is
overall performance improvements may be
lower error rates in the second is less
overfitting on source damages therefore
we conduct the following experiments we
use our Papago a mostly more
conversational telethon speech corpus in
the experiments for each language there
are two sets of data one is FLP full
language pack contains about 40 to 80
hours data per language and the other is
ll t limited language pack contains only
10 hours data and it's also the subset
of FLT now we use the source and target
languages as follows we use sort we use
Bengali tagalog zulu turkish telugu
lavanya
as source damages used in miniature and
we use fairness Swahili Tommy oh c'mon G
as target languages evaluated during
manifesto
when it comes to validation to decide
which portion in steps of effects we use
cross-validation for example if we want
to adapt unfairness we will use Swahili
tambien Comanche as tradition says so on
and so forth ok so here comes the
results to answer the first question
here is the table of character arrays of
FLP for each target language the lower
the value the better the performance and
this row represents different to channel
7 for example know for trend means
random initialization and this role
means we use Bengali Tagalog Zulu as
foreign languages and for each target
language we report the multi a socket
wrench and maintenance approach and
translation in different 2 colors and we
have the following observations first
application from mentally saw before
it's better than rent initialization you
can see that the values inside the
orange square is always smaller the
values inside green square which means
render in translation Thanks the second
is the expression languages and target
language pairs mate is our is always
better than multivariate so you can see
that the values inside our square is
also smaller than the values inside
Green Square where the Green Square is
the chat areas of multi areas of return
model right
to answer the second question we need to
look at the learning curve here I will
explain what is the meaning of one
points on the learning curve take this
point for example this point means I per
trends twenty thousand returning steps
of pretend languages then use the
obtained initial parameters to adapt our
target language and that's why there is
56 percent correct errors is development
sense here is the source languages and
toponyms pair and is corresponding
learning curve so as you can see in this
figure that's a free training growth
learning curve of mega innocence and
maintenance of the channelization before
it's better and the trend is goes down
the error in trainers goes down that
means the meta is a fraternity
translation is less over fitted on the
source damages and we observe the
similar trends of different source
languages and target language pair and
actually we observed the similar trends
of all source damages and turbulence
pair we conducted in the experiments but
I just lists but I just listed two of
them so in conclusion from the two
metrics mentionable
we can see that the adaptation using
modern parameters is beneficial and such
technique can be applied to different
applications beyond speech recognition
for example
text-to-speech or first conversion etc
and by the way we still need to extend
our more appreciative languages and
target language pairs to improve its
robustness here is today's presentation
thank you for your listening and the
following is my contact information you
can stand the QR code to contact me
[Music]
