剛才就是用了一堆比喻
然後告訴你 GAN 是怎麼運作的
然後也實際上告訴你
GAN 的操作是怎麼操作的
那接下來呢
我們要講一點理論的部分
講一點農場文不會講到的部分
告訴你說實際上
為什麼 GAN 的這一番操作
為什麼這個 Generator 跟 Discriminator 的互動
可以讓我們的 Generator
產生像是真正的人臉的圖片
那這背後的互動在做的
到底是什麼樣的事情
那我們先來弄清楚
我們今天的訓練的目標到底是什麼
你知道我們在訓練 Network 的時候
你就是要定一個 Loss Function
定完以後用 Gradient Descent 去調你的參數
去 Minimize 那個 Loss Function 就結束了
那在這個 Generation 的問題裡面
到底我們要 Minimize 的
或者是我們要 Maximize 的
到底是什麼樣的東西呢
我們要把這些事弄清楚
才能夠做接下來的事情
好 那在 Generator 裡面
我們到底想要 Minimize
或者是 Maximize 什麼樣的東西呢
我們想要 Minimize 的東西是這個樣子的
我們有一個 Generator
給它一大堆的 Vector
給它從 Normal Distribution Sample 出來的東西
丟進這個 Generator 以後
會產生一個比較複雜的 Distribution
這個複雜 Distribution
我們叫它 PG
然後呢 我們有一堆的 Data
這個是真正的 Data
真正的 Data 也形成了另外一個 Distribution
叫做 Pdata
我們期待 PG 跟 Pdata 越接近越好
好 那如果你一下子沒有辦法想像
這個 PG Pdata 是怎麼一回事的話
那我們用一維的狀況來跟大家說明
我們假設 Generator 的 Input 是一個一維的向量
Generator 的 Output 也是一維的向量
我們真正的 Data 也是一維的向量
那我們的 Normal Distribution 就長這個樣子
沒有問題
那丟到 Generator 以後
這邊這每 1 個點
假設你輸入 5 個點
那邊這每一個點
它的位置會改變
那你就產生一個新的 Distribution
那可能本來大家都集中在中間
通過這個 Generator
通過一個 Network 裡面很複雜
不知道做了什麼事情以後
這些點就分成兩邊
所以你的 Distribution 就變成這個樣子
而 Pdata 是指真正的資料的分布
真正資料分布可能長這個樣子
它分兩面的狀況是更極端的
左邊的東西比較多
右邊的東西比較少
那你期待左邊這個分布跟右邊這個分布
越接近越好
如果寫成式子的話
你可以寫成這個樣子
你這邊這個 Div Of PG 跟 Pdata
它指的意思就是 PG 跟 Pdata
這兩個 Distribution 之間的 Divergence
那 Divergence 這邊指的是什麼意思呢
Divergence 這邊指的意思就是
這兩個你可以想成是
這兩個 Distribution 之間的某種距離
如果這個 Divergence 越大
就代表這兩個 Distribution 越不像
Divergence 越小
就代表這兩個 Distribution 越相近
Divergence 這就是衡量
兩個的 Distribution 相似度的一個 Major
然後呢 我們現在的目標
是要去找一個 Generator
那所謂的找一個 Generator
實際上骨子裡做的事情是
找一個 Generator 裡面的參數
找一組 Generator 裡面的參數
就 Generator 也是一個 Network
裡面有一大堆的 Weight 跟 Bias
找一組 Generator 的參數
它可以讓我們產生出來的 PG 跟 Pdata
之間的 Divergence 越小越好
我要找的就是這樣子的 Generator
這邊把它寫作 G*
所以我們這邊要做的事情
跟一般 Train Network 其實非常地像
我們第一堂課就告訴你說
我們定義了 Loss Function
找一組參數 Minimize Loss Function
我們現在其實也定義了我們的 Loss Function
在 Generation 這個問題裡面
我們的 Loss Function
就是 PG 跟 Pdata 的 Divergence
就是它們兩個之間的距離
它們兩個越近
那就代表這個產生出來的 PG 跟 Pdata 越像
所以 PG 跟 Pdata
我們希望它們越相像越好
所以我們希望 PG 跟 Pdata 的
Divergence 越小越好
我們要做的事情就找一個 G
讓 Divergence 變得最小
但是我們這邊遇到一個困難的問題
怎麼樣困難的問題呢
這個 Loss
我們是可以算的
但是這個 Divergence 是要怎麼樣算呢
那你可能知道一些 Divergence 的式子
比如說 KL Divergence
比如說 JS Divergence
這些 Divergence 用在這種 Continues 的
Distribution 上面
你要做一個很複雜的
在實作上你幾乎不知道要怎麼算的積分
那我們根本就無法把這個 Divergence 算出來
我們算不出這個 Divergence
我們又要如何去找一個 G
去 Minimize 這個 Divergence 呢
這個就是 GAN 所遇到的問題
這就是我們在 Train 這一種
Generator 的時候會遇到的問題
而 GAN 呢
是一個很神奇的做法
它可以突破
我們不知道怎麼計算 Divergence 的限制
所以我現在遇到的問題就是
不知道怎麼計算 Divergence
而 GAN 告訴我們就是
GAN 告訴我們的就是
只要你知道怎麼從 PG 和 Pdata
這兩個 Distributions Sample 東西出來
就有辦法算 Divergence
你不需要知道 PG 跟 Pdata
它們實際上的 Formulation 長什麼樣子
你只要能夠 Sample
就能夠算 Divergence
而 PG 跟 Pdata 是可以 Sample 的嗎
是可以 Sample 的
怎麼從真正的 Data 裡面
Sample 出東西來呢
那你就把你的圖庫拿出來
從圖庫裡面隨機產生
隨機 Sample 一些圖片出來
你就得到 Pdata 了
那怎麼從 Generator 裡面
產生一些東西出來呢
那你就把你的 Generator
輸入這個 Normal 的
從 Normal Distribution Sample 出來的 Vector
丟到 Generator 裡面
我們剛才說過說
你這邊的這個 Distribution
你拿來 Sample 那個 Distribution
要是簡單的
要是你有辦法 Sample 的
所以我們選 Normal Distribution
式子我們是知道的
是有辦法 Sample 的
我們從 Normal Distribution 裡面
Sample 一堆 Vector 出來丟給 Generator
讓 Generator 產生一堆圖片出來
那這些圖片就是從 PG Sample 出來的結果
所以我們有辦法從 PG 做 Sample
我們有辦法從 Pdata 做 Sample
接下來
GAN 這一整個系列的 Work
就是要告訴你說
怎麼在只有做 Sample 的前提之下
我根本不知道 PG 跟 Pdata
實際上完整的 Formulation 長什麼樣子
在只能做 Sample 的前提之下
居然就算出了
居然就估測出了 Divergence
好 那這個就是要靠 Discriminator 的力量
那我們剛才講過說 Discriminator
是怎麼訓練出來的呢
我們有一大堆的 Real Data
這個 Real Data 就是從 Pdata Sample 出來的結果
我們有一大堆 Generative 的 Data
Generative 的 Data
就可以看作是從 PG Sample 出來的結果
根據 Real 的 Data 跟 Generative 的 Data
我會去訓練一個 Discriminator
它的訓練的目標
是看到 Real Data
就給它比較高的分數
看到這個 Generative 的 Data
就給它比較低的分數
我們剛才一直說
Discriminator 訓練的目標
就是要分辨好的圖跟不好的圖
分辨真的圖跟生成的圖
所以看到真的圖給它高分
看到生成的圖給它低分
那實際上剛才怎麼樣
你也可以把它寫成式子
把它當做是一個 Optimization 的問題
這個 Optimization 的問題是這樣子的
我們要訓練一個 Discriminator
這個 Discriminator 可以去 Maximize
某一個 Function
我們這邊叫做 Objective Function
就我們要 Maximize 的東西
我們會叫 Objective Function
如果 Minimize 我們就叫它 Loss Function
我們現在要找一個 D
它可以 Maximize 這個 Objective Function
這個 Objective Function 長什麼樣子呢
這個 Objective Function 長這個樣子
我們有一堆 Y
它是從 Pdata 裡面 Sample 出來的
也就是它們是真正的 Image
而我們把這個真正的 Image 丟到 D 裡面
得到一個分數再去弄
那另外一方面呢
我們有一堆 Y
它是從 PG 從 Generator 所產生出來的
把這些圖片也丟到 Discriminator 裡面
得到一個分數
再取 Log 1 - D (Y)
那我們希望這個 Objective Function V
越大越好
我們希望 V 越大越好
意味著我們希望這邊的 D (Y) 越大越好
我們希望 Y 如果是從 Pdata Sample 出來的
它就要越大越好
我們希望說如果 Y 是從
這個 PG Sample 出來的
它就要越小越好
那我們就去最大化 V 這個式子
我們就去最大化
找一個 D 可以 Maximize
這個 Objective Function
我們其實就是讓 D (Y) 越大越好
讓這邊的 D (Y) 也就是機器
Generator 生成圖片的值越小越好
Discriminator Output 的值越小越好
那這件事情呢
其實又等同於
你可能覺得沒事突然寫出這個式子有點奇怪
但你不一定要把這個 Objective Function
寫成這個樣子
它完全可以有其他的寫法
那最早年之所以寫成這個樣子
是有一個很明確的理由
有一個很明確的動機
是為了要把 Discriminator
跟 Binary Classification
跟分類
跟二元的分類扯上關係
怎麼說呢
事實上這個 Objective Function
它就是 Cross Entropy 乘一個負號
我們知道我們在訓練一個 Classifier 的時候
我們就是要 Minimize Cross Entropy
所以當我們 Maximize
這個 Objective Function
Maximize Cross Entropy 乘一個負號的時候
其實等同於 Minimize Cross Entropy
也就等同於是在訓練一個
也就是等同於是在訓練一個 Classifier
所以這個 Discriminator 真的做的事情
如果 Discriminator 做的事情
是去 Maximize 這個 Objective Function
那這個 Discriminator
其實可以當做是一個 Classifier
它做的事情就是把藍色這些點
從 Pdata Sample 出來的真實的 Image
當作 Class 1
把從 PG Sample出來的這些假的 Image
當作 Class 2
有兩個 Class 的 Data
訓練一個 Binary 的 Classifier
訓練完就等同於是
解了這一個 Optimization 的問題
那這邊最神奇的地方是以下這句話
這一個式子
這個紅框框裡面的數值
它跟 JS Divergence 有關
那事實上有趣的事情是
我覺得最原始的 GAN 的 Paper
它的發想可能真的是從 Binary Classifier 來的
一開始是把 Discriminator
寫成 Binary 的 Classifier
然後有了這樣的 Objective Function
然後再經過一番推導以後
這個 Objective Function
它的 Maximum
就是你找到一個 D
可以讓這個 Objective Function
它的值最大的時候
這個最大的值跟 JS Divergence 是有關的
它們沒有完全一模一樣
所以顯然一開始
並不是針對 JS Divergence 設計的
而是經過一番推導以後
發現它們是非常有關聯的
那至於實際上的推導過程
你可以參見原始 Ian J. Goodfellow 寫的文章
那其實裡面的推導過程
我覺得寫得算是蠻清楚的
好 所以真正神奇的地方就是
這一個 Objective Function 的最大值
它跟 Divergence 是有關的
所以我們剛才說
我們不知道怎麼算 Divergence
沒關係
Train 你的 Discriminator
Train 完以後
看看它的 Objective Function 可以到多大
那個值就跟 Divergence 有關
好 那這邊我們並沒有把證明拿出來
跟大家講了
但是我們還是可以從直觀上來理解一下
為什麼這個 Objective Function 的值
會跟 Divergence 有關呢
那這個直觀的理解並沒有很困難
因為你可以想想看
假設 PG 跟 Pdata
它的 Divergence 很小
也就 PG 跟 Pdata 很像
它們差距沒有很大
它們很像 PG 跟 Pdata Sample 出來的
藍色的星星跟紅色的星星
它們是混在一起的
那個時候對 Discriminator 來說
Discriminator 就是在 Train 一個
Binary 的 Classifier
對 Discriminator 來說
既然這兩堆資料是混在一起的
那就很難分開
這個問題很難
所以既然這個問題很難
你在解這個 Optimization Problem 的時候
你就沒有辦法讓這個 Objective 的值非常地大
所以這個 Objective 這個 V 的
Maximum 的值就比較小
所以小的 Divergence
對應到小的這個 Objective Function 的
Maximum 的值
所以不是 Objective Function 的值本身哦
是 Objective Function 在窮舉說
Discriminator 要可以得到的最大的值
如果今天呢
你的兩組 Data 很不像
它們的 Divergence 很大
那對 Discriminator 而言
就可以輕易地把它分開
當 Discriminator 可以輕易把它分開的時候
這個 Objective Function 就可以衝得很大
那所以當你有大的 Divergence 的時候
這個 Objective Function 的 Maximum 的值
就可以很大
當然這邊是用直觀的方法來跟你講
那詳細的證明請參見 GAN 原始的 Paper
裡面在做了一些假設
比如說 Discriminator 的 Capacity 是無窮大
等等的假設以後
可以做出這個 Maximum 的值
跟 JS Divergence 一些相關的這個推導
好 所以我們說
我們本來的目標是要找一個 Generator
去 Minimize PG 跟 Pdata 的 Divergence
但我們卡在不知道怎麼計算 Divergence
那我們現在要知道
我們只要訓練一個 Discriminator
訓練完以後
這個 Objective Function 的最大值
就是這個 Divergence
就跟這個 Divergence 有關
那我們何不就把紅框框裡面這一項
跟 Divergence 做替換呢
我們何不就把 Divergence
替換成紅框框裡面這一項呢
所以我們就有了這樣一個 Objective Function
這個 Objective Function 乍看之下有點複雜
它有一個 Minimum
又有一個 Maximum
所以你不小心就會腦筋轉不過來
我們是要 Mini
我們是要找一個 Generator
去 Minimize 紅色框框裡面這件事
但是紅框框裡面這件事
又是另外一個 Optimization Problem
它是在給定 Generator 的情況下
去找一個 Discriminator
這個 Discriminator
可以讓 V 這個 Objective Function 越大越好
然後我們要找一個 G
讓紅框框裡面的值最小
這個 G 就是我們要的 Generator
而剛才我們講的這個 Generator 跟 Discriminator
互動啊 互相欺騙這個過程
其實就是想解這一個有 Minimize
又有 Maximize 這個 Min Max
Min Max 的問題
就是透過下面這一個
我們剛才講的 GAN 的 Argument 來解的
那至於實際上
為什麼下面這個 Argument 可以解這個問題
你也可以參見原始 GAN 的 Paper
那講到這邊
也許你就會問說
為什麼是 JS Divergence
而且還不是真的 JS Divergence
是跟 JS Divergence 相關而已
怎麼不用真正的 JS Divergence
或不用別的
比如說 KL Divergence
你完全可以這麼做
你只要改了那個 Objective Function
你就可以量各式各樣的 Divergence
那至於怎麼樣設計 Objective Function
得到不同的 Divergence
那有一篇叫做 F GAN 的 Paper 裡面
有非常詳細的證明
它有很多的 Table 告訴你說
不同的 Divergence
要怎麼設計它的 Objective Function
你設計什麼樣的 Objective Function
去找它的 Maximum Value
就會變成什麼樣的 Divergence
在這篇文章裡面都有詳細的記載
這一開始有人會覺得說
GAN 之所以沒有很好 Train
也許是因為
就是我們沒有在真的
這個 Minimize JS Divergence
但是有了這個 F GAN 這個 Paper以後
它就告訴你說
我們有辦法 Minimize JS Divergence
但就算你真的可以 Minimize JS Divergence
結果也還是沒有很好
GAN 還是沒有很好 Train
好 所以 GAN 呢
是以不好 Train 而聞名的
所以你知道俗話就說
No Pain No Gain 這樣子
好 所以這顯示 GAN 呢
是以不好 Train 而聞名的
所以接下來我們就要講一些
GAN 訓練的小技巧
而 GAN 有什麼樣訓練的小技巧呢
而其中的最
其實它 GAN 訓練的小技巧非常非常多
那我想了很久以後
我們只挑一個最知名的來講
這個最知名的就是很多人都聽過
是不是沒電了
Hello Hello
好 換一個麥克風
Hello Hello
好 這個最知名的
就是很多人都聽過的 WGAN
那這個 WGAN 是什麼呢
在講 WGAN 之前
我們先講 JS Divergence 有什麼樣的問題
在最早的 GAN 說
我們要 Minimize 的是 JS Divergence
那選擇 JS Divergence 的時候
會有什麼問題呢
好 在想 JS Divergence 的問題之前
我們先看一下 PG 跟 Pdata 有什麼樣的特性
那 PG 跟 Pdata 有一個非常關鍵的特性是
PG 跟 Pdata 它們重疊的部分往往非常少
怎麼說呢
這邊有兩個理由
第一個理由是來自於 Data 本身的特性
因為你想 PG 跟 Pdata
它們都是要產生圖片的
那圖片其實是高維空間裡面的
一個低維的 Manifold
怎麼知道圖片是高維空間
裡面低維的 Manifold 呢
因為你想想看
你在高維空間裡面
隨便 Sample 一個點
它通常都沒有辦法構成一個
二次元人物的頭像
所以二次元人物的頭像它的分布啊
在高維的空間中
其實是非常狹窄的
所以二次元頭像的分布
這個圖片的分布
其實是高維空間中的低維的 Manifold
或者是如果是以二維空間來想的話
那圖片的分布
可能就是二維空間的一條線
二維空間中多數的點都不是圖片
就高維空間中隨便 Sample 一個點
都不是圖片
只有非常小的範圍
Sample 出來它會是圖片
所以從這個角度來看
從資料本身的特性來看
PG 跟 Pdata
它們都是 Low Dimensional 的 Manifold
用二維空間來講
PG 跟 Pdata 都是二維空間中的兩條直線
而二維空間中的兩條直線
除非它剛好重合
不然它們相交的範圍
幾乎是可以忽略的
這是第一個理由
那也許有人說
啊 這個 也許圖片根本就不是什麼
Low Dimensional 的 Manifold
那會不會第一個理由就不成立了呢
那我給你第二個理由
第二個理由是
我們是從來都不知道 PG 跟 Pdata 長什麼樣子
我們對 PG 跟 Pdata
它的分布的理解
其實來自於 Sample
所以也許 PG 跟 Pdata
它們是有非常大的 Overlap 的範圍
但是我們實際上
在了解這個 PG 跟 Pdata
在計算它們的 Divergence 的時候
我們是從 Pdata 裡面 Sample 一些點出來
從 PG 裡面 Sample 一些點出來
如果你 Sample 的點不夠多
你 Sample 的點不夠密
那就算是這兩個 Divergence 實際上
這兩個 Distribution 實際上有重疊
但是假設你 Sample 的點不夠多
對 Discriminator 來說
它也是沒有重疊的
就是這個藍色的分布跟紅色的分布
明明是有重疊的
但如果你從藍色分布 Sample 一些點
紅色分布 Sample 一些點
這些點你又 Sample 得不夠多
你根本就可以畫一條楚河漢界
把紅色的點跟藍色的點完全地分開來
然後說紅色的點
它的分布就是在這個楚河漢界的右邊
藍色的點就在左邊
它們完全是沒有任何衝突
所以以上給你兩個理由
試圖說服你說 PG 跟 Pdata 這兩個分布
它們重疊的範圍是非常小的
而幾乎沒有重疊這件事情
對於 JS Divergence 會造成什麼問題呢
JS Divergence 有個特性
是兩個沒有重疊的分布
JS Divergence 算出來
就永遠都是 Log2
不管這兩個分布長什麼樣
所以兩個分布只要沒有重疊
算出來就一定是 Log2
不管它們長什麼樣子
算出來都是 Log2
所以舉例來說
假設這是你的 Pdata
這是你的 PG
它們都
假設它們都是一條直線
然後中間有很長的距離
你算它們的 JS Divergence
是 Log2
假設你的 PG 跟 Pdata 其實蠻接近的
那中間的間隔其實是比較小的
算出來結果還是 Log2
除非你的 PG 跟 Pdata 有重合
不然這個 PG 跟 Pdata 只要它們是兩條直線
它們這兩條直線沒有相交
那算出來就是 Log2
算出來這個 Case
算出來是 Log2
這個 Case 算出來也是 Log2
那但是明明這個 Case 就比這個 Case 好
中間這個 Case
中間這個 Generator
明明就比左邊這個 Generator 好
但是你不知道
明明藍色的線就跟紅色的線比較近
但是從 JS Divergence 上面
看不出這樣子的現象
那既然從 JS Divergence 上
看不出這樣的現象
你在 Training 的時候
你根本就沒有辦法把這樣子的 Generator
Update 參數變成這樣子的 Generator
因為對你的 Loss 來說
對你的目標來說
這兩個 Generator 是一樣好
或者是一樣糟
那以上是從比較理論的方向來說明
如果我們從更直觀的實際操作的角度來說明
你會發現
當你是用 JS Divergence 的時候
你就假設你今天在 Train 一個
Binary 的 Classifier
去分辨 Real 的 Image
跟 Generated Image
你會發現實際上你通常 Train 完以後
正確率幾乎都是 100%
為什麼
因為你 Sample 的圖片根本就沒幾張
對你的 Discriminator 來說
你 Sample 256 張 Real 的圖片
256 張 Fake 的圖片
它直接用硬背的
都可以把這兩組圖片分開
知道說誰是 Real 誰是 Fake
所以實際上
如果你有自己 Train 過 GAN 的話你會發現
如果你用 Binary 的 Classifier Train 下去
你會發現
你幾乎每次 Train 完你的 Classifier 以後
也就你 Train 完你的 Discriminator 以後
正確率都是 100%
我們本來會期待說
這個 Discriminator 的 Loss
也許代表了某些事情
這個 Binary Classifier Loss
也許代表某些事情
這個 Loss 越來越大
代表問題越來越難
代表我們的 Generated Data
跟 Real 的 Data 越來越接近
但實際上
你在實際操作的時候你根本觀察不到這個現象
這個 Binary Classifier 訓練完的 Loss
根本沒有什麼意義
因為它總是可以讓它的正確率變到 100%
兩組 Image 都是 Sample 出來的
它硬背都可以得到 100% 的正確率
你根本就沒有辦法看出你的 Generator
有沒有越來越好
所以過去
尤其是在還沒有 WGAN 這樣的技術
在我們還用 Binary Classifier
當作 Discriminator 的時候
Train GAN 真的就很像巫術 黑魔法
你根本就不知道你 Train 的時候
有沒有越來越好
所以怎麼辦呢
那時候做法就是
你每次 Update 幾次 Generator 以後
你就要把你的圖片 Print 出來看
然後你就要一邊那個吃飯
一邊看那個圖片生成的結果
然後跑一跑就發現 哇 壞掉了
然後咔掉重做這樣子
所以以前你根本就沒有
不像我們在 Train 一般的 Network 的時候
你有個 Loss Function
然後那個 Loss 隨著訓練的過程
會慢慢慢慢變小
那你就會看說 Loss 慢慢變小
你就放心知道說你的 Network 有在 Train
但會不會 Overfitting 是另外一件事
至少還在它在 Training Data 上有越來越好
但是對 GAN 而言
本來我們期待 Classifier 的 Loss
可以提供一些資訊
但是當你的 Classifier 是一個
簡單 一般的 Binary Classifier 的時候
它訓練的結果你就沒有任何資訊
你每次訓練出來正確率都是 100%
你根本不知道你的 Generator
有沒有越來越好
變成你只能夠用人眼看
用人眼守在電腦前面看
發現結果不好 咔掉
重新用一組 Hyperparameter
重新調一下 Network
加工重做
所以過去訓練 GAN 是有點辛苦的
那既然是 JS Divergence 的問題
於是有人就想說
那會不會換一個
衡量兩個 Distribution 的相似程度的方式
換一種 Divergence
就可以解決這個問題了呢
於是就有了這個 Wasserstein
或使用 Wasserstein Distance 的想法
好 那 Wasserstein Distance 這邊有一個冷
這邊有一個冷知識
就是這個 W
其實這邊是唸 V
不是唸 不是發 W 的音
不是唸 Wasserstein Distance
是唸 Wasserstein Distance
好 那這個 Wasserstein Distance
是怎麼計算的呢
Wasserstein Distance 的想法是這個樣子
假設你有兩個 Distribution
一個 Distribution 我們叫它 P
另外一個 Distribution 我們叫它 Q
Wasserstein Distance 它計算的方法
就是想像你在開一台推土機
推土機的英文叫做 Earth Mover
想像你在開一台推土機
那你把 P 想成是一堆土
把 Q 想成是你要把土堆放的目的地
那這個推土機把 P 這邊的土
挪到 Q 所移動的平均距離
就是 Wasserstein Distance
在這個例子裡面
我們假設 P 都集中在這個點
Q 都集中在這個點
對推土機而言
假設它要把 P 這邊的土挪到 Q 這邊
那它要平均走的距離
就是 D
所以在這個例子裡面
假設 P 集中在一個點
Q 集中在一個點
這兩個點之間的距離是 D 的話
那 P 跟 Q 的 Wasserstein Distance
就是 D
那因為在講這個
Wasserstein Distance 的時候
你要想像有一個 Earth Mover
有一個推土機在推土
所以其實 Wasserstein Distance
又叫 Earth Mover Distance
但是如果是更複雜的 Distribution
你要算 Wasserstein Distance
就有點困難了
怎麼說呢
假設這是你的 P
假設這是你的 Q
假設你開了一個推土機
想要把 P 把它重新塑造一下形狀
讓 P 的形狀跟 Q 比較接近一點
那有什麼樣的做法呢
你會發現說
你可能的 Moving Plans
就是你把 Q 把 P
重新塑造成 Q 的方法有無窮多種
你可以說我把這邊的土搬到這裡來
我把這邊的土搬到這裡來
把 P 變成 Q
但你也可以捨近求遠說
我把這裡的土搬到這裡來
把這裡的土搬到這裡來
捨近求遠
一樣還是可以把 P 變成 Q
所以當我們考慮
比較複雜的 Distribution 的時候
把 Q 把 P 變成 Q 的方法
是有非常非常多不同的方法
你有各式各樣不同的 Moiving Plan
用不同的 Moving Plan
你算出來的距離
你推土機平均走的距離就不一樣
在左邊這個例子裡面
推土機平均走的距離比較少
在右邊這個例子裡面因為捨近求遠
推土機平均走的距離比較大
那難道這個 P 跟 Q 它們之間的
Wasserstein Distance
會根據你的不同的方法
不同的這個推土機行進的方法
就算出不同的值嗎
為了讓 Wasserstein Distance 只有一個值
所以這邊 Wasserstein Distance 的定義是
窮舉所有的 Moving Plans
然後看哪一個推土的方法
哪一個 Moving 的計畫
哪一個推土的計畫
可以讓平均的距離最小
那個最小的值
才是 Wasserstein Distance
所以會窮舉所有把 P 變成 Q 的方法
然後看哪一個推土的平均距離最短
那選最短的那個距離
當作是 Wasserstein Distance
所以其實要計算 Wasserstein Distance
是挺麻煩的
你會發現說
光我只是要計算一個 Distance
我居然還要解一個 Optimization 的問題
解出這個 Optimization 的問題
才能算 Wasserstein Distance
好 那我們先不講
怎麼計算 Wasserstein Distance 這件事
我們先來講假設我們能夠計算
Wasserstein Distance 的話
它可以帶給我們什麼樣的好處呢
那假設 PG 跟 Pdata 它們的距離是 D0
那在這個例子裡面
Wasserstein Distance 算出來就是 D0
在這個例子裡面
PG 跟 Pdata 它們之間的距離是 D1
那 Wasserstein Distance 算出來的距離
就是 D1
那假設 D1 比較小
D0 比較大
那算 Wasserstein Distance 的時候
這個 Case 的 Wasserstein Distance 就比較小
這個 Case 的 Wasserstein Distance 就比較大
所以我們就可以知道說
由左向右的時候
Wasserstein Distance 是越來越小的
所以如果你觀察
Wasserstein Distance 的話會知道說
從左到右我們的 Generator 越來越進步
但是如果你觀察 Discriminator
你會發現你觀察不到任何東西
對 Discriminator 而言
這邊每一個 Case 算出來的 JS Divergence
都是一樣
都是一樣好或一樣差
但是如果換成 Wasserstein Distance
由左向右的時候我們會知道說
我們的 Discriminator 做
我們的 Generator 做得越來越好
所以我們換一個計算 Divergence 的方式
我們就可以解決 JS Divergence
有可能帶來的問題
這讓我想到什麼呢
這又讓我想到一個演化的例子
這是眼睛的生成
右邊這個是人類的眼睛
人類的眼睛是非常地複雜的
那有一些生物它有非常原始的眼睛
比如說有一些細胞具備有感光的能力
這可以看做是最原始的眼睛
但是這些最原始的眼睛
怎麼變成最複雜的眼睛呢
這對人類來說其實覺得非常難想像
這個這麼簡單
只是一些感光的細胞在皮膚上
經過突變產生一些感光的細胞
聽起來像是一個合理的
但是天擇突變
怎麼可能產生這麼複雜的器官呢
怎麼產生眼睛這麼精巧的器官呢
那如果你直接覺得說
從這個地方就可以一步跳到這個地方
那根本不可能發生
但是中間其實是有很多連續的步驟
從感光細胞到眼睛
中間其實是有連續的步驟的
舉例來說
感光的細胞可能會
出現在一個比較凹陷的地方
皮膚凹陷下去
這樣感光細胞可以接受來自不同方向的光源
然後後來覺得說
乾脆把凹陷的地方蓋起來
後來覺得蓋起來的地方裡面
可以放一些液體
然後最後就變成了人的眼睛
而從這邊跳到這邊這一步
非常大
但是這邊每一小步
都可以讓一個生命存活的機率變大
都可以讓生命繁衍下去的機率變高
既然這邊每一個步驟
都可以讓生命繁衍的機率變高
那生命就可以從左邊一直演化到右邊
最終產生複雜的器官
而我覺得對於當你使用 WGAN
當你使用這個 Wasserstein Distance
來衡量你的 Divergence 的時候
其實就製造了類似的效果
本來 PG0 跟 Pdata 非常地遙遠
你要它一步從這裡跑到這裡
一步從這裡跑到這裡
讓這個 PG0 跟 Pdata
直接 Align 在一起
是不可能的
可能非常地困難
對 JS Divergence 而言
它需要做到直接從這一步跳到這一步
它的 JS Divergence 的 Loss 才會有差異
但是對 W Distance 而言
你只要每次
有稍微把 PG 往 Pdata 挪近一點
W Distance 就會有變化
W Distance 有變化
你才有辦法 Train 你的 Generator
去 Minimize W Distance
所以這就是為什麼
當我們從 JS Divergence
換成 Wasserstein Distance 的時候
可以帶來的好處
好 那 WGAN 實際上就是用
當你用 Wasserstein Distance
來取代 JS Divergence 的時候
這個 GAN 就叫做 WGAN
那接下來你會遇到的問題就是
Wasserstein Distance 是要怎麼算呢
Pdata 跟 PG
它的 Wasserstein Distance 要怎麼計算呢
Wasserstein Distance
是一個非常複雜的東西
我光要算個 Wasserstein Distance
還要解一個 Optimization 的問題
實際上要怎麼計算
那這邊就不講過程
直接告訴你結果
解下面這個 Opimilazion 的 Problem
解出來以後你得到的值
就是 Wasserstein Distance
就是 Pdata 跟 PG 的 Wasserstein Distance
那這邊我發現我犯了一個小小的錯誤
是什麼樣小小的錯誤呢
就是這邊的 X 可能都把它改成 Y
會跟前面的投影片比較一致
所以這邊的 X 在前面的投影片裡面
其實都是 Y
它們指的都是一張圖片
而不是
它們指的都是 Network 的輸出
而不是 Network 的輸入
好 那這個式子裡面有什麼樣的東西呢
我們就觀察一下這個式子
這個式子裡面有說
X 如果是從 Pdata 來的
那我們要計算它的 Ex 的期望值
X 如果是從 PG 來的
我們計算它的 Dx 的期望值
但是前面乘上一個負號
所以如果你要 Maximum
這個 Objective Function
你會達成什麼樣的效果
你會達成
如果 X 是從 Pdata Sample 出來的
Ex
就 Discriminator 的 Output 要越大越好
如果 X 是從 PG
從 Generator Sample 出來的
那 Dx
也就 Discriminator 的 Output
應該要越小越好
但是這邊還有另外一個限制
它不是光叫你把這裡
括號 大括號裡面的值變大就好
還有一個限制是
D 不能夠是一個隨便的 Function
E 必須要是一個 1-Lipschitz 的 Function
可能會問說
1-Lipschitz 是什麼東西呢
如果你不知道是什麼的話
也沒有關係
我們這邊你就想成
D 必須要是一個足夠平滑的 Function
它不可以是變動很劇烈的 Function
它必須要是一個足夠平滑的 Function
那為什麼足夠平滑這件事情是非常重要的呢
我們可以從直觀來理解它
假設這個是真正的資料的分布
這是 Generated 的資料的分布
如果我們沒有這個限制
只看大括號裡面的值的話
大括號裡面的目標
是要這些真正的值
它的 Dx 越大越好
那要讓 Generated 的值
它的 Dx 越小越好
如果你沒有做任何限制
只單純要這邊的值越大越好
這邊的值越小越好
在藍色的點跟綠色的點
也就是真正的 Image
跟 Generated 的 Image
沒有任何重疊的情況下
你的 Discriminator 會做什麼
它會給 Real 的 Image 無限大的正值
給 Generated 的 Image 無限大的負值
所以你這個 Training 根本就沒有辦法收斂
而且你會發現說
只要這兩堆 Data 沒有重疊
你算出來的值都是無限大
你算出來的這個 Maximum 值都是無限大
這顯然不是我們要的
這不就跟 JS Divergence 的問題一模一樣嗎
所以這邊你需要加上這個限制
其實你要加上這個限制以後
你這個 Maximum 的值
才會是 Wasserstein Distance
才是做 WGAN
好 那為什麼加上這個限制
就可以解決剛才的問題呢
因為這個限制是要求 Discriminator
不可以太變化劇烈
它必須要夠聽話
那今天如果你
要求你的 Discriminator 夠平滑的時候
假設 Real Data 跟 Generated Data
它們距離比較近
那你就沒有辦法讓 Real 的 Data 值非常大
然後 Generated 的值非常小
因為如果你讓 Real 的值非常大
Generated 的值非常小
它們中間的差距很大
那這一個 Discriminator 變化就很劇烈
它就不平滑了
它就不是 1-Lipschitz
那為了要是 1-Lipschitz
這邊的值沒辦法很大
這邊的值沒辦法很小
讓 Discrimination 必須足夠
只覺得發現說
如果 Real 跟generated 的 Data 差距離很遠
那它們的值就可以差很多
這邊算出來的值就會比較大
你的 Wasserstein Distance 就比較大
如果 Real 跟 Generated 很近
就算它們沒有重合
因為有了這一個限制
有了這一個寫在 Max 下面的
1-Lipschitz Function 的限制
那你就發現說
它們其實不會真的都跑到無限大
它們的距離
因為有 1-Lipschitz Function 的限制
所以 Real Data 的值跟 Generated Data 的值
就沒有辦法差很多
那你算出來的 Wasserstein Distance
就會比較小
好 那接下來的問題就是
怎麼做到這個限制呢
怎麼確保 Discriminator
一定符合 1-Lipschitz Function 的限制呢
最早剛提出 WGAN 的時候
其實沒有什麼好想法
只知道寫出了這個式子
那要怎麼真的解這個式子呢
有點困難
所以最早的一篇 WGAN 的 Paper
最早使用 Wasserstein 的那一篇 Paper
它說了它做了一個比較 Rough
比較粗糙的處理的方法
它是說我就 Train Network
那 Train Network 的時候
如果我 Training 的那個參數
我就要求它放得在 C 跟 -C 之間
如果超過 C
用 Gradient Descent Update 以後超過 C
就設為 C
Gradient Descent Update 以後小於 -C
就直接設為 -C
那其實這個方法
並不一定真的能夠讓 Discriminator
變成 1-Lipschitz Function
那你可以想像說這個方法
也許真的可以讓我們的 Discriminator
比較平滑
但它並沒有真的去解這個
Optimization 的 Problem
它並沒有真的讓 Discriminator
符合這個限制
所以接下來就有其它的想法
有一個想法叫做 Gradient Penalty
Gradient Penalty 是出自
Improved WGAN 這篇 Paper
那 Improve WGAN 這邊paper 是說
假設這個是你的 Real Data 的分布
這個是你的這個 Fake Data 的分布
那我在 Real Data 這邊取一個 Sample
Fake Data 這邊取一個 Sample
兩點連線中間再取一個 Sample
我要求這個點它的 Gradient 要接近
那你可能覺得說這個
不知道 不知道在說些什麼這樣
這件事情的關係
跟這個限制的關係
到底是什麼呢
那就詳見 Improved WGAN 的 Paper
那其實我覺得你現在
也不一定要真的非常較真說
這件事情 Gradient Penalty
跟這個限制之間的關係
因為其實有更多其它的方法
真的可以去解這個問題
那其實後來 Improved WGAN 之後
還有什麼 Improved 的 Improved WGAN
真的有這篇 Paper
它就是把這個限制再稍微改一改
有另外一篇 Paper 就叫
Improved The Improved WGAN
那今天其實你有一個方法
真的把 D 限制
讓它是 1-Lipschitz Function
這個叫做 Spectral Normalization
那我就把它的論文放在這邊給大家參考
那如果你要 Train 真的非常好的 GAN
你可能會需要用到 Spectral Normalizaion
