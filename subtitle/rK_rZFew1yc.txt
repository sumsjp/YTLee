好,那各位同學大家好啊,那我們就來上課吧
那最近幾週呢,又發生了很多跟大型語言模型有關的事情
所以我們今天就講三個最近跟大型語言模型有關的故事
然後講完呢,我們就請助教來講作業
好,那第一個要跟大家分享的故事是
窮人如何用自己有限的資源來復刻自己的ChatGPT
現在滿坑滿谷的人都在想辦法用自己手頭上有的資源來復刻自己的ChatGPT
好,那為什麼有人會需要自己的ChatGPT呢?
那通常是有資安方面的考量
因為當你把你的資料上傳到ChatGPT的時候
你不知道OpenAI會拿它來做什麼事情
到底OpenAI會怎麼樣使用我們的資料呢?
當你上傳你的對話,當你跟ChatGPT講話的時候
到底你講的這些話,OpenAI會不會拿去做其他用途呢?
很有可能會的,因為其實OpenAI官方已經說了
當你今天是用non-API的service去使用ChatGPT跟DALI的時候
他們可能會用你輸入的Prop,機器的Response
你上傳的Image還有生成出來的Image來增強他們的服務
所以OpenAI顯然是會使用你的資料
OpenAI有關ChatGPT資料使用的官方回覆裡面也提到說
有人問說你會不會用我跟ChatGPT的對話來進行訓練呢?
他說會,你的對話可能會被他們的AI trainer看到
然後拿來improve他們的system
有人會說那我能不能夠delete掉我的data呢?
如果今天不小心說了一個有機敏性的資料
我用ChatGPT來改一下我公司的code
但是後來發現這個code照理說是不應該外流的
怎麼辦呢?我有沒有辦法把資料delete掉呢?
那OpenAI這邊是說它有一個連結告訴你怎麼delete掉你的data
那怎麼delete掉呢?這邊點進去啊,就是delete掉你的account
就是delete掉data唯一的方法就是delete掉你的account
那這件事呢,不知道為什麼要花四個禮拜的時間
才能把你的account delete掉
那如果你說我不想delete掉整個account
我只想把某一則對話裡面的某一個point delete掉
有沒有辦法呢?這件事是沒有辦法的
所以,我這邊OpenAI給大家的建議是
如果你有些東西你不想讓ChatGPT知道
那你就不應該讓ChatGPT知道
你不應該讓ChatGPT知道,OpenAI可以拿來訓練他們的模型
以後模型就知道這個秘密,然後不知道什麼時候
它會把這個秘密說出去
所以很多人對於使用ChatGPT其實是有所保留的
所以就開始有一個新的風潮
想辦法用自己手上的資源來複刻ChatGPT
那要怎麼複刻ChatGPT呢?
你要準備兩個東西
第一個是一個現成的pre-trained模型
現在這些複刻的動作通常你不會再重新pre-trained你的模型了
因為已經有很多open的pre-trained模型
比如說之前Meta才釋出的Lama是你可以使用的
然後再來呢,你必須要有一個ChatGPT的account
你一定要可以用它的API
然後怎麼複刻呢?
這個說穿了就是一句話就講完了
那這招呢,在Self-in-Chart這篇paper裡面已經有所記載
這個是去年12月的文章
然後怎麼複刻ChatGPT呢?
就是以ChatGPT為師
你先把一個問題,比如說請修改以下這句話的文法錯誤
丟給ChatGPT,它會給你一個答案修改過文法以後的句子
然後你就訓練自己的模型
你的模型的訓練方式就是給自己的模型一模一樣的輸入
然後呢,它的正確答案就是ChatGPT的答案
你的模型就是想辦法update它的參數
讓它的輸出可以跟ChatGPT一模一樣
那大家都知道說這一招呢,就叫做Knowledge Destination
那其實在有這個大型語言模型之前
這招是非常早就有的招數
那你可以用一個小模型去模仿一個大模型的行為
然後小模型往往可以跟大模型學得差不多好
那這邊會遇到另外一個問題
就是那我怎麼知道要丟給ChatGPT什麼樣的輸入呢?
舉例來說,我想要做一個可以自己幫忙做編修的模型
那我怎麼找到一堆有文法錯誤的句子
來讓我的模型來當作ChatGPT的輸入好得到答案
讓自己的模型可以跟ChatGPT學習呢?
這件事說穿了也不值錢
連可能的輸入都讓老師幫忙想
都讓ChatGPT幫忙想
你就告訴ChatGPT說我們現在的任務呢
是要修正文法錯誤
那我給你一個輸入的例子
那你能不能幫我想出更多類似的例子
ChatGPT就會幫你想出更多類似的例子
那你可能會想說,也許我要做的不只是改文法的錯誤
我要做各種跟編修文章有關的事情
可能有破寫啊、可能有摘要啊等等
但是我想不出來要做哪些任務
怎麼辦呢?這個也請老師幫你想
你就告訴ChatGPT說我現在有兩個任務
你再幫我想更多類似的任務
所以就是這樣
整個過程通通都是依靠ChatGPT來產生資料
任務是ChatGPT想的
輸入也是ChatGPT想的
答案也是ChatGPT想的
你有這些資料,你就可以來訓練自己的模型了
在這一系列復刻ChatGPT的活動裡面
最知名的模型是Stanford Alpaca
這張圖是從他們的官網上展下來的
Stanford Alpaca是怎麼做的呢?
他們的老師不是ChatGPT
所以你可以發現這應該是比較早就開始的project
他們的老師是Davinci
在ChatGPT之前,OpenAI就已經釋出了一個線上的模型
他們首先先想了175個種子任務
這就是全部了
其實那175個種子任務還不是這個團隊自己想的
因為前面已經有一篇叫Self-Entrust GBT的paper
他是直接拿那篇paper的175個任務來當作種子
然後來生出更多的任務
所以種子任務可能是長這個樣子
這是一個種子任務的範例
那我們就來brainstorm想一下
這個新年的新計畫
然後就叫這個Davinci大型語言模型
想更多類似的任務
比如說大型語言模型就想了另外一個任務是
我們來想一個有創意的點子
來設計一個會議室
總之就想了52K,5萬多個
這不是5萬多個任務喔
這是5萬多個input跟output的成對的資料
他們只收集了5萬多筆資料
接下來他們就拿那個meta的一個叫Lama的模型
那這個Lama的大小是7個Billion的參數
然後接下來就拿這5萬多筆資料去finetune一下Lama
就得到Alpaca
那Alpaca是什麼呢?
Alpaca就是俗話說的那個草泥馬啦
就是羊駝
那為什麼要叫做Alpaca呢?
因為Lama其實也是羊駝
但是Lama是比較大隻的羊駝
一般我們說草泥馬其實是Alpaca
這是大隻的羊駝
這個是小隻的羊駝叫Alpaca
這個就是Alpaca的訓練過程
那這個Alpaca其實它是線上
你是可以找到一些連結去玩那個Alpaca
那為什麼要跟那個Chair GPT講話呢?
當然是沒Chair GPT那麼聰明啦
聊起來也是有87%像啦
所以這個故事其實告訴我們的一件事情是
你會發現Alpaca其實是一個非常小的模型
只有7筆
它的訓練資料其實也不多
只有5萬筆
但是這告訴我們說今天
在已經有Chair GPT作為老師的情況下
未來你要開發類似的應用
可能都會簡單很多
就OpenAI開發Chair GPT成本是最高的
但是日後大家拿Chair GPT當老師
每一個模型想辦法去逼近Chair GPT的成本
可能會比過去開發Chair GPT的成本還要低很多
那除了Alpaca以外呢
做類似工作的團隊真的是滿坑滿谷啦
那另外一個叫做Vikuna
那這個也是美國一些大學合起來做的
那他們用的資料跟Alpaca比較不一樣
Vikuna它的資料是從一個叫做Share GPT的網站上拿來的
Share GPT那個網站就是
你可以把你跟Chair GPT的對話分享到那個網站
你可以安裝一個插件
安裝那個插件以後呢
你就點一下
就你跟Chair GPT對話完囉
你點一個按鈕叫做Share
然後你的對話就會被Share到Share GPT那個網站
那Vikuna做的事情就是把Share GPT那個網站上面
人跟Chair GPT的對話載下來
然後FindTune它的模型
然後就沒有然後就結束了
那就可以Deploy它的模型到網路上給大家玩
那它FindTune的模型
FindTune比較大的啦
那個Alpaca是7B嘛
那Vikuna是13B
那Vikuna也是羊駝
也是小隻的羊駝
但是它跟草泥馬不太一樣
草泥馬是白色有毛的
那Vikuna是黑色的
那這個Vikuna一個比較有趣的地方就是
那我們要怎麼知道Vikuna到底做得好不好呢
跟這個Chair GPT有多少趴向呢
他們居然是用GPT-4來Evaluate這些語言模型
怎麼Evaluate呢
這個也是說穿了不值錢
這個方法就是這樣
你先出一個任務
比如說幫我寫一封Email
然後呢給兩個不同的模型
比如說Alpaca跟Vikuna
然後他們各自都產生一個答案
把這個答案丟給GPT-4
你就相信GPT-4是最強的
它已經強到跟老師一樣
那就跟GPT-4說
現在有兩個Agent都提供了一個答案
那在1到10分之間
你給這兩個模型幾分
然後GPT-4呢
它會幫這兩個模型升一些評價喔
就對他們的這個答案做一些評價
然後最後就給個分數說
系統1我給9分
系統2我給10分
然後這個就是Vikuna怎麼去Evaluate他們的模型
然後他們假設呢
這個GPT-4就是10分
然後如果他們的模型拿到9點多分
他們就可以到處炫耀說
你看這個Vikuna有GPT-4的9成實力
是不是真的
你也很難講啦
因為你並不知道GPT-4評分的標準是怎樣
會不會太寬鬆
就算很爛的答案也會給個8、9分
所以你很難說
GPT-4給9分就是有達到GPT-4的9成實力
當然這個Vikuna的官網其實也有加個免責聲明啦
就是說用GPT-4來Evaluation
只是好玩然後不科學
那更嚴謹的Evaluation就是之後再說
那在Vikuna的官網上面呢
它也比較了幾個語言模型他們用的資料
還有你訓練的時候所需要耗費的成本
這個縱軸就是四個模型
LAMA是Meta釋出的是沒有FindQ只有Pretend的模型
ELPACA跟Vikuna是有FindQ的
然後BAR跟確GPT是最後一個Column
那最後一個Column當然一切都是未知
所以都是Not Available
那Dataset呢 LAMA用了1T的Token
那ELPACA呢是用了52K的成對的資料去FindQ LAMA啦
所以這一行呢
這些資料其實它的用途是不一樣的
LAMA這些資料是Pretend的
ELPACA跟Vikuna這些資料是拿來FindQ的
那Vikuna的資料多一點有70K
它是從Sharechain GPT那個網站上拿下來的
這邊講了一下訓練的時候的Cost啦
你看LAMA 7B 82K GPU Hour
那這個運算資源就不是誰都可以拿得出來的
那ELPACA呢
ELPACA是這個用了500塊美金
因為他們要Call那個Davinci的API
所以是花了一些錢啦
500塊美金去蒐集資料
然後訓練這個是很低成本只花了100美金
那Vikuna呢花了140美金
如果確認7B的模型
那13B的模型呢就花了300美金而已
所以這個可能是一般人可以負擔得起的
當然這個錢是換算到如果你租
比如說雲端的運算資源所需要花的錢啦
那ELPACA是說他們是用
他們在這個8張A100上是Train了三個小時啦
你其實手上也沒有A100對不對
我告訴你那些窮人都還是比我們有錢的多
他們是比較有錢的窮人
好那另外一個我想跟大家分享的模型是Dolly
其實這種模型現在這種複科TrainGPU的活動
真的是滿坑滿谷
這個模型真的是多得不可勝數
所以我就只再多講一個叫做Dolly
那Dolly他特別的地方是什麼呢
就是前面那些模型
他們的Portrait Model用的都是LAMA
但是LAMA有一個限制
這個限制不是技術上的限制
是Copyright的限制
LAMA的License呢是不能夠商用的
所以你用LAMAFINE2的模型
你恐怕是不能夠商用
然後再來呢
就是現在像那個ELPACA都是去把Chad GVT當作老師
從Chad GVT那邊偷學東西出來
這件事情到底可不可以呢
OpenAI的聲明是這樣子的
你不能夠拿Chad GVT的輸出去做一個Service
而這個Service是跟OpenAI有競爭關係的
所以從這句話的解釋
你是不能夠使用這種Knowledge Destination的方法
去把Chad GVT當作老師去訓練一個很類似的模型
好像是不能這樣子
不過當然從另外一個角度來看
你也可以強辯說
世界上沒有人可以跟OpenAI抗議
做出來的東西跟OpenAI差了一大截
怎麼能夠算是抗議呢
不過這個到底OpenAI接不接受
你就要問他們的律師了
好所以總之
你在剛才那個ELPACA還有Vikuna
他們在使用上如果要商用的話
還是有一些限制的
所以就有了Dolly
Dolly用的Pretend的模型
還有FINE2的資料
都是可以商用的
他們用的Pretend的模型
叫做Pythea
是一個可以商用的模型
那Pythea呢
就是一系列由小到大的模型
最小的只有19M
最大的有12個Billion
它是有人訓練的一系列
各式各樣不同大小的模型
並把它試出來供全世界的人使用
那FINE2的資料怎麼辦呢
之前大家都是想辦法把Chad GVT當作老師
那Dolly2.0的做法就是
怎麼辦 找人來標啊
Dolly背後是有家公司叫Data Brick
他們有5000個員工
那5000個員工呢
在3月到4月間
硬標了15000筆的資料
人多就是有好辦事啊
你仔細想想看
他們其實雖然說15000筆資料也覺得很多
但5000個人一個人平均才標3筆而已
那這個Data Brick是有強調一下
他們並沒有虐待員工
他是辦了一個比賽這樣子
然後呢
辦了一個比賽
教大家來想這些Pump
還有好的答案
然後想得最好最多的人
可以得到額外的獎勵
那類似的模型真的是滿坑滿谷啦
你可以在一個LLM Zoo
LLM動物園裡面
找到更多類似的模型
你會發現說他們的時間啊
基本上都是在3到4月間
沒幾天就有人宣稱說
我也複刻了Chair GPT
他有Chair GPT的子承功力
那這邊呢
是4月才放到Archive上的Paper
這是Microsoft的Paper
他做的事情是什麼呢
他做的事情就是
趁著大家還沒有GPT-4的API的時候
他們先爆摳一下GPT-4
把GPT-4當老師
也訓練了一個小模型
你可以想像他的結論就是
用GPT-4做為老師
是比用原本的Chair GPT當老師
結果還要再稍微強一點
不過這邊有一個很有趣的結果
就是Vikuna其實真的是滿強的
我們來看一下這邊的這個模型
他們比較GPT-4
Chair GPT Bar的
還有Llama GPT-4
這個Llama GPT-4
就是這篇Paper裡面自己的模型
他就是仿造Alpaca
但是他的老師是GPT-4
還有Vikuna Alpaca
還有原來的Llama
那這邊這個數值是怎麼比的呢
這個數值啊
就是把
上面這個圖是跟Chair GPT比3
下面這個圖是直接跟GPT-4來比
然後呢
把這些模型的輸出
都拿去給GPT-4做評分
跟Vikuna那個評分的方式是一樣的
就把GPT-4當老師
然後這邊的百分比就是
他每一個模型拿到了
這個GPT-4的
每一個模型拿到了
他比較對象的百分之多少的分數
所以這邊96%
意思就是說這個模型他的分數呢
是Chair GPT的96%
然後這邊87%
這個87%
不然再更高
這個87%
就是得到GPT-4分數的87%
所以這邊結論發生什麼
你發現Vikuna的分數
才是最高的
他居然有Chair GPT的99%的分數
有GPT-4的89%的分數
所以看起來啊
Vikuna的那些Data恐怕特別好
因為你說Vikuna有什麼特別厲害的地方
他的Portrait模型是一樣的啊
這個他Portrait模型也就是拉嘛
比較特別厲害的地方
應該是在Fighting的Data
看起來使用跟人互動的那些Data
人自己想的各式各樣的問題
相較於Alpaca那些問題
也是Chair GPT想的
人想的問題還是比較厲害一點
所以這個圖其實帶給我的啟示是
Vikuna其實真的是蠻強的
用Chair GPT的那些Data來Chair
應該是會給你比較好的模型
好那
接下來還會有一個問題
大家知道說FindU之後的下一個階段
是要做Reinforcement Learning
要做Reinforcement Learning
那你得要有真實的使用者啊
但你哪裡去找真實的使用者呢
所以有一個很狂的方法就是
那我們就把GPT-4當作是人類這樣
由GPT-4來告訴你他的Preference
然後模型就都去跟GPT-4的Preference做學習
你就可以做Reinforcement Learning就結束了
好這個圖啊
是告訴你說GPT-4評分的那個Distribution啦
那這個藍色的是一個比較差的模型
這個模型是OPT
然後GPT-3.5是橙色的
GPT-4是這個綠色的
然後這邊的這個分數的分佈是GPT-4
根據這些模型的輸出給分的分佈啦
那看起來GPT-4其實也不會給自己10分啦
他給自己也通常是分佈
分數的分佈大概都是落在9分左右而已
這個方向是我覺得比較奇怪一點
用GPT-4來打分數
我覺得他的問題是這個樣子的
因為如果你今天要
與其用GPT-4來打分數
那我覺得還倒不如直接把GPT-4當作老師
因為你都反正你都要Call GPT-4的API了
Call GPT-4來提供給你這個Preference
還不如直接Call GPT-4
叫他給你答案
得到更多的Pair Data來訓練
恐怕還更有效率一點
好那其實剛才那種Knowledge Destination
把語言模型當老師的方法
其實不只可以幫助小模型
甚至也可以幫助大模型自己本身
所以有人用了很類似的方法
來讓大的語言模型再自我進步
大家記得說我們在講到
那個Chain of Thought的時候
我們講到一個方法叫做Self Consistency
那Self Consistency的方法就是
你讓同一個模型呢
回答同樣的問題多次
然後每次的答案都不一樣
然後再看哪一個答案出現最多次
那就把那個答案當作正確的答案
那用這一招呢
在一個數學問題的資料集上
可以從56%的正確率
進步到74%的正確率
那這招是我們過去講過的
那這招呢
還有一個後手
這個後手是這個樣子的
好那我們剛才用Self Consistency的方法
你已經知道哪一些答案是正確的
你也知道那些正確的答案
他的推論的過程
那你就把那些正確的答案
還有可以得到這些正確答案的推論過程
當作新的資料
再重新去微調你的語言模型
就可以讓語言模型變得更強
用他自己產生的資料來訓練自己
所以你用Self Consistency
從56%進步到74%
再加上這個自我訓練
把Self Consistency得到的結果
再來微調語言模型
可以得到82%的正確率
好那以上這份投影片呢
就是跟大家分享
現在窮人如何用低資源
複合自己的Chain GPT
