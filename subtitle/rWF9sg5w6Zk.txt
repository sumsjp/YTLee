好 那接下來的課程呢
要跟大家講 Life Long Learning
那什麼是 Life Long Learning 呢
如果你 Google Life Long Learning 這個東西
你最有可能找到的
不是跟 Machine Learning 相關的內容
Life Long Learning
從它字面上的翻譯
你可以知道 Life Long Learning 指的就是
終身學習
也就是活到老學到老
所以如果你用 Life Long Learning 做關鍵字
去 Google 的話
你通常找到的都是有關人類的
Life Long Learning
人類怎麼活到老學到老
那雖然今天大家關注的主題
比較偏向人類怎麼做 Life Long Learning
但是其實機器也需要做 Life Long Learning
機器可以做 Life Long Learning 這件事情呢
非常接近人類對 AI 的想像
你知道在還沒有修這門課之前
在還沒有接觸
任何 Machine Learning 的內容之前
也許你對 AI 的想像是這個樣子的
我們先教機器做某一件事情
比如說學會做語音辨識
那它就會做語音辨識了
接下來你再教它第二個任務
教它做影像辨識
它就會做影像辨識了
接下來你再教它做第三個任務
也許是翻譯
它就會做影像辨識加語音辨識加翻譯了
你不斷教它新的技能
等它學會上百萬 上千萬個技能以後
它就變成天網
然後就可以統治人類
我們一般人對 AI 的想像是
AI 可以不斷地學習新的任務
最終越來越厲害
直到人類不能企及的程度
那這個構想 這個目標就是
Life Long Learning
那 Life Long Learning 呢
常常縮寫成三個 L
LLL
Triple L
不是 LoL 是 LLL
那 Life Long Learning 呢
也有很多其他很潮的名字
比如說有的人叫它 Continuous Learning
有人叫它 Never Ending Learning
聽起來都很潮
有一個比較不潮的名字是
Incremental Learning
好 但是你可能會想說
Life Long Learning 這個目標太過遠大
我今天又沒有要做天網
那 Life Long Learning 對我有什麼意義呢
在真實的 Application 裡面
Life Long Learning 也是派得上用場的
舉例來說啊
今天你在實驗室裡面開發出某一個模型
你在實驗室裡面蒐集一些資料
把這些資料進行訓練
訓練出一個模型
模型上線以後
它會取得來自使用者的 Feedback
這時候我們都希望
蒐集資料這件事情可以變成一個循環
我們模型上線以後蒐集到新的資料
新的資料就可以讓我們來更新
我們模型的參數
模型的參數更新以後
又可以蒐集更多的資料
蒐集更多的資料
模型的參數又可以再次更新
不斷更新模型的參數
最終我們的系統就會越來越厲害
那你可以把舊有的資料想成是過去的任務
把新的資料
來自於使用者 Feedback 的資料
想成是新的任務
所以這樣子的情境
也可以看作是 Life Long Learning 的問題
機器不斷地在線上蒐集資料
用線上蒐集的資料來更新模型
這本質上就是一個 Life Long Learning 的問題
那 Life Long Learning 有什麼樣的難點呢
我們不就是讓機器不斷地看新的資料
不斷地去 Update 它的參數
就做到 Life Long Learning 了嗎
那為什麼 Life Long Learning
會是一個值得研究的問題呢
以下舉一個簡單的例子告訴你說
Life Long Learning 的難點出在什麼樣的地方
假設呢
我們現在有兩個任務
那第一個任務是要做手寫數字辨識
那給它一張非常 Noisy 的 Image
機器要判斷說這裡面是圖片 0
任務二也是手寫數字辨識
那只是現在是比較簡單的任務
你的圖片裡面是沒有任何雜訊的
我們要讓機器學會這兩個任務
那講到這邊有人可能會說
啊 老師這不算是兩個任務啦
這個算是同一個任務 不同的 Domain
你要這樣想也沒問題
你也可以想成是同一個任務 不同的 Domain
但是其實啊
在這個
我知道說
當我說我們要讓機器學一連串的任務的時候
在你心裡的想像也許是
機器先學個語音辨識
再學個影像辨識
再學個翻譯
但其實今天 Life Long Learning
都還沒有做到那個程度
一般在 Life Long Learning 的文獻上
所謂的不同任務指的差不多就是
我這邊這種等級
通常比較像是不同的 Domain
而不是不同的任務
只是我們在這邊
我們把它當做不同的任務來看待
但就算是非常類似的任務
你在做 Life Long Learning 的時候
也會有以下的問題
等下就是來看看有什麼樣的問題
好 那我這邊
我就訓練一個非常簡單的 Network
它只有三層
每層五十個 Neuron
先在任務一上學一下
在任務一上學完以後
我們得到的結果是這個樣子的
任務一正確率 90%
就算還沒有看過任務二
任務二也已經得到 96% 的正確率了
這個 Transfer 的結果非常地好
能夠解任務一
其實就能夠解任務二了
好 那任務一學完之後
我們再讓同一個模型繼續去學任務二
所謂同一個模型繼續去學任務二的意思就是
我們在學任務二的時候
並不是讓機器從頭學起
並不是讓機器從一組
Random Initialize 的參數學起
而是用任務一的資料更新完模型之後
同一個的模型接下來
繼續用任務二的資料來更新
好 所以聽清楚哦
是同一個模型繼續用任務二的資料來更新
好 那所以同一個已經學完任務一的模型
再學任務二會發生什麼事呢
這是我們得到的結果
任務二正確率變更高了
因為之前根本沒看過任務二的資料就有 96% 了
看過任務二的資料當然更厲害
變成 97%
但糟糕的事情是
機器忘了怎麼做任務一了
它本來任務一有 90% 的正確率
在它學會任務二以後
任務一變成只有 80% 的正確率
它忘記了它過去已經學到的技能
那有人看到這邊可能會覺得說
欸 老師這有什麼好奇怪的呢
你這個 Network 就是一個小小的 Network 啊
那你叫它學任務二嘛
那任務一是之前學的嘛
那當然就
它的能力有限啊
它腦容量有限啊
學完任務二以後當然就忘了任務一嘛
但是我接下來告訴你另外一個實驗
假設我們把任務一跟任務二的資料
直接倒在一起
會發生什麼事呢
假設我們把任務一跟任務二的資料倒在一起
同時去訓練這一個 Network
我們得到的結果是這樣子的
任務一可以得到 89%的正確率
任務二可以得到 98% 的正確率
也就是對這個 Network 而言
要同時學好任務一跟任務二
它是辦得到的
雖然它每一層只有五十個 Neuron
但五十個 Neuron 已經足以讓它
同時在任務一上 任務二上
得到這樣子的正確率
那不知道為什麼
如果不是同時學任務一 任務二
而是先學任務一 再學任務二的話
它在學任務二的時候
就會忘記任務一學過的東西了
它有足夠的能力把兩個任務都學好
但是當你讓它依序學習的時候
它沒辦法記住舊的任務
好 那我看看有沒有同學有問題要問的
有同學問說老師是在家裡開直播嗎
答案是
是 我在家裡開直播
好
好 那我們就繼續
我剛才舉的例子呢
是影像辨識的例子
那我接下來再舉一個
這個自然語言處理的例子
告訴你說剛才看到的那個狀況
它不是一個特例
它是一個非常一般 非常常見的現象
這邊要舉的例子啊
是 QA Question Answering
也就是我們的作業七
在作業七裡面
你知道你可以讓機器讀一篇文章
問它一個問題
然後它可以回答你的問題
那我們在這邊用的並不是作業七的資料
而是更簡單的 QA 的任務
這個 QA 的任務叫做 bAbi
通常就念成 bAbi
那 bAbi 是一個非常早的 QA 的任務
在人們剛開始研究 QA
在人類剛開始想要用
這個 Deep Learning 的技術
解 QA 的問題的時候
一開始人們覺得 QA 的問題太難了
我們要用 Neuron Network
用 Deep Learning 的技術解它
感覺非常地困難
所以 Facebook 呢
就先定義了二十個簡單的 QA 的任務
它們叫做 bAbi
那這些 QA 的任務不是真實的 QA 的任務
你如果打開你的作業七的資料
跟 bAbi 的資料進行比較的話
你會發現你作業七的資料是
遠比 bAbi 難得多的
bAbi 裡面的文章都是用某種規則生成的
用某種 Template
固定的句型生成的
問題也是用固定的句型生成的
所以 bAbi 是一個非常簡單的任務
它裡面看起來就像這樣
Mary 把蛋糕給了 Fred
然後 Fred 把蛋糕給了 Bill
然後 Bill 把牛奶給了 Jeff
然後問你說誰把蛋糕給了 Fred
答案是 Mary
就這麼簡單
或者是第十五個任務裡面是
羊會怕狼
貓會怕狗
然後老鼠會怕貓
然後呢 Gertrud 它是一個羊
那它怕什麼
它怕狼就這樣
都是這麼簡單
這麼簡單的問題
今天你一定會覺得說
這個問題對 Network 來說不是問題
作業七都學得起來
這麼簡單的問題沒有學不起來的道理
不過在當年啊
能夠讓機器學會這麼簡單的問題
人們已經覺得非常震驚了
好 那接下來我們要做的事情是
讓機器依序學過這二十個 QA 的任務
那一般 bAbi 的使用方法是把
二十個任務通通倒在一起
讓機器一次學二十個任務
或者是二十個任務就 Train 二十個模型
那二十個模型各自有不同的技能
那我這邊想要做的事情是
把二十個任務一字排開
讓機器從第一個任務學起
學到第二十個任務
那看看它能不能夠把二十個任務都學會
好 那這邊的結果是這個樣子
我們這邊只看任務五的正確率
所以這個縱軸呢
是任務五的正確率
橫軸呢
是依序學二十個任務的過程
好 那任務五就是這麼簡單
就是我們剛才看過的那個蛋糕的例子
好 先讓機器學任務一
再學任務二
再學任務三
再學任務四
把這四個任務依序學完
你發現說
欸 任務五都是
正確率都是 0
把任務一到四都學完
任務五正確率都是0
這件事沒什麼好驚訝的
因為它還沒學到任務五啊
所以它當然不知道要怎麼解任務五的問題啊
不教而殺謂之虐嘛
所以它不會解任務五的問題
得到正確率 0%
不能怪你的 Model
而接下來學完任務五以後
會發生什麼事呢
學完任務五以後
正確率直接爆衝變成 100%
因為看過任務五的訓練資料了嘛
機器知道怎麼解任務五
所以任務五正確率變 100%
但是當我們繼續學剩下的任務的時候
會發生什麼事呢
你發現正確率一陣暴跌
當機器學完任務六之後
任務五的正確率就變 0% 了
學完任務七再去測試任務五就變 0% 了
機器只要一學新的任務
舊的任務馬上就忘個精光
那你可能會以為說
會不會是因為機器就是沒有能力
多學好幾個任務呢
其實不是的
剛才在左邊這個圖是任務五的正確率
讓機器依序學這二十個任務
如果我們把二十個任務的資料通通倒在一起
讓機器同時學二十個任務的話會發生什麼事呢
右邊這張圖是機器同時學二十個任務的結果
那這邊的縱軸啊
並不是某一個任務的正確率
而是這個對應到 1 的這個正確率
對應到 1 這個座標的正確率
就代表第一個任務的正確率
第二個任務的正確率
第三個任務的正確率
一直到第二十個任務的正確率 以此類推
你發現讓機器同時學二十個任務的時候
當然有些任務很難
比如任務十九機器學不會
但是機器是可以同時學會多個任務的
有好幾個任務機器都可以得到非常高的正確率
但是這是同時學的狀況
那你讓機器依序學的時候
它就是學了新的東西就忘了舊的東西
而右邊這個實驗告訴我們說
機器明明有能力學多個任務
但是你讓它依序學一個一個任務的時候
它就是不肯把多個任務都學會
所以它明明可以精通多個任務卻不肯做到
它不是做不到
它是是不為也 非不能也
所以你會發現說
當機器依序學多個任務的時候
它就好像是一個腦袋有洞的人
它就像左邊這個人一樣
新的任務進來
舊的東西就掉出去了
它永遠學不會多個技能
而這個狀況叫做 Catastrophic Forgetting
在 Forgetting 前面呢
特別加上 Catastrophic 這個形容詞
因為 Forgetting 遺忘可能
人類也會遺忘啊
所以機器會遺忘也許不是什麼特別驚人的事
但是機器遺忘的程度也未免太過分了
基本上它根本就學不會新的技能
所以這種遺忘前面加上了一個形容詞
叫 Catastrophic 災難性的
告訴我們說
這個遺忘不是一般的遺忘
它是災難性的遺忘
好 講到這邊啊
我們等一下就會繼續來看說
怎麼解災難性遺忘的問題
怎麼讓機器有辦法依序學習多個任務
但在我們繼續討論技術之前
也許你會有一個問題
也許你會問說
等一下
剛才我們不是看到說
只要把多個任務的資料通通倒在一起
機器就可以學多個任務了嗎
把多個任務的資料倒在一起同時學
這個叫做 Multi-Task 的 Training
Multi-Task Training
就可以讓機器學會多個任務了
那這個 Life Long Learning 的問題
有什麼好研究的
但是你想想看喔
假設現在我們要讓機器學
第 1000 個任務
你要讓機器避免遺忘前面 999 個任務
你必須要把前面 999 個任務的資料
通通都拿出來
然後把它跟第 1000 個任務倒在一起
把這 1000 個任務所有的資料通通倒在一起
一起做訓練
機器才能同時學會
同時具有 999 個
同時具有這 1000 個任務
我們要它學的技能
但是在實務上這可能會是有問題的
因為如果我們要讓機器學第 1000 個技能
需要前面 999 個任務的資料
那意味著機器需要把它一輩子看過的資料
通通都背在身上
它必須要把一輩子看過的資料
通通都存下來
你可能根本沒有那麼大的空間
可以儲存所有的資料
而另外一方面呢
Computation 也是一個問題
如果我們今天需要把 1000 個任務的資料
通通倒在一起
才能進行訓練
那這個訓練的時間可能太長了
1000 個任務的資料全部倒在一起
可能太多了
那你訓練的時間可能會太長
那你就沒有辦法讓機器學習多個任務
所以假設今天機器一定要做
Multi-Task Learning
才能夠學習多個任務的話
那就好像是說有一個人
假設我們要叫他上一門新的課
他必須要把他這輩子所有學過的課
所有讀過的教材
通通都再讀一遍
他才有辦法學習新的任務
那這樣顯然非常沒有效率嘛
而且隨著你要學的任務越來越多
你訓練的時間就會越來越長
你需要儲存的資料也會越來越多
所以 Multi-Task Training
雖然可以讓機器學習多個任務
但是它不是解決 Life Long Learning
最終的 Solution
那在文獻上啊
通常會把 Multi-Task Training
看作是 Life Long Learning 的 Upper Bound
就是如果我們把所有的資料通通倒在一起
雖然當任務多的時候
這是一個不切實際的做法
但是它可以讓機器學會多個任務
這把所有的任務倒在一起一次做訓練
Multi-Task Learning
往往視為是
Life Long Learning 的 Upper Bound
是 Life Long Learning 沒有辦法超越的結果
所以你在做 Life Long Learning 研究的時候
你往往會
比如說先跑個 Multi-Task Training 的結果
告訴我們說 Upper Bound 在哪裡
然後再看看你的 Life Long Learning 的技術
能不能夠逼近這個 Upper Bound 的結果
好 我們來看一下有沒有同學有問題
好 有同學說呢
Multi-Task Learning 等於是讓機器做複習
Performance 當然比較好
對 對 我們現在要問的就是
在不准複習的前提之下
可不可以不要忘記之前看過的東西
不要每次學新的東西都一定要複習舊的東西
好 有同學問說
會有這種 Catastrophic Forgetting 的現象
是因為它的 Loss 是根據多個 Task 做調整的嗎
可以說是
等一下我們其實會解釋
Catastrophic Forgetting 的現象是怎麼來的
有同學說分別學 再做（00：19：18）
等一下我會告訴你說
或下一頁投影片會告訴你說
分別學會有什麼樣的問題
好 有同學說
如果是接著學
把舊的 Parameter 改成不好的方向
卻沒有用原本的 Loss
把它校正回來是這樣嗎
對 對 沒錯
等一下我們就會解釋
Catastrophic Forgetting 為什麼會發生
但跟這位同學他名字是日文的
講的是蠻類似的
好 我們就繼續吧
好 下一頁投影片就是
那我們怎麼不每一個任務
就學一個模型就好了呢
幹嘛要那麼執著於
Life Long Learning 的問題呢
為什麼一定要讓一個模型學多個任務呢
為什麼不一個任務
一個任務學一個模型就好了呢
如果我們只讓
讓每一個任務都分開學一個模型
確實就沒有 Catastrophic Forgetting 的問題
但是我們會遇到的第一個問題是
假設我們要叫機器學的技能
非常非常地多
我們要學個天網
天網總是要會上億個技能吧
我們總不能每個技能都有一個模型吧
這樣子你可能沒有辦法把所有的模型儲存下來
另外一方面
如果我們是不同的任務就用不同的模型
不同任務的資料間就不能夠互通有無
它沒有辦法從其他的任務裡面
汲取單一個任務所沒有辦法學到的資訊
而且你想想看
對人類來說我們只有一個腦
但這個腦卻可以學會多種不同的任務
不斷學會新的技能
我們並不需要每一個任務
都用一個獨立的腦來儲存
但是為什麼機器不能夠做到一樣的事情呢
這個就是 Life Long Learning 想要探討的問題
能不能一個模型學多個任務
好 那講到這邊有的同學可能會說
這個聽起來跟 Transfer Learning 挺像的
Transfer Learning 就是讓機器在任務一上學習
希望任務一上學到的技能
可以 Transfer 到任務二上面去
但是 Life Long Learning 跟 Transfer Learning
雖然它們都是叫機器學多個任務
但它們的關注點是不一樣的
在 Transfer Learning 裡面
我們在意的事情是
機器在第一個任務上面學到的技能
能不能夠對第二個任務有幫助
所以我們只在意在第二個任務上
機器做的好不好
但 Life Long Learning 的關注點是不一樣的
Life Long Learning 的關注點是
當機器學完第二個任務的時候
回過頭去再看第一個任務
它到底還能不能夠解第一個任務
所以雖然 Life Long Learning
跟 Transfer Learning
都會 Involve 兩個任務
都要考慮兩個任務
但 Transfer Learning 在意的是
新的任務做得怎麼樣
而 Life Long Learning 它是在意
舊的那個任務做得怎麼樣
好 那在講 Life Long Learning 的技術之前
我們來講一下
怎麼評估一個 Life Long Learning 的技術
做得好不好
當然要做 Life Long Learning 之前
你得先有一把任務
讓機器可以依序做學習
但是其實今天
如果你看那些 Life Long Learning 的文獻的話
所謂這個一把任務
往往都是比較簡單的一些任務
一個常見的 Setting 是這個樣子
你的任務一 是做手寫數字辨識
任務二其實還是手寫數字辨識
但是這些點點
這些看起來像是星
這些看起來像是星星的圖
到底是在做什麼呢
這些是我們把每一個數字
用某一種特殊的
用某一種固定的規則把它打亂
那每一個任務
就是把數字做不同的打亂
就成為不同的任務
那 Permutation 呢
還算是比較難的
還有看過更簡單的是
把所有的數字轉
往右轉 15 度算是新的任務
往左轉 15 度也算是新的任務
那所以每一個任務都還是數字
只是呢圖片的角度不太一樣而已
那這樣你也可以來研究 Life Long Learning
或者是另外一種狀況是
你的任務一是要讓機器分辨 0 跟 1
任務二是要讓機器分辨 2 跟 3
任務三是要讓機器分辨 4 跟 5
以此類推
但是對機器來說
0 就是第一個 Class
1 就是第一個 Class
然後 2 就是第一個 Class
3 就是第二個 Class
4 就是第一個 Class
5 就是第二個 Class
所以今天你給它一張 5
它是第二
它是要判斷 5 屬於第二個 Class
判斷 3 屬於第二 Class
1 屬於第二個 Class
然後 0 2 4 屬於第一個 Class
然後依序進行訓練
那這個 Life Long Learning
這個作業是選擇題
那助教也有提供一些程式
但是這些程式你能夠跑過是最好
但我們要的就不是程式的結果
是根據程式的內容問大家一些問題
那其中一個送分的問題就是會問你說
在助教的程式裡面
所謂的不同的任務是怎麼樣定義的
看到同學有些問題
那我來回答一下
有方法可以讓 NN 加一些約束
讓它和原本的參數不要差太多
讓它記得舊的任務怎麼做嗎
太好了 其實就是這樣解的
這就是等一下 Life Long Learning 的
其中一個最常用的解法
算是被破梗了
我們需要的是讓機器只有一個使命
後面還給打一個叉 好
好 那我們就繼續吧
那這邊呢是有關任務 Sequence 的定義
那再來要講
我們如果有一堆任務的話
我們怎麼評估一個 Life Long Learning 的演算法
做得好不好呢
你評估的方法是這個樣子的
好 你有一排任務
有一排任務
然後呢你先有一個隨機初始化的參數
把這隨機初始化的參數
用在這大 T 個任務上
得到大 T 個正確率
你有這大 T 個任務的 Casting Set
把隨機初始化的參數用在這大 T 個任務上
得到大 T 的 Accuracy
大 T 個 Accuracy
然後接下來
你讓 Model 先學第一個任務
學完第一個任務
拿第一個任務的訓練資料出來
學完第一個任務以後在這 T 個任務上
再去量一次正確率
然後學完第二個任務以後
再去這 T 個任務上再量一次正確率
學到第 T-1 個任務以後
在這 T 個任務上再學一次正確率
學完最後一個任務以後
在這 T 個任務上再算一次正確率
你會得到這樣一個表格
接下來呢你會用這個表格呢
來判斷一個 Life Long Learning 的 Model
做得怎麼樣
那在這個表格裡面
每一個數值指的就是
某一個任務它的測試資料的正確率
那這個表格裡面的每一個數值呢
都有兩個下標 i 跟 j
第一個下標代表說呢
這個是訓練完第 i 個任務以後的正確率
第二個下標指的是
這是在第 j 個任務上的正確率
比如說 R2,1 的意思就是說
現在呢你的 Model 剛學完任務 2
它在任務一的正確率上怎麼樣
RT-1,2的意思就是說呢
你的模型剛學完大 T-1 這個任務
在任務二上表現的怎麼樣
好 所以如果我們今天看的
是 i 大於 j 的那一些正確率的話
那意味著什麼呢
i 是比較後面的任務
j 是比較前面的任務
就我們要知道
我們想要知道的事情是
今天讓模型訓練完任務 i 以後
它在過去已經訓練過的任務 j 上
到底表現得怎麼樣
它有沒有忘記任務 j 過去學過的東西
如果今天
我們看的是 i 小於 j 的那些 R 的話
那代表什麼
代表是說我們剛學完任務 i
還沒去學任務 j
但機器會不會就無師自通
已經會解任務 j 了呢
這邊要看的是機器 Transfer 的能力
在新的沒有看過的任務上
Transfer 的能力怎麼樣
好 那最常見的
評估一個 Life Long Learning 系統的方法
就是把最後這個 R 的正確率加起來就結束了
你就讓你的模型依序學過所有的任務
到最後的任務都學完以後
去之前所有的任務上面
都算一遍正確率
平均起來就代表
你的 Life Long Learning 的方法的好壞
當然這個值可能會是最高的
因為剛學完任務大 T
在任務大 T 上當然表現最好
在前面的任務
那你的模型就會逐漸忘記
第一個任務可能就是忘記得很慘了
完全忘記了
可能正確率是趨近於零的
第二個任務可能稍微好一點
正確率 1 2% 等等
那把這些所有的正確率平均起來
就是評估一個 Life Long Learning 系統的好壞
常見的用法
那其實還有其他的評估方法
有一個評估方法叫做 Backward 的 Transfer
這個 Backward 的 Transfer 呢
是拿兩個數值出來相減
它是拿 RT-1 去減掉 R1,1
拿 RT-2 去減掉 R2,2
以此類推
然後把所有的任務都加起來做平均
那這個值呢就是 Backward 的 Transfer
那這個 RT,1 減 R1,1
這邊是拿 RT,1 減 R1,1
或者是 RT,2減 R2,2
RT,2 減 R2,2
它們到底是什麼意思呢
它們的意思是說
當你的模型先學完任務一的時候
在任務一上的正確率
跟學到大 T 個任務完以後
在任務一上的正確率差多少
當學完任務一的時候記憶猶新
這個時候正確率是最高的
那隨著學的任務越來越多
那你的正確率就會不斷地遞減
那到底會減少多少呢
所以我們把這兩個 R 進行相減
可以評估說現在遺忘的程度有多嚴重
那因為呢機器每次看到新的任務以後
舊的任務就會不斷遺忘
所以你可以想見說
RT-1 通常是比 R1,1 小的了
RT-2 通常是比 R2,2 小的了
所以如果你是拿 RT,1 減 R1,1
RT,2減 R2,2 的話
你通常得到的值是負的
所以 Backward Transfer
通常算出來的值是負的 是小於 0 的
如果你今天可以提出一個
Life Long Learning 的方法
它很厲害
它的 Backward Transfer 算出來是正的
那你就很厲害了
因為通常 Backward Transfer 都是負的
如果你說
機器學了新的任務以後
它還可以觸類旁通
把原來的任務一做得更好
它學完新的任務以後觸類旁通
把原來的任務二做得更好
那你就
你提出來的 Life Long Learning 就很厲害了
一般 Life Long Learning 做不到這件事
通常只要這個值不要負得太嚴重
就已經很厲害了
好 那還有一種評估方式
叫做 Forward Transfer
那 Forward Transfer
通常就比較不是 Life Long Learning 的重點
Forward Transfer 想要問的問題是說
今天在看過一系列的任務
我這個有點卡頓
我也不知道為什麼
我的那個滑鼠有點卡頓
好 不過沒關係
我們現在看看同學有沒有問題
好 大家沒有問題
好 我們繼續講
好 今天這個 Forward Transfer
要問的問題是說呢
在還沒有看過某個任務
只看過其他任務的時候
機器到底已經學到什麼樣的程度
所以你在做 Forward Transfer 的時候
你就是拿 RT-1,T 去減 R0,T
這個 RT-1,T 去減 R0,T
到底意思呢
它的意思是說
今天在還沒有看到任務大 T 的時候
只看到任務 T1 到 T-1
只看到任務 T1 到 T-1 的時候
你的模型到底可以學出什麼樣程度的結果
這個是 Forward Transfer
好 那接下來就是準備要進入
這個 Life Long Learning 的解法
