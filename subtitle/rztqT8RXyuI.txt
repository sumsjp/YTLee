hi i'm iachin a phd student in national
town university and i intern at nvidia
air technology center
i want to present my work darth asr
differentiable architecture search for
multilingual speech recognition and
adaptation
co-authored by rayang tsungkwan and
hongyi
so first of all let me introduce the
background and motivation
architectural design has played an
important role in deep learning
for example researchers have kept
inventing new state-of-the-art cm model
architectures
on image classification tasks the
original vg model has a simpler
architecture with lower accuracy on
imagenet
dataset and essentially
inception models have more complex
architectures
and better performance however
traditionally the architectural design
of such successful models have always
relied on human experience and intuition
taking a lot of effort on trial and
errors to design
complex architectures
so many researchers started to study
neural architecture search
on image classification its goal is to
use a search algorithm
to automatically search for a good
architecture in a predefined search
space
for example a mobile net achieves better
accuracy
than models designed by human we can
further take a look at this figure
edge point represents a model with its
corresponding parameter size
and accuracy on imagenet
efficient nets on the red lines and
[Music]
a mobile nets nas nets on the blue line
are
architectures found by some architecture
search algorithms
these automatically found architectures
have better performance
on image classification than traditional
human design models
under the condition of similar parameter
size
however on the task of speech
recognition
there is little attention on neural
architecture search
even the traditional vgg architecture is
still used in many
sr models so in this work
we want to study neural architecture
search on asl models
there are two settings in this work in
the first one
we perform monolingual asr given data of
a language
we want to use an architecture search
algorithm to find a good architecture
for
this language
in the second one we perform
multilingual sr
where we have data of several languages
in this setting we want to use the
architecture search algorithm to find
one general good architecture for many
languages
so in this paper we propose darth asr
differentiable architecture search
automatic speech recognition
it consists of a cn module a biosta
module
and several decoding heads the input x
is a segment of acoustic features such
as small filter banks
and for each different language a
specific hat is used to upgrade the
transcription text sequence
the objective function is that cdc loss
computed with our predictions and labels
and we use differentiable architecture
search on the cn module to find
a good scene architecture next i'm going
to describe differentiable architecture
search
or darts if we want to transform a cn
feature map into another
we have many choices such as
convolutions
pooling or skip connection so the goal
of darts
is to select the suitable transformation
for
future maps automatically first of all
we have to define some transformation
candidates
and each candidate can transform the
imperfection map into another
then the witty sum g of h of these
transformed feature maps
is computed with some continuous
variables alpha
and with this softmax equation
here the f represents a transformation
candidate
and this softmax over transformations
can be regarded as the selection
of architecture to be simpler
let's call the softmax weighted sum
operation between the transformational
feature map geofetch
and the original feature map h and h
then for the whole search space of darts
we can define
many intermediate feature maps for each
feature map
there are input edges connected with all
its
previous feature maps the feature map
outputs of these
input edges are summed into one final
feature map
and the variables alpha in softmax are
jointly trained with parameter weights
directly by gradient descent
this optimization process can be
considered as
controlling the architecture and
parameter weights together
in our following experiments we have two
settings monolingual and multilingual
asr
the dataset is the multilingual corpus
payment
we use four target languages in babel
for training and testing
and in the multilingual setting three
additional
languages are used to train the model
the acoustic features are 80 dimensional
male filter banks
and three-dimensional pitch features
i'll describe the two settings in more
details later
and there are seven transformation
candidates used in darts
in this paper including standard
convolutions dialectic
makes pooling average pooling and scale
connection
the fixed architecture bjg has commonly
used in asr models
so it serves as our baseline
to measure the depth of bgg our search
space of stars
consists of five intermediate feature
maps
first i want to show the monolingual sr
results
in the monolingual sr setting for each
different target language
a different asl model is trained and
test separately with data of this
language
here are the character arrays of each
model using different cn modules on
different
target languages the second right most
column
the full dark star means there are seven
transformation candidates that this
as described before before
and the rightmost column they only come
three by three
dart csr means there is only three by
three convolution in each age
so in the whole cn module there are only
three by three convolutions to transform
the future maps
we adjust the channel size and
convolutions to make the parameter size
match for ultra sr
from this table we can see the full dart
csr outperforms
the only convolution 3x3 dot csr
it indicates the variety
of transformation candidates is actually
helpful
allowing darts to search for a suitable
transformation
in each age and the left most come in
this table
vgg small is commonly used in literature
and visually large is the one with
larger channel size
matching the parameter size of two dars
csr variants
from this table we can see both two rsi
variants
are performed two residue variants
it indicating given the same depth and
parameter size
they automatically searched
architectures can perform better than
fixed architectural models we also plot
the curves of validation losses of elsa
models
with vug or the 4.sr the solid lines
are the results of vgg and the dashed
lines are
those of those heads are from these
lines
we can observe the convergence of visual
is generally faster than dart csr
but rssr can reach much lower validation
losses in the end
we further plot and analyze the search
architectures by the full darcr
to simplify the illustration of
architecture we use a node to
represent a feature map and for each
node
we plot the most dominant transformation
among all
candidates in all input ages
the third architectures for each
language on monolingual asr is shown
here
the architectures of vietnamese and
swahili are similar
they are very shallow and all of the
dominant transformations are standard
convolutions
the architectures of tamiya and
kermangji are quite different from one
another
interestingly in deeper architectures
the dialectic convolutions are used more
often
next i'm going to describe the
multilingual sr setting
in this setting we pretend a single
shared asr model on
all source languages except different
hats for different languages
hoping to find a generally good
architecture for many languages
then we here in the pre-trained model on
target languages
to see the generalizability of darth asr
as for fighting we experiment with three
adaptation approaches in multilingual sr
the first one we adapt only parameter
weights
the continuous variables of our from
training are fixed
that is the network architecture is
learned from the source languages
and with the learned languages and with
the learned architecture
its network parameters are learned from
the talking language
in the second one we adapt both
parameter ways and
architecture both alpha and parameter
weights and
transformations keep being trained that
is both the network architecture and
network parameters learned from source
languages
are further fine-tuned on the target
language
in the third one the architecture
learned from the source languages
is proved by removing all
transformations
but the top few ones with the highest
alpha values in each age
then the print alpha keeping fine tune
during the with remaining parameter
weights
so we present the asr results under the
monolingual setting
the model is first portrayed on three
source languages and
adapted on the same four defending
target languages
we first compare three adaptation
approaches
from this table we can observe that
adapting
both architecture and parameter ways
obtains the best performance on every
cer
however the other two application
approaches are
only a little worse it is in case after
pre-training
darth asr can find a generally good
architecture and parameter ways for
different languages
and the prune architecture can reduce
computational
cost while suffering little performance
drop
then use the final fine-tuning approach
that adapts both architecture and
parameter ways for dot csr
in the following experiments in this
table
vgg modules and rsr are compared in the
multi-lingual sr setting
all three kinds of cm modules get much
better performance on
multi-lingual sr than monolingual asr
among those darth asr still outperforms
for bgg
and visually small ambitious large by a
significant margin
it indicates that sr can also benefit
from multilingual learning
to build a shared acoustic trend model
with a better
architecture and parameter ways here we
also plot the search
architectures of star csr on four target
language
for multilingual sr of the four search
architectures are quite similar
convolutions with larger condo sizes
are dominant here they are all five by
five
similarly dialectic convolutions are
dominant in deeper architectures
this result shows that this kind of
architecture
is the architecture generally suitable
for a wide range of languages
in conclusion we apply a differentiable
architecture search approach on asr
and the architecture searched by darshan
sr can achieve
better performance on both monolingual
and multilingual asr
than traditional fixed architecture
models in addition
multilingual pre-training for
architectures can help find
an architecture generally suitable for a
wide range of languages
in future work dart csr can be
incorporated with other asr or meta
learning approaches for further
improvement
we can also experiment on larger scale
models or data sets
moreover we may also experiment on
different speech related tasks
and we can explore some new
transformation operations
thanks for your attention
