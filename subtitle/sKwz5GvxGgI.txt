hello everyone thanks for watching my
presentation I'm having a PhD student in
National Taiwan University today I'm
gonna talk about a nice paper defence
against Oliver several tanks on spoofing
con the measures of automatic speaker
verification this is an outline today
today's presentation is divided into
five parts motivation by the Rosario
attack/defense experiment and the
conclusion let's talk health alone
motivation automatic speaker
verification chocodiles ASV in self
great importance for biometric
identification and great number of ESP
systems have been proposed
most of them come with high performance
however high performance and speed
systems still be deceived by spoofing
audios toughest audios generated by
audio replay text-to-speech are for its
conversion we also need strategies to
filter the spoofing audios so we need
hunti spoofing models and his moving
model is a protector for HV systems it
protects the SV systems by identifying
the spoofing audios the van blocking
them for example if the audio is the
piece of spoofing audio generated by
voice conversion the anti-spoofing model
will pay for it spoofing and the
blockage well if the input is the piece
of users audio the anti-spoofing model
will label it non spoofing and allow the
audio to pass to the edge fin system in
the healthy spoof 2019 challenge
finding high-performance anti-spoofing
models have been proposed
however previous works show that
high-performance anti-spoofing models
are subject to aniversario attacks
let me introduce bodies out of a serial
attack here suppose X is a piece of
spoofing hockey anti-spoofing model but
label it spoofing and the blockage
however if some attackers can generate a
text signal Delta and then add it to the
original audio pegs to generate and
Rosario example X tohe remark tights the
noise tilde is carefully designed such
that the modified audio X tilde is
indistinguishable from the original
audio eggs for human ears but the
classification result will be different
extra will make the anti-spoofing model
only predict nonce moving and the
exposed the SV system to the attackers
this phenomenon will cause some security
problems so we want to rest of our
ability Fanta spoofing models to
otherwise aerial attacks and the device
defense measures now I'd like to move on
to the second part of the presentation
adversarial attack first I would like to
show you how to fund
adversarial examples look at what we
have we have the original example X
anti-spoofing model F parameter by theta
we want to find a tactic known pella to
generate adversarial example AK told her
to make the prediction of FX and FX tada
different as possible how to do it's
just like training a neural network
pathway optimize the input X rather than
networks parameter theta
specifically we fix the model parameters
and we do brilliant descent to find a
supercar to fulfill this equation our
objective is to make the prediction
affectaura
as different as possible to FX also we
want extra to be a similar context so
that human cannot tell the difference
between them so Tara the noise shouldn't
be too large in this paper we constrain
the 13 space for Delta in a small
infinity norm then I'd like to talk
about the tag method in this paper we
use the protective brilliant descent PGG
as attack method
our objective is to find X star for view
this equation and we use PTT PTT is an
iterative method in PT I start from
input X 0 which equals to the original
example X and it is iteratively updated
and States equation in each iteration we
take the gradient of the function with
respect to X stem function simply takes
the son of the gradient then we multiply
it by alpha then we added to XK finally
we use the clip function to project this
term back into the 13 space we defined
before let's move on to defend methods
the first one spatial smoothing many
people also call it filter under several
example
composter of the original audio and the
dangerous attack signal before putting
adversarial example into the
anti-spoofing model for
today we put it into a filter in order
to let the text signal become less
harmful but without influencing the
classification result of the original
audio there are lots of filters in this
work in pewter cauldron filter and
medium filter i used then how can we to
filter look at a spectrogram take out a
3 by 3 min filter as an example one way
to filter it with a spectrogram of 3 by
3
slicing window moves over the
spectrogram and the central value in the
window will be replaced by the mean of
the values in the slicing window
different filters result in different
ways to calculate the central value in
filter uses a mean Gaussian filter uses
the this equation the median filter uses
a median the tagging defense method is a
personal training the basic idea of
Hydra stereo training is to find and fix
the blanks port of the anti-spoofing
model given the training data we first
train the anti-spoofing model and then
we do the two steps iterative Li step 1
find the plants ports
given the anti-spoofing model and the
original data for use PGD to generate
adversarial examples
step 2 fix the plant spores we have
several examples then we use both the
original example and the adversarial
examples to return the anti-spoofing
model the way to step 1 and step 2
iteratively until converge
get into the experiment part for the
datasets we used to have a partition in
ESB spoof 2019 until at her site
contains fake audios generated by TDS
and the VC models
the higher a partition is itself divided
into evaluation development and a
training set we directly follow the
partition two different anti-spoofing
models are used as annette and the VCG
we just simply borrow the model
structures from previous papers so if
you are interested in more details about
the two models you can read their papers
the tag method we use is PGD two
different methods including spatial
smoothing and the restaurant training
are used now let's get into the defense
performance the numbers in the table
testing accuracy of a scene edge
according to the table as in that
retrieves high performance in in
original examples however when we test
the model to adversarial examples the
testing accuracy troughs drastically so
the as in that is subject to adversarial
attack let's look at the spectrogram of
the original example under the interval
zero example from humans eye it is
indistinguishable we also did subjective
listening test the result is that the
listeners cannot tell the different
difference between adversarial examples
and the original examples ok this column
from way firstly to filter Tula and
Mysterio exam host before evaluating the
testing accuracy there is a great
increase in testing accuracy all three
kinds of filters help me improve
robustness of anti-spoofing models
and that we can see the improvements of
culture and filter instead it is less
than the other two filters comparing
this role before aniversario training
the testing accuracy for adversarial
example is below 50% after all to the
thorough training it increases to over
90% so at the Rosario training improves
the robustness of anti-spoofing models
look at this column only use and over
several training the testing accuracy is
92.4% adding medium filter or mean
filter helps increase it increase the
testing accuracy however adding Gaussian
filter decreases the testing accuracy in
our experiments I think medium filter
and the mediator are more desirable
filters than culture and filter this is
the testing accuracy for PGG we can see
a similar phenomenon for vgg compared
with as Annette and the conclusion post
adversarial training and the spiritual
smoothing can make the anti-spoofing
models robust enough to counter
adversarial attacks and I think what
different matters should be adopted to
improve the robustness of anti-spoofing
models that's all I have
thanks for listening
