臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心http://ai.ntu.edu.tw/
今天的計畫是這樣 今天會講四件事
會講一些用 GAN 和 Feature Extraction 有關的事情
然後會講 Cycle GAN，或者是用 GAN 做 Unsupervised Conditional Generation
用 GAN 做 Unsupervised Conditional Generation 是作業 3-3 要做的事情
接下來會講 WGAN
最後會講一些 GAN 的應用 怎麼用 GAN 來做一個智能的 Photoshop
最後助教會來講作業 3-3
第一堂課就來講一下一些和用 GAN 做 Feature Extraction 有關的事情
我想先跟大家講的是 InfoGAN
大家在作業 1 裡面或作業 3-1 3-2 也都會 train 一個 GAN
我們知道 GAN 會 random input 一個 vector
然後 output 一個你要的 object
我們通常期待 input 的那個 vector 它的每一個 dimension 代表了某種 specific 的 characteristic
你改了 input 的某個 dimension
output 就會有一個對應的變化
然後你可以知道每一個 dimension 它做的事情是甚麼
但是實際上未必有那麼容易
如果真的 train 了一個 GAN 你會發現
input 的 dimension 跟 output 的關係 有甚麼觀察不到甚麼關係
這邊這是一個文獻上的例子
假設 train 了一個 GAN 這個 GAN 做的事情
是手寫數字的生成
你會發現你改了 input 的某一個維度
對 output 來說 這邊這個橫軸
代表說改變了 input 的某一個維度
output 的變化是看不太出規律的 比如說這邊的 7
突然中間寫了一橫也不知道是甚麼意思 搞不清楚說
改變了某一維度到底對 output 的結果
起了什麼樣的作用
為甚麼會這樣呢
因為我們原先期待說假設 現在這個投影片上這個二維平面
代表 generator input 的 random vector 的 space
假設 input 的 vector 只有兩維
我們通常期待在這個 latent 的 space 上面
不同的 characteristic 的 object 它的分布是有某種規律性的
我們這邊用不同的顏色來代表 假設你在這個區塊
你使用這個區塊的 vector 當作 generator 的 input
它 output 會有藍色的特徵，這個區塊會有橙色的特徵 這個區塊會有黃色的特徵，這個區塊會有綠色的特徵
本來的假設是這些不同的特徵 他們在 latent space 上的分布是有某種規律性的
但是實際上也許它的分布是非常不規則的
我們本來期待如果改變了 input vector 的某一個維度
它就會從綠色變到黃色再變到橙色再變到藍色 它有一個固定的變化
但是實際上也許它的分布長的這個樣子
也許 latent space 跟你要生成的那個 object 之間的關係 是非常繁複的
所以當你改變某一個維度的時候 你從藍色變到綠色再變到黃色又再變回藍色
你就覺得說不知道在幹嘛
所以 InfoGAN 就是想要解決這個問題
InfoGAN 的概念是這樣 這邊是一個原來的 GAN
我們知道原來的 GAN 就是有一個 generator 有一個 discriminator
在 InfoGAN 裡面你會把 input 的 vector 分成兩個部分
比如說假設 input vector 是二十維 就說前十維把它叫作 c
後十維我們把它叫作 z'
在 InfoGAN 裡面你會 train 一個 classifier
這個 classifier 工作是甚麼
這個 classifier 工作是他看 generator 的 output
然後決定根據這個 generator 這個 output 去預測現在 generator input 的 c 是甚麼
所以這個 generator 吃這個 vector
產生了 x，classifier 要能夠從 x 裡面反推原來 generator 輸入的 c 是什麼樣的東西
在這個 InfoGAN 裡面 你可以把 classifier 視為一個 decoder
這個 generator 視為一個 encoder
這個 generator 跟 classifier 合起來 可以把它看作是一個 Autoencoder
它跟傳統的 Autoencoder 做的事情是正好相反的 所以這邊加一個雙引號
因為我們知道傳統的 Autoencoder 做的事情是給一張圖片，他把它變成一個 code
再把 code 解回原來的圖片
但是在 InfoGAN 裡面這個 generator 和 classifier 所組成的 Autoencoder 做的事情
跟我們所熟悉的 Autoencoder 做的事情 是正好相反的
在 InfoGAN 裡面，generator 是一個 code 產生一張 image
然後 classifier 要根據這個 image 決定那個原來的 code 是甚麼樣的東西
當然如果只有 train generator 跟 classifier 是不夠的 這個 discriminator 一定要存在
為甚麼 discriminator 一定要存在
假設沒有 discriminator 的話
對 generator 來說 因為 generator 想要幫助 classifier
讓 classifier 能夠成功的預測 x 是從什麼樣的 c 弄出來的
如果沒有 discriminator 的話 對 generator 來說
最容易讓 classifier 猜出 c 的方式就是直接把 c 貼在這個圖片上，結束
就把 c 貼在圖片的中間
然後 classifier 只要知道他去讀這個圖片中間的數值 就知道 c 是甚麼
那這樣就完全沒有意義不是我們要的
所以這邊一定要有一個 discriminator
discriminator 會檢查這張 image 看起來像不像是一個 real image
如果 generator 為了要讓 classifier 猜出 c 是甚麼
而刻意地把 c 原本的數值
我們期待是 generator 根據 c 所代表的資訊 去產生對應的 x
但 generator 它可能就直接把 c 原封不動貼到這個圖片上
但是如果只是把 c 原封不動貼到這個圖片上
discriminator 就會發現這件事情不對
發現這看起來不像是真的圖片
所以 generator 並不能夠直接把 c 放在圖片裡面 透露給 classifier 知道
InfoGAN 在實作上 discriminator 跟 classifier 往往會 share 參數
因為他們都是吃同樣的 image 當作 input
不過他們 output 的地方不太一樣 一個是 output scalar，一個是 output 一個 code、vector
不過通常你可以讓他們的一些參數是 share 的
為甚麼用 InfoGAN 這個架構 為甚麼加上這個 classifier 以後
會有甚麼好處 我們說我們剛才想要解的問題就是
input feature 它對 output 的影響不明確這件事
InfoGAN 怎麼解決 input feature 對 output 影響不明確這件事呢
InfoGAN 的想法是這個樣子
為了要讓 classifier 可以成功地從 image x 裡面知道原來的 input c 是甚麼
generator 要做的事情就是
他必須要讓 c 的每一個維度
對 output 的 x 都有一個明確的影響
如果 generator 可以學到 c 的每一個維度對 output 的 x 都有一個非常明確的影響
那 classifier 就可以輕易地根據 output 的 image 反推出原來的 c 是甚麼
如果 generator 沒有學到讓 c 對 output 有明確影響 就像剛看到那個例子
改了某一個 dimension 對 output 影響是很奇怪的
classifier 就會無法從 x 反推原來的 c 是甚麼
在原來的 InfoGAN 裡面他把 input z 分成兩塊 一塊是 c 一塊是 z'
這個 c 他代表了某些特徵 也就是 c 的每一個維度代表圖片某些特徵
他對圖片是會有非常明確影響
如果你是做手寫數字生成，那 c 的某一個維度可能就代表了那個數字筆畫有多粗
那另外一個維度可能代表寫的數字的角度是甚麼
其實在 generator input 裡面還有一個 z' 在原始的 InfoGAN 裡面他還加一個 z'
z' 代表的是純粹隨機的東西 代表的是那些無法解釋的東西
那有人可能會問這個 c 跟 z' 到底是怎麼分的
我們怎麼知道前十維這個 feature 是應該對 output 有影響的，後十維這個 feature 他是屬於 z'
對 output 的影響是隨機的呢 你不知道
但是這邊的道理是這個 c 並不是因為它代表了某些特徵
而被歸類為 c
而是因為他被歸類為 c 所以他會代表某些特徵
大家可以聽得懂這個意思嗎
這是個充滿哲理的話 我不知道大家聽不聽得懂我的意思
並不是因為他代表某些特徵所以我們把他設為 c
而是因為他被設為 c 以後根據 InfoGAN 的 training
使得他必須具備某種特徵
希望大家聽得懂我的意思
這個是 InfoGAN
這個是文獻上的結果
第一張圖是 learn 了 InfoGAN 以後
他改了 c 的第一維，然後發現甚麼事
發現 c 的第一維代表了 digit
這個很神奇，改了 c 的第一維以後
更動他的數值就從 0 跑到 9
這個 b 是原來的結果，他有做普通的 GAN
output 結果是很奇怪的
改第二維的話你產生的數字的角度就變了
改第三維的話你產生的數字就從筆劃很細變到筆劃很粗
這個就是 InfoGAN
另外一個跟大家介紹的叫作 VAE-GAN
VAE-GAN 是甚麼
VAE-GAN 可以看作是用 GAN 來強化 VAE
也可以看作是用 VAE 來強化 GAN
VAE 在 ML 有講過的就是 Autoencoder 的變形
這個 Variational Autoencoder
Autoencoder 大家都很熟 就是有一個 encoder
有一個 decoder，encoder input x output 是一個 z
decoder 吃那個 z output 原來的 x
你要讓 input 跟 output 越近越好
這個是 Variational Autoencoder
如果是 Variational Autoencoder 你還會給 z 一個 constrain，希望 z 的分布像是一個 Normal Distribution
只是在這邊圖上沒有把它畫出來
那 VAE-GAN 的意思是在原來的 encoder decoder 之外 再加一個 discriminator
這個 discriminator 工作就是 check 這個 decoder 的 output x 看起來像不像是真的
如果看前面的 encoder 跟 decoder 他們合起來是一個 Autoencoder
如果看後面的這個 decoder 跟 discriminator 在這邊 decoder 他扮演的腳色其實是 generator
我們看這個 generator 跟 discriminator 他們合起來是一個 GAN
在 train VAE-GAN 的時候，一方面 encoder decoder 要讓這個 Reconstruction Error 越小越好
但是同時 decoder 也就是這個 generator 要做到另外一件事
他會希望他 output 的 image 越 realistic 越好
如果從 VAE 的角度來看
原來我們在 train VAE 的時候
是希望 input 跟 output 越接近越好
但是對 image 來說
如果單純只是讓 input 跟 output 越接近越好
VAE 的 output 不見得會變得 realistic
他通常產生的東西就是很模糊的 如果你實際做過 VAE 生成的話
因為根本不知道怎麼算 input 跟 output 的 loss
如果 loss 是用 L1 L2 norm 那 machine 學到的東西就會很模糊
那怎麼辦，就加一個 discriminator
你就會迫使 Autoencoder 在生成 image 的時候 不是只是 minimize Reconstruction Error
同時還要產生比較 realistic image 讓 discriminator 覺得是 realistic
所以從 VAE 的角度來看
加上 discriminator 可以讓他的 output 更加 realistic
如果從 GAN 的角度來看
前面這邊 generator 加 discriminator 合起來
是一個 GAN 然後在前面放一個 encoder
從 GAN 的角度來看，原來在 train GAN 的時候
你是隨機 input 一個 vector 你希望那個 vector 最後可以變成一個 image
對 generator 來說他從來沒有看過真正的 image 長甚麼樣子
他要花很多力氣，你需要花很多的時間去調參數
才能夠讓 generator 真的學會產生真正的 image，知道 image 長甚麼樣子
但是如果加上 Autoencoder 的架構
在學的時候 generator 不是只要騙過 discriminator
他同時要 minimize Reconstruction Error
generator 在學的時候他不是只要騙過 discriminator 他還有一個目標
他知道真正的 image 長甚麼樣子
他想要產生一張看起來像是 encoder input 的 image
他在學習的時候有一個目標不是只看 discriminator 的 feedback
不是只看 discriminator 傳來那邊的 gradient
所以 VAE-GAN 學起來會比較穩一點
在 VAE-GAN 裡面，encoder 要做的事情就是要 minimize Reconstruction Error
同時希望 z 它的分布接近 Normal Distribution
對 generator 來說他也是要 minimize Reconstruction Error，同時他想要騙過 discriminator
對 discriminator 來說他就要分辨一張 image 是真正的 image 還是生成出來的 image
跟一般的 discriminator 是一樣的
假如你對 VAE-GAN 有興趣的話這邊也是列一下 algorithm
這 algorithm 是這樣
有三個東西，一個 encoder 一個 decoder 一個 discriminator，他們都是 network
所以先 initialize 他們的參數這樣就是他的 algorithm
這 algorithm 是這樣說的
我們要先 sample M 個 real image
接下來再產生這 M 個 image 的 code 把這個 code 寫作 z tilde
把 x 丟到 encoder 裡面產生 z tilde 他們是真正的 image 的 code
接下來再用 decoder 去產生 image
你把真正的 image 的 code z tilde 把 z tilde 丟到 decoder 裡面
decoder 就會產生 reconstructed image
就邊寫作 x tilde，x tilde 是 reconstructed image
接下來 sample M 的 z 這個現在 z 不是從某一張 image 生成的
他們是從一個 Normal Distribution 生成的
這邊的 z 是從某一張 image 生成的
這邊這個 z 是從一個 Normal Distribution sample 出來的
用這些從 Normal Distribution sample 出來的 image
再丟到 encoder 裡面再產生 image 這邊叫做 x hat
現在總共有三種 image
一種是真的從 database 裡面 sample 出來的 image
一個是從 database sample 出來的 image 做 encode
變成 z tilde 以後再用 decoder 再還原出來 叫做 x tilde
還有一個是 generator 自己生成的 image
他不是看 database 裡面任何一張 image 生成的
他是自己根據一個 Normal Distribution sample 所生成出來的 image，這邊寫成 x hat
再來在 training 的時候，你先 train encoder，encoder 目標是甚麼
他要 minimize Autoencoder Reconstruction Error
所以要讓真正的 image xi 跟 reconstruct 出來的 image x tilde 越接近越好
這應該是 decoder
這個不是 encoder
這個是一個 decoder，等一下告訴你叫甚麼名字
這是一個 decoder
這邊要講現在你有原來 input 的 image 跟 reconstructed image
encoder 目的是甚麼
他希望原來 input 的 image 跟 reconstructed image x 跟 x tilde 越接近越好，這第一件他要做的事
第二件他要做的事情是他希望這個 x 產生出來的 z tilde 跟 Normal Distribution 越接近越好
這事本來 VAE 要做的事情
接下來 decoder 要做的事情是他同時要 minimize Reconstruction Error
他有另外一個工作是他希望他產生出來的東西
可以騙過 discriminator
他希望他產生出來的東西 discriminator 會給他高的分數
而現在 decoder 其實會產生兩種東西
一種是 x tilde 是 reconstructed image
通常 reconstructed image 就是會看起來整個結構比較好 但是比較模糊
這個 x tilde 產生一個 reconstructed image
這個 reconstructed image 就到 discriminator 裡面 分數要越大越好
那你把 x hat 就是 machine 自己生出來的 image
不是 reconstructed image 是自己生出來的 image
丟到 discriminator 裡面，希望值越大越好
最後輪到 discriminator，discriminator 要做的事情是如果是一個 real image 給他高分
如果是 faked image，faked image 有兩種
一種是 reconstruct 出來的，一種是自己生成出來的，都要給他低分
這是 VAE-GAN 的作法
但其實我還看過另外一個做法是 discriminator 他不是一個 Binary Classifier
我們之前看到 discriminator 都是一個 Binary Classifier
他就是要鑑別一張 image 是 real 還是 fake
其實還有另外一個做法是
discriminator 其實是一個三個 class 的 classifier
給他一張 image 他要鑑別他是 real 還是 generated 還是 reconstructed
因為 generated image 跟 reconstructed image 他們本質上看起來頗不像的
在右邊的 algorithm 裡面
是把 generated 跟 reconstructed 視為是同一個 class 就是 fake 的 class，都當作 fake 的 image
但是我有看過做法是把 generate 出來的 image 跟 reconstruct 出來的 image
視為兩種不同的 image
discriminator 必須去學著鑑別這兩種的差異
generator 在學的時候
這是 discriminator，discriminator 要把一張 image 分成
input 一張 image，discriminator 要把它分成三類
但對 generator 來說他有可能產生 generated image 他也有可能產生 reconstructed image
他都要試著讓這兩種 image discriminator 都誤判 認為他是 real 的 image
這個是 VAE-GAN
VAE-GAN 是去修改了 Autoencoder
還有另外一個技術叫做 BiGAN
BiGAN 他也是修改了 Autoencoder
他怎麼做呢 我們知道在 Autoencoder 裡面
有一個 encoder，有一個 decoder
在 Autoencoder 裡面是把 encoder 的 output 丟給 decoder 去做 reconstruction
但是在 BiGAN 裡面不是
在 BiGAN 裡面就有一個 encoder 有一個 decoder
但是他們的 input output 不是接在一起的
encoder 吃一張 image 他就變成一個 code
decoder 是從一個 Normal Distribution 裡面 sample 一個 z 出來丟進去，他就產生一張 image
但是我們並不會把 encoder 的輸出丟給 decoder
並不會把 decoder 的輸出丟給 encoder
這兩個是分開的 有一個 encoder 有一個 decoder
這兩個是分開的那他們怎麼學呢
在 Autoencoder 裡面可以學是因為收集了一大堆 image 要讓 Autoencoder 的 input 等於 Autoencoder output
現在 encoder 跟 decoder 各自都只有一邊
encoder 只有 input 他不知道 output target 是甚麼
decoder 他只有 input 他不知道 output 的 image 應該長甚麼樣子
怎麼學這個 encoder 跟 decoder
這邊的做法是再加一個 discriminator
這個 discriminator 他是吃 encoder 的 input 加 output
他吃 decoder 的 input 加 output 他同時吃一個 code z 跟一個 image x，一起吃進去
然後它要做的事情是鑑別 x 跟 z 的 pair 他們是從 encoder 來的還是從 decoder 來的
所以它要鑑別一個 pair 他是從 encoder 來的還是從 decoder 來的
其實 BiGAN 還有另外一個技術
跟他非常地相近
其實不只是相近根本是一模一樣，叫做 ALI
BiGAN 跟 ALI 如果沒記錯的話是同時發表在 ICLR 2017 上面
有甚麼差別？就是沒有任何差別
不同的兩群人居然想出了一模一樣的方法
而且我發現 BiGAN 的 citation 比較高
我想原因就是因為他有 GAN 然後 ALI 他沒有用到 GAN 這個字眼，citation 就少一點
我們先講一下 BiGAN 的 algorithm 然後再告訴你為甚麼
BiGAN 這樣做到底是有什麼樣的道理 先講一下他的 algorithm
現在有一個 encoder 有一個 decoder 有一個 discriminator
這個跟剛才講 VAE-GAN 他有一個 encoder 有一個 decoder 有一個 discriminator
不過這邊 BiGAN 的運作方式跟 VAE-GAN 是非常不一樣
BiGAN 有一個 encoder 有一個 decoder 有一個 discriminator，但每一個 iteration 裡面
你會 sample M 個 realistic image 出來
你會 sample M 個 code 出來
這邊 encoder 會做的事情是
剛才講錯，這個不是 sample 出來
先從 database 裡面 sample 出 M 張真的 image
然後把這些真的 image 丟到 encoder 裡面
encoder 會 output code 就得到了 M 組 code 得到了 M 個 z tilde
這個是用 encoder 生出來的東西
接下來用 decoder 生東西
decoder 怎麼生東西 sample M 個 code
這個從一個 Normal Distribution sample 出來
把這些 code 丟到 decoder 裡面
decoder 就產生他自己生成的 image x tilde
所以這邊沒有 tilde 的東西都是真的 有 tilde 的東西都是生成的
這邊有 M 個 real image 生成出 M 個 code
這邊有 M 個 code 生成出 M 個 image
接下來要 learn 一個 discriminator
discriminator 工作是給他 encoder 的 input 跟 output 給他高分
給它 decoder 的 input 跟 output 給它低分
如果這個 pair 是 encoder 的 input 跟 output 給他高分
如果這個 pair 是 decoder 的 input 跟 output 就給他低分
有人會問為甚麼是 encoder 會給高分 decoder 會給低分
其實反過來講你也會問同樣的問題
不管是你要讓 encoder 高分 decoder 低分 還是 encoder 低分 decoder 高分
是一樣的，意思是完全一模一樣的
learn 出來結果也會是一樣的
它並沒有甚麼差別只是選其中一個方法來做就是了
encoder 跟 decoder 要做的事情就是去騙過 discriminator
如果 discriminator 要讓 encoder 的 input output 高分 decoder 的 input output 低分
encoder decoder 他們就要聯手起來
讓 encoder 的 input output 讓 discriminator 給它低分
讓 decoder 的 input output discriminator 給他高分
所以 discriminator 要做甚麼事
encoder 跟 decoder 就要聯手起來
去騙過 discriminator 就對了
到底要讓 encoder 高分還是 decoder 高分 是無關緊要的
這個是 BiGAN 的 algorithm
BiGAN 這麼做到底是有甚麼道理
我們知道 GAN 做的事情
這個 discriminator 做的事情就是在 evaluate 兩組 sample 出來的 data
到底他們接不接近
我們上週講過從 real database 裡面 sample 一堆 image 出來
用 generator sample 一堆 image出來
一個 discriminator 做的事情其實就是在量這兩堆 image 的某種 divergence 到底接不接近
這個道理是一樣的
可以把 encoder 的 input output 合起來
當作是一個 Joint Distribution
encoder input 跟 output 合起來有一個 Joint Distribution 寫成 P(x, z)
decoder input 跟 output 合起來也是另外一個 Joint Distribution Q(x, z)
discriminator 要做的事情就是去衡量這兩個 distribution 之間的差異
然後希望透過 discriminator 的引導讓這兩個 distribution 之間越近越好
希望在原來的 GAN 裡面，我們希望 PG generator 生成出來的 data distribution
跟 P data 越接近越好
這邊的道理是完全一模一樣的
discriminator 希望 encoder input output 所組成的 Joint Probability
跟 decoder input output 所組成的 Joint Probability 這兩個 Data Distribution 越接近越好
P 跟 Q 這兩個 distribution 越接近越好
所以 eventually 在理想的狀況下
應該會學到 P 這個 distribution 也就是 encoder 的 input 跟 output 所組成的 distribution
跟 Q 這個 distribution，這兩個 distribution
他們是一模一樣
如果最後他們 learn 到一模一樣的時候 會發生甚麼事情
你可以輕易的證明這個沒什麼好特別證明的 你用直觀想一下其實就是這個樣子
你可以輕易的知道如果 P 跟 Q 的 distribution 是一模一樣的
你把一個 image x' 丟到 encoder 裡面讓它給你一個 code z'
再把 z' 丟到 decoder 裡面讓它給你一個 image x'
x' 會等於原來的 input x'
你把 x' 丟進去它會產生 z'
你把 z' 丟到 decoder 裡面 它會產生原來的 x'
你把 z'' 丟到 decoder 裡面讓它產生 x''
你就把 x'' 丟到 encoder 裡面 那它就會產生 z''
所以 encoder 的 input 產生一個 output
再把 output 丟到 decoder 裡面會產生原來 encoder 的 input
decoder 給它一個 input 它產生一個 output
再把它的 output 丟到 encoder 裡面 它會產生一模一樣的 input
雖然說實際上在 training 的時候 encoder 跟 decoder 並沒有接在一起
但是透過 discriminator 會讓 encoder decoder 最終在理想上達成以下的特性
所以有人會問這樣 encoder 跟 decoder 做的事情是不是就好像是 learn 了一個 Autoencoder
這個 Autoencoder input 一張 image 它變成一個 code
再把 code 用 decoder 解回原來一樣的 image
你還會 learn 一個反向的 Autoencoder 所謂的反向的 Autoencoder 的意思是
decoder 吃一個 code 它產生一張 image
再從這個 image 還原回原來的 code
要讓 input 跟 output 越像越好
你要讓 encoder input 跟 decoder output 越像越好 你要讓 decoder input 跟 encoder output 越像越好
假設在理想狀況下
BiGAN 它可以 learn 到 optimal 的結果
確實會跟同時 learn 這樣子一個 encoder 跟 Autoencoder 得到的結果是一樣的
那有人就會問為甚麼不 learn 這樣子一個 encoder 跟一個 inverse Autoencoder 就好了呢
為甚麼還要引入 GAN 這樣聽起來感覺上是畫蛇添足
我覺得如果用 BiGAN learn 的話
得到的結果還是會不太一樣
這邊想要表達的意思是
learn 一個 BiGAN
跟 learn 一個下面這個 Autoencoder
他們在最佳的 solution 他們的 optimal solution 是一樣的
但它他們的 Error Surface 是不一樣的
如果這兩個 model 都 train 到 optimal 的 case
得到的結果會是一樣的
但是實際上不可能 train 到 optimal 的 case BiGAN 無法真的 learn 到 P 跟 Q 的 distribution 一模一樣
Autoencoder 無法 learn 到 input 跟 output 真的一模一樣 這件事情是不可能發生的
所以不會真的收斂到 optimal solution
但不是收斂到 optimal solution 的狀況下 這兩種方法 learn 出來的結果就會不一樣
到底有甚麼不一樣，這邊沒有把文獻上的圖片列出來 如果你看一下文獻上的圖片的話
一般的 Autoencoder learn 完以後 input 一張 image 它就是 reconstruct 另外一張 image
跟原來的 input 很像
然後比較模糊
這個大家應該都知道 Autoencoder 就是這麼回事
但是如果用 BiGAN 的話，其實也是 learn 出了一個 Autoencoder
learn 了一個 encoder 一個 decoder 他們合起來就是一個 Autoencoder
但是當你把一張 image 丟到這個 encoder 再從 decoder 輸出出來的時候
其實你可能會得到的 output 跟 input 是非常不像的
它會比較清晰
但是非常不像
比如說你把一隻鳥丟進去
它 output 還是會是一隻鳥 但是是另外一隻鳥
這個就是 BiGAN 的特性 你可以去看一下它的 paper
如果跟 Autoencoder 比起來 他們的最佳的 solution 是一樣的
但是實際上 learn 出來的結果會發現這兩種 Autoencoder
就是用這種 minimize Reconstruction Error 方法 learn 了一個 Autoencoder
還是用 BiGAN learn 的 Autoencoder
他們的特性其實是非常不一樣
BiGAN 的 Autoencoder 它比較能夠抓到語意上的資訊
就像剛才說的你 input 一隻鳥
它知道牠是一隻鳥
它 reconstruct 出來的結果 decoder output 也是一隻鳥
但是不是同一隻鳥
這就是一個還滿神奇的結果
這個是 BiGAN
有 BiGAN，Bi 就是二的意思
那就有三，就是 Triple GAN
我沒有打算要仔細講 Triple GAN，但是你之後會知道為甚麼要這邊要特別放一個 Triple GAN
我們可以非常快的跟大家解釋一下 Triple GAN
Triple GAN 裡面有三個東西
一個 discriminator 一個 generator
一個 classifier
如果先不要管 classifier 的話
Triple GAN 本身就是一個 Conditional GAN
Conditional GAN 上週講過了 input 一個東西，output 一個東西
比如說 input 一個文字 然後就 output 一張圖片
generator 就是吃一個 condition 這邊 condition 寫成 Y
然後產生一個 x
它把 x 跟 y 的 pair 丟到 discriminator 裡面
discriminator 要分辨出 generator 產生出來的東西是 fake 的
然後 real database sample 出來的東西就是 true
所以 generator 跟 discriminator 合起來就是一個 Conditional GAN
這邊是沒有甚麼特別的地方
都是上周就已經講過的東西
這邊再加一個 classifier 是甚麼意思
這邊再加一個 classifier 意思是 BiGAN 是一個 Semi-supervised Learning 的做法 ( 講錯了 )
不是 BiGAN 一個 Semi-supervised Learning 說錯了
Triple GAN 是一個 Semi-supervised Learning 的做法
在 Triple GAN setup 裡面假設有少量的 labeled data
但是大量的 unlabeled data
也就是說你有少量的 X 跟 Y 的 pair
有大量的 X 跟 Y 他們是沒有被 pair 在一起
所以 Triple GAN 它主要的目標
是想要去學好一個 classifier，這 classifier 可以 input X
然後就 output Y
你可以用 labeled data 去訓練 classifier 你可以從有 label 的 data 的 set 裡面
去 sample X Y 的 pair
去 train classifier
但是同時也可以根據 generator generator 會吃一個 Y 產生一個 X
把 generator 產生出來的 X Y 的 pair
也丟給這個 classifier 去學
它的用意就是增加 training data
本來有 labeled 的 X Y 的 pair 很少
但是有一大堆的 X 跟 Y 是沒有 pair 的
所以用 generator 去給他吃一些 Y 讓它產生 X
得到更多 X Y 的 pair 去 train classifier
這個 classifier 它也可以吃 X
然後去產生 Y
discriminator 會去鑑別這 classifier input 跟 output 之間的關係
看起來跟真正 X Y 的 pair 有沒有像
所以 Triple GAN 是一個 Semi-supervised Learning 的做法，這邊就不特別再仔細地說它
只是告訴大家有 Triple GAN 這個東西 有 BiGAN 就要有 Triple GAN
最後我要很快地複習一下 Domain-adversarial training
因為等一下在講 Unsupervised Conditional Generation 的時候，我們用得上這個技術
這個技術在 ML 有講過，所以這邊就只是再複習一下
這個 Domain-adversarial training 要做的事情是甚麼
就是要 learn 一個 generator 這個 generator 工作就是抽 feature
假設要做影像的分類
這個 generator 工作就是吃一張圖片 output 一個 feature
在做 Machine Learning 的時候
很害怕遇到一個問題是
training data 跟 testing data 不 match
假設 training data 是黑白的 MNIST
testing data 是彩色的圖片
是彩色的 MNIST
你可能會以為你在這個 training data 上 train 起來 apply 到這個 testing data 上
搞不好也 work，因為 machine 搞不好可以學到反正 digit 就是跟顏色無關
考慮形狀就好了
所以他在黑白圖片上 learn 的東西也可以 apply 到彩色圖片
但是事實上事與願違，machine 就是很笨
實際上 train 下去，train 在黑白圖片上 apply 彩色圖片上
雖然你覺得 machine 只要學到把彩色圖片自己在某個 layer 轉成黑白的，應該就可以得到正確結果
但是實際上不是，它很笨，它就是會答錯
怎麼辦？我們希望有一個好的 generator
這個 generator 做的事情是 training set 跟 testing set 的 data 不 match 沒有關係
透過 generator 幫你抽出 feature
然後在 training set 跟 testing set 雖然他們不 match 他們的 domain 不一樣
但是透過 generator 抽出來的 feature
他們有同樣的 distribution，他們是 match
這個就是 Domain-adversarial training
怎麼做呢 這個圖在 Machine Learning 那門課有看過了
就 learn 一個 generator
其實就是 feature extractor
它吃一張 image 它會 output 一個 feature
有一個 Domain Classifier 其實就是 discriminator
這個 discriminator 是要判斷現在這個 feature 來自於哪個 domain
假設有兩個 domain，domain x 跟 domain y 你要 train 在 domain x 上面
apply 在 domain y 上面
有兩個 domain，domain x 跟 domain y
要 train 在 domain x 上面 apply 在 domain y 上面
然後這個時候 Domain Classifier 要做的事情是分辨這個 feature 來自於 domain x 還是 domain y
在這邊同時你又要有另外一個 classifier
這個 classifier 工作是根據這個 feature 判斷 假設現在是數字的分類
要根據這個 feature 判斷它屬於哪個 class
它屬於哪個數字
這三個東西是一起 learn 的
但是實際上在真正 implement 的時候不一定要一起 learn
在原始 Domain-adversarial training 的 paper 裡面
它就是一起 learn 的
這三個 network 就是一起 learn
只是這個 Domain Classifier 它的 gradient 在 back propagate 的時候在這邊
在進入 Feature Extractor 之前
會乘一個負號
但是實際上真的在 implement 的時候你不一定要同時一起 train
你可以 iterative train 就像 GAN 一樣
在 GAN 裡面也不是同時 train generator 跟 discriminator 你是 iterative 的去 train
有人可能會問能不能夠同時 train generator 跟 discriminator
其實是可以的
如果你去看 f-GAN 那篇 paper 的話
它其實就 propose 一個方法，它的 generator 跟 discriminator 是 simultaneously 同時 train 的
就跟原始的 Domain-adversarial training 的方法是一樣
我們有同學試過類似的作法，但發現同時 train 比較不穩
如果是 iterative train 其實比較穩
如果先 train Domain Classifier
再 train Feature Extractor
先 train discriminator 再 train generator
iterative 的去 train
它的結果會是比較穩的
這個是 Domain-adversarial training
用類似這樣的技術可以做一件事情 這件事情叫做 Feature Disentangle
Feature Disentangle 是甚麼意思
用語音來做一下舉例
在別的 domain 上比如說 image processing
或者是 video processing
這樣的技術也是用得非常多
用語音來做例子
假設 learn 一個語音的 Autoencoder
learn 一個 sequence to sequence 的 Autoencoder
learn 一個 Autoencoder 它 input 是一段聲音訊號
把這段聲音訊號壓成 code
再把這段 code 透過 decoder 解回原來的聲音訊號
你希望 input 跟 output 越接近越好
就要 learn 這樣一個 sequence to sequence Autoencoder
它中間你的 encoder 會抽出一個 latent representation
現在你的期待是 latent representation 可以代表發音的資訊
但是你發現你實際 train 這樣 sequence to sequence Autoencoder 的時候
你抽出來未必能讓中間的 latent representation 代表發音的資訊
為甚麼？因為中間的 latent representation 它可能包含了很多各式各樣不同的資訊
因為 input 一段聲音訊號，這段聲音訊號裡面不是只有發音的資訊
它還有語者的資訊
還有環境的資訊
對 decoder 來說
這個 feature 裡面一定必須要同時包含各種的資訊 包含發音的資訊
包含語者的資訊
包含環境的資訊
這個 decoder 根據所有的資訊合起來
才可以還原出原來的聲音
我們希望做的事情是
知道在這個 vector 裡面
到底哪些維度代表了發音的資訊
那些維度代表了語者的資訊或者是其他的資訊
這邊就需要用到一個叫做 Feature Disentangle 的技術
這種技術就有很多的用處因為你可以想像
假設你可以 learn 一個 encoder
它的 output 你知道那些維是跟發音有關的
那些維是跟語者有關的
你可以只把發音有關的部分
丟到語音辨識系統裡面去做語音辨識
只跟語者有關的部分丟到語者的 speaker 的 verification
speaker verification 中文怎麼翻
語者識別嗎
這個有很多很多的應用，比如說你打電話去花旗銀行的時候
聲紋比對
這個技術通常叫作聲紋比對
你就把有關語者的資訊
丟到聲紋比對的系統裡面去
然後它就會知道現在是不是某個人說的
所以像這種 Feature Disentangle 技術有很多的應用
怎麼做到 Feature Disentangle 這件事
現在假設要 learn 兩個 encoder
一個 encoder 它的 output 就是發音的資訊
另外一個 encoder 它的 output 就是語者的資訊
然後 decoder 吃發音的資訊加語者的資訊合起來
還原出原來的聲音訊號
接下來就可以把抽發音資訊的 encoder 拔出來
把它的 output 去接語音辨識系統
因為在做語音辨識的時候
常會遇到的問題是兩個不同的人說同一句話
它聽起來不太一樣，在聲音訊號上不太一樣
如果這個 encoder 可以把語者的 variation、語者所造成的差異 remove 掉
對語音辨識系統來說辨識就會比較容易
對聲紋比對也是一樣，同一個人說不同的句子
他的聲音訊號也是不一樣
如果可以把這種發音的資訊、content 的資訊、跟文字有關的資訊
把它濾掉，只抽出語者的特徵的話
對後面聲紋比對的系統也是非常有用
這件事怎麼做
怎麼讓機器自動學到這個 encoder，如果這三個東西 joint learn
當然沒有辦法保證它的 output 一定要是發音的資訊 它的 output 一定要是語者的資訊
怎麼辦 就需要加一些額外的 constrain
比如說對語者的地方
你可能可以假設現在 input 一段聲音訊號在訓練的時候
我們知道那些聲音訊號是同一個人說的
這個假設其實也還滿容易達成的 因為可以假設同一句話就是同一個人說的
同一句話把它切成很多個小塊 每一個小塊就是同一個人說的
所以對 Speaker Encoder 來說，給它同一個人說的聲音訊號
雖然他們的聲音訊號可能不太一樣
但是 output 的 vector、output 的 embedding 要越接近越好
同時假設 input 的兩段聲音訊號是不同人說的 那 output 的 embedding 就不可以太像
他們要有一些區別
就算是這樣做，你只能夠讓 Speaker Encoder 的 output 考慮語者的資訊
沒有辦法保證 Phonetic Encoder output 一定是發音的資訊，因為也許語者的資訊也會被藏在綠色的 vector 裡
所以怎麼辦？這邊就可以用到 Domain Adversarial Training 的概念
再另外去 train 一個 Speaker Classifier
這 Speaker Classifier 作用是甚麼
這 Speaker Classifier 作用是給它兩個 vector
它去判斷這兩個 vector 到底是同一個人說的還是不同的人說的
Phonetic Encoder 要做的事情就是去想辦法騙過 Speaker Classifier
Speaker Classifier 要盡力去判斷給他兩個 vector 到底是同一個人說的還是不同人說的
Phonetic Encoder 要想盡辦法去騙過 classifier
這個其實就是個 GAN，後面就是 discriminator，前面就是 generator
如果 Phonetic Encoder 可以騙過 Speaker Classifier
Speaker Classifier 完全無法從這些 vector 判斷到底是不是同一個人說的
那就意味著 Phonetic Encoder 它可以濾掉所有跟語者有關的資訊
只保留和語者無關的資訊
這個就是 Feature Disentangle 的技術 這邊就是一些真正的實驗結果
training 是 train 在一個叫做 LibriSpeech 的 corpus 上面
它就是蒐集很多有聲書給機器去學
這邊的結果左邊是 Phonetic Encoder 的 output
右邊是 Speaker Encoder 的 output
上面兩個圖每一個點就代表一段聲音訊號
這邊不同顏色的點代表聲音訊號背後對應的詞彙是不一樣的
但他們都是不同的人講的
如果看 Phonetic Embedding 的 output 就會發現 同樣的詞彙它是被聚集在一起的
雖然他們是不同人講的但是 Phonetic Encoder 知道它會把語者的資訊濾掉
知道不同人講的聲音訊號不太一樣
但是這些都是同一個詞彙
如果看 Speaker Encoder output 就會發現 Speaker Encoder output 很明顯就分成兩群
不同的詞彙發音雖然不太一樣
但是因為現在 Speaker Encoder 已經把發音的資訊都濾掉只保留語者的資訊
就會發現不同的詞彙都是混在一起的
下面是兩個不同顏色的點代表兩個不同的 speaker 兩個不同的語者他們所發出來的聲音訊號
就會發現如果是看 Phonetic Embedding 看發音上面的資訊
兩個不同的人他們很有可能會說差不多的內容
他們說出來的可能就是那幾個詞彙
所以你會發現如果看 Phonetic Encoder 這兩個人的東西
是重疊在一起的
這兩個 embedding 重疊在一起
如果看 Speaker Encoding 就會發現這兩個人的聲音 是很明顯的分成兩群的
這個就是 Feature Disentangle，這邊是舉語音做例子 但是它也可以用在影像等等其他 application 上
臺灣大學人工智慧中心 科技部人工智慧技術暨全幅健康照護聯合研究中心 http://aintu.tw
