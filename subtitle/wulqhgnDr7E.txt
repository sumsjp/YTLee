好那有關GAN的最後一段
我們要講一個GAN的神奇應用
這個是什麼樣神奇的應用呢
這個是把GAN
用在這個unsupervised Learning上
你常常聽到有人說
GAN可以用在
Unsupervised Learning上
現在就要告訴你說
GAN怎麼用在Unsupervised Learning
到目前為止呢
我們講的幾乎都是
Supervised Learning
我們要訓練一個Network
Network的輸入叫做X輸出叫做Y
我們需要成對的資料
才有辦法訓練這樣子的Network
但是你可能會遇到一個狀況是
我們有一堆X我們有一堆Y
但X跟Y是不成對的
在這種狀況下
我們有沒有辦法拿這樣的資料
來訓練Network呢
像這一種沒有成對的資料
我們就叫做unlabeled的資料
沒有標註的資料
至於怎麼使用
這些沒有標註的資料呢
其實在作業三跟作業五裡面
都提供給你兩個例子
我們就把這個怎麼用
沒有標註的資料
怎麼做Semi-supervised Learning
這件事情放在作業裡面
如果你有興致的話就可以來
體驗一下semi-supervised Learning
到底可以帶多大的幫助
但是不管是作業三的pseudo labeling
還是作業五的back translation
這些方法或多或少
都還是需要一些成對的資料
在作業三裡面
你得先訓練出一個模型
這個模型可以幫你提供pseudo label
如果你一開始
根本就沒有太多有標註的資料
你的模型很差
你根本就沒有辦法產生
比較好的pseudo label
或是back translation
你也得有一個
back translation 的model
你才辦法做back translation
所以不管是作業三
還是作業五的方法
還是都需要一些成對的資料
但是假設我們遇到
一個更艱鉅的狀況
是我們一點成對的資料都沒有
那要什麼怎麼辦呢
你可能會問說什麼時候
會一點成對的資料都沒有呢
我永遠可以找個工讀生
還是或多或少幫我標一點資料
只是可能不一定可以標很多而已
什麼時候會完全沒有成對的資料呢
我們這邊舉一個例子
舉例來說 影像風格轉換
假設今天我要訓練
一個Deep Network
它要做的事情是把X domain的圖
X domain的圖
我們假設是真人的照片
Y domain的圖是二次元人物的頭像
真人的頭像轉成二次元人物的頭像
這個叫做影像風格轉換
真人的頭像是X domain
二次元頭像是Y domain
把X domain的東西
轉成Y domain的東西
這個是影像風格轉換
在這個例子裡面我們可能
就沒有任何的成對的資料 對不對
如果你想要成對的資料
那你得先比如說這是新垣結衣
幫新垣結衣拍一個照片
然後在把新垣結衣二次元的版本
畫出來
你才有辦法訓練Network
這個顯然實在是太昂貴了
工讀生也沒辦法做這件事情
所以影像風格轉換
你可能一點成對的資料都沒有
在這種狀況下
還有沒有辦法訓練一個Network
輸入一個X產生一個Y呢
這個就是GAN可以幫我們做的事情
那接下來我們就是看看怎麼用GAN
在這種完全沒有成對資料的情況下
進行學習
這個是我們之前在講
unconditional的generation的時候
你看到的generator的架構
輸入是一個Gaussian的分佈
輸出可能是一個複雜的分佈
現在我們在稍微
轉換一下我們的想法
輸入我們不說它是Gaussian的分佈
我們說它是X domain的圖片的分佈
那輸出我們說
是Y domain圖片的分佈
我們有沒有可能訓練
這樣的generator
輸入是X domain圖片的分佈
輸出是Y domain圖片的分佈呢
如果可以做到的話其實就結束了
這個問題就結束了 就做出來了
你就去訓練出一個Network
你可以給它一個X domain的東西
讓它把它轉成Y domain的東西
那有沒有辦法做這件事情呢
乍聽之下好像沒有很難
你完全可以套用原來的GAN的想法
在原來的GAN裡面我們說
我們從Gaussian sample一個向量
丟到Generator裡面
那我們一開始也說
其實不一定要從Gaussian sample
只要那一個distribution
是有辦法被sample的就行了
我們選Gaussian只是因為
Gaussian的formulation我們知道
我們可以從Gaussian sample
那我們現在如果
輸入是X domain的distribution
我們只要改成可以
從X domain sample就結束了
那你有沒有辦法
從X domain sample呢
可以 你就從人臉的照片裡面
真實的人臉裡面隨便挑一張出來
這是一個死臭酸宅然後就結束了
你就可以從X domain
sample照片出來
你把這個照片丟到generator裡面
讓它產生另外一張圖片
產生另外一個distribution
裡面的圖片
那怎麼讓它變成
是Y domain的distribution呢
那就要兩三個discriminator
那這個discriminator給它
看過很多Y軸 domain的圖
所以它能夠分辨Y domain的圖
跟不是Y domain的圖的差異
看到Y domain的圖就給它高分
看到不是Y domain的圖
不是二次元人物就給它低分
那就這樣結束了
你說這個跟原來的GAN的訓練
有什麼不同
沒什麼不同 沒什麼不同
如果你想要自己
在那個作業裡面做一下的話
就記得說本來在作業裡面
Gaussian generator的input裡的
sample是從Gaussian distribution
sample出來
現在記得換一個sample的方法
從真人的人臉裡面
sample一張圖片出來
這樣就結束了
但是你再仔細想想看
光是套用原來的GAN訓練
generator跟discriminator
好像是不夠的 怎麼說呢
因為我們現在的discriminator
它要做的事情是要讓這個generator
輸出一張Y domain的圖
那generator它可能真的
可以學到輸出Y domain的圖
但是它輸出的Y domain的圖
一定要跟輸入有關係嗎
你沒有任何的限制
要求你的generator做這件事
你的generator也許就把這張圖片
當作一個Gaussian的noise
然後反正它就是看到
不管你輸入什麼它都無視它
反正它就輸出一個
像是二次元人物的圖片
discriminator覺得它做得很好
其實就結束了對不對
所以如果我們完全只套用
這個一般的GAN的做法
只訓練一個generator
這個generator input的distribution
從Gaussian變成X domain的image
然後訓練一個discriminator
顯然是不夠的
因為你訓練出來的generator
它可以產生二次元人物的頭像
但是跟輸入的真實的照片
沒有什麼特別的關係
那這個不是我們要的
那怎麼辦呢 怎麼解決這個問題
怎麼強化輸入與輸出的關係呢
這個generator完全無視輸入這件事
你會發現說
我們在conditional GAN的時候
是不是也看過一模一樣的問題呢
在講conditional GAN的時候
我有特別提到說
假設你的discriminator只看Y
那它可能會無視generator的輸入
那產生出來的結果不是我們要的
但是這邊啊
如果我們要從unpaired的data學習
我們也沒有辦法
直接套用conditional GAN的想法
因為在剛才講的
conditional GAN裡面
我們是有成對的資料
我們可以用這些成對的資料
來訓練的discriminator
但今天現在我們沒有成對的資料
我們根本沒有辦法拿出成對的資料
來告訴discriminator說
怎麼樣的X跟Y的組合才是對的
我們沒有這種資料 怎麼辦呢
那邊就用了一個
這邊這個想法叫做Cycle GAN
在Cycle GAN裡面
我們會train兩個generator
第一個generator它的工作是
把X domain的圖變成Y domain的圖
第二個generator它的工作是
看到一張Y domain的圖
把它還原回X domain的圖
在訓練的時候
我們今天增加了一個額外的目標
就是我們希望輸入一張圖片
從X domain轉成Y domain以後
要從Y domain轉回原來
一模一樣的X domain的圖
經過兩次轉換以後
輸入跟輸出要越接近越好
你說怎麼讓兩張圖片越接近越好呢
這個很簡單哪
這是一個圖片
其實就是一個向量對不對
兩張圖片就是兩個向量
這兩個向量之間的距離
你就是讓這兩個向量
它們之間的距離越接近越好
就是要兩張圖片越像越好
因為這邊有一個循環
從X到Y 在從Y回到X
它是一個cycle
所以叫做Cycle GAN
這個要讓輸入經過兩次轉換以後
變成輸出 輸入跟輸出越接近越好
這個叫做Cycle的consistency
所以現在這邊我們有三個Network
第一個generator
它的工作是把X轉成Y
第二個generator
它的工作是要把Y還原回原來的X
那這個discriminator
它的工作仍然是要看
藍色的這個generator它的輸出
像不像是Y domain的圖
那加入了這個橙色的
從Y到X的generator以後
會有什麼樣不一樣的地方呢
對於前面這個藍色的generator來說
它就再也不能夠隨便亂做了
它就不能夠隨便產生亂七八糟
跟輸入沒有關係的人臉了
這邊假設輸入一個死臭酸宅
這邊假設輸出的是輝夜
另外一個這個不知道這是誰的
那是輝夜這樣子知道嗎
她是輝夜大小姐
然後對第二個generator來說
它就是視這張輝夜作為輸入
它根本無法想像說
要把輝夜還原回死臭酸宅
它根本不知道說
原來輸入的圖片長什麼樣子
所以怎麼辦呢
對第一個generator來說
為了要讓第二個generator能夠
成功的還原原來的圖片
它產生出來的圖片
就不能跟輸入差太多
所以這邊是一個死臭酸宅
這邊輸出至少也得是一個
戴眼鏡的男生的角色才行吧
所以這邊是一個戴眼鏡男生的角色
這個是新八
然後第二個generator才能夠
把這個角色還原回原來的輸入
所以如果你加Cycle GAN
你至少可以強迫你的generator
它輸出的Y domain的圖片
至少跟輸入的X domain的圖片
有一些關係
但講到這邊
你可能會有的一個問題就是
你這邊只保證有一些關係啊
你怎麼知道這個關係是我們要的呢
機器有沒有可能學到很奇怪的轉換
輸入一個戴眼鏡的人
然後這個generator學到的是
看到眼鏡就把眼鏡抹掉
然後把它變成一顆痣
然後第二個generator橙色的學到的
就是看到痣就還原回眼鏡
這樣還是可以滿足cycle consistency
還是可以把輸入的圖片
變成輸出的圖片
我舉一個更極端的例子
假設第一個generator學到的就是
把圖片反轉 左右翻轉
第二個generator它也只要學到
把圖片左右翻轉
你就可以還原了啊
所以今天如果我們做Cycle GAN
用cycle consistency
似乎沒有辦法保證
我們輸入跟輸出的人臉
看起來真的很像
因為也許機器會學到很奇怪的轉換
反正只要第二個generator
可以轉得回來就好了
那會不會有這樣的問題發生呢
確實有可能有這樣的問題發生
那有什麼要特別好的解法呢
目前沒有什麼特別好的解法
但我可以告訴你說
實際上你要使用Cycle GAN的時候
這樣子的狀況沒有那麼容易出現
如果你實際上使用Cycle GAN
你會發現輸入跟輸出往往
真的就會看起來非常像
而且甚至在實作上
在實作的經驗上
你就算沒有第二個generator
你不用cycle GAN
拿一般的GAN來做
這種圖片風格轉換的任務
你往往也做得起來
因為在實作上你會發現
Network其實非常懶惰
它輸入一個圖片
它往往就想輸出
by default就是想輸出很像的東西
它不太想把輸入的圖片
做太複雜的轉換
像是什麼眼鏡變成一顆痣這種狀況
它不愛這麼麻煩的東西
有眼鏡就輸出眼鏡
可能對它來說是比較容易的抉擇
所以在真的實作上
這個問題沒有很大
輸入跟輸出會是像
但是理論上好像沒有什麼保證說
輸入跟輸出的圖片一定要很像
就算你加了cycle consistency
所以這個是實作與理論上
你可能會遇到的差異
總之雖然Cycle GAN沒有保證說
輸入跟輸出一定很像
但實際上你會發現輸入跟輸出
往往非常像
你只是改變了風格而已
那這個Cycle GAN可以是雙向的
什麼意思呢
我們剛才有一個generator
輸入Y domain的圖片
輸出X domain的圖片
我們是先把X domain的圖片轉成Y
在把Y轉回X
在訓練cycle GAN的時候
你可以同時做另外一個方向的訓練
也就是你把
這個橙色的generator拿來
給它Y domain的圖片
讓它產生X domain的圖片
然後在把藍色的generator拿來
把X domain的圖片
還原回原來Y domain的圖片
那你依然要讓
輸入跟輸出越接近越好
那你一樣要訓練一個discriminator
這個discriminator是
X domain的discriminator
它是要看一張圖片
像不像是真實人臉的discriminator
這個discriminator要去看說
這一個橙色的generator的輸出
像不像是真實的人臉
這個橙色的generator它要去騙過
這個Dx這個綠色的左邊
這一個discriminator
這個合起來就是Cycle GAN
那除了Cycle GAN以外
你可能也聽過很多其他的
可以做風格轉換的GAN
比如說Disco GAN 比如說Dual GAN
他們跟Cycle GAN有什麼不同呢
就是沒有半毛錢的不同這樣子
你可以發現Disco GAN
Dual GAN跟Cycle GAN
其實是一樣的東西
他們是一樣的想法
神奇的事情是完全不同的團隊
在幾乎一樣的時間
提出了幾乎一模一樣的想法
你發現這三篇文章
放到arxiv上的時間
都是17年的3月
17年的4月跟17年的3月
不同的團隊幾乎在一樣的時間
有了一樣的想法
除了Cycle GAN以外
還有另外一個更進階的
可以做影像風格轉換的版本
叫做StarGAN
Cycle GAN只能在兩種風格間做轉換
那StarGAN 它厲害的地方是
它可以在多種風格間做轉換
不過這個就不是我們接下來
想要細講的重點
我們就停在這個地方
這個真實的人臉轉二次元的任務
實際上能不能做呢
實際上可以做了
右上角這邊放了一個連結
這個應該是一個韓國團隊
他們做了一個網站
你可以上傳一張圖片
它可以幫你變成二次元的人物
他們實際上用的不是Cycle GAN啦
他們用的也是GAN的技術
但是是一個進階版的東西
那我們這邊就不細講
我就把論文的連結
放在這邊給大家參考
這個網頁做得怎麼樣呢
我就實際測試了一下
這個不知道大家認不認得
這是新垣結衣
這個是你老婆這樣
你總該認得吧
把這個圖片轉成
把你老婆轉成二次元的人物
長成是這個樣子
你老婆二次元長這個樣子知道嗎
你會發現說機器確實
有學到一些二次元人物的特徵
比如說 把眼睛變大
本來眼睛其實沒有很大
變成二次元人物之後
眼睛變這麼大
但有時候也是會失敗
比如說 這個是美國前總統
轉完以後變成這個樣子
兩隻眼睛一眼大一眼小就是了
它不是總是會成功的
那同樣的技術不是只能用在影像上
也可以用在文字上
你也可以做文字風格的轉換
比如說
把一句負面的句子轉成正面的句子
當然如果你要做一個模型
輸入一個句子輸出的句子
這個模型就是要能夠
吃一個sequence 輸出一個sequence
所以它等於是一個
sequence to sequence的model
你可能就會用到
我們在作業五裡面的
Transformer的架構
來做這個文字風格轉換的問題
我們在作業五做的是翻譯嘛
輸入一個語言輸出另外一個語言嘛
現在如果要做文字風格轉換
就是輸入一個句子
輸出另外一個風格的句子
怎麼做文字的風格轉換呢
跟Cycle GAN是一模一樣的
首先你要有訓練資料
收集一大堆負面的句子
收集一大堆正面的句子
假設你要把負面的句子
轉成正面的句子
它的風格轉換問題就是
把負面的句子轉成正面的句子
收集一堆負面的句子
收集一堆正面的句子
這個其實沒有那麼難收集
你可以就是網路上爬一爬
像我們就是去PTT上爬
然後只要是推文就當作是正面的
噓文就當作是負面的
就有一大堆正面的句子
跟負面的句子
只是成對的資料沒有而已
你不知道這句推文
要怎麼轉成這句噓文
這些噓文要怎麼轉成這句推文
你沒有這種資料
但是一堆推文一堆噓文的資料
你總是可以找得到的
那接下來呢
完全套用Cycle GAN的方法
完全沒有任何不同
這邊就不需要再細講 很快講過
有一個discriminator
discriminator要看說
假設我們是要負面的句子
轉正面的句子
discriminator要看說
現在generator的輸出
像不像是真正的正面的句子
然後我們還要有另外一個generator
要有兩個generator
這個generator要學會
把正面的句子轉回原來負面的句子
你要用Cycle consistency
負面的句子轉成正面的以後
還可以轉回原來負面的句子
你可能會問說
這兩個句子 它們兩個是句子啊
怎麼算它們的相似度啊
圖片還比較好理解
圖片就是個向量啊
兩個向量的距離就是它們的相似度
那兩個句子要怎麼做呢
這個如果你有興趣
在留給你慢慢研究
那這邊還有另外一個問題就是
這個sequence to sequence model
輸出是文字
可是剛才不是有講說
如果輸出是文字
接到discriminator會有問題嗎
對 會有問題 這邊你就要用RL硬做
那做出來的結果怎麼樣呢
這個是真正的demo啦
就是真的拿PTT的推文
當正面的句子
噓文當負面的句子
那你就可以給它一個負面的句子
它就幫你轉成正面的句子
做起來像是這個樣子
你跟它說 胃疼沒睡醒各種不舒服
它就說 生日快樂 睡醒 超級舒服
或者你跟它說
我都想去上班了 真夠賤的
它就說 我都想去睡了 真帥的 這樣
所以它很厲害啊
它知道上班的相反就是去睡呀
還挺聰明的
那你跟它說
暈死了 吃燒烤 竟然遇到個變態狂
它就說
哈哈好 吃燒烤 竟然遇到帥狂
它就把變態狂變成了帥狂
它自己發明了一個詞彙
也不知道在說些什麼
但是因為這個訓練
是完全unsupervised
就是給它正面的句子跟負面的句子
在有時候會犯非常奇怪的錯誤
比如說我跟它說 我肚子痛得厲害
它就說 我生日快樂厲害 這樣
那你會發現說 機器雖然犯錯
但是錯的是有固定的規則的
你發現胃疼跟肚子痛
只要是腹部有毛病
它轉過來都是生日快樂
不知道為什麼機器覺得說
腹部有毛病的相反就是生日快樂
你可能問說這個系統有什麼用
就是沒有任何用處 沒半點用處
但是如果你覺得
你的老闆說話特別壞的話
就可以把這個系統
裝在你的耳機裡面
把所有的負面的句子
轉成正面的句子
你的人生可能就會
過得特別快樂一點
那其實像這一種文字風格轉換
還有很多其他的應用
不是只有正面句子轉負面句子
舉例來說 假設我有很多長的文章
我有另外一堆摘要
這些摘要不是這些長的文章的摘要
是不同的來源
一堆長的文章 一堆摘要
讓機器學習文字風格的轉換
你可以讓機器學會把長的文章
變成簡短的摘要
讓它學會怎麼精簡的寫作
讓它學會把長的文章變成短的句子
甚至還有更狂的
同樣的想法可以做
unsupervised的翻譯
什麼叫做unsupervised的翻譯呢
收集一堆英文的句子
收集一堆中文的句子
沒有任何成對的資料
這就跟你作業五不一樣
作業五你有成對的資料嘛
你有知道說這句英文對到這句中文
但是unsupervised翻譯就是
完全不用任何成對的資料
網路上爬一堆中文
網路上爬一堆英文
用剛才那個Cycle GAN的做法硬做
機器就可以學會把中文翻成英文了
你可以自己看一下文獻
看看說機器做得怎麼樣
到目前為止
我們說的兩種風格都還是文字
可不可以兩種風格
甚至是不同類型的資料呢
有可能做
這是我們實驗室是最早做的
我們試圖去做非督導式的語音辨識
也就是讓機器聽一堆
語音辨識是什麼
語音辨識就是
你需要收集成對的資料啊
你需要收集一大堆的聲音訊號
然後找工讀生
幫你把這些聲音訊號標註
機器才能夠學會
某個語言的語音辨識
但是要標註資料所費不貲
所以我們想要挑戰
非督導式的語音辨識
也就是機器只聽了一堆聲音
這些聲音沒有對應的文字
機器上網爬一堆文字
這些文字沒有對應的聲音
然後用Cycle GAN硬做
看看機器有沒有辦法
把聲音轉成文字
看看它的正確率
可以做到什麼樣的地步
至於正確率可以做到
什麼樣的地步呢
那我把文獻留在這邊給大家參考
那以上就是有關GAN的部分
