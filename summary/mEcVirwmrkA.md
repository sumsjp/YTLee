### 小節歸納

#### 核心主題  
- 自我監督學習（Self-Supervised Learning）及其模型介紹。  

#### 主要觀念  
1. **自我監督學習模型命名來源**：  
   - 多個自我監督學習模型以 Sesame Street 的角色命名，例如 ELMO、BERT、ERNIE 和 Big Bird。  
2. **模型規模**：  
   - 自我監督學習模型規模從早期的 ELMO（94 million parameters）到現在的更大模型，如 GPT-3（17 billion parameters）和 Switch Transformer（1.6T parameters）。  

#### 問題原因  
- 早期語言模型規模較小，無法充分捕捉語言的複雜性。  

#### 解決方法  
- 引入自我監督學習技術，通過預訓練和微調的方式提升模型性能。  

#### 優化方式  
1. **模型架構優化**：  
   - 使用 Transformer 架構來提升並行計算效率和模型能力。  
2. **SCALE（規模擴展）**：  
   - 通過增加模型參數量（如 GPT-3 和 Switch Transformer）來提升模型的表現。  

#### 結論  
- 自我監督學習模型在自然語言處理領域取得了顯著進展，未來將繼續朝更大規模和更高效架構方向發展。